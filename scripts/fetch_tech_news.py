#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import os
import requests
import time
import re
from datetime import datetime, timezone
from pathlib import Path
import logging
from dotenv import load_dotenv
from bs4 import BeautifulSoup

# Naƒç√≠st .env soubor pokud existuje (pro lok√°ln√≠ development)
load_dotenv()

# Nastaven√≠ logov√°n√≠
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Mapov√°n√≠ technologick√Ωch zdroj≈Ø na emoji
SOURCE_EMOJIS = {
    'techcrunch': 'üöÄ',
    'the-verge': '‚ö°',
    'wired': 'üîß',
    'ars-technica': 'üî¨',
    'engadget': 'üì±',
    'hacker-news': 'üíª',
    'the-next-web': 'üåê',
    'reddit-r-technology': 'üëΩ'
}

# Mapov√°n√≠ d≈Øle≈æitosti na emoji a n√°zvy
IMPORTANCE_LEVELS = {
    5: {'emoji': 'üî•', 'name': 'KRITICK√Å', 'color': '#dc2626', 'bg_color': '#fef2f2'},
    4: {'emoji': '‚ö°', 'name': 'VYSOK√Å', 'color': '#ea580c', 'bg_color': '#fff7ed'},
    3: {'emoji': 'üì¢', 'name': 'ST≈òEDN√ç', 'color': '#2563eb', 'bg_color': '#eff6ff'},
    2: {'emoji': 'üìù', 'name': 'N√çZK√Å', 'color': '#059669', 'bg_color': '#ecfdf5'},
    1: {'emoji': 'üí¨', 'name': 'INFO', 'color': '#6b7280', 'bg_color': '#f9fafb'}
}

# Kategorie technologick√Ωch zpr√°v
TECH_CATEGORIES = {
    'ai': {'emoji': 'ü§ñ', 'name': 'AI & ML', 'cs_name': 'Umƒõl√° inteligence'},
    'programming': {'emoji': 'üíª', 'name': 'Programming', 'cs_name': 'Programov√°n√≠'},
    'hardware': {'emoji': 'üñ•Ô∏è', 'name': 'Hardware', 'cs_name': 'Hardware'},
    'startups': {'emoji': 'üöÄ', 'name': 'Startups', 'cs_name': 'Startupy'},
    'security': {'emoji': 'üîí', 'name': 'Security', 'cs_name': 'Bezpeƒçnost'},
    'mobile': {'emoji': 'üì±', 'name': 'Mobile', 'cs_name': 'Mobiln√≠'},
    'web': {'emoji': 'üåê', 'name': 'Web', 'cs_name': 'Web'},
    'gaming': {'emoji': 'üéÆ', 'name': 'Gaming', 'cs_name': 'Hry'},
    'crypto': {'emoji': '‚Çø', 'name': 'Crypto', 'cs_name': 'Kryptomƒõny'},
    'science': {'emoji': 'üî¨', 'name': 'Science', 'cs_name': 'Vƒõda a v√Ωzkum'}
}

def check_environment():
    """Zkontroluje nutn√© promƒõnn√© prost≈ôed√≠"""
    news_key = os.environ.get('NEWS_API_KEY')
    openrouter_key = os.environ.get('OPENROUTER_API_KEY')

    if not news_key:
        logger.error("NEWS_API_KEY nen√≠ nastaven. Nastavte ho v GitHub Secrets.")
        raise ValueError("Chyb√≠ NEWS_API_KEY")

    if not openrouter_key:
        logger.warning("‚ö†Ô∏è OPENROUTER_API_KEY nen√≠ nastaven - ƒçl√°nky nebudou p≈ôelo≈æeny do ƒçe≈°tiny")
        openrouter_key = "skip"  # Pou≈æ√≠t p≈Øvodn√≠ texty bez p≈ôekladu

    logger.info("‚úÖ API kl√≠ƒçe jsou nastaveny")
    return news_key, openrouter_key

def detect_category(title, description):
    """Detekuje kategorii ƒçl√°nku podle kl√≠ƒçov√Ωch slov"""
    # O≈°et≈ôen√≠ None hodnot
    title = title or ""
    description = description or ""
    text = f"{title} {description}".lower()

    category_keywords = {
        'ai': [
            # Z√°kladn√≠ AI term√≠ny
            'ai', 'artificial intelligence', 'machine learning', 'ml', 'neural', 'deep learning', 'llm', 'nlp',
            # Konkr√©tn√≠ modely a firmy (podle marigold.cz obsahu)
            'gpt', 'chatgpt', 'openai', 'anthropic', 'claude', 'gemini', 'mistral', 'deepseek', 'llama', 'grok',
            # AI aplikace
            'reasoning', 'agents', 'automation', 'computer vision', 'robotics', 'humanoid'
        ],
        'programming': [
            # Jazyky a technologie
            'javascript', 'python', 'rust', 'golang', 'typescript', 'java', 'react', 'vue', 'angular',
            # V√Ωvojov√© n√°stroje (podle obsahu blogu)
            'framework', 'library', 'code', 'developer', 'programming', 'github', 'cursor', 'copilot',
            'open-source', 'api', 'software development'
        ],
        'hardware': [
            # Procesory a komponenty
            'cpu', 'gpu', 'processor', 'intel', 'amd', 'nvidia', 'chip', 'semiconductor', 'arm', 'quantum computing',
            # Automotive (siln√° kategorie na blogu)
            'automotive', 'electric vehicle', 'ev', 'tesla', 'autonomous driving', 'lidar'
        ],
        'startups': [
            # Startup ekosyst√©m
            'startup', 'funding', 'investment', 'venture', 'unicorn', 'ipo', 'acquisition', 'founder', 'entrepreneur',
            'crowdfunding', 'kickstarter', 'series a', 'series b', 'exit', 'valuation'
        ],
        'security': [
            # Bezpeƒçnost a soukrom√≠
            'security', 'hack', 'breach', 'vulnerability', 'cyber', 'password', 'encryption', 'privacy',
            'malware', 'ransomware', 'phishing', 'data protection', 'gdpr', 'surveillance'
        ],
        'mobile': [
            # Mobiln√≠ technologie (specialita blogu)
            'android', 'ios', 'iphone', 'smartphone', 'mobile', 'app store', 'google play', 'samsung', 'apple',
            # Mobiln√≠ s√≠tƒõ (ƒçast√© t√©ma)
            '5g', '4g', 'lte', 'cellular', 'carrier', 'telecom', 'spectrum', 'antenna'
        ],
        'web': [
            # Web technologie
            'web', 'browser', 'chrome', 'firefox', 'safari', 'html', 'css', 'frontend', 'backend',
            'internet', 'website', 'domain', 'hosting', 'cdn', 'apis', 'cloud'
        ],
        'gaming': [
            # Gaming a z√°bava
            'gaming', 'game', 'playstation', 'xbox', 'nintendo', 'steam', 'epic', 'esports', 'console',
            'vr', 'ar', 'metaverse', 'virtual reality', 'augmented reality'
        ],
        'crypto': [
            # Kryptomƒõny a blockchain
            'crypto', 'bitcoin', 'ethereum', 'blockchain', 'nft', 'defi', 'web3', 'mining', 'wallet',
            'stablecoin', 'altcoin', 'dao', 'smart contract'
        ],
        'science': [
            # Vƒõda a v√Ωzkum
            'quantum', 'space', 'nasa', 'research', 'discovery', 'experiment', 'study', 'scientific', 'physics',
            'spacex', 'satellite', 'mars', 'climate', 'energy', 'renewable', 'nuclear'
        ]
    }

    for category, keywords in category_keywords.items():
        if any(keyword in text for keyword in keywords):
            return category

    return 'web'  # Default kategorie

def detect_importance(title, description, category):
    """Detekuje d≈Øle≈æitost ƒçl√°nku na ≈°k√°le 1-5"""
    # O≈°et≈ôen√≠ None hodnot
    title = title or ""
    description = description or ""
    text = f"{title} {description}".lower()

    # Kritick√° d≈Øle≈æitost (5) - pr≈Ølomy, velk√© akvizice, bezpeƒçnostn√≠ incidenty
    critical_keywords = [
        # Z√°sadn√≠ ud√°losti
        'breakthrough', 'major', 'massive', 'revolutionary', 'groundbreaking', 'historic',
        'billion', 'acquisition', 'merger', 'ipo', 'goes public', 'bankrupt', 'shutdown', 'discontinued',
        # Bezpeƒçnostn√≠ incidenty
        'hack', 'data breach', 'vulnerability', 'cyber attack', 'ransomware attack',
        # AI pr≈Ølomy (podle obsahu blogu)
        'quantum computing', 'artificial general intelligence', 'agi', 'superintelligence',
        'reasoning breakthrough', 'autonomous', 'humanoid robot'
    ]

    # Vysok√° d≈Øle≈æitost (4) - v√Ωznamn√© novinky
    high_keywords = [
        # Nov√© produkty a verze
        'new', 'first', 'latest', 'update', 'release', 'version', 'launches', 'announces', 'reveals',
        # Byznys
        'investment', 'funding', 'partnership', 'deal', 'series a', 'series b', 'unicorn',
        # Kl√≠ƒçov√© firmy (podle ƒçetnosti na blogu)
        'apple', 'google', 'microsoft', 'meta', 'tesla', 'nvidia', 'amazon', 'spacex',
        'openai', 'anthropic', 'deepseek', 'mistral', 'claude', 'gemini'
    ]

    # N√≠zk√° d≈Øle≈æitost (2) - spekulace, germy
    low_keywords = [
        'rumors', 'speculation', 'might', 'could', 'reportedly',
        'allegedly', 'sources say', 'leak', 'hint', 'suggests',
        'beta', 'preview', 'concept'
    ]

    # Poƒçet kritick√Ωch kl√≠ƒçov√Ωch slov
    critical_count = sum(1 for keyword in critical_keywords if keyword in text)
    high_count = sum(1 for keyword in high_keywords if keyword in text)
    low_count = sum(1 for keyword in low_keywords if keyword in text)

    # Kategorie-specifick√© v√°hy (podle anal√Ωzy marigold.cz kategori√≠)
    category_weights = {
        'ai': 1.4,          # AI (234 ƒçl√°nk≈Ø) - nejpopul√°rnƒõj≈°√≠ t√©ma, vysok√° v√°ha
        'security': 1.3,    # Bezpeƒçnost (17 ƒçl√°nk≈Ø) - kritick√© pro tech
        'startups': 1.2,    # Startupy (36 ƒçl√°nk≈Ø) - d≈Øle≈æit√© pro ekosyst√©m
        'mobile': 1.1,      # Mobiln√≠ (44+39+20 ƒçl√°nk≈Ø) - specialita autora
        'hardware': 1.1,    # Hardware/Automotive (109 ƒçl√°nk≈Ø) - tech focus
        'programming': 1.0, # Programov√°n√≠ (7 ƒçl√°nk≈Ø) - st≈ôedn√≠ v√°ha
        'web': 1.0,         # Web/Internet (112 ƒçl√°nk≈Ø) - z√°kladn√≠ tech
        'science': 1.2,     # Vƒõda/v√Ωzkum - d≈Øle≈æit√© objevy
        'crypto': 0.8,      # Kryptomƒõny (m√©nƒõ obsahu na blogu)
        'gaming': 0.7       # Gaming (nejm√©nƒõ relevantn√≠ pro Marigold)
    }

    # Z√°kladn√≠ sk√≥re
    if critical_count >= 2:
        base_score = 5
    elif critical_count >= 1:
        base_score = 4
    elif high_count >= 2:
        base_score = 4
    elif high_count >= 1:
        base_score = 3
    elif low_count >= 1:
        base_score = 2
    else:
        base_score = 3  # St≈ôedn√≠ d≈Øle≈æitost

    # Aplikovat kategorijn√≠ v√°hu
    weighted_score = base_score * category_weights.get(category, 1.0)

    # Zaokrouhlit a omezit na rozsah 1-5
    final_score = max(1, min(5, round(weighted_score)))

    return final_score

def fetch_og_image(article_url, timeout=5):
    """St√°hne Open Graph obr√°zek ze str√°nky ƒçl√°nku"""
    try:
        response = requests.get(article_url, timeout=timeout, headers={
            'User-Agent': 'Mozilla/5.0 (Marigold.cz Tech News Bot)'
        })

        if response.ok:
            soup = BeautifulSoup(response.text, 'html.parser')

            # Open Graph image
            og_image = soup.find('meta', property='og:image')
            if og_image:
                return og_image.get('content')

            # Twitter card image
            twitter_image = soup.find('meta', attrs={'name': 'twitter:image'})
            if twitter_image:
                return twitter_image.get('content')

            # Schema.org image
            schema_image = soup.find('meta', attrs={'itemprop': 'image'})
            if schema_image:
                return schema_image.get('content')

    except Exception as e:
        logger.debug(f"Nelze z√≠skat OG image z {article_url}: {e}")

    return None

def translate_with_openrouter(text, api_key, max_retries=3):
    """P≈ôelo≈æ√≠ text pomoc√≠ OpenRouter API"""
    if not text or not text.strip():
        logger.warning("Pr√°zdn√Ω text pro p≈ôeklad")
        return text

    # Pokud nen√≠ API kl√≠ƒç nebo je test kl√≠ƒç, vr√°tit p≈Øvodn√≠ text
    if not api_key or api_key == "test-key" or api_key == "skip":
        logger.info("‚ö†Ô∏è OpenRouter p≈ôeklad p≈ôeskoƒçen - pou≈æit origin√°ln√≠ text")
        return text

    logger.info(f"üîÑ P≈ôekl√°d√°m: {text[:50]}...")

    for attempt in range(max_retries):
        try:
            # Rate limiting
            if attempt > 0:
                time.sleep(2 ** attempt)  # Exponential backoff

            prompt = f"""P≈ôelo≈æ n√°sleduj√≠c√≠ anglick√Ω text do ƒçe≈°tiny. Zachovej technick√© term√≠ny, kter√© jsou v ƒçe≈°tinƒõ bƒõ≈ænƒõ pou≈æ√≠van√© v origin√°le (nap≈ô. AI, API, framework, startup). Odpovƒõz pouze p≈ôelo≈æen√Ωm textem, bez koment√°≈ô≈Ø.

Text: "{text}"

P≈ôeklad:"""

            response = requests.post('https://openrouter.ai/api/v1/chat/completions',
                headers={
                    'Authorization': f'Bearer {api_key}',
                    'Content-Type': 'application/json',
                    'HTTP-Referer': 'https://www.marigold.cz',
                    'X-Title': 'Marigold Tech News Translation'
                },
                json={
                    'model': 'deepseek/deepseek-chat-v3.1:free',
                    'messages': [{'role': 'user', 'content': prompt}],
                    'max_tokens': 200,
                    'temperature': 0.3
                },
                timeout=30
            )

            logger.info(f"OpenRouter response: {response.status_code}")

            if response.status_code == 429:  # Rate limit
                logger.warning(f"Rate limit, pokus {attempt + 1}/{max_retries}")
                if attempt < max_retries - 1:
                    time.sleep(10)  # ƒåekat 10 sekund
                    continue

            if not response.ok:
                error_text = response.text
                logger.error(f"OpenRouter API chyba {response.status_code}: {error_text}")
                raise requests.RequestException(f"API chyba {response.status_code}: {error_text}")

            data = response.json()
            translated = data.get('choices', [{}])[0].get('message', {}).get('content', '').strip()

            if not translated:
                logger.error(f"Pr√°zdn√° odpovƒõƒè z OpenRouter: {data}")
                raise ValueError("OpenRouter nevr√°til p≈ôeklad")

            # Odstranit uvozovky
            translated = re.sub(r'^["\'"]|["\'"]$', '', translated)

            logger.info(f"‚úÖ P≈ôeklad √∫spƒõ≈°n√Ω: {translated[:50]}...")
            return translated

        except Exception as e:
            logger.error(f"Pokus {attempt + 1} selhal: {e}")
            if attempt == max_retries - 1:
                logger.error(f"V≈°echny pokusy selhaly pro text: {text[:50]}...")
                raise

    return text  # Fallback - toto by se nikdy nemƒõlo st√°t

def fetch_tech_news(api_key):
    """Z√≠sk√° technologick√© zpr√°vy z NewsAPI pomoc√≠ category=technology"""

    logger.info("üîÑ Stahuji zpr√°vy z kategorie technology")

    try:
        response = requests.get('https://newsapi.org/v2/top-headlines',
            params={
                'category': 'technology',
                'pageSize': 30,
                'apiKey': api_key
            },
            timeout=30
        )

        logger.info(f"NewsAPI response: {response.status_code}")

        if not response.ok:
            error_text = response.text
            logger.error(f"NewsAPI chyba {response.status_code}: {error_text}")
            raise requests.RequestException(f"NewsAPI chyba {response.status_code}: {error_text}")

        data = response.json()

        if data.get('status') != 'ok':
            logger.error(f"NewsAPI ne√∫spƒõ≈°n√Ω status: {data}")
            raise ValueError(f"NewsAPI chyba: {data.get('message', 'Nezn√°m√° chyba')}")

        articles = data.get('articles', [])
        logger.info(f"‚úÖ Naƒçteno {len(articles)} ƒçl√°nk≈Ø z kategorie technology")

        return articles

    except Exception as e:
        logger.error(f"Stahov√°n√≠ technologick√Ωch zpr√°v selhalo: {e}")
        raise

def create_markdown_file(article, category_info, source_emoji, importance_info, output_dir, article_index):
    """Vytvo≈ô√≠ Markdown soubor pro ƒçl√°nek"""

    # Vytvo≈ô slug z titulku
    slug = re.sub(r'[^\w\s-]', '', article['czech_title'].lower())
    slug = re.sub(r'[-\s]+', '-', slug).strip('-')
    slug = slug[:50]  # Omezit d√©lku

    # Datum pro filename
    pub_date = datetime.fromisoformat(article['published_at'].replace('Z', '+00:00'))
    date_str = pub_date.strftime('%Y-%m-%d')

    filename = f"{date_str}-{article_index:02d}-{slug}.md"
    filepath = output_dir / filename

    # Front matter podle tech_news_article layoutu
    front_matter = {
        'layout': 'tech_news_article',
        'title': article['czech_title'],
        'original_title': article['title'],
        'description': article['czech_description'],
        'publishedAt': article['published_at'],
        'date': pub_date.strftime('%Y-%m-%d %H:%M:%S'),
        'url': article['url'],
        'urlToImage': article.get('url_to_image'),
        'category': category_info['name'].lower(),
        'importance': article['importance'],
        'source': {
            'name': article['source']['name'],
            'id': article['source'].get('id', ''),
            'emoji': source_emoji
        }
    }

    # Vytvo≈ôit obsah
    content = f"""---
{chr(10).join(f"{key}: {json.dumps(value, ensure_ascii=False) if isinstance(value, (str, list, dict)) else value}" for key, value in front_matter.items())}
---

{article['czech_description']}

[P≈ôeƒç√≠st cel√Ω ƒçl√°nek na {article['source']['name']}]({article['url']})
"""

    # Zapsat soubor
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(content)

    logger.info(f"‚úÖ Vytvo≈ôen: {filename}")

def main():
    """Hlavn√≠ funkce"""
    try:
        logger.info("üöÄ Spou≈°t√≠ se Tech News Fetcher")

        # Kontrola prost≈ôed√≠
        news_api_key, openrouter_api_key = check_environment()

        # Vytvo≈ôit v√Ωstupn√≠ adres√°≈ô
        output_dir = Path('_tech_news')
        output_dir.mkdir(exist_ok=True)

        # Vyƒçistit star√Ω obsah
        for old_file in output_dir.glob('*.md'):
            old_file.unlink()
        logger.info("üßπ Vyƒçi≈°tƒõn star√Ω obsah")

        # St√°hnout zpr√°vy
        articles = fetch_tech_news(news_api_key)

        if not articles:
            logger.error("‚ùå ≈Ω√°dn√© ƒçl√°nky nenalezeny")
            return

        logger.info(f"üîÑ Zpracov√°v√°m {len(articles)} ƒçl√°nk≈Ø...")

        processed_count = 0

        for i, article in enumerate(articles[:20], 1):  # Omezit na 20
            try:
                # P≈ôeskoƒçit ƒçl√°nky bez obsahu
                if not article.get('title') or article['title'] == '[Removed]':
                    logger.warning(f"P≈ôeskakuji ƒçl√°nek {i} - chyb√≠ titulek")
                    continue

                logger.info(f"üì∞ Zpracov√°v√°m ƒçl√°nek {i}/20: {article['title'][:50]}...")

                # Detekce kategorie
                category_key = detect_category(article['title'], article.get('description', ''))
                category_info = TECH_CATEGORIES[category_key]

                # Detekce d≈Øle≈æitosti
                importance_level = detect_importance(article['title'], article.get('description', ''), category_key)
                importance_info = IMPORTANCE_LEVELS[importance_level]

                logger.info(f"üéØ D≈Øle≈æitost: {importance_info['emoji']} {importance_info['name']} ({importance_level}/5)")

                # Emoji pro zdroj
                source_id = article.get('source', {}).get('id', '').lower()
                source_emoji = SOURCE_EMOJIS.get(source_id, 'üí°')

                # P≈ôeklad
                czech_title = translate_with_openrouter(article['title'], openrouter_api_key)
                czech_description = ''

                # Ovƒõ≈ôen√≠ a p≈ôeklad description
                description = article.get('description')
                if description and description != '[Removed]':
                    czech_description = translate_with_openrouter(description, openrouter_api_key)
                else:
                    # Pou≈æ√≠t content jako n√°hradn√≠ description
                    content = article.get('content', '')
                    if content and content != '[Removed]':
                        # Zkr√°tit content na prvn√≠ vƒõtu
                        short_content = content.split('.')[0] + '.' if '.' in content else content[:200]
                        czech_description = translate_with_openrouter(short_content, openrouter_api_key)
                    else:
                        czech_description = ''

                # Z√≠skat obr√°zek - nejd≈ô√≠ve z NewsAPI, pak OG jako fallback
                image_url = article.get('urlToImage')
                if not image_url and article['url']:
                    logger.info(f"üñºÔ∏è Z√≠sk√°v√°m OG obr√°zek z {article['url'][:50]}...")
                    image_url = fetch_og_image(article['url'])

                # P≈ô√≠prava ƒçl√°nku
                processed_article = {
                    'title': article['title'] or 'Bez n√°zvu',
                    'czech_title': czech_title or article['title'] or 'Bez n√°zvu',
                    'description': description or '',
                    'czech_description': czech_description or description or '',
                    'url': article['url'],
                    'source': article['source'],
                    'published_at': article['publishedAt'],
                    'url_to_image': image_url,
                    'importance': importance_level
                }

                # Vytvo≈ôen√≠ Markdown souboru
                create_markdown_file(processed_article, category_info, source_emoji, importance_info, output_dir, processed_count + 1)
                processed_count += 1

                # Rate limiting mezi ƒçl√°nky
                time.sleep(1)

            except Exception as e:
                logger.error(f"‚ùå Chyba p≈ôi zpracov√°n√≠ ƒçl√°nku {i}: {e}")
                continue

        logger.info(f"‚úÖ √öspƒõ≈°nƒõ zpracov√°no {processed_count} ƒçl√°nk≈Ø")

        # Vytvo≈ô√≠ index soubor
        index_content = f"""---
layout: tech_news_index
title: Technologick√© zpravodajstv√≠
description: Nejnovƒõj≈°√≠ zpr√°vy ze svƒõta technologi√≠ p≈ôelo≈æen√© do ƒçe≈°tiny
permalink: /tech-news/
---

Automaticky aktualizovan√© technologick√© zpr√°vy ze svƒõtov√Ωch zdroj≈Ø jako TechCrunch, The Verge, Wired a dal≈°√≠ch.

Posledn√≠ aktualizace: {datetime.now(timezone.utc).strftime('%d.%m.%Y %H:%M UTC')}
"""

        with open(output_dir / 'index.md', 'w', encoding='utf-8') as f:
            f.write(index_content)

        logger.info("‚úÖ Tech News Fetcher √∫spƒõ≈°nƒõ dokonƒçen")

    except Exception as e:
        logger.error(f"üí• Kritick√° chyba: {e}")
        raise

if __name__ == "__main__":
    main()