#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import yaml
import json
import os
import re
import requests
from datetime import datetime, timezone
from pathlib import Path
import logging
from dotenv import load_dotenv

# Naƒç√≠st .env soubor
load_dotenv()

# Nastaven√≠ logov√°n√≠
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class NewsAPITechNewsGenerator:
    """Gener√°tor tech-news z NewsAPI s p≈ôeklady a detekc√≠"""

    def __init__(self):
        self.output_dir = Path('_tech_news')
        self.output_dir.mkdir(exist_ok=True)
        self.news_api_key = os.getenv('NEWS_API_KEY', '')
        self.openrouter_api_key = os.getenv('OPENROUTER_API_KEY', '')
        self.translation_enabled = self.openrouter_api_key and self.openrouter_api_key != 'skip'

    def fetch_newsapi_articles(self):
        """St√°hne ƒçl√°nky z NewsAPI"""
        if not self.news_api_key:
            logger.error("‚ùå NEWS_API_KEY nen√≠ nastaven!")
            return []

        url = "https://newsapi.org/v2/top-headlines"
        params = {
            'category': 'technology',
            'apiKey': self.news_api_key,
            'pageSize': 40,  # Max 40 ƒçl√°nk≈Ø
            'language': 'en'
        }

        try:
            logger.info("üì° Stahuji ƒçl√°nky z NewsAPI...")
            response = requests.get(url, params=params, timeout=30)

            if response.status_code == 200:
                data = response.json()
                if data['status'] == 'ok':
                    articles = data.get('articles', [])
                    logger.info(f"‚úÖ Sta≈æeno {len(articles)} ƒçl√°nk≈Ø z NewsAPI")

                    # Vyƒçistit a p≈ôipravit ƒçl√°nky
                    processed_articles = []
                    for article in articles:
                        # P≈ôeskoƒçit ƒçl√°nky bez podstatn√Ωch dat
                        if not article.get('title') or article['title'] == '[Removed]':
                            continue
                        if not article.get('url'):
                            continue

                        # P≈ôipravit zdroj
                        source_info = {
                            'id': article['source'].get('id', 'unknown'),
                            'name': article['source'].get('name', 'Unknown'),
                            'emoji': self.get_source_emoji(article['source'].get('name', ''))
                        }

                        processed_article = {
                            'title': article['title'],
                            'description': article.get('description', ''),
                            'url': article['url'],
                            'urlToImage': article.get('urlToImage'),
                            'publishedAt': article['publishedAt'],
                            'source': source_info,
                            'content': article.get('content', '')
                        }

                        processed_articles.append(processed_article)

                    return processed_articles
                else:
                    logger.error(f"‚ùå NewsAPI error: {data.get('message', 'Unknown')}")
            else:
                logger.error(f"‚ùå HTTP {response.status_code}: {response.text}")

        except Exception as e:
            logger.error(f"‚ùå Chyba p≈ôi stahov√°n√≠ z NewsAPI: {e}")

        return []

    def get_source_emoji(self, source_name):
        """Vr√°t√≠ emoji pro zdroj"""
        emoji_map = {
            'TechCrunch': 'üöÄ',
            'The Verge': '‚ö°',
            'Wired': 'üîß',
            'Ars Technica': 'üî¨',
            'MIT Technology Review': 'üéì',
            'OpenAI': 'ü§ñ',
            'Associated Press': 'üì∞',
            'Bloomberg': 'üíπ',
            'Forbes': 'üíº',
            'Axios': 'üì°',
            'CBS News': 'üì∫',
            'The Wall Street Journal': 'üìà',
        }

        for name, emoji in emoji_map.items():
            if name.lower() in source_name.lower():
                return emoji

        return 'üì∞'  # Default

    def create_jekyll_article(self, article, article_index):
        """Vytvo≈ô√≠ Jekyll ƒçl√°nek s optimalizovan√Ωm front matter"""

        # Vytvo≈ôit slug z titulku
        slug = self.create_slug(article['title'])

        # Datum pro filename - p≈ôev√©st na UTC
        pub_date_str = article['publishedAt']
        if pub_date_str.endswith('Z'):
            pub_date = datetime.fromisoformat(pub_date_str.replace('Z', '+00:00'))
        elif '+' in pub_date_str or pub_date_str.endswith('00:00'):
            pub_date = datetime.fromisoformat(pub_date_str)
        else:
            pub_date = datetime.fromisoformat(pub_date_str).replace(tzinfo=timezone.utc)

        # Zajistit UTC
        if pub_date.tzinfo is None:
            pub_date = pub_date.replace(tzinfo=timezone.utc)
        else:
            pub_date = pub_date.astimezone(timezone.utc)

        date_str = pub_date.strftime('%Y-%m-%d')

        filename = f"{date_str}-{slug}.md"
        filepath = self.output_dir / filename

        # P≈ôev√©st na ƒçesk√Ω titulek a popis
        czech_title = self.translate_title(article['title'])
        czech_description = self.translate_description(article.get('description', ''))

        # Detekce kategorie, d≈Øle≈æitosti, firem a osobnost√≠
        category = self.detect_category(article['title'], article.get('description', ''))
        importance = self.detect_importance(article['title'], article.get('description', ''), category)
        companies = self.detect_companies(article['title'], article.get('description', ''))
        people = self.detect_people(article['title'], article.get('description', ''))

        # Front matter podle tech_news_article layoutu
        front_matter = {
            'layout': 'tech_news_article',
            'title': czech_title,
            'original_title': article['title'],
            'slug': slug,
            'description': czech_description,
            'publishedAt': pub_date.isoformat(),
            'date': pub_date.strftime('%Y-%m-%d %H:%M:%S'),
            'url': article['url'],
            'category': category,
            'importance': importance,
            'source': article['source']
        }

        # P≈ôidat firmy a osobnosti pouze pokud existuj√≠
        if companies:
            front_matter['companies'] = companies
        if people:
            front_matter['people'] = people

        # P≈ôidat urlToImage pouze pokud existuje
        if article.get('urlToImage'):
            front_matter['urlToImage'] = article['urlToImage']

        # Vytvo≈ôit obsah
        content = f"""---
{yaml.dump(front_matter, default_flow_style=False, allow_unicode=True)}---

{czech_description}

[ƒå√≠st p≈Øvodn√≠ ƒçl√°nek]({article['url']})

**Zdroj:** {article['source']['emoji']} {article['source']['name']}
"""

        # Zapsat soubor
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)

        logger.info(f"‚úÖ Vytvo≈ôen: {filename}")
        return filepath

    def create_slug(self, title):
        """Vytvo≈ô√≠ URL-friendly slug z titulku"""
        slug = re.sub(r'[^\w\s-]', '', title.lower())
        slug = re.sub(r'[-\s]+', '-', slug).strip('-')

        # Pokud slug zaƒç√≠n√° ƒç√≠slic√≠, p≈ôidat prefix "A-"
        if slug and slug[0].isdigit():
            slug = 'A-' + slug

        # Pokud je slug pr√°zdn√Ω, pou≈æ√≠t fallback
        if not slug:
            slug = 'article'

        return slug[:50]  # Omezit d√©lku

    def translate_text(self, text, text_type="text"):
        """P≈ôelo≈æ√≠ text pomoc√≠ OpenRouter API"""
        if not self.translation_enabled or not text or text.strip() == '':
            return text

        try:
            # R≈Øzn√© syst√©mov√© prompty podle typu textu
            system_prompts = {
                "title": "P≈ôekl√°dej technologick√© nadpisy ƒçl√°nk≈Ø z angliƒçtiny do ƒçe≈°tiny. Zachovej technick√© term√≠ny v angliƒçtinƒõ, pokud jsou bƒõ≈ænƒõ pou≈æ√≠van√©. Odpovƒõz POUZE p≈ôelo≈æen√Ωm nadpisem, bez jak√Ωchkoli dodateƒçn√Ωch text≈Ø jako 'Nadpis ƒçl√°nku v ƒçe≈°tinƒõ:' nebo uvozovek.",
                "description": "P≈ôekl√°dej perex/popis technologick√Ωch ƒçl√°nk≈Ø z angliƒçtiny do ƒçe≈°tiny. Zachovej technick√© term√≠ny v angliƒçtinƒõ, pokud jsou bƒõ≈ænƒõ pou≈æ√≠van√©. Odpovƒõz POUZE p≈ôelo≈æen√Ωm textem, bez jak√Ωchkoli dodateƒçn√Ωch koment√°≈ô≈Ø nebo uvozovek."
            }

            system_prompt = system_prompts.get(text_type, system_prompts["description"])

            headers = {
                'Authorization': f'Bearer {self.openrouter_api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': 'anthropic/claude-3-haiku',
                'messages': [
                    {'role': 'system', 'content': system_prompt},
                    {'role': 'user', 'content': text}
                ],
                'max_tokens': 200 if text_type == "title" else 500,
                'temperature': 0.3
            }

            response = requests.post(
                'https://openrouter.ai/api/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('choices') and len(result['choices']) > 0:
                    translated = result['choices'][0]['message']['content'].strip()
                    translated = translated.strip('"\'')
                    logger.debug(f"P≈ôeklad {text_type}: {text[:30]}... ‚Üí {translated[:30]}...")
                    return translated

            logger.warning(f"P≈ôeklad selhal (HTTP {response.status_code}), pou≈æ√≠v√°m origin√°l")

        except Exception as e:
            logger.warning(f"Chyba p≈ôekladu: {e}, pou≈æ√≠v√°m origin√°l")

        return text

    def translate_title(self, title):
        """P≈ôelo≈æ√≠ titulek"""
        return self.translate_text(title, "title")

    def translate_description(self, description):
        """P≈ôelo≈æ√≠ popis"""
        return self.translate_text(description or '', "description")

    def detect_category(self, title, description):
        """Detekuje kategorii ƒçl√°nku pomoc√≠ LLM"""
        if not self.translation_enabled:
            return 'tech'

        try:
            prompt = f"""P≈ôi≈ôaƒè tomuto technologick√©mu ƒçl√°nku jednu p≈ôesnou kategorii (1-2 slova v ƒçe≈°tinƒõ).

Nadpis: {title}
Popis: {description or 'Nen√≠ k dispozici'}

Kategorie by mƒõla b√Ωt:
- Struƒçn√° (1-2 slova)
- V ƒçe≈°tinƒõ
- Specifick√° pro obsah ƒçl√°nku
- Bez emoji

P≈ô√≠klady kategori√≠: AI, hardware, startupy, programov√°n√≠, mobiln√≠ aplikace, kybernetika, kosmonautika, elektromobilita, hern√≠ pr≈Ømysl, kryptomƒõny, j√≠dlo, zdrav√≠ atd.

Odpovƒõz POUZE n√°zvem kategorie, nic jin√©ho."""

            headers = {
                'Authorization': f'Bearer {self.openrouter_api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': 'anthropic/claude-3-haiku',
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 20,
                'temperature': 0.1
            }

            response = requests.post(
                'https://openrouter.ai/api/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('choices') and len(result['choices']) > 0:
                    category = result['choices'][0]['message']['content'].strip()
                    category = category.lower().strip('"\'.,!?')
                    if len(category) > 20:
                        category = category[:20]

                    logger.debug(f"LLM kategorie: {title[:30]}... ‚Üí {category}")
                    return category

            logger.warning(f"LLM kategorie selhala, pou≈æ√≠v√°m fallback")

        except Exception as e:
            logger.warning(f"Chyba LLM kategorie: {e}")

        return 'tech'

    def detect_companies(self, title, description):
        """Detekuje v√Ωznamn√© firmy zm√≠nƒõn√© v ƒçl√°nku pomoc√≠ LLM"""
        if not self.translation_enabled:
            return []

        try:
            prompt = f"""Identifikuj v≈°echny v√Ωznamn√© technologick√© firmy zm√≠nƒõn√© v tomto ƒçl√°nku.

Nadpis: {title}
Popis: {description or 'Nen√≠ k dispozici'}

Zamƒõ≈ô se na:
- Technologick√© firmy (Apple, Google, Microsoft, Tesla, SpaceX, OpenAI, atd.)
- Startupy a scale-upy
- V√Ωznamn√© instituce (NASA, MIT, atd.)

Ignoruj:
- Obecn√© term√≠ny
- Produkty nebo slu≈æby (m√≠sto firem)
- Nez√°va≈æn√© zm√≠nky

Odpovƒõz POUZE seznam n√°zv≈Ø firem oddƒõlen√Ωch ƒç√°rkami, nic jin√©ho.
Pokud nejsou ≈æ√°dn√© v√Ωznamn√© firmy, odpovƒõz "≈æ√°dn√©"."""

            headers = {
                'Authorization': f'Bearer {self.openrouter_api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': 'anthropic/claude-3-haiku',
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 100,
                'temperature': 0.1
            }

            response = requests.post(
                'https://openrouter.ai/api/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('choices') and len(result['choices']) > 0:
                    companies_text = result['choices'][0]['message']['content'].strip()

                    if companies_text.lower() in ['≈æ√°dn√©', 'zadne', 'none', '']:
                        return []

                    companies = [
                        company.strip().strip('"\'.,!?')
                        for company in companies_text.split(',')
                        if company.strip() and len(company.strip()) > 1
                    ]

                    logger.debug(f"LLM firmy: {title[:30]}... ‚Üí {companies}")
                    return companies[:5]

        except Exception as e:
            logger.warning(f"Chyba LLM firem: {e}")

        return []

    def detect_people(self, title, description):
        """Detekuje v√Ωznamn√© osobnosti zm√≠nƒõn√© v ƒçl√°nku pomoc√≠ LLM"""
        if not self.translation_enabled:
            return []

        try:
            prompt = f"""Identifikuj v≈°echny v√Ωznamn√© osobnosti zm√≠nƒõn√© v tomto ƒçl√°nku.

Nadpis: {title}
Popis: {description or 'Nen√≠ k dispozici'}

Zamƒõ≈ô se na:
- CEO a zakladatele tech firem (Elon Musk, Tim Cook, Satya Nadella, atd.)
- V√Ωznamn√© investory a podnikatele
- Vƒõdce a v√Ωzkumn√≠ky
- Politiky souvisej√≠c√≠ s technologiemi

Ignoruj:
- Obecn√© role bez jmen
- Fiktivn√≠ postavy
- Nez√°va≈æn√© zm√≠nky

Odpovƒõz POUZE seznam jmen oddƒõlen√Ωch ƒç√°rkami, nic jin√©ho.
Pokud nejsou ≈æ√°dn√© v√Ωznamn√© osobnosti, odpovƒõz "≈æ√°dn√©"."""

            headers = {
                'Authorization': f'Bearer {self.openrouter_api_key}',
                'Content-Type': 'application/json'
            }

            data = {
                'model': 'anthropic/claude-3-haiku',
                'messages': [
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 100,
                'temperature': 0.1
            }

            response = requests.post(
                'https://openrouter.ai/api/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=10
            )

            if response.status_code == 200:
                result = response.json()
                if result.get('choices') and len(result['choices']) > 0:
                    people_text = result['choices'][0]['message']['content'].strip()

                    if people_text.lower() in ['≈æ√°dn√©', 'zadne', 'none', '']:
                        return []

                    people = [
                        person.strip().strip('"\'.,!?')
                        for person in people_text.split(',')
                        if person.strip() and len(person.strip()) > 2
                    ]

                    logger.debug(f"LLM osobnosti: {title[:30]}... ‚Üí {people}")
                    return people[:3]

        except Exception as e:
            logger.warning(f"Chyba LLM osobnost√≠: {e}")

        return []

    def detect_importance(self, title, description, category):
        """Detekuje d≈Øle≈æitost ƒçl√°nku"""
        text = f"{title} {description}".lower()

        # Vysok√° d≈Øle≈æitost
        if any(word in text for word in ['breakthrough', 'major', 'billion', 'acquisition', 'merge']):
            return 5

        # St≈ôedn√≠-vysok√° d≈Øle≈æitost
        if any(word in text for word in ['new', 'launches', 'announces', 'first', 'partnership']):
            return 4

        # N√≠zk√° d≈Øle≈æitost
        if any(word in text for word in ['rumors', 'might', 'reportedly', 'could']):
            return 2

        return 3  # Default

    def clean_duplicates(self, new_articles):
        """Sma≈æe pouze ƒçl√°nky s duplicitn√≠m slug, zachov√° archiv"""
        if not new_articles:
            logger.info("üßπ ≈Ω√°dn√© nov√© ƒçl√°nky - p≈ôeskakuji ƒçi≈°tƒõn√≠ duplicit≈Ø")
            return

        # Z√≠skat slugy nov√Ωch ƒçl√°nk≈Ø
        new_slugs = set()
        for article in new_articles:
            slug = self.create_slug(article.get('title', ''))
            new_slugs.add(slug)

        logger.info(f"üßπ Kontroluji duplicity pro {len(new_slugs)} nov√Ωch ƒçl√°nk≈Ø...")

        removed_count = 0
        for old_file in self.output_dir.glob('*.md'):
            if old_file.name == 'index.md':
                continue

            try:
                # Extrahovat slug ze jm√©na souboru
                # Form√°t: YYYY-MM-DD-slug.md
                file_parts = old_file.stem.split('-', 3)
                if len(file_parts) >= 4:
                    file_slug = file_parts[3]

                    if file_slug in new_slugs:
                        logger.debug(f"üóëÔ∏è Ma≈æu duplicitn√≠ ƒçl√°nek: {old_file.name}")
                        old_file.unlink()
                        removed_count += 1
                    else:
                        logger.debug(f"‚úÖ Zachov√°v√°m archivn√≠ ƒçl√°nek: {old_file.name}")

            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Probl√©m p≈ôi kontrole souboru {old_file.name}: {e}")

        if removed_count > 0:
            logger.info(f"üßπ Smaz√°no {removed_count} duplicitn√≠ch ƒçl√°nk≈Ø, archiv zachov√°n")
        else:
            logger.info("üßπ ≈Ω√°dn√© duplicity nenalezeny")

    def generate_tech_news(self):
        """Hlavn√≠ funkce pro generov√°n√≠ tech-news z NewsAPI"""
        logger.info("üöÄ Spou≈°t√≠ se generov√°n√≠ tech-news z NewsAPI")

        # Z√≠skat ƒçl√°nky z NewsAPI
        articles = self.fetch_newsapi_articles()

        if not articles:
            logger.error("‚ùå ≈Ω√°dn√© ƒçl√°nky nenalezeny z NewsAPI")
            return False

        logger.info(f"üì∞ Zpracov√°v√°m {len(articles)} ƒçl√°nk≈Ø...")

        # Chytr√© smaz√°n√≠ duplicit≈Ø
        self.clean_duplicates(articles)

        processed_count = 0

        for i, article in enumerate(articles, 1):
            try:
                # P≈ôeskoƒçit ƒçl√°nky bez obsahu
                if not article.get('title'):
                    logger.warning(f"‚è≠Ô∏è P≈ôeskakuji ƒçl√°nek {i} - chyb√≠ titulek")
                    continue

                logger.info(f"üìù Zpracov√°v√°m ƒçl√°nek {i}: {article['title'][:50]}...")

                # Kontrola obr√°zku
                if article.get('urlToImage'):
                    logger.info(f"üñºÔ∏è Obr√°zek nalezen: {article['urlToImage'][:50]}...")
                else:
                    logger.warning("üñºÔ∏è Obr√°zek chyb√≠")

                # Vytvo≈ôen√≠ Jekyll souboru
                self.create_jekyll_article(article, processed_count + 1)
                processed_count += 1

            except Exception as e:
                logger.error(f"‚ùå Chyba p≈ôi zpracov√°n√≠ ƒçl√°nku {i}: {e}")
                continue

        logger.info(f"‚úÖ √öspƒõ≈°nƒõ zpracov√°no {processed_count} ƒçl√°nk≈Ø")

        # Vytvo≈ôen√≠ index str√°nky
        self.create_index_page(processed_count)

        return True

    def create_index_page(self, article_count):
        """Vytvo≈ô√≠ index str√°nku tech-news"""
        index_content = f"""---
layout: tech_news_index
title: Technologick√© zpr√°vy
permalink: /tech-news/
description: Nejnovƒõj≈°√≠ zpr√°vy ze svƒõta technologi√≠ z NewsAPI s p≈ôeklady do ƒçe≈°tiny
---

# Technologick√© zpr√°vy

Automaticky aktualizovan√© zpr√°vy ze svƒõta technologi√≠ z NewsAPI, p≈ôelo≈æen√© do ƒçe≈°tiny.

**Celkem ƒçl√°nk≈Ø:** {article_count}
**Posledn√≠ aktualizace:** {datetime.now(timezone.utc).strftime('%d.%m.%Y %H:%M UTC')}

## Zdroje

ƒål√°nky jsou z√≠sk√°v√°ny z NewsAPI Technology kategorie, vƒçetnƒõ zdroj≈Ø jako:
- üì∞ **Associated Press** - zpravodajstv√≠
- üöÄ **TechCrunch** - startupy a technologie
- üíπ **Bloomberg** - business a finance
- üíº **Forbes** - podnik√°n√≠ a investice
- üì° **Axios** - technologie a politika
- ü§ñ **OpenAI** - AI pr≈Ølomy
"""

        index_path = self.output_dir / 'index.md'
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(index_content)

        logger.info("‚úÖ Index str√°nka vytvo≈ôena")

    def generate_daily_pages(self):
        """Generuje str√°nky pro ka≈æd√Ω den s ƒçl√°nky"""
        from collections import defaultdict

        # Cesty
        pages_dir = Path('tech-news')

        # Naƒç√≠st v≈°echny ƒçl√°nky a seskupit podle data
        articles_by_date = defaultdict(list)

        for article_file in self.output_dir.glob('*.md'):
            with open(article_file, 'r', encoding='utf-8') as f:
                content = f.read()

            # Extrahovat front matter
            if content.startswith('---'):
                parts = content.split('---', 2)
                if len(parts) >= 3:
                    try:
                        front_matter = yaml.safe_load(parts[1])

                        # Z√≠skat datum
                        date_str = None
                        if 'publishedAt' in front_matter:
                            date_obj = datetime.fromisoformat(front_matter['publishedAt'].replace('Z', '+00:00'))
                            date_str = date_obj.strftime('%Y-%m-%d')
                        elif 'date' in front_matter:
                            if isinstance(front_matter['date'], str):
                                date_obj = datetime.fromisoformat(front_matter['date'].split(' ')[0])
                            else:
                                date_obj = front_matter['date']
                            date_str = date_obj.strftime('%Y-%m-%d')

                        if date_str:
                            articles_by_date[date_str].append(article_file.name)

                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Chyba p≈ôi zpracov√°n√≠ {article_file.name}: {e}")

        # Vytvo≈ôit str√°nku pro ka≈æd√Ω den
        for date_str, articles in articles_by_date.items():
            # Vytvo≈ôit adres√°≈ô pro tento den
            day_dir = pages_dir / date_str
            day_dir.mkdir(parents=True, exist_ok=True)

            # Vytvo≈ôit index.md pro tento den
            index_file = day_dir / 'index.md'

            # Front matter pro denn√≠ str√°nku
            front_matter = {
                'layout': 'tech_news_day',
                'title': f'Technologick√© zpr√°vy - {date_str}',
                'date': date_str,
                'permalink': f'/tech-news/{date_str}/'
            }

            # Vytvo≈ôit obsah str√°nky
            content = f"""---
{yaml.dump(front_matter, default_flow_style=False, allow_unicode=True)}---

<!-- Tato str√°nka automaticky zobrazuje ƒçl√°nky z kolekce _tech_news pro datum {date_str} -->
"""

            # Zapsat soubor
            with open(index_file, 'w', encoding='utf-8') as f:
                f.write(content)

            logger.debug(f"üìÖ Vytvo≈ôena denn√≠ str√°nka pro {date_str}")

def main():
    """Hlavn√≠ funkce"""
    generator = NewsAPITechNewsGenerator()

    # Kontrola API kl√≠ƒç≈Ø
    if not generator.news_api_key:
        logger.error("‚ùå NEWS_API_KEY nen√≠ nastaven v .env souboru!")
        return 1

    logger.info(f"üìä NewsAPI generator p≈ôipraven")
    if generator.translation_enabled:
        logger.info("‚úÖ P≈ôeklady povoleny (OpenRouter API)")
    else:
        logger.info("‚ö†Ô∏è P≈ôeklady zak√°z√°ny (chyb√≠ OPENROUTER_API_KEY)")

    # Generovat tech-news
    success = generator.generate_tech_news()

    if success:
        # Generovat denn√≠ archivn√≠ str√°nky
        generator.generate_daily_pages()
        logger.info("üéâ Generov√°n√≠ tech-news z NewsAPI dokonƒçeno")
    else:
        logger.error("üí• Generov√°n√≠ tech-news z NewsAPI selhalo")
        return 1

    return 0

if __name__ == "__main__":
    exit(main())