#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bulk sta≈æen√≠ a zpracov√°n√≠ LLM model≈Ø z OpenRouter API za rok 2024.

Jednor√°zov√Ω skript pro lok√°ln√≠ pou≈æit√≠ - st√°hne modely od vybran√Ωch
provider≈Ø a vytvo≈ô√≠ Jekyll posty v _llm/ adres√°≈ôi.

POZOR: OpenRouter API obsahuje simulovan√° data s budouc√≠mi timestampy.
Tento skript filtruje pouze re√°lnƒõ existuj√≠c√≠ modely.

Funkce:
- Filtruje jen modely s re√°ln√Ωm timestampem (ne budouc√≠)
- Deduplikuje verze model≈Ø (gpt-4o-2024-11-20 vs gpt-4o)
- Ignoruje varianty :free, :extended, :exacto (jsou to aliasy)
- Vyb√≠r√° nejnovƒõj≈°√≠ verzi z ka≈æd√© skupiny model≈Ø

Pou≈æit√≠:
    python scripts/bulk_fetch_llm_2025.py --dry-run          # N√°hled bez zpracov√°n√≠
    python scripts/bulk_fetch_llm_2025.py --limit 10         # Zpracovat max 10 model≈Ø
    python scripts/bulk_fetch_llm_2025.py --no-analyze       # Bez LLM anal√Ωzy
    python scripts/bulk_fetch_llm_2025.py --year 2024        # Modely za rok 2024
    python scripts/bulk_fetch_llm_2025.py                    # Pln√© zpracov√°n√≠

Podporovan√≠ provide≈ôi:
    - anthropic (Claude)
    - google (Gemini)
    - openai (GPT)
    - deepseek (DeepSeek)
    - mistralai (Mistral)
    - meta-llama (Llama)
    - x-ai (Grok)
"""

import json
import os
import re
import sys
import argparse
import requests
import time
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict

# Naƒç√≠st .env soubor pokud existuje
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# Import benchmark fetcheru
try:
    from fetch_llm_benchmarks import BenchmarkFetcher
    BENCHMARKS_AVAILABLE = True
except ImportError:
    try:
        # Zkusit import z aktu√°ln√≠ho adres√°≈ôe
        sys.path.insert(0, str(Path(__file__).parent))
        from fetch_llm_benchmarks import BenchmarkFetcher
        BENCHMARKS_AVAILABLE = True
    except ImportError:
        BENCHMARKS_AVAILABLE = False


class BulkLLMFetcher:
    """Bulk fetcher pro LLM modely z OpenRouter."""

    API_URL = "https://openrouter.ai/api/v1/models"
    CHAT_API_URL = "https://openrouter.ai/api/v1/chat/completions"

    # V√Ωstupn√≠ adres√°≈ô pro Jekyll posty
    OUTPUT_DIR = Path(__file__).parent.parent / "_llm"

    # Backup adres√°≈ô pro JSON data
    BACKUP_DIR = Path(__file__).parent.parent / "_data" / "llm_backup"

    # ƒåasov√© konstanty
    # Re√°ln√Ω aktu√°ln√≠ ƒças - dynamicky z time.time()
    # (d≈ô√≠ve byl statick√Ω, co≈æ zp≈Øsobovalo odfiltrov√°n√≠ nov√Ωch model≈Ø)
    REAL_NOW_TIMESTAMP = int(time.time())

    # Timestampy pro zaƒç√°tky rok≈Ø
    YEAR_STARTS = {
        2023: 1672531200,  # 1.1.2023
        2024: 1704067200,  # 1.1.2024
        2025: 1735689600,  # 1.1.2025
        2026: 1767225600,  # 1.1.2026
    }

    # V√Ωchoz√≠ rok pro filtraci
    DEFAULT_YEAR = 2025

    # C√≠lov√≠ provide≈ôi
    TARGET_PROVIDERS = [
        'anthropic',
        'google',
        'openai',
        'deepseek',
        'mistralai',
        'meta-llama',
        'x-ai'
    ]

    # V≈°ichni hlavn√≠ provide≈ôi pro srovn√°n√≠ v anal√Ωze
    COMPETITOR_PROVIDERS = ['anthropic', 'google', 'openai', 'x-ai', 'mistralai', 'deepseek']

    # Model pro anal√Ωzu
    ANALYZER_MODEL = "google/gemini-2.0-flash-001"

    # Pauza mezi API vol√°n√≠mi (sekundy)
    API_DELAY = 2

    # Suffixes kter√© ignorujeme (jsou to aliasy/varianty)
    IGNORED_SUFFIXES = [':free', ':extended', ':exacto']

    # Master Prompt v4.0 (Ultimate Edition) - podle dokumentu LLM-testy.pdf
    ANALYSIS_PROMPT_TEMPLATE = """Jsi expertn√≠ AI analytik. Tv√Ωm √∫kolem je vytvo≈ôit detailn√≠ "kreditn√≠ sk√≥re" pro LLM model na z√°kladƒõ vstupn√≠ch dat. Mus√≠≈° vyv√°≈æit technickou kvalitu, cenu, rychlost a pou≈æitelnost v praxi.

=== VSTUPN√ç DATA ===

MODEL:
- N√°zev: {model_name}
- ID: {model_id}
- Cena: ${prompt_price}/1M vstup, ${completion_price}/1M v√Ωstup
- Blend cena: ${blend_price}/1M
- Kontext: {context_length} token≈Ø
- Max v√Ωstup: {max_completion} token≈Ø
- Modality: {input_modalities} ‚Üí {output_modalities}

BENCHMARK SK√ìRE:
{benchmark_section}

KATEGORIE (p≈ôedpoƒç√≠tan√©):
{categories_section}

POPIS MODELU:
{description}

KONKURENƒåN√ç MODELY:
{competitor_models}

=== ANALYTICK√Å LOGIKA ===

KROK 1: 360¬∞ Kategorizace
Za≈ôaƒè model do jedn√© nebo v√≠ce kategori√≠:
- Program√°tor (LiveCodeBench, SWE-bench)
- Vƒõdec (AIME, GPQA)
- Kreativec/Lokalizace (MMMLU - ƒçe≈°tina, tv≈Ørƒç√≠ psan√≠)
- Agent/Data (Tau-Bench, ZeroBench)
- Speedster (Vysok√© TPS, n√≠zk√© TTFT)

KROK 2: Anal√Ωza benchmark≈Ø
Vyu≈æij poskytnut√° data pro p≈ôesn√© hodnocen√≠. Porovnej s pr≈Ømƒõry kategorie a konkurenc√≠.

KROK 3: V√Ωpoƒçet "Real-World Value"
Value Score = (Logic Core + Agent Core) / (Blend cena * 10)
Interpretace: Kolik "inteligence" dostanu za 1 dolar.

KROK 4: V√Ωstup
Vra≈• POUZE validn√≠ JSON v n√°sleduj√≠c√≠m form√°tu:

{{
  "profile": {{
    "developer": "N√°zev spoleƒçnosti",
    "architecture": "Popis architektury (Transformer, MoE, poƒçet parametr≈Ø)",
    "parameters": "Poƒçet parametr≈Ø nebo null",
    "focus": ["prim√°rn√≠ zamƒõ≈ôen√≠ 1", "prim√°rn√≠ zamƒõ≈ôen√≠ 2"],
    "model_category": "Program√°tor/Vƒõdec/Kreativec/Agent/Speedster"
  }},

  "radar": {{
    "logic_code": {logic_score},
    "agentic": {agentic_score},
    "languages": {languages_score},
    "safety": {safety_score},
    "speed": "{speed_tier}"
  }},

  "economy": {{
    "blend_price": {blend_price},
    "value_score": 0.0,
    "context_sufficient_for_rag": true
  }},

  "characteristics": "1-3 vƒõty o tom, co dƒõl√° tento model technicky unik√°tn√≠m. Vyu≈æij benchmark data.",

  "strengths": [
    {{"area": "Kr√°tk√Ω n√°zev oblasti", "description": "Specifick√° s√≠la s fakty/benchmarky"}}
  ],

  "weaknesses": [
    {{"area": "Kr√°tk√Ω n√°zev oblasti", "description": "Specifick√° slabina"}}
  ],

  "competitors": [
    {{
      "provider": "N√°zev poskytovatele",
      "model": "Konkr√©tn√≠ model ze seznamu konkurent≈Ø",
      "model_id": "model/id ze seznamu",
      "price_comparison": "Jak se li≈°√≠ ceny (nap≈ô. '2x levnƒõj≈°√≠ vstup, podobn√Ω v√Ωstup')",
      "comparison": "Proƒç konkuruje, co je lep≈°√≠/hor≈°√≠"
    }}
  ],

  "recommendation": {{
    "target_users": ["C√≠lov√° skupina 1", "C√≠lov√° skupina 2"],
    "use_cases": ["Dobr√Ω use case 1", "Dobr√Ω use case 2"],
    "avoid_for": ["Kdy NEPOU≈Ω√çVAT 1", "Kdy NEPOU≈Ω√çVAT 2"]
  }},

  "expert_verdict": {{
    "killer_feature": "To jedno, v ƒçem je model nejlep≈°√≠",
    "hidden_risk": "Skryt√© riziko (nap≈ô. 'Pomal√° inference kv≈Øli CoT', 'Slab√° ƒçe≈°tina')",
    "recommended_use_case": "Konkr√©tn√≠ doporuƒçen√Ω sc√©n√°≈ô pou≈æit√≠"
  }},

  "verdict": "1-2 vƒõty shrnut√≠ - kdo by mƒõl tento model pou≈æ√≠vat a proƒç"
}}

=== PRAVIDLA ===
- Vra≈• POUZE JSON, ≈æ√°dn√Ω markdown/text
- V≈°echny hodnoty ƒçesky
- Min 2 siln√© str√°nky, 2 slabiny, 4 konkurenti
- Vyber konkurenty z POSKYTNUT√âHO SEZNAMU
- Buƒè objektivn√≠, bez superlativ≈Ø ("revoluƒçn√≠", "neuvƒõ≈ôiteln√Ω")
- Zamƒõ≈ô se na mƒõ≈ôiteln√© rozd√≠ly
- Vyu≈æij benchmark data pro konkr√©tn√≠ argumentaci
- Pokud benchmark chyb√≠, neodhaduj - uveƒè "data nejsou k dispozici"
- Polo≈æ d≈Øraz na MMMLU pro hodnocen√≠ ƒçe≈°tiny (kritick√© pro lok√°ln√≠ nasazen√≠)"""

    # Prompt pro p≈ôeklad popisu
    TRANSLATE_PROMPT = """P≈ôelo≈æ n√°sleduj√≠c√≠ anglick√Ω text do ƒçe≈°tiny. Zachovej technickou terminologii.
Vra≈• POUZE p≈ôelo≈æen√Ω text, nic jin√©ho.

Text k p≈ôekladu:
{text}"""

    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.api_key = os.getenv('OPENROUTER_API_KEY', '')
        self.models_data = None
        self.processed_count = 0
        self.error_count = 0

        # Inicializace benchmark fetcheru
        self.benchmark_fetcher = None
        self.benchmark_data = None
        if BENCHMARKS_AVAILABLE:
            self.benchmark_fetcher = BenchmarkFetcher(verbose=verbose)
            try:
                self.benchmark_data = self.benchmark_fetcher.fetch_and_process()
                self.log("üìä Benchmark data naƒçtena")
            except Exception as e:
                self.log(f"‚ö†Ô∏è Benchmark data nejsou dostupn√°: {e}")

    def log(self, message: str):
        """Vyp√≠≈°e zpr√°vu pokud je verbose mode."""
        if self.verbose:
            print(message)

    def fetch_models(self) -> list:
        """St√°hne seznam v≈°ech model≈Ø z OpenRouter API."""
        headers = {}
        if self.api_key:
            headers['Authorization'] = f'Bearer {self.api_key}'

        self.log("üì° Stahuji seznam model≈Ø z OpenRouter API...")
        response = requests.get(self.API_URL, headers=headers, timeout=30)
        response.raise_for_status()

        data = response.json()
        self.models_data = data.get('data', [])
        self.log(f"   Nalezeno {len(self.models_data)} model≈Ø celkem")
        return self.models_data

    def extract_base_model(self, model_id: str) -> str:
        """
        Extrahuje z√°kladn√≠ n√°zev modelu bez verze a suffix≈Ø.

        P≈ô√≠klady:
        - openai/gpt-4o-2024-11-20 -> openai/gpt-4o
        - anthropic/claude-3-opus-20240229 -> anthropic/claude-3-opus
        - mistralai/mistral-large-2411 -> mistralai/mistral-large
        - meta-llama/llama-3.2-3b-instruct:free -> meta-llama/llama-3.2-3b-instruct
        """
        # Odstra≈à suffixes jako :free, :extended, :exacto
        base = re.sub(r':[a-z]+$', '', model_id)

        provider = base.split('/')[0] if '/' in base else ''
        name = base.split('/')[-1] if '/' in base else base

        # Odstra≈à date-based verze (YYYY-MM-DD nebo YYYYMMDD nebo -YYMM)
        name = re.sub(r'-20\d{2}-\d{2}-\d{2}$', '', name)  # -2024-11-20
        name = re.sub(r'-20\d{6}$', '', name)              # -20240229
        name = re.sub(r'-\d{4}$', '', name)                # -2411, -2501

        return f'{provider}/{name}' if provider else name

    def is_ignored_variant(self, model_id: str) -> bool:
        """Zkontroluje, zda je model ignorovan√° varianta (:free, :extended, atd.)."""
        for suffix in self.IGNORED_SUFFIXES:
            if model_id.endswith(suffix):
                return True
        return False

    def filter_models(self, providers: list = None, year: int = None) -> list:
        """
        Filtruje modely podle provider≈Ø a roku s deduplikac√≠ verz√≠.

        Args:
            providers: Seznam provider≈Ø k filtraci
            year: Rok pro filtraci (default: 2024)

        Returns:
            Seznam unik√°tn√≠ch model≈Ø (nejnovƒõj≈°√≠ verze z ka≈æd√© skupiny)
        """
        if not self.models_data:
            self.fetch_models()

        providers = providers or self.TARGET_PROVIDERS
        year = year or self.DEFAULT_YEAR

        year_start = self.YEAR_STARTS.get(year, self.YEAR_STARTS[2024])
        year_end = self.YEAR_STARTS.get(year + 1, self.REAL_NOW_TIMESTAMP)

        # Omezit na re√°ln√Ω ƒças (ne budouc√≠ data)
        max_timestamp = min(year_end, self.REAL_NOW_TIMESTAMP)

        self.log(f"   Filtruji modely za rok {year}")
        self.log(f"   ƒåasov√© rozmez√≠: {datetime.fromtimestamp(year_start)} - {datetime.fromtimestamp(max_timestamp)}")

        # Prvn√≠ pr≈Øchod: z√°kladn√≠ filtrace
        candidates = []
        for model in self.models_data:
            model_id = model.get('id', '')
            created = model.get('created', 0)

            # Filtr: re√°ln√Ω timestamp (ne budouc√≠)
            if created > self.REAL_NOW_TIMESTAMP:
                continue

            # Filtr: rok
            if created < year_start or created >= max_timestamp:
                continue

            # Filtr: provider
            provider = model_id.split('/')[0] if '/' in model_id else ''
            if provider not in providers:
                continue

            # Filtr: ignorovan√© varianty (:free, :extended)
            if self.is_ignored_variant(model_id):
                continue

            candidates.append(model)

        self.log(f"   Kandid√°t≈Ø po z√°kladn√≠ filtraci: {len(candidates)}")

        # Druh√Ω pr≈Øchod: deduplikace verz√≠ - vybrat nejnovƒõj≈°√≠ z ka≈æd√© skupiny
        from collections import defaultdict
        model_groups = defaultdict(list)

        for model in candidates:
            base = self.extract_base_model(model['id'])
            model_groups[base].append(model)

        # Vybrat nejnovƒõj≈°√≠ verzi z ka≈æd√© skupiny
        filtered = []
        for base, models in model_groups.items():
            # Se≈ôadit podle created timestamp (nejnovƒõj≈°√≠ prvn√≠)
            models.sort(key=lambda x: x.get('created', 0), reverse=True)
            newest = models[0]

            # Pokud je v√≠ce verz√≠, logovat
            if len(models) > 1:
                self.log(f"   Deduplikace {base}: vybr√°no {newest['id']} z {len(models)} verz√≠")

            filtered.append(newest)

        # Se≈ôadit podle data vytvo≈ôen√≠ (nejstar≈°√≠ prvn√≠)
        filtered.sort(key=lambda x: x.get('created', 0))

        self.log(f"   V√Ωsledek: {len(filtered)} unik√°tn√≠ch model≈Ø za rok {year} od {len(providers)} provider≈Ø")
        return filtered

    def get_competitor_models_text(self, exclude_id: str = None) -> str:
        """P≈ôiprav√≠ textov√Ω p≈ôehled konkurenƒçn√≠ch model≈Ø pro prompt."""
        if not self.models_data:
            self.fetch_models()

        lines = []

        for provider in self.COMPETITOR_PROVIDERS:
            provider_models = [
                m for m in self.models_data
                if m['id'].startswith(provider + '/') and m['id'] != exclude_id
            ]

            if not provider_models:
                continue

            provider_models.sort(key=lambda x: x.get('created', 0), reverse=True)

            lines.append(f"\n{provider.upper()}:")
            for m in provider_models[:3]:
                pricing = m.get('pricing', {})
                prompt_price = float(pricing.get('prompt', 0)) * 1_000_000
                compl_price = float(pricing.get('completion', 0)) * 1_000_000
                ctx = m.get('context_length', 0)
                lines.append(
                    f"  - {m['id']}: ${prompt_price:.2f}/${compl_price:.2f} per 1M, "
                    f"context {ctx:,} tokens"
                )

        return '\n'.join(lines)

    def get_benchmark_data(self, model_id: str) -> Optional[Dict]:
        """Z√≠sk√° benchmark data pro model z cache."""
        if not self.benchmark_data:
            return None

        models = self.benchmark_data.get('models', {})

        # P≈ô√≠m√Ω lookup
        if model_id in models:
            return models[model_id]

        # Zkusit normalizovan√© varianty
        normalized = model_id.lower()
        for key in models:
            if key.lower() == normalized:
                return models[key]

        # Zkusit verzi bez suffixu za dvojteƒçkou (:thinking, :beta, :free atd.)
        if ':' in model_id:
            base_without_suffix = model_id.rsplit(':', 1)[0]
            if base_without_suffix in models:
                return models[base_without_suffix]
            # Zkusit i lowercase
            for key in models:
                if key.lower() == base_without_suffix.lower():
                    return models[key]

        # Zkusit ƒç√°steƒçnou shodu (base model bez verze)
        base = self.extract_base_model(model_id)
        for key in models:
            if self.extract_base_model(key) == base:
                return models[key]

        return None

    def format_benchmark_section(self, benchmark_data: Dict) -> str:
        """Form√°tuje benchmark sekci pro LLM prompt."""
        if not benchmark_data:
            return "Benchmark data nejsou k dispozici pro tento model."

        benchmarks = benchmark_data.get('benchmarks', {})
        if not benchmarks:
            return "Benchmark data nejsou k dispozici pro tento model."

        lines = []

        # Benchmark hodnoty
        benchmark_names = {
            'aime_2025': 'AIME 2025 (matematika)',
            'gpqa_diamond': 'GPQA Diamond (vƒõda)',
            'math_500': 'MATH-500 (matematika)',
            'swe_bench_verified': 'SWE-bench Verified (k√≥d)',
            'livecodebench': 'LiveCodeBench (k√≥d)',
            'aider_polyglot': 'Aider Polyglot (k√≥d)',
            'tau2_bench': 'œÑ2-Bench (agenti)',
            'terminal_bench': 'Terminal-Bench (CLI)',
            'osworld': 'OSWorld (desktop)',
            'mmlu_pro': 'MMLU Pro (znalosti)',
            'hle': 'HLE (hard logic)',
            'arc_agi_2': 'ARC-AGI-2 (abstrakce)',
            'zerobench': 'ZeroBench (extrakce)',
            'ocrbench': 'OCRBench (OCR)',
            'ruler_niah': 'RULER NIAH (retrieval)',
            'mmmu': 'MMMU (multimodal)',
            'video_mmmu': 'Video-MMMU',
            'mathvista': 'MathVista',
            'truthfulqa': 'TruthfulQA (pravdivost)',
            'safetybench': 'SafetyBench (bezpeƒçnost)',
            'mmmlu': 'MMMLU (multilingv√°ln√≠)',
            'mgsm': 'MGSM (multilingv√°ln√≠ mat.)',
            'intelligence_index': 'AI Intelligence Index',
        }

        for key, value in benchmarks.items():
            if value is not None:
                name = benchmark_names.get(key, key)
                lines.append(f"- {name}: {value:.1f}%")

        # Performance metriky
        performance = benchmark_data.get('performance', {})
        if performance.get('tps'):
            lines.append(f"- TPS (tokens/s): {performance['tps']:.1f}")
        if performance.get('ttft_seconds'):
            lines.append(f"- TTFT (latence): {performance['ttft_seconds']:.3f}s")

        return '\n'.join(lines) if lines else "Benchmark data nejsou k dispozici."

    def format_categories_section(self, benchmark_data: Dict) -> str:
        """Form√°tuje kategorii sekci pro LLM prompt."""
        if not benchmark_data:
            return "Kategorie nejsou k dispozici."

        categories = benchmark_data.get('categories', {})
        if not categories:
            return "Kategorie nejsou k dispozici."

        lines = []
        for cat_key, cat_data in categories.items():
            icon = cat_data.get('icon', '')
            name = cat_data.get('name', cat_key)
            score = cat_data.get('score')
            tier = cat_data.get('tier', 'N/A')

            if score is not None:
                lines.append(f"{icon} {name}: {score:.1f}/100 ({tier})")
            else:
                lines.append(f"{icon} {name}: Nedostupn√©")

        # Celkov√© hodnocen√≠
        summary = benchmark_data.get('summary', {})
        if summary.get('overall_score'):
            lines.append(f"\nüìä CELKOV√â SK√ìRE: {summary['overall_score']:.1f}/100 ({summary.get('overall_tier', 'N/A')})")

        return '\n'.join(lines)

    def get_radar_values(self, benchmark_data: Dict) -> Dict:
        """Extrahuje hodnoty pro radar chart z benchmark dat."""
        default_values = {
            'logic_score': 0,
            'agentic_score': 0,
            'languages_score': 0,
            'safety_score': 0,
            'speed_tier': 'Nehodnoceno'
        }

        if not benchmark_data:
            return default_values

        categories = benchmark_data.get('categories', {})

        # Logic = pr≈Ømƒõr science + coding
        science_score = categories.get('science', {}).get('score') or 0
        coding_score = categories.get('coding', {}).get('score') or 0
        logic_score = (science_score + coding_score) / 2 if (science_score or coding_score) else 0

        return {
            'logic_score': round(logic_score, 1),
            'agentic_score': categories.get('agentic', {}).get('score') or 0,
            'languages_score': categories.get('languages', {}).get('score') or 0,
            'safety_score': categories.get('safety', {}).get('score') or 0,
            'speed_tier': categories.get('speed', {}).get('tier') or 'Nehodnoceno'
        }

    def translate_text(self, text: str) -> str:
        """P≈ôelo≈æ√≠ text do ƒçe≈°tiny pomoc√≠ LLM."""
        if not self.api_key:
            return text

        if not text or len(text.strip()) < 10:
            return text

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'https://marigold.cz',
            'X-Title': 'LLM Bulk Fetcher'
        }

        data = {
            'model': 'google/gemini-2.0-flash-001',
            'messages': [
                {'role': 'user', 'content': self.TRANSLATE_PROMPT.format(text=text[:2000])}
            ],
            'max_tokens': 2000,
            'temperature': 0.1
        }

        try:
            response = requests.post(
                self.CHAT_API_URL,
                headers=headers,
                json=data,
                timeout=60
            )
            response.raise_for_status()

            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                return result['choices'][0]['message']['content'].strip()
        except Exception as e:
            self.log(f"   ‚ö†Ô∏è P≈ôeklad selhal: {e}")

        return text

    def analyze_model(self, model: dict) -> dict:
        """Analyzuje model pomoc√≠ LLM s integrovan√Ωmi benchmark daty."""
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY nen√≠ nastaven")

        context_length = model.get('context_length') or model.get('top_provider', {}).get('context_length') or 'N/A'
        max_completion = model.get('top_provider', {}).get('max_completion_tokens') or 'N/A'

        pricing = model.get('pricing', {})
        prompt_price = float(pricing.get('prompt', 0)) * 1_000_000
        completion_price = float(pricing.get('completion', 0)) * 1_000_000
        # Blend cena = (3 * prompt + 1 * completion) / 4 - typick√Ω pomƒõr
        blend_price = (prompt_price * 3 + completion_price) / 4

        architecture = model.get('architecture', {})
        input_modalities = ', '.join(architecture.get('input_modalities', ['text']))
        output_modalities = ', '.join(architecture.get('output_modalities', ['text']))

        competitor_models = self.get_competitor_models_text(exclude_id=model['id'])

        # Z√≠skat benchmark data
        benchmark_data = self.get_benchmark_data(model['id'])
        benchmark_section = self.format_benchmark_section(benchmark_data)
        categories_section = self.format_categories_section(benchmark_data)
        radar_values = self.get_radar_values(benchmark_data)

        if benchmark_data:
            self.log(f"   üìä Benchmark data nalezena pro {model['id']}")
        else:
            self.log(f"   ‚ö†Ô∏è Benchmark data nenalezena pro {model['id']}")

        prompt = self.ANALYSIS_PROMPT_TEMPLATE.format(
            model_name=model.get('name', model['id']),
            model_id=model['id'],
            context_length=f"{context_length:,}" if isinstance(context_length, int) else context_length,
            max_completion=f"{max_completion:,}" if isinstance(max_completion, int) else max_completion,
            input_modalities=input_modalities,
            output_modalities=output_modalities,
            prompt_price=f"{prompt_price:.2f}",
            completion_price=f"{completion_price:.2f}",
            blend_price=f"{blend_price:.2f}",
            description=model.get('description', 'Popis nen√≠ k dispozici.')[:1000],
            competitor_models=competitor_models,
            benchmark_section=benchmark_section,
            categories_section=categories_section,
            logic_score=radar_values['logic_score'],
            agentic_score=radar_values['agentic_score'],
            languages_score=radar_values['languages_score'],
            safety_score=radar_values['safety_score'],
            speed_tier=radar_values['speed_tier']
        )

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'https://marigold.cz',
            'X-Title': 'LLM Model Analyzer'
        }

        data = {
            'model': self.ANALYZER_MODEL,
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'max_tokens': 4000,
            'temperature': 0.2,
            'response_format': {'type': 'json_object'}
        }

        self.log(f"   ü§ñ Analyzuji pomoc√≠ {self.ANALYZER_MODEL}...")

        response = requests.post(
            self.CHAT_API_URL,
            headers=headers,
            json=data,
            timeout=120
        )
        response.raise_for_status()

        result = response.json()

        if 'choices' in result and len(result['choices']) > 0:
            raw_response = result['choices'][0]['message']['content']

            usage = result.get('usage', {})
            self.log(f"   Tokeny: {usage.get('prompt_tokens', 'N/A')} / {usage.get('completion_tokens', 'N/A')}")

            try:
                clean_response = raw_response.strip()
                if clean_response.startswith('```'):
                    clean_response = clean_response.split('\n', 1)[1]
                    clean_response = clean_response.rsplit('```', 1)[0]

                analysis = json.loads(clean_response)
                self.log("   ‚úÖ JSON √∫spƒõ≈°nƒõ rozparsov√°n")
                return analysis
            except json.JSONDecodeError as e:
                self.log(f"   ‚ö†Ô∏è Chyba parsov√°n√≠ JSON: {e}")
                return {'_raw_text': raw_response, '_parse_error': str(e)}
        else:
            raise ValueError("Neplatn√° odpovƒõƒè z API")

    def create_slug(self, model_id: str) -> str:
        """Vytvo≈ô√≠ URL-friendly slug z model ID."""
        slug = model_id.replace('/', '-')
        slug = re.sub(r'[^a-zA-Z0-9\-]', '-', slug)
        slug = re.sub(r'-+', '-', slug)
        slug = slug.strip('-')
        return slug.lower()

    def _dict_to_yaml(self, d: dict, indent: int = 0) -> str:
        """Jednoduch√Ω p≈ôevod dict na YAML string."""
        lines = []
        prefix = '  ' * indent

        for key, value in d.items():
            if value is None:
                lines.append(f"{prefix}{key}: null")
            elif isinstance(value, bool):
                lines.append(f"{prefix}{key}: {str(value).lower()}")
            elif isinstance(value, (int, float)):
                lines.append(f"{prefix}{key}: {value}")
            elif isinstance(value, str):
                if '\n' in value or ':' in value or '"' in value or value.startswith('['):
                    escaped = value.replace('"', '\\"').replace('\n', '\\n')
                    lines.append(f'{prefix}{key}: "{escaped}"')
                else:
                    lines.append(f"{prefix}{key}: {value}")
            elif isinstance(value, list):
                if not value:
                    lines.append(f"{prefix}{key}: []")
                elif all(isinstance(v, str) for v in value):
                    lines.append(f"{prefix}{key}:")
                    for item in value:
                        lines.append(f"{prefix}  - {item}")
                else:
                    lines.append(f"{prefix}{key}:")
                    for item in value:
                        if isinstance(item, dict):
                            first = True
                            for k, v in item.items():
                                if first:
                                    if isinstance(v, str) and (':' in v or '"' in v):
                                        lines.append(f'{prefix}  - {k}: "{v}"')
                                    else:
                                        lines.append(f"{prefix}  - {k}: {v}")
                                    first = False
                                else:
                                    if isinstance(v, str) and (':' in v or '"' in v):
                                        lines.append(f'{prefix}    {k}: "{v}"')
                                    else:
                                        lines.append(f"{prefix}    {k}: {v}")
                        else:
                            lines.append(f"{prefix}  - {item}")
            elif isinstance(value, dict):
                lines.append(f"{prefix}{key}:")
                lines.append(self._dict_to_yaml(value, indent + 1).rstrip())
            else:
                lines.append(f"{prefix}{key}: {value}")

        return '\n'.join(lines) + '\n'

    def generate_jekyll_post(self, model: dict, analysis: dict = None) -> Path:
        """Vygeneruje Jekyll post pro model s benchmark daty."""
        self.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

        created_ts = model.get('created', 0)
        created_date = datetime.fromtimestamp(created_ts)
        date_str = created_date.strftime('%Y-%m-%d')
        slug = self.create_slug(model['id'])

        filename = f"{date_str}-{slug}.md"
        file_path = self.OUTPUT_DIR / filename

        # Extrakce dat
        pricing = model.get('pricing', {})
        prompt_price = float(pricing.get('prompt', 0)) * 1_000_000
        completion_price = float(pricing.get('completion', 0)) * 1_000_000
        blend_price = (prompt_price * 3 + completion_price) / 4

        architecture = model.get('architecture', {})
        context_length = model.get('context_length') or model.get('top_provider', {}).get('context_length') or 0
        max_output = model.get('top_provider', {}).get('max_completion_tokens') or 0

        # Provider z model ID
        provider = model['id'].split('/')[0].title()
        provider_map = {
            'X-Ai': 'xAI',
            'Meta-Llama': 'Meta',
            'Mistralai': 'Mistral',
            'Deepseek': 'DeepSeek'
        }
        provider = provider_map.get(provider, provider)

        # P≈ôeklad popisu
        description = model.get('description', '')
        self.log("   üìù P≈ôekl√°d√°m popis...")
        description_cs = self.translate_text(description) if description else ''

        # Z√≠skat benchmark data
        benchmark_data = self.get_benchmark_data(model['id'])

        # P≈ô√≠prava dat z anal√Ωzy
        if analysis and '_raw_text' not in analysis:
            profile = analysis.get('profile', {})
            focus = profile.get('focus', [])
            strengths = analysis.get('strengths', [])
            weaknesses = analysis.get('weaknesses', [])
            competitors = analysis.get('competitors', [])
            recommendation = analysis.get('recommendation', {})
            verdict = analysis.get('verdict', '')
            characteristics = analysis.get('characteristics', '')
            radar = analysis.get('radar', {})
            expert_verdict = analysis.get('expert_verdict', {})
        else:
            focus = []
            strengths = []
            weaknesses = []
            competitors = []
            recommendation = {}
            verdict = ''
            characteristics = ''
            radar = {}
            expert_verdict = {}

        # P≈ôipravit kategorie z benchmark dat
        categories_data = {}
        overall_score = None
        overall_tier = None

        if benchmark_data:
            categories = benchmark_data.get('categories', {})
            for cat_key, cat_data in categories.items():
                if cat_data.get('score') is not None:
                    categories_data[cat_key] = {
                        'name': cat_data.get('name'),
                        'icon': cat_data.get('icon'),
                        'score': cat_data.get('score'),
                        'tier': cat_data.get('tier')
                    }
            summary = benchmark_data.get('summary', {})
            overall_score = summary.get('overall_score')
            overall_tier = summary.get('overall_tier')

        # Front matter
        front_matter = {
            'layout': 'llm_review',
            'title': model.get('name', model['id']),
            'date': created_date.strftime('%Y-%m-%d %H:%M:%S'),
            'model_id': model['id'],
            'slug': slug,
            'provider': provider,
            'pricing': {
                'prompt_per_m': round(prompt_price, 4),
                'completion_per_m': round(completion_price, 4),
                'blend_per_m': round(blend_price, 4)
            },
            'context_length': f"{context_length:,}" if context_length else "N/A",
            'max_output': f"{max_output:,}" if max_output else "N/A",
            'input_modalities': architecture.get('input_modalities', ['text']),
            'output_modalities': architecture.get('output_modalities', ['text']),
            'focus': focus[:5] if focus else [],
            'strengths': strengths[:4] if strengths else [],
            'weaknesses': weaknesses[:4] if weaknesses else [],
            'competitors': competitors[:4] if competitors else [],
            'recommendation': recommendation,
            'verdict': verdict,
            'benchmark_categories': categories_data if categories_data else None,
            'overall_score': overall_score,
            'overall_tier': overall_tier,
            'radar': radar if radar else None,
            'expert_verdict': expert_verdict if expert_verdict else None,
            'analyzer_model': self.ANALYZER_MODEL if analysis else None,
            'analyzed_at': datetime.now().strftime('%Y-%m-%d %H:%M') if analysis else None
        }

        # Generov√°n√≠ obsahu
        content_parts = []

        if description_cs:
            content_parts.append(description_cs)
            content_parts.append("")

        if characteristics:
            content_parts.append("## Unik√°tn√≠ charakteristiky")
            content_parts.append("")
            content_parts.append(characteristics)
            content_parts.append("")

        if strengths:
            content_parts.append("## Siln√© str√°nky")
            content_parts.append("")
            for s in strengths:
                content_parts.append(f"### {s.get('area', '')}")
                content_parts.append(s.get('description', ''))
                content_parts.append("")

        if weaknesses:
            content_parts.append("## Slab√© str√°nky")
            content_parts.append("")
            for w in weaknesses:
                content_parts.append(f"### {w.get('area', '')}")
                content_parts.append(w.get('description', ''))
                content_parts.append("")

        # Sestaven√≠ souboru
        yaml_content = "---\n"
        yaml_content += self._dict_to_yaml(front_matter)
        yaml_content += "---\n\n"
        yaml_content += '\n'.join(content_parts)

        file_path.write_text(yaml_content, encoding='utf-8')
        return file_path

    def save_backup(self, models: list):
        """Ulo≈æ√≠ JSON backup v≈°ech model≈Ø."""
        self.BACKUP_DIR.mkdir(parents=True, exist_ok=True)

        backup_file = self.BACKUP_DIR / f"models_2025_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        backup_file.write_text(
            json.dumps(models, indent=2, ensure_ascii=False),
            encoding='utf-8'
        )
        self.log(f"üíæ Backup ulo≈æen: {backup_file}")

    def check_existing(self, model_id: str) -> bool:
        """Zkontroluje, zda ji≈æ existuje Jekyll post pro model."""
        slug = self.create_slug(model_id)
        existing = list(self.OUTPUT_DIR.glob(f"*-{slug}.md"))
        return len(existing) > 0

    def run(self, dry_run: bool = False, limit: int = None,
            no_analyze: bool = False, skip_existing: bool = True,
            year: int = None) -> list:
        """
        Hlavn√≠ metoda - st√°hne a zpracuje modely.

        Args:
            dry_run: Pouze zobrazit, nezpracov√°vat
            limit: Maxim√°ln√≠ poƒçet model≈Ø
            no_analyze: P≈ôeskoƒçit LLM anal√Ωzu
            skip_existing: P≈ôeskoƒçit modely, kter√© ji≈æ maj√≠ Jekyll post
            year: Rok pro filtraci (default: 2024)

        Returns:
            Seznam zpracovan√Ωch model≈Ø
        """
        # St√°hnout a filtrovat modely
        models = self.filter_models(year=year)

        if not models:
            self.log("‚ùå ≈Ω√°dn√© modely k zpracov√°n√≠")
            return []

        # Ulo≈æit backup
        self.save_backup(models)

        # Filtrovat existuj√≠c√≠
        if skip_existing:
            original_count = len(models)
            models = [m for m in models if not self.check_existing(m['id'])]
            skipped = original_count - len(models)
            if skipped > 0:
                self.log(f"   P≈ôeskoƒçeno {skipped} existuj√≠c√≠ch model≈Ø")

        # Aplikovat limit
        if limit and len(models) > limit:
            models = models[:limit]
            self.log(f"   Omezeno na {limit} model≈Ø")

        # Statistiky
        self.log(f"\n{'='*60}")
        self.log("P≈òEHLED MODEL≈Æ K ZPRACOV√ÅN√ç")
        self.log(f"{'='*60}")

        providers_count = {}
        for m in models:
            provider = m['id'].split('/')[0]
            providers_count[provider] = providers_count.get(provider, 0) + 1

        for provider, count in sorted(providers_count.items()):
            self.log(f"   {provider}: {count} model≈Ø")

        self.log(f"\n   CELKEM: {len(models)} model≈Ø")
        self.log(f"{'='*60}\n")

        if dry_run:
            self.log("DRY RUN - v√Ωpis model≈Ø:\n")
            for i, m in enumerate(models, 1):
                created = datetime.fromtimestamp(m.get('created', 0)).strftime('%Y-%m-%d')
                self.log(f"   {i:3}. [{created}] {m['id']}")
                self.log(f"        {m.get('name', 'N/A')}")
            return models

        # Zpracov√°n√≠
        processed = []
        models_without_benchmarks = []

        for i, model in enumerate(models, 1):
            self.log(f"\n{'='*60}")
            self.log(f"[{i}/{len(models)}] {model['id']}")
            self.log(f"{'='*60}")

            try:
                # Zkontrolovat dostupnost benchmark≈Ø
                benchmark_data = self.get_benchmark_data(model['id'])
                if not benchmark_data:
                    models_without_benchmarks.append(model['id'])

                analysis = None
                if not no_analyze and self.api_key:
                    analysis = self.analyze_model(model)
                    time.sleep(self.API_DELAY)

                file_path = self.generate_jekyll_post(model, analysis)
                self.log(f"   ‚úÖ Ulo≈æeno: {file_path.name}")

                processed.append(model)
                self.processed_count += 1

            except Exception as e:
                self.log(f"   ‚ùå Chyba: {e}")
                self.error_count += 1

            # Rate limiting
            if i < len(models):
                time.sleep(self.API_DELAY)

        # Souhrn
        self.log(f"\n{'='*60}")
        self.log("SOUHRN")
        self.log(f"{'='*60}")
        self.log(f"   √öspƒõ≈°nƒõ zpracov√°no: {self.processed_count}")
        self.log(f"   Chyby: {self.error_count}")
        self.log(f"   Jekyll posty: {self.OUTPUT_DIR}")

        # V√Ωpis model≈Ø bez benchmark≈Ø
        if models_without_benchmarks:
            self.log(f"\n   ‚ö†Ô∏è Modely bez benchmark dat ({len(models_without_benchmarks)}):")
            for model_id in models_without_benchmarks:
                self.log(f"      - {model_id}")

        self.log(f"{'='*60}\n")

        return processed


def main():
    """Entry point."""
    parser = argparse.ArgumentParser(
        description='Bulk sta≈æen√≠ LLM model≈Ø z OpenRouter'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Pouze zobrazit modely bez zpracov√°n√≠'
    )
    parser.add_argument(
        '--limit', '-n',
        type=int,
        default=None,
        help='Maxim√°ln√≠ poƒçet model≈Ø k zpracov√°n√≠'
    )
    parser.add_argument(
        '--year', '-y',
        type=int,
        default=2025,
        help='Rok pro filtraci model≈Ø (default: 2025)'
    )
    parser.add_argument(
        '--no-analyze',
        action='store_true',
        help='P≈ôeskoƒçit LLM anal√Ωzu (rychlej≈°√≠, ale m√©nƒõ dat)'
    )
    parser.add_argument(
        '--include-existing',
        action='store_true',
        help='Zpracovat i modely, kter√© ji≈æ maj√≠ Jekyll post'
    )
    parser.add_argument(
        '--quiet', '-q',
        action='store_true',
        help='Tich√Ω re≈æim'
    )

    args = parser.parse_args()

    fetcher = BulkLLMFetcher(verbose=not args.quiet)

    if not fetcher.api_key:
        print("‚ö†Ô∏è  OPENROUTER_API_KEY nen√≠ nastaven!")
        print("   Export: export OPENROUTER_API_KEY='sk-or-v1-xxx'")
        if not args.no_analyze:
            print("   Pou≈æijte --no-analyze pro spu≈°tƒõn√≠ bez API kl√≠ƒçe")
            sys.exit(1)

    try:
        processed = fetcher.run(
            dry_run=args.dry_run,
            limit=args.limit,
            no_analyze=args.no_analyze,
            skip_existing=not args.include_existing,
            year=args.year
        )

        if not args.quiet:
            print(f"\nüéâ Hotovo! Zpracov√°no {len(processed)} model≈Ø.")

        sys.exit(0)

    except Exception as e:
        print(f"‚ùå Chyba: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
