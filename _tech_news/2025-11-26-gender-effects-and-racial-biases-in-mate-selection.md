---
author: Marisa Aigen
category: ai a spoleÄnost
date: '2025-11-26 00:00:00'
description: VÃ½zkum publikovanÃ½ v Äasopise Scientific Reports vyuÅ¾il strojovÃ© uÄenÃ­
  k analÃ½ze dat ze speed datingÅ¯ a odhalil vÃ½znamnÃ© pohlavnÃ­ i rasovÃ© pÅ™edpojatosti
  v procesu vÃ½bÄ›ru partnera.
importance: 3
layout: tech_news_article
original_title: Gender effects and racial biases in mate selection as revealed by
  machine learning
publishedAt: '2025-11-26T00:00:00+00:00'
slug: gender-effects-and-racial-biases-in-mate-selection
source:
  emoji: ğŸ“°
  id: null
  name: Nature.com
title: PohlavnÃ­ rozdÃ­ly a rasovÃ¡ zaujatost ve vÃ½bÄ›ru partnera odhalenÃ© strojovÃ½m uÄenÃ­m
url: https://www.nature.com/articles/s41598-025-25028-x
---

## Souhrn
VÃ½zkumnÃ­ci pouÅ¾ili modernÃ­ metody strojovÃ©ho uÄenÃ­ k analÃ½ze veÅ™ejnÄ› dostupnÃ½ch dat ze speed datingÅ¯ a zjistili, Å¾e algoritmy dokÃ¡Å¾ou pÅ™edpovÄ›dÄ›t vzÃ¡jemnÃ½ zÃ¡jem ÃºÄastnÃ­kÅ¯ s pÅ™esnostÃ­ 85,4â€“86,4 %. ZÃ¡roveÅˆ prokÃ¡zali, Å¾e odstranÄ›nÃ­ rasovÃ½ch ÃºdajÅ¯ z modelu nevede k vÃ½raznÃ©mu poklesu pÅ™esnosti, coÅ¾ otevÃ­rÃ¡ cestu k etiÄtÄ›jÅ¡Ã­m aplikacÃ­m v oblasti online seznamovÃ¡nÃ­.

## KlÃ­ÄovÃ© body
- StrojovÃ© uÄenÃ­ dokÃ¡Å¾e pÅ™edpovÃ­dat vzÃ¡jemnÃ½ zÃ¡jem ve speed datingu s pÅ™esnostÃ­ pÅ™es 85 %.
- VÃ½zkum testoval kombinaci rÅ¯znÃ½ch algoritmÅ¯ (LGBM, nÃ¡hodnÃ½ les, logistickÃ¡ regrese atd.) a metod vÃ½bÄ›ru pÅ™Ã­znakÅ¯.
- RasovÄ› â€oslepenÃ©â€œ modely dosahujÃ­ srovnatelnÃ© pÅ™esnosti jako modely vyuÅ¾Ã­vajÃ­cÃ­ rasovÃ© informace.
- VÃ½sledky naznaÄujÃ­ vÃ½raznÃ© pohlavnÃ­ rozdÃ­ly v kritÃ©riÃ­ch vÃ½bÄ›ru partnera.
- Studie podporuje vÃ½voj inkluzivnÄ›jÅ¡Ã­ch a chovÃ¡nÃ­ zamÄ›Å™enÃ½ch technologiÃ­ v oblasti AI pro seznamovÃ¡nÃ­.

## Podrobnosti
VÃ½zkum vyuÅ¾il veÅ™ejnÄ› dostupnou datovou sadu ze speed datingÅ¯ (OpenML ID: 40536) a aplikoval na ni Å¡irokou Å¡kÃ¡lu algoritmÅ¯ strojovÃ©ho uÄenÃ­, vÄetnÄ› LightGBM, nÃ¡hodnÃ©ho lesa, logistickÃ© regrese, stochastickÃ©ho gradientnÃ­ho sestupu a metody k nejbliÅ¾Å¡Ã­ch sousedÅ¯. Tyto modely byly kombinovÃ¡ny s rÅ¯znÃ½mi technikami vÃ½bÄ›ru pÅ™Ã­znakÅ¯ â€“ od jednoduchÃ½ch filtrovÃ½ch metod aÅ¾ po pokroÄilÃ© embedded a wrapper pÅ™Ã­stupy. CÃ­lem bylo identifikovat, kterÃ© faktory nejvÃ­ce ovlivÅˆujÃ­ rozhodnutÃ­ o vzÃ¡jemnÃ©m zÃ¡jmu, a zÃ¡roveÅˆ posoudit, zda lze vytvoÅ™it modely, kterÃ© ignorujÃ­ citlivÃ© atributy jako je rasa, aniÅ¾ by to negativnÄ› ovlivnilo jejich vÃ½konnost. VÃ½sledky ukÃ¡zaly, Å¾e i bez rasovÃ½ch ÃºdajÅ¯ dosahujÃ­ modely tÃ©mÄ›Å™ stejnÃ© pÅ™esnosti, coÅ¾ naznaÄuje, Å¾e rasovÃ© preference nejsou klÃ­ÄovÃ½m prediktorem ÃºspÄ›chu ve vÃ½bÄ›ru partnera. Naopak pohlavÃ­ ÃºÄastnÃ­kÅ¯ hraje vÃ½raznÄ›jÅ¡Ã­ roli â€“ muÅ¾i a Å¾eny hodnotÃ­ rÅ¯znÃ© vlastnosti (napÅ™. vzhled vs. inteligence) odliÅ¡nÄ›.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½zkum mÃ¡ vÃ½znamnÃ© dÅ¯sledky pro etickÃ½ vÃ½voj AI v sociÃ¡lnÃ­ch aplikacÃ­ch, zejmÃ©na v oblasti online seznamovÃ¡nÃ­. Ukazuje, Å¾e je moÅ¾nÃ© navrhovat algoritmy, kterÃ© nezpevÅˆujÃ­ existujÃ­cÃ­ stereotypy nebo diskriminaci, aniÅ¾ by to sniÅ¾ovalo jejich uÅ¾iteÄnost. V kontextu rostoucÃ­ kritiky algoritmickÃ© zaujatosti v sociÃ¡lnÃ­ch technologiÃ­ch pÅ™edstavuje studie praktickÃ½ pÅ™Ã­klad, jak lze AI navrhovat inkluzivnÄ›ji a zÃ¡roveÅˆ efektivnÄ›. ZÃ¡roveÅˆ otevÃ­rÃ¡ prostor pro dalÅ¡Ã­ vÃ½zkum chovÃ¡nÃ­ lidÃ­ v partnerskÃ½ch vztazÃ­ch pomocÃ­ datovÄ› Å™Ã­zenÃ½ch metod.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.nature.com/articles/s41598-025-25028-x)

**Zdroj:** ğŸ“° Nature.com
