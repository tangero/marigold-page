---
author: Marisa Aigen
category: ai a spoleÄnost
date: '2025-11-26 00:00:00'
description: VÃ½zkum publikovanÃ½ v Äasopise Scientific Reports vyuÅ¾il strojovÃ© uÄenÃ­
  k analÃ½ze dat ze speed datingÅ¯ a odhalil vliv pohlavÃ­ a rasy na vzÃ¡jemnÃ½ zÃ¡jem ÃºÄastnÃ­kÅ¯.
importance: 3
layout: tech_news_article
original_title: Gender effects and racial biases in mate selection as revealed by
  machine learning
publishedAt: '2025-11-26T00:00:00+00:00'
slug: gender-effects-and-racial-biases-in-mate-selection
source:
  emoji: ğŸ“°
  id: null
  name: Nature.com
title: PohlavnÃ­ rozdÃ­ly a rasovÃ¡ zaujatost ve vÃ½bÄ›ru partnerÅ¯ odhalenÃ© strojovÃ½m uÄenÃ­m
url: https://www.nature.com/articles/s41598-025-25028-x
---

## Souhrn
VÃ½zkumnÃ­ci vyuÅ¾ili pokroÄilÃ© metody strojovÃ©ho uÄenÃ­ (ML) k analÃ½ze dat ze speed datingÅ¯ a zjistili, Å¾e ML modely dokÃ¡Å¾ou pÅ™edpovÄ›dÄ›t vzÃ¡jemnÃ½ zÃ¡jem ÃºÄastnÃ­kÅ¯ s pÅ™esnostÃ­ 85,4â€“86,4 %. ZÃ¡roveÅˆ prokÃ¡zali, Å¾e modely â€oslepenÃ©â€œ vÅ¯Äi rasovÃ½m informacÃ­m dosahujÃ­ srovnatelnÃ© pÅ™esnosti, coÅ¾ otevÃ­rÃ¡ cestu k etiÄtÄ›jÅ¡Ã­m aplikacÃ­m v oblasti online randÄ›nÃ­.

## KlÃ­ÄovÃ© body
- ML modely (LGBM, nÃ¡hodnÃ½ les, logistickÃ¡ regrese, atd.) dosÃ¡hly pÅ™esnosti pÅ™es 85 % pÅ™i predikci vzÃ¡jemnÃ©ho zÃ¡jmu.
- Byly testovÃ¡ny rÅ¯znÃ© metody vÃ½bÄ›ru pÅ™Ã­znakÅ¯ (feature selection), vÄetnÄ› filter-based a embedded pÅ™Ã­stupÅ¯.
- RasovÄ› neutrÃ¡lnÃ­ modely dosahujÃ­ tÃ©mÄ›Å™ stejnÃ© pÅ™esnosti jako ty vyuÅ¾Ã­vajÃ­cÃ­ rasovÃ© Ãºdaje.
- VÃ½zkum pouÅ¾il veÅ™ejnÄ› dostupnÃ¡ data a open-source nÃ¡stroje, coÅ¾ zajiÅ¡Å¥uje reprodukovatelnost vÃ½sledkÅ¯.

## Podrobnosti
VÃ½zkum analyzoval veÅ™ejnÄ› dostupnou datovou sadu ze speed datingÅ¯ (OpenML ID: 40536), kterÃ¡ obsahuje informace o preferencÃ­ch, demografii a rozhodnutÃ­ch ÃºÄastnÃ­kÅ¯. AutoÅ™i nasadili Å¡irokou Å¡kÃ¡lu ML algoritmÅ¯ â€“ od LightGBM pÅ™es nÃ¡hodnÃ½ les aÅ¾ po k nejbliÅ¾Å¡Ã­ch sousedÅ¯ â€“ a kombinovali je s rÅ¯znÃ½mi metodami vÃ½bÄ›ru pÅ™Ã­znakÅ¯, aby identifikovali ty nejrelevantnÄ›jÅ¡Ã­ faktory pro predikci â€matcheâ€œ. ZÃ¡sadnÃ­ zjiÅ¡tÄ›nÃ­ spoÄÃ­vÃ¡ v tom, Å¾e i kdyÅ¾ rasovÃ© informace zvyÅ¡ujÃ­ pÅ™esnost modelu jen minimÃ¡lnÄ›, lze je zcela vynechat bez vÃ½raznÃ©ho poklesu vÃ½konu. To naznaÄuje, Å¾e chovÃ¡nÃ­ a preference ÃºÄastnÃ­kÅ¯ jsou silnÄ›jÅ¡Ã­mi prediktory neÅ¾ demografickÃ© kategorie. VÃ½zkumnÃ­ci takÃ© navrhujÃ­ pohlavÃ­-specifickÃ© modely, kterÃ© lÃ©pe zachycujÃ­ rozdÃ­ly v partnerstvÃ­ mezi muÅ¾i a Å¾enami.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½zkum pÅ™ispÃ­vÃ¡ k probÃ­hajÃ­cÃ­ diskusi o etice AI v citlivÃ½ch sociÃ¡lnÃ­ch oblastech, jako je randÄ›nÃ­ nebo nÃ¡bor. Ukazuje, Å¾e technologickÃ© Å™eÅ¡enÃ­ rasovÃ© zaujatosti nemusÃ­ znamenat obÄ›tovÃ¡nÃ­ pÅ™esnosti â€“ naopak, dÅ¯raz na chovÃ¡nÃ­ a preference mÅ¯Å¾e vÃ©st k inkluzivnÄ›jÅ¡Ã­m systÃ©mÅ¯m. Pro vÃ½vojÃ¡Å™e rande aplikacÃ­ to znamenÃ¡, Å¾e je moÅ¾nÃ© navrhovat doporuÄovacÃ­ algoritmy, kterÃ© nebudou posilovat stereotypy nebo diskriminaci. ZÃ¡roveÅˆ vÃ½zkum demonstruje, jak open-source data a nÃ¡stroje (napÅ™. software df-analyze na GitHubu) umoÅ¾ÅˆujÃ­ transparentnÃ­ a ovÄ›Å™itelnÃ½ vÃ½zkum v oblasti AI a spoleÄnosti.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.nature.com/articles/s41598-025-25028-x)

**Zdroj:** ğŸ“° Nature.com
