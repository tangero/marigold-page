---
author: Marisa Aigen
category: ai etika
date: '2025-11-05 16:22:08'
description: VÃ½zkumnÃ­ci pÅ™edstavili FHIBE, novÃ½ otevÅ™enÃ½ obrazovÃ½ dataset zamÄ›Å™enÃ½
  na ÄlovÄ›ka, navrÅ¾enÃ½ podle pÅ™Ã­snÃ½ch etickÃ½ch standardÅ¯ pro souhlas, soukromÃ­, odmÄ›nu,
  bezpeÄnost a diverzitu. SlouÅ¾Ã­ jako referenÄnÃ­ sada pro testovÃ¡nÃ­ fÃ©rovosti a biasu
  v AI systÃ©mech pro poÄÃ­taÄovÃ© vidÄ›nÃ­.
importance: 3
layout: tech_news_article
original_title: Fair human-centric image dataset for ethical AI benchmarking - Nature
publishedAt: '2025-11-05T16:22:08+00:00'
slug: fair-human-centric-image-dataset-for-ethical-ai-be
source:
  emoji: ğŸ“°
  id: null
  name: Nature.com
title: 'Fair Human-Centric Image Benchmark: etickÃ½ obrazovÃ½ dataset pro mÄ›Å™enÃ­ fÃ©rovosti
  AI'
url: https://www.nature.com/articles/s41586-025-09716-2
urlToImage: https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-025-09716-2/MediaObjects/41586_2025_9716_Fig1_HTML.png
urlToImageBackup: https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-025-09716-2/MediaObjects/41586_2025_9716_Fig1_HTML.png
---

## Souhrn
Fair Human-Centric Image Benchmark (FHIBE) je novÃ½ veÅ™ejnÄ› dostupnÃ½ obrazovÃ½ dataset zamÄ›Å™enÃ½ na ÄlovÄ›ka, vytvoÅ™enÃ½ jako etickÃ½ standard pro hodnocenÃ­ fÃ©rovosti modelÅ¯ poÄÃ­taÄovÃ©ho vidÄ›nÃ­. NabÃ­zÃ­ detailnÃ­ anotace demografie, fyzickÃ½ch znakÅ¯ a prostÅ™edÃ­, aby umoÅ¾nil pÅ™esnÄ›jÅ¡Ã­ identifikaci a mÄ›Å™enÃ­ biasu v Å¡irokÃ© Å¡kÃ¡le AI Ãºloh.

## KlÃ­ÄovÃ© body
- Dataset je navrÅ¾en s dÅ¯razem na souhlas, ochranu soukromÃ­, spravedlivou odmÄ›nu ÃºÄastnÃ­kÅ¯ a bezpeÄnost dat.
- Obsahuje rozmanitÃ© demografickÃ© skupiny a podmÃ­nky snÃ­mÃ¡nÃ­, coÅ¾ umoÅ¾Åˆuje odhalovat systÃ©movÃ© biasy.
- UmoÅ¾Åˆuje testovÃ¡nÃ­ fÃ©rovosti u Ãºloh jako pose estimation, person segmentation, face detection a verification Äi visual question answering.
- DetailnÃ­ anotace (demografie, fyzickÃ© atributy, kontext prostÅ™edÃ­, technickÃ© parametry snÃ­mkÅ¯) podporujÃ­ granularnÃ­ analÃ½zu chovÃ¡nÃ­ modelÅ¯.
- SlouÅ¾Ã­ jako praktickÃ½ vzor, jak zodpovÄ›dnÄ› vytvÃ¡Å™et trÃ©ninkovÃ© a validaÄnÃ­ datasety pro AI v prÅ¯myslu i akademii.

## Podrobnosti
FHIBE reaguje na dlouhodobÃ½ problÃ©m v oblasti poÄÃ­taÄovÃ©ho vidÄ›nÃ­: vÄ›tÅ¡ina historickÃ½ch datasetÅ¯ vznikala bez plnÄ› informovanÃ©ho souhlasu zobrazenÃ½ch osob, s nedostateÄnou ochranou soukromÃ­ a s vÃ½raznou nerovnovÃ¡hou v zastoupenÃ­ pohlavÃ­, vÄ›ku, etnicity Äi fyzickÃ½ch znakÅ¯. To vedlo k modelÅ¯m, kterÃ© fungujÃ­ hÅ¯Å™e pro nÄ›kterÃ© skupiny uÅ¾ivatelÅ¯, a v citlivÃ½ch aplikacÃ­ch (bezpeÄnost, zdravotnictvÃ­, veÅ™ejnÃ½ prostor) vytvÃ¡Å™ejÃ­ konkrÃ©tnÃ­ rizika diskriminace.

FHIBE je navrÅ¾en jako hodnoticÃ­ benchmark, nikoli jako libovolnÃ½ zdroj trÃ©novacÃ­ch dat. VÃ½zkumnÃ­ci deklarujÃ­ implementaci "best practices" v nÄ›kolika oblastech: osoby na snÃ­mcÃ­ch poskytly informovanÃ½ souhlas, byly zaplaceny za ÃºÄast, byla pÅ™ijata opatÅ™enÃ­ minimalizujÃ­cÃ­ zneuÅ¾itÃ­ dat (napÅ™Ã­klad omezenÃ­ extrÃ©mnÄ› citlivÃ½ch scÃ©nÃ¡Å™Å¯), a metadata jsou strukturovanÃ¡ tak, aby umoÅ¾nila analÃ½zu dopadÅ¯ na rÅ¯znÃ© skupiny, aniÅ¾ by zbyteÄnÄ› zvyÅ¡ovala riziko reidentifikace. Dataset zahrnuje rÅ¯znÃ© svÄ›telnÃ© podmÃ­nky, prostÅ™edÃ­, obleÄenÃ­, pozice tÄ›la a kompozice scÃ©n, coÅ¾ umoÅ¾Åˆuje testovat modely v reÃ¡lnÄ›jÅ¡Ã­m spektru situacÃ­ neÅ¾ tradiÄnÃ­, Ãºzce zamÄ›Å™enÃ© datasety.

DÅ¯leÅ¾itÃ½m prvkem jsou komplexnÃ­ anotace: kromÄ› zÃ¡kladnÃ­ch demografickÃ½ch charakteristik obsahuje FHIBE takÃ© fyzickÃ© atributy, environmentÃ¡lnÃ­ faktory (napÅ™Ã­klad typ pozadÃ­, vnitÅ™nÃ­ vs. venkovnÃ­ prostÅ™edÃ­), instrument-level informace (kamera, optika) a pixel-level anotace (segmentace, bounding boxy). To umoÅ¾Åˆuje vÃ½robcÅ¯m AI produktÅ¯ pÅ™esnÄ›ji identifikovat, kde model selhÃ¡vÃ¡: zda je problÃ©m spojen s konkrÃ©tnÃ­ skupinou uÅ¾ivatelÅ¯, typem scÃ©ny, kvalitou obrazu nebo kombinacÃ­ faktorÅ¯. FHIBE tÃ­m posouvÃ¡ standardy pro hodnoticÃ­ datasety a vytvÃ¡Å™Ã­ konkrÃ©tnÃ­, prakticky pouÅ¾itelnÃ½ rÃ¡mec pro fÃ©rovÄ›jÅ¡Ã­ AI.

## ProÄ je to dÅ¯leÅ¾itÃ©
Pro prÅ¯mysl i regulÃ¡tory pÅ™edstavuje FHIBE chybÄ›jÃ­cÃ­ ÄlÃ¡nek mezi abstraktnÃ­mi etickÃ½mi principy a praktickÃ½m vÃ½vojem AI systÃ©mÅ¯. Firmy, kterÃ© vyvÃ­jejÃ­ rozpoznÃ¡vÃ¡nÃ­ obliÄeje, biometrickÃ© ovÄ›Å™ovÃ¡nÃ­, analÃ½zu videa v retailu, bezpeÄnostnÃ­ dohled, asistivnÃ­ technologie Äi nÃ¡stroje pro analÃ½zu chovÃ¡nÃ­ uÅ¾ivatelÅ¯, mohou tento dataset vyuÅ¾Ã­t k objektivnÄ›jÅ¡Ã­mu testovÃ¡nÃ­ dopadÅ¯ svÃ½ch modelÅ¯ na rÅ¯znÃ© skupiny. V kontextu pÅ™ipravovanÃ½ch regulacÃ­ (napÅ™Ã­klad AI Act v EU) a rostoucÃ­ho tlaku na prokazatelnou fÃ©rovost a auditovatelnost AI poskytuje FHIBE mÄ›Å™itelnÃ½ a reprodukovatelnÃ½ zpÅ¯sob, jak demonstrovat snahu o minimalizaci biasu.

ZÃ¡roveÅˆ je dÅ¯leÅ¾itÃ© vnÃ­mat FHIBE realisticky: sÃ¡m o sobÄ› neÅ™eÅ¡Ã­ problÃ©m nespravedlivÃ½ch modelÅ¯, ale zvyÅ¡uje laÅ¥ku pro to, jak mÃ¡ vypadat odpovÄ›dnÄ› vytvoÅ™enÃ½ dataset. ZavÃ¡dÃ­ tlak na velkÃ© hrÃ¡Äe, aby pÅ™ehodnotili pouÅ¾Ã­vÃ¡nÃ­ neeticky zÃ­skanÃ½ch obrazovÃ½ch kolekcÃ­ a investovali do transparentnÃ­ch, regulÃ©rnÄ› licencovanÃ½ch dat. Pokud se FHIBE nebo podobnÃ© projekty stanou standardem pro benchmarking, mÅ¯Å¾e to postupnÄ› zmÄ›nit praxi v celÃ©m ekosystÃ©mu AI pro poÄÃ­taÄovÃ© vidÄ›nÃ­ smÄ›rem k robustnÄ›jÅ¡Ã­m a spoleÄensky pÅ™ijatelnÄ›jÅ¡Ã­m systÃ©mÅ¯m.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.nature.com/articles/s41586-025-09716-2)

**Zdroj:** ğŸ“° Nature.com
