---
author: Marisa Aigen
category: ai bezpeÄnost
date: '2026-02-12 16:26:56'
description: Od ÃºtokÅ¯ typu prompt injection po podvody s deepfakes bezpeÄnostnÃ­ vÃ½zkumnÃ­ci
  uvÃ¡dÄ›jÃ­, Å¾e nÄ›kolik chyb nemÃ¡ znÃ¡mou opravu. Zde je pÅ™ehled tÄ›chto problÃ©mÅ¯.
importance: 5
layout: tech_news_article
original_title: These 4 critical AI vulnerabilities are being exploited faster than
  defenders can respond
publishedAt: '2026-02-12T16:26:56+00:00'
slug: these-4-critical-ai-vulnerabilities-are-being-expl
source:
  emoji: ğŸ“°
  id: null
  name: ZDNet
title: Tyto 4 kritickÃ© zranitelnosti AI jsou zneuÅ¾Ã­vÃ¡ny rychleji, neÅ¾ obrÃ¡nci stihnou
  reagovat
url: https://www.zdnet.com/article/ai-security-threats-2026-overview/
urlToImage: https://www.zdnet.com/a/img/resize/32db0bda826046b0d2703b9713fd04f9739cf838/2026/02/10/bfe5dd37-f08f-4991-8009-84b7c6022267/gettyimages-1346242220.jpg?auto=webp&fit=crop&height=675&width=1200
urlToImageBackup: https://www.zdnet.com/a/img/resize/32db0bda826046b0d2703b9713fd04f9739cf838/2026/02/10/bfe5dd37-f08f-4991-8009-84b7c6022267/gettyimages-1346242220.jpg?auto=webp&fit=crop&height=675&width=1200
---

## Souhrn
ÄŒtyÅ™i hlavnÃ­ zranitelnosti v systÃ©mech umÄ›lÃ© inteligence jsou aktivnÄ› zneuÅ¾Ã­vÃ¡ny ÃºtoÄnÃ­ky, zatÃ­mco bezpeÄnostnÃ­ tÃ½my nemajÃ­ k dispozici ÃºÄinnÃ© opravy. Mezi nimi patÅ™Ã­ Ãºtoky na autonomnÃ­ AI agenty, otrava trÃ©ninkovÃ½ch dat, prompt injection a deepfake podvody. BezpeÄnostnÃ­ vÃ½zkumnÃ­ci varujÃ­, Å¾e rychlost vÃ½voje AI pÅ™ekonÃ¡vÃ¡ moÅ¾nosti obrany.

## KlÃ­ÄovÃ© body
- AutonomnÃ­ AI agenti jsou hijackovÃ¡ni stÃ¡tem sponzorovanÃ½mi hackery, napÅ™Ã­klad ÄÃ­nskÃ½mi aktÃ©ry na nÃ¡stroji Claude Code od Anthropic.
- Otrava trÃ©ninkovÃ½ch dat vyÅ¾aduje jen 250 dokumentÅ¯ a 60 dolarÅ¯.
- Ãštoky prompt injection ÃºspÄ›Å¡nÄ› prolomÃ­ 56 procent velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
- RepozitÃ¡Å™e modelÅ¯ obsahujÃ­ stovky tisÃ­c Å¡kodlivÃ½ch souborÅ¯.
- Deepfake videohovory vedly k odcizenÃ­ desÃ­tek milionÅ¯ dolarÅ¯.

## Podrobnosti
ÄŒlÃ¡nek zdÅ¯razÅˆuje, Å¾e systÃ©my umÄ›lÃ© inteligence ÄelÃ­ souÄasnÃ½m ÃºtokÅ¯m na vÃ­ce frontÃ¡ch, pÅ™iÄemÅ¾ vÄ›tÅ¡ina zranitelnostÃ­ postrÃ¡dÃ¡ znÃ¡mÃ© Å™eÅ¡enÃ­. PrvnÃ­ z nich se tÃ½kÃ¡ autonomnÃ­ch systÃ©mÅ¯: v zÃ¡Å™Ã­ Anthropic odhalil, Å¾e ÄÃ­nÅ¡tÃ­ hackeÅ™i sponzorovanÃ­ stÃ¡tem zneuÅ¾ili nÃ¡stroj Claude Code â€“ coÅ¾ je AI nÃ¡stroj pro generovÃ¡nÃ­ a Ãºpravu kÃ³du â€“ k provÃ¡dÄ›nÃ­ kybernetickÃ½ch ÃºtokÅ¯. Tito autonomnÃ­ AI agenti, navrÅ¾enÃ­ pro samostatnÃ© plnÄ›nÃ­ ÃºkolÅ¯ jako programovÃ¡nÃ­ nebo analÃ½za dat, se stÃ¡vajÃ­ ideÃ¡lnÃ­mi zbranÄ›mi, protoÅ¾e ÃºtoÄnÃ­ci je mohou pÅ™esmÄ›rovat na Å¡kodlivÃ© aktivity bez dalÅ¡Ã­ho zÃ¡sahu.

DruhÃ¡ zranitelnost spoÄÃ­vÃ¡ v otravÄ› trÃ©ninkovÃ½ch dat (data poisoning), kde staÄÃ­ infikovat jen 250 dokumentÅ¯ za cenu 60 dolarÅ¯, aby byl model natrvalo naruÅ¡en. Tento Ãºtok mÄ›nÃ­ chovÃ¡nÃ­ modelu jeÅ¡tÄ› pÅ™ed nasazenÃ­m, coÅ¾ ovlivÅˆuje vÃ½stupy v produkÄnÃ­m prostÅ™edÃ­, napÅ™Ã­klad v systÃ©mech pro detekci podvodÅ¯ nebo medicÃ­nskou diagnostiku.

TÅ™etÃ­ problÃ©m je prompt injection, technika, pÅ™i kterÃ© ÃºtoÄnÃ­k vloÅ¾Ã­ Å¡kodlivÃ½ pÅ™Ã­kaz do vstupnÃ­ho textu, aby pÅ™epsal instrukce modelu. Podle vÃ½zkumu uspÄ›je u 56 procent testovanÃ½ch LLM, jako jsou GPT nebo Claude varianty. To umoÅ¾Åˆuje Ãºnik citlivÃ½ch dat nebo provedenÃ­ neoprÃ¡vnÄ›nÃ½ch akcÃ­, coÅ¾ ohroÅ¾uje chatbota v podnikovÃ½ch aplikacÃ­ch.

ÄŒtvrtÃ¡ hrozba pochÃ¡zÃ­ z repozitÃ¡Å™Å¯ modelÅ¯, jako je Hugging Face, kde se skrÃ½vajÃ­ stovky tisÃ­c Å¡kodlivÃ½ch souborÅ¯. Tyto modely, urÄenÃ© pro sdÃ­lenÃ­ a fine-tuning, mohou obsahovat backdoory, kterÃ© se aktivujÃ­ po staÅ¾enÃ­. K tomu se pÅ™idÃ¡vajÃ­ deepfake videohovory, kterÃ© uÅ¾ vedly k ukradenÃ­ desÃ­tek milionÅ¯ dolarÅ¯ prostÅ™ednictvÃ­m faleÅ¡nÃ½ch jednÃ¡nÃ­ s manaÅ¾ery.

Tyto exploity vyuÅ¾Ã­vajÃ­ pÅ™esnÄ› ty vlastnosti, kterÃ© AI ÄinÃ­ uÅ¾iteÄnou â€“ autonomii, rychlost uÄenÃ­ a generovÃ¡nÃ­ obsahu. BezpeÄnostnÃ­ tÃ½my tak stojÃ­ pÅ™ed dilematem: buÄ se vyhnout AI a ztratit konkurenÄnÃ­ vÃ½hodu, nebo nasadit systÃ©my s inherentnÃ­mi slabostmi.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tyto zranitelnosti ukazujÃ­ systÃ©movÃ© selhÃ¡nÃ­ v AI ekosystÃ©mu, kde rychlost inovacÃ­ pÅ™edbÃ­hÃ¡ bezpeÄnostnÃ­ vÃ½voj. Pro firmy znamenÃ¡ riziko finanÄnÃ­ch ztrÃ¡t, ÃºnikÅ¯ dat a reputaÄnÃ­ch Å¡kod, zejmÃ©na v oblastech jako finance nebo zdravotnictvÃ­. V Å¡irÅ¡Ã­m kontextu posilujÃ­ argumenty pro regulaci AI, jako je nadchÃ¡zejÃ­cÃ­ EU AI Act, a nutnost investic do robustnÃ­ch obrannÃ½ch mechanismÅ¯, jako adversarial training nebo sandboxing. Bez rychlÃ½ch opatÅ™enÃ­ se AI stane vÄ›tÅ¡Ã­ hrozbou neÅ¾ pÅ™Ã­nosem, coÅ¾ ovlivnÃ­ celÃ½ technologickÃ½ prÅ¯mysl.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.zdnet.com/article/ai-security-threats-2026-overview/)

**Zdroj:** ğŸ“° ZDNet
