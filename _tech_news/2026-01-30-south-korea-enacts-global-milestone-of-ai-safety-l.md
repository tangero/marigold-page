---
author: Marisa Aigen
category: ai regulace
date: '2026-01-30 08:15:00'
description: JiÅ¾nÃ­ Korea pÅ™ijala zÃ¡kony o umÄ›lÃ© inteligenci a stala se prvnÃ­ velkou
  zemÃ­, kterÃ¡ to udÄ›lala samostatnÄ›. ÄŒlÃ¡nek podrobnÄ› analyzuje novÃ© pÅ™edpisy, zdÅ¯razÅˆuje
  jejich silnÃ© i slabÃ© strÃ¡nky. ExkluzivnÃ­ pohled od AI Insider.
importance: 5
layout: tech_news_article
original_title: South Korea Enacts Global Milestone Of AI Safety Laws Including Covering
  Mental Health Impacts
publishedAt: '2026-01-30T08:15:00+00:00'
slug: south-korea-enacts-global-milestone-of-ai-safety-l
source:
  emoji: ğŸ’¼
  id: null
  name: Forbes
title: JiÅ¾nÃ­ Korea zavÃ¡dÃ­ globÃ¡lnÃ­ milnÃ­k v zÃ¡konech o bezpeÄnosti umÄ›lÃ© inteligence
  vÄetnÄ› dopadÅ¯ na duÅ¡evnÃ­ zdravÃ­
url: https://www.forbes.com/sites/lanceeliot/2026/01/30/south-korea-enacts-global-milestone-of-ai-safety-laws-including-covering-mental-health-impacts/
urlToImage: https://imageio.forbes.com/specials-images/imageserve/697ad4ae7ce519811db188ca/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds
urlToImageBackup: https://imageio.forbes.com/specials-images/imageserve/697ad4ae7ce519811db188ca/0x0.jpg?format=jpg&height=900&width=1600&fit=bounds
---

## Souhrn
JiÅ¾nÃ­ Korea nedÃ¡vno schvÃ¡lila prvnÃ­ nÃ¡rodnÃ­ zÃ¡kon o bezpeÄnosti umÄ›lÃ© inteligence, ÄÃ­mÅ¾ se stala prvnÃ­ velkou ekonomikou, kterÃ¡ zavÃ¡dÃ­ komplexnÃ­ regulace samostatnÄ› mimo mezinÃ¡rodnÃ­ rÃ¡mce jako EU AI Act. ZÃ¡kon pokrÃ½vÃ¡ vysoce rizikovÃ© systÃ©my AI, vÄetnÄ› dopadÅ¯ na duÅ¡evnÃ­ zdravÃ­ uÅ¾ivatelÅ¯, a zavÃ¡dÃ­ povinnosti pro vÃ½vojÃ¡Å™e i provozovatele. Tato regulace nastavuje globÃ¡lnÃ­ precedent, ale vyvolÃ¡vÃ¡ otÃ¡zky ohlednÄ› byrokracie a inovacÃ­.

## KlÃ­ÄovÃ© body
- PrvnÃ­ samostatnÃ½ nÃ¡rodnÃ­ AI zÃ¡kon v major ekonomice, ÃºÄinnÃ½ od roku 2025.
- PovinnÃ¡ registrace a testovÃ¡nÃ­ vysoce rizikovÃ½ch AI systÃ©mÅ¯, vÄetnÄ› tÄ›ch ovlivÅˆujÃ­cÃ­ch mentÃ¡lnÃ­ zdravÃ­ (napÅ™. doporuÄovacÃ­ algoritmy sociÃ¡lnÃ­ch sÃ­tÃ­).
- Sankce aÅ¾ do vÃ½Å¡e 30 milionÅ¯ wonÅ¯ (cca 20 000 eur) za poruÅ¡enÃ­, vÄetnÄ› povinnÃ©ho reportingu incidentÅ¯.
- VÃ½jimky pro vÃ½zkum a open-source modely s nÃ­zkÃ½m rizikem.
- Integrace s existujÃ­cÃ­mi zÃ¡kony o osobnÃ­ch datech a spotÅ™ebitelskÃ© ochranÄ›.

## Podrobnosti
ZÃ¡kon, schvÃ¡lenÃ½ parlamentem v prosinci 2024, reaguje na rostoucÃ­ obavy z AI v kaÅ¾dodennÃ­m Å¾ivotÄ›. Definuje vysoce rizikovÃ© aplikace jako ty, kterÃ© ovlivÅˆujÃ­ rozhodovÃ¡nÃ­ ve zdravotnictvÃ­, dopravÄ›, vzdÄ›lÃ¡vÃ¡nÃ­ nebo bezpeÄnosti, a nynÃ­ rozÅ¡iÅ™uje na mentÃ¡lnÃ­ zdravÃ­. KonkrÃ©tnÄ› vyÅ¾aduje, aby AI systÃ©my jako personalizovanÃ© doporuÄenÃ­ na platformÃ¡ch typu TikTok nebo YouTube prochÃ¡zely hodnocenÃ­m rizik zÃ¡vislosti a manipulace emocÃ­. VÃ½vojÃ¡Å™i musÃ­ provÃ¡dÄ›t pÅ™ed nasazenÃ­m bias testy, transparentnost algoritmÅ¯ a simulace dopadÅ¯ na uÅ¾ivatele, vÄetnÄ› longitudinÃ¡lnÃ­ch studiÃ­ o duÅ¡evnÃ­m zdravÃ­.

ProvozovatelÃ© jsou povinni vÃ©st registry systÃ©mÅ¯ u KorejskÃ© agentury pro digitÃ¡lnÃ­ technologie (KDTA), reportovat incidenty do 24 hodin a umoÅ¾nit audity. ZÃ¡kon vychÃ¡zÃ­ z rÃ¡mce NIST AI Risk Management Framework, ale pÅ™izpÅ¯sobuje ho lokÃ¡lnÃ­m podmÃ­nkÃ¡m â€“ JiÅ¾nÃ­ Korea mÃ¡ vysokou penetraci AI v mobilnÃ­ch aplikacÃ­ch a sociÃ¡lnÃ­ch sÃ­tÃ­ch, kde 70 % populace trÃ¡vÃ­ dennÄ› pÅ™es 2 hodiny. PozitivnÃ­ je, Å¾e zahrnuje etickÃ© smÄ›rnice pro generativnÃ­ AI, jako povinnÃ© watermarking pro deepfakes, coÅ¾ brÃ¡nÃ­ dezinformacÃ­m.

Na druhÃ© stranÄ› kritici upozorÅˆujÃ­ na slabiny: definice "dopadu na mentÃ¡lnÃ­ zdravÃ­" je pÅ™Ã­liÅ¡ Å¡irokÃ¡, coÅ¾ mÅ¯Å¾e vÃ©st k soudnÃ­m sporÅ¯m. MalÃ© firmy, jako startupovÃ© vÃ½vojÃ¡Å™e chatbotÅ¯ pro terapii, ÄelÃ­ vysokÃ½m nÃ¡kladÅ¯m na compliance â€“ odhaduje se 5â€“10 % rozpoÄtu na testovÃ¡nÃ­. NavÃ­c zÃ¡kon neÅ™eÅ¡Ã­ globÃ¡lnÃ­ modely jako GPT-4o, kterÃ© se importujÃ­, a spolÃ©hÃ¡ se na dobrovolnou spoluprÃ¡ci s firmami jako Samsung nebo Naver, kterÃ© dominujÃ­ lokÃ¡lnÃ­mu trhu AI. SrovnÃ¡nÃ­ s EU AI Act ukazuje, Å¾e korejskÃ½ pÅ™Ã­stup je mÃ©nÄ› pÅ™Ã­snÃ½ v kategorizaci rizik, ale agresivnÄ›jÅ¡Ã­ v sankcÃ­ch pro opakovanÃ© poruÅ¡enÃ­. CelkovÄ› zÃ¡kon pokrÃ½vÃ¡ 80 % komerÄnÃ­ch AI nasazenÃ­ v zemi, kde AI pÅ™ispÃ­vÃ¡ 5 % HDP.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato regulace nastavuje precedens pro Asii a globÃ¡lnÄ›, protoÅ¾e JiÅ¾nÃ­ Korea je tÅ™etÃ­m nejvÄ›tÅ¡Ã­m investorem do AI (po USA a ÄŒÃ­nÄ›) s rozpoÄtem 2,5 miliardy dolarÅ¯ roÄnÄ›. Dopady pro prÅ¯mysl zahrnujÃ­ nutnost pÅ™epracovat modely â€“ napÅ™. HyperCLOVA od Naveru musÃ­ integrovat mentÃ¡lnÃ­ zdravÃ­ checks, coÅ¾ zpomalÃ­ nasazenÃ­ o 6â€“12 mÄ›sÃ­cÅ¯. Pro uÅ¾ivatele znamenÃ¡ lepÅ¡Ã­ ochranu pÅ™ed manipulativnÃ­mi algoritmy, kterÃ© pÅ™ispÃ­vajÃ­ k Ãºzkostem (studie ukazujÃ­ 15% nÃ¡rÅ¯st deprese u teenegerÅ¯ kvÅ¯li sociÃ¡lnÃ­m sÃ­tÃ­m). V Å¡irÅ¡Ã­m kontextu tlaÄÃ­ na USA a ÄŒÃ­nu k reakci, potenciÃ¡lnÄ› harmonizujÃ­c regulace a sniÅ¾ujÃ­c fragmentaci. Kriticky vÅ¡ak riskuje, Å¾e odradÃ­ talenty â€“ Korejci tvoÅ™Ã­ 10 % vÃ½zkumnÃ­kÅ¯ v LLM â€“ a posÃ­lÃ­ dominance velkÃ½ch hrÃ¡ÄÅ¯ jako OpenAI, kteÅ™Ã­ si compliance dovolÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.forbes.com/sites/lanceeliot/2026/01/30/south-korea-enacts-global-milestone-of-ai-safety-laws-including-covering-mental-health-impacts/)

**Zdroj:** ğŸ’¼ Forbes
