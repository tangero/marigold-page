---
category: ai
date: '2025-10-22 12:55:57'
description: VÃ½zkum ukazuje, Å¾e trÃ©novÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ na nekvalitnÃ­ch
  datech ze sociÃ¡lnÃ­ch sÃ­tÃ­ vede k mÄ›Å™itelnÃ©mu poklesu jejich kognitivnÃ­ch schopnostÃ­.
importance: 3
layout: tech_news_article
original_title: Clickbait Gives AI Models â€˜Brain Rot,â€™ Researchers Find - Gizmodo
publishedAt: '2025-10-22T12:55:57+00:00'
slug: clickbait-gives-ai-models-brain-rot-researchers-fi
source:
  emoji: ğŸ“°
  id: null
  name: Gizmodo.com
title: Clickbait a spam zpÅ¯sobujÃ­ AI modelÅ¯m 'degradaci schopnostÃ­', zjistili vÄ›dci
url: https://gizmodo.com/clickbait-gives-ai-models-brain-rot-researchers-find-2000675101
urlToImage: https://gizmodo.com/app/uploads/2025/10/llm_AI_brain_rot-1200x675.jpg
urlToImageBackup: https://gizmodo.com/app/uploads/2025/10/llm_AI_brain_rot-1200x675.jpg
---

## Souhrn

VÃ½zkumnÃ½ tÃ½m z americkÃ½ch univerzit prokÃ¡zal, Å¾e trÃ©novÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) na nekvalitnÃ­ch datech ze sociÃ¡lnÃ­ch sÃ­tÃ­ vede k vÃ½raznÃ©mu zhorÅ¡enÃ­ jejich vÃ½konu. Studie nazvanÃ¡ "LLM Brain Rot Hypothesis" testovala ÄtyÅ™i rÅ¯znÃ© modely na datech z platformy X a zjistila pokles v logickÃ©m uvaÅ¾ovÃ¡nÃ­, porozumÄ›nÃ­ kontextu i dodrÅ¾ovÃ¡nÃ­ bezpeÄnostnÃ­ch standardÅ¯.

## KlÃ­ÄovÃ© body

- VÃ½zkumnÃ­ci z Texas A&M University, University of Texas at Austin a Purdue University identifikovali dva typy "nekvalitnÃ­ch" dat: krÃ¡tkÃ© pÅ™Ã­spÄ›vky ze sociÃ¡lnÃ­ch sÃ­tÃ­ s vysokou mÃ­rou interakcÃ­ a delÅ¡Ã­ obsah s clickbaitovÃ½mi titulky
- TestovÃ¡ny byly ÄtyÅ™i modely: Llama3 8B, Qwen2.5 7B/0.5B a Qwen3 4B na vzorku jednoho milionu pÅ™Ã­spÄ›vkÅ¯ z platformy X
- Meta Llama3 prokÃ¡zal nejvyÅ¡Å¡Ã­ citlivost na nekvalitnÃ­ data, zatÃ­mco menÅ¡Ã­ model Qwen3 4B byl odolnÄ›jÅ¡Ã­
- VyÅ¡Å¡Ã­ podÃ­l nekvalitnÃ­ch dat vedl k ÄastÄ›jÅ¡Ã­mu "no thinking" reÅ¾imu, kdy model neposkytuje zdÅ¯vodnÄ›nÃ­ svÃ© odpovÄ›di
- VÅ¡echny testovanÃ© modely zaznamenaly mÄ›Å™itelnÃ½ pokles kognitivnÃ­ch schopnostÃ­

## Podrobnosti

VÃ½zkumnÃ­ci definovali dva zÃ¡kladnÃ­ typy problematickÃ½ch trÃ©novacÃ­ch dat. PrvnÃ­ kategorii tvoÅ™Ã­ krÃ¡tkÃ© pÅ™Ã­spÄ›vky ze sociÃ¡lnÃ­ch sÃ­tÃ­, kterÃ© majÃ­ vysokou mÃ­ru zapojenÃ­ uÅ¾ivatelÅ¯ formou lajkÅ¯ a sdÃ­lenÃ­, ale nÃ­zkou informaÄnÃ­ hodnotu. Druhou kategorii pÅ™edstavuje delÅ¡Ã­ obsah charakteristickÃ½ senzacechtivÃ½mi titulky, pÅ™ehnanou prezentacÃ­ a povrchnÃ­ ÃºrovnÃ­ skuteÄnÃ½ch informacÃ­.

Pro experiment vÃ½zkumnÃ­ci sesbÃ­rali vzorek jednoho milionu pÅ™Ã­spÄ›vkÅ¯ z platformy X a trÃ©novali ÄtyÅ™i rÅ¯znÃ© jazykovÃ© modely na rÅ¯znÃ½ch pomÄ›rech kontrolnÃ­ch dat a nekvalitnÃ­ho obsahu. VÃ½sledky jednoznaÄnÄ› prokÃ¡zaly negativnÃ­ dopad na vÅ¡echny testovanÃ© modely.

NejvÃ½raznÄ›jÅ¡Ã­ pokles zaznamenal model Llama3 8B od spoleÄnosti Meta, kterÃ½ vykazoval zhorÅ¡enÃ­ v oblasti logickÃ©ho uvaÅ¾ovÃ¡nÃ­, porozumÄ›nÃ­ kontextu a dodrÅ¾ovÃ¡nÃ­ bezpeÄnostnÃ­ch protokolÅ¯. PÅ™ekvapivÄ› se jako odolnÄ›jÅ¡Ã­ ukÃ¡zal menÅ¡Ã­ model Qwen3 4B, i kdyÅ¾ ani ten nebyl imunnÃ­ vÅ¯Äi degradaci schopnostÃ­.

ZajÃ­mavÃ½m zjiÅ¡tÄ›nÃ­m je, Å¾e s rostoucÃ­m podÃ­lem nekvalitnÃ­ch dat se modely ÄastÄ›ji dostÃ¡valy do reÅ¾imu, kdy neposkytovaly Å¾Ã¡dnÃ© zdÅ¯vodnÄ›nÃ­ svÃ½ch odpovÄ›dÃ­. Tyto nezdÅ¯vodnÄ›nÃ© odpovÄ›di byly zÃ¡roveÅˆ s vyÅ¡Å¡Ã­ pravdÄ›podobnostÃ­ nesprÃ¡vnÃ©, coÅ¾ naznaÄuje pÅ™Ã­mou souvislost mezi kvalitou trÃ©novacÃ­ch dat a spolehlivostÃ­ vÃ½stupÅ¯.

## ProÄ je to dÅ¯leÅ¾itÃ©

Tato studie pÅ™ichÃ¡zÃ­ v dobÄ›, kdy se velkÃ© jazykovÃ© modely stÃ¡le vÃ­ce spolÃ©hajÃ­ na automatizovanÃ© sbÄ›ry dat z internetu pro svÃ© trÃ©novÃ¡nÃ­. S rostoucÃ­m mnoÅ¾stvÃ­m AI-generovanÃ©ho obsahu a clickbaitovÃ½ch materiÃ¡lÅ¯ na webu se problÃ©m nekvalitnÃ­ch trÃ©novacÃ­ch dat mÅ¯Å¾e v budoucnu jeÅ¡tÄ› zhorÅ¡ovat.

VÃ½zkum mÃ¡ pÅ™Ã­mÃ© dÅ¯sledky pro vÃ½voj AI systÃ©mÅ¯ a ukazuje na nutnost peÄlivÄ›jÅ¡Ã­ kurÃ¡torskÃ© prÃ¡ce s trÃ©novacÃ­mi daty. Firmy vyvÃ­jejÃ­cÃ­ jazykovÃ© modely budou muset investovat vÃ­ce prostÅ™edkÅ¯ do filtrovÃ¡nÃ­ a ovÄ›Å™ovÃ¡nÃ­ kvality zdrojovÃ½ch dat, pokud chtÄ›jÃ­ udrÅ¾et nebo zlepÅ¡it vÃ½kon svÃ½ch modelÅ¯. ZjiÅ¡tÄ›nÃ­ takÃ© vyvolÃ¡vÃ¡ otÃ¡zky o dlouhodobÃ© udrÅ¾itelnosti souÄasnÃ©ho pÅ™Ã­stupu k trÃ©novÃ¡nÃ­ AI, kdy se modely uÄÃ­ z ÄÃ­m dÃ¡l vÄ›tÅ¡Ã­ho mnoÅ¾stvÃ­ nekvalitnÃ­ho obsahu generovanÃ©ho jinÃ½mi AI systÃ©my.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://gizmodo.com/clickbait-gives-ai-models-brain-rot-researchers-find-2000675101)

**Zdroj:** ğŸ“° Gizmodo.com
