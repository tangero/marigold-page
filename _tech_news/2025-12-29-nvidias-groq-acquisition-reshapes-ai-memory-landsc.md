---
author: Marisa Aigen
category: ai hardware
companies:
- Nvidia
- Groq
- Samsung Electronics
date: '2025-12-29 02:53:55'
description: SpoleÄnost Nvidia ÃºdajnÄ› investovala 20 miliard dolarÅ¯ do zÃ­skÃ¡nÃ­ technologickÃ½ch
  licencÃ­ od Groq, coÅ¾ pÅ™edstavuje jejÃ­ nejvÄ›tÅ¡Ã­ investici v historii. Tento krok
  pÅ™itahuje pozornost v JiÅ¾nÃ­ Koreji dÃ­ky podpoÅ™e Groq ze strany Samsung Electronics
  a jejich spoluprÃ¡ci.
importance: 5
layout: tech_news_article
original_title: Nvidia's Groq acquisition reshapes AI memory landscape
publishedAt: '2025-12-29T02:53:55+00:00'
slug: nvidias-groq-acquisition-reshapes-ai-memory-landsc
source:
  emoji: ğŸ“°
  id: null
  name: Digitimes
title: Akvizice Groq spoleÄnostÃ­ Nvidia mÄ›nÃ­ krajinu pamÄ›tÃ­ pro umÄ›lou inteligenci
url: https://www.digitimes.com/news/a20251229PD211/nvidia-groq-ai-inference-demand-technology.html
urlToImage: https://img.digitimes.com/newsshow/20251229pd211_files/2_b.jpg
urlToImageBackup: https://img.digitimes.com/newsshow/20251229pd211_files/2_b.jpg
---

## Souhrn
SpoleÄnost Nvidia investovala 20 miliard dolarÅ¯ do akvizice technologickÃ½ch licencÃ­ od startupu Groq, specializujÃ­cÃ­ho se na Äipy pro rychlÃ½ inference modelÅ¯ umÄ›lÃ© inteligence. Tato nejvÄ›tÅ¡Ã­ investice Nvidia dosud souvisÃ­ s obranou dominance v oblasti AI hardware a ovlivÅˆuje trh s pamÄ›Å¥ovÃ½mi moduly jako HBM a SRAM. Groq, podporovanÃ½ Samsungem, pÅ™inÃ¡Å¡Ã­ inovativnÃ­ architekturu pro zpracovÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).

## KlÃ­ÄovÃ© body
- Nvidia zÃ­skala licence na technologii Groq za 20 miliard USD, coÅ¾ je jejÃ­ nejvÄ›tÅ¡Ã­ jednorÃ¡zovÃ¡ investice.
- Groq vyvÃ­jÃ­ Language Processing Units (LPU), optimalizovanÃ© pro inference AI modelÅ¯ s vysokou propustnostÃ­.
- SpoluprÃ¡ce Groq se Samsungem zahrnuje vÃ½robu ÄipÅ¯ a pamÄ›tÃ­, coÅ¾ ovlivÅˆuje jiÅ¾nÃ­ Koreu.
- Tato akvizice signalizuje posun k specializovanÃ½m ÄipÅ¯m pro inference pÅ™i rostoucÃ­m objemu AI Ãºloh.
- SouvisÃ­ s Nvidia strategiÃ­ Rubin CPX GPU, kterÃ© mÄ›nÃ­ dodavatelskÃ© Å™etÄ›zce pamÄ›tÃ­.

## Podrobnosti
Nvidia, dominantnÃ­ hrÃ¡Ä na trhu grafickÃ½ch procesorÅ¯ (GPU) pro trÃ©nink a inference AI, se rozhodla posÃ­lit svou pozici investicÃ­ do Groq. Groq je americkÃ½ startup zaloÅ¾enÃ½ v roce 2016, kterÃ½ se zamÄ›Å™uje na vÃ½voj specializovanÃ½ch ÄipÅ¯ nazvanÃ½ch Language Processing Units (LPU). Tyto Äipy jsou navrÅ¾eny pro rychlÃ© zpracovÃ¡nÃ­ inference v modelech umÄ›lÃ© inteligence, jako jsou velkÃ© jazykovÃ© modely (LLM), kde dosahujÃ­ propustnosti aÅ¾ 1000 tokenÅ¯ za sekundu na jeden Äip â€“ vÃ½raznÄ› vyÅ¡Å¡Ã­ neÅ¾ u standardnÃ­ch GPU. Na rozdÃ­l od Nvidia H100 nebo Blackwell GPU, kterÃ© spolÃ©hajÃ­ na HBM pamÄ›ti s vysokou kapacitou, Groq pouÅ¾Ã­vÃ¡ architekturu zaloÅ¾enou na SRAM pro niÅ¾Å¡Ã­ latenci a vyÅ¡Å¡Ã­ energetickou Ãºspornost.

Tato akvizice licencÃ­ umoÅ¾nÃ­ Nvidia integrovat Groq technologii do svÃ½ch budoucÃ­ch produktÅ¯, jako je Å™ada Rubin CPX GPU, kterÃ¡ mÃ¡ revoluÄnÄ› zmÄ›nit inference AI. Rubin CPX je navrÅ¾en pro Å¡kÃ¡lovÃ¡nÃ­ AI Ãºloh v datovÃ½ch centrech, kde inference tvoÅ™Ã­ stÃ¡le vÄ›tÅ¡Ã­ podÃ­l oproti trÃ©ninku â€“ odhady hovoÅ™Ã­ o 80procentnÃ­m podÃ­lu inference v budoucÃ­ch AI vÃ½poÄtech. Investice takÃ© reaguje na rostoucÃ­ poptÃ¡vku po specializovanÃ½ch Äipech, kde konkurenti jako AMD s MI300X nebo Intel s Gaudi3 zkouÅ¡ejÃ­ naruÅ¡it Nvidia monopol.

KlÃ­ÄovÃ½m faktorem je zapojenÃ­ Samsung Electronics, kterÃ½ investoval do Groq a spolupracuje na vÃ½robÄ› ÄipÅ¯ v Texasu. Samsung dodÃ¡vÃ¡ HBM pamÄ›ti a GDDR moduly pro AI hardware, takÅ¾e tato dohoda ovlivnÃ­ dodavatelskÃ© Å™etÄ›zce v Asii. V JiÅ¾nÃ­ Koreji to vyvolÃ¡vÃ¡ obavy z posunu technologie k USA, zejmÃ©na v kontextu americkÃ½ch omezenÃ­ exportu ÄipÅ¯ do ÄŒÃ­ny. ÄŒlÃ¡nek z DIGITIMES Asia zmiÅˆuje souvisejÃ­cÃ­ pÅ™Ã­bÄ›hy o partnerstvÃ­ Nvidia-Groq pro specializovanÃ© inference Äipy a obranu trhu s AI inference.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato investice posiluje Nvidia pozici v inference, kde se oÄekÃ¡vÃ¡ explozivnÃ­ rÅ¯st dÃ­ky nasazenÃ­ LLM v cloudovÃ½ch sluÅ¾bÃ¡ch jako ChatGPT nebo Gemini. Pro prÅ¯mysl znamenÃ¡ diverzifikaci pamÄ›tÃ­ â€“ posun od HBM k hybridnÃ­m Å™eÅ¡enÃ­m SRAM/GDDR, coÅ¾ snÃ­Å¾Ã­ zÃ¡vislost na SK Hynix a Samsungu. UÅ¾ivatelÃ© datovÃ½ch center zÃ­skajÃ­ rychlejÅ¡Ã­ a levnÄ›jÅ¡Ã­ inference, coÅ¾ urychlÃ­ adopci AI v odvÄ›tvÃ­ch jako zdravotnictvÃ­ nebo finance. V Å¡irÅ¡Ã­m kontextu to urychluje soutÄ›Å¾ mezi GPU a specializovanÃ½mi Äipy, potenciÃ¡lnÄ› sniÅ¾uje nÃ¡klady na AI o 30-50 procent dÃ­ky vyÅ¡Å¡Ã­ efektivitÄ› Groq architektury. DlouhodobÄ› to mÅ¯Å¾e vÃ©st k konsolidaci trhu, kde Nvidia absorbuje inovace startupÅ¯, zatÃ­mco Samsung musÃ­ hledat novÃ© partnery.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.digitimes.com/news/a20251229PD211/nvidia-groq-ai-inference-demand-technology.html)

**Zdroj:** ğŸ“° Digitimes
