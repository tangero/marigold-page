---
author: Marisa Aigen
category: kyberbezpeÄnost
companies:
- Microsoft
date: '2026-01-24 18:00:14'
description: Zranitelnost v bezpeÄnosti Microsoft Copilot umoÅ¾Åˆuje ÃºtoÄnÃ­kÅ¯m krÃ¡st
  data prostÅ™ednictvÃ­m Å¡kodlivÃ½ch odkazÅ¯. ZjistÄ›te, jak Ãºtok funguje, a nauÄte se
  chrÃ¡nit.
importance: 5
layout: tech_news_article
original_title: Why clicking the wrong Copilot link could put your data at risk
publishedAt: '2026-01-24T18:00:14+00:00'
slug: why-clicking-the-wrong-copilot-link-could-put-your
source:
  emoji: ğŸ“°
  id: fox-news
  name: Fox News
title: ProÄ kliknutÃ­ na Å¡patnÃ½ odkaz Copilot ohrozÃ­ vaÅ¡e data
url: https://www.foxnews.com/tech/why-clicking-wrong-copilot-link-could-put-your-data-risk
urlToImage: https://static.foxnews.com/foxnews.com/content/uploads/2026/01/microsoft-copilot.jpg
urlToImageBackup: https://static.foxnews.com/foxnews.com/content/uploads/2026/01/microsoft-copilot.jpg
---

## Souhrn
BezpeÄnostnÃ­ vÃ½zkumnÃ­ci z firmy Varonis odhalili zranitelnost v Microsoft Copilot nazvanou Reprompt, kterÃ¡ umoÅ¾Åˆuje ÃºtoÄnÃ­kÅ¯m pÅ™evzÃ­t aktivnÃ­ relaci AI asistenta a vylouÄit data z uÅ¾ivatelova Microsoft ÃºÄtu pouhÃ½m kliknutÃ­m na Å¡kodlivÃ½ odkaz. Tento Ãºtok probÃ­hÃ¡ na pozadÃ­ bez viditelnÃ½ch zmÄ›n na obrazovce. Copilot, propojenÃ½ s ÃºÄtem, tak mÅ¯Å¾e nechtÄ›nÄ› zpracovat skrytÃ© instrukce a odeslat citlivÃ© informace.

## KlÃ­ÄovÃ© body
- Ãštok Reprompt vyuÅ¾Ã­vÃ¡ speciÃ¡lnÄ› vytvoÅ™enÃ½ odkaz, kterÃ½ obsahuje skrytÃ© instrukce pro Copilot.
- Copilot automaticky zpracovÃ¡vÃ¡ tyto instrukce v aktivnÃ­ relaci spojenÃ© s uÅ¾ivatelovÃ½m Microsoft ÃºÄtem.
- VÃ½zkumnÃ­ci z Varonis, firmy specializujÃ­cÃ­ se na ochranu dat, ukÃ¡zali, jak lze obejÃ­t ochrannÃ© mechanismy AI.
- Å½Ã¡dnÃ© instalace nenÃ­ potÅ™eba, staÄÃ­ kliknutÃ­ na odkaz z e-mailu nebo zprÃ¡vy.
- DoporuÄenÃ­: NepÅ™echÃ¡zejte podezÅ™elÃ© odkazy a sledujte aktualizace od Microsoftu.

## Podrobnosti
Microsoft Copilot je AI asistent integrovanÃ½ do produktÅ¯ spoleÄnosti Microsoft, jako jsou webovÃ© prohlÃ­Å¾eÄe Edge, aplikace Office nebo Windows. SlouÅ¾Ã­ k psanÃ­ e-mailÅ¯, shrnutÃ­ dokumentÅ¯, odpovÃ­dÃ¡nÃ­ na otÃ¡zky a prÃ¡ci s daty z uÅ¾ivatelova ÃºÄtu. Jeho sÃ­la spoÄÃ­vÃ¡ v propojenÃ­ s Microsoft ÃºÄtem, dÃ­ky ÄemuÅ¾ mÃ¡ pÅ™Ã­stup k minulÃ½m konverzacÃ­m, souborÅ¯m a osobnÃ­m ÃºdajÅ¯m. NicmÃ©nÄ› prÃ¡vÄ› toto propojenÃ­ se stalo slabinou.

VÃ½zkumnÃ­ci z Varonis, americkÃ© firmy zamÄ›Å™enÃ© na detekci a ochranu citlivÃ½ch dat v cloudu a enterprise prostÅ™edÃ­ch, objevili metodu Reprompt. Tato technika umoÅ¾Åˆuje ÃºtoÄnÃ­kÅ¯m vloÅ¾it do bÄ›Å¾nÄ› vypadajÃ­cÃ­ho odkazu na Copilot skrytÃ© instrukce. KdyÅ¾ uÅ¾ivatel klikne na takovÃ½ odkaz â€“ napÅ™Ã­klad z e-mailu nebo chatu â€“, Copilot jej otevÅ™e v aktivnÃ­ relaci a bez dalÅ¡Ã­ho potvrzenÃ­ zpracuje pÅ™Ã­kazy. Ty mohou zahrnovat vyhledÃ¡nÃ­ specifickÃ½ch dat, jako jsou konverzace, pÅ™Ã­lohy nebo metadata z ÃºÄtu, a jejich odeslÃ¡nÃ­ ÃºtoÄnÃ­kovi.

OchrannÃ© mechanismy Copilotu, jako filtry proti Ãºniku citlivÃ½ch informacÃ­, Reprompt obchÃ¡zÃ­ tÃ­m, Å¾e simuluje legitimnÃ­ poÅ¾adavek. Ãštok nevyÅ¾aduje instalaci malware, protoÅ¾e vyuÅ¾Ã­vÃ¡ dÅ¯vÄ›ryhodnou relaci uÅ¾ivatele. Varonis demonstrovali scÃ©nÃ¡Å™, kde ÃºtoÄnÃ­k poÅ¡le odkaz pÅ™edstÃ­rajÃ­cÃ­ sdÃ­lenÃ­ dokumentu; po kliknutÃ­ Copilot na pozadÃ­ extrahuje data. Microsoft zatÃ­m oficiÃ¡lnÄ› nereagoval, ale podobnÃ© zranitelnosti v AI nÃ¡strojÃ­ch, jako prompt injection Ãºtoky, ukazujÃ­ na systÃ©movÃ© riziko velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), kterÃ© zpracovÃ¡vajÃ­ kontext bez dostateÄnÃ© validace.

Pro uÅ¾ivatele to znamenÃ¡, Å¾e i v korporÃ¡tnÃ­m prostÅ™edÃ­, kde Copilot zpracovÃ¡vÃ¡ firemnÃ­ data, hrozÃ­ Ãºnik. DoporuÄuje se pouÅ¾Ã­vat Copilot v izolovanÃ©m oknÄ›, ovÄ›Å™ovat zdroje odkazÅ¯ a aktivovat dvoufÃ¡zovÃ© ovÄ›Å™ovÃ¡nÃ­ ÃºÄtu. Varonis navrhuje i lepÅ¡Ã­ sandboxing relacÃ­ AI.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento objev podtrhuje rostoucÃ­ rizika v AI asistentech propojenÃ½ch s uÅ¾ivatelskÃ½mi ÃºÄty, kde miliardy uÅ¾ivatelÅ¯ Microsoftu jsou potenciÃ¡lnÃ­mi cÃ­li. V Å¡irÅ¡Ã­m kontextu posiluje debatu o bezpeÄnosti LLM, kde prompt injection a podobnÃ© techniky ohroÅ¾ujÃ­ enterprise nasazenÃ­. Pro prÅ¯mysl to znamenÃ¡ nutnost revize guardrails v AI, jako jsou pokroÄilÃ© filtry kontextu nebo oddÄ›lenÃ© relace. Pokud Microsoft neopravÃ­ tuto slabinu rychle, mÅ¯Å¾e to vÃ©st k masivnÃ­m ÃºnikÅ¯m dat, podobnÄ› jako u minulÃ½ch zranitelnostÃ­ v ChatGPT nebo Gemini. Jako expert na AI vidÃ­m zde potÅ™ebu standardizovanÃ½ch bezpeÄnostnÃ­ch protokolÅ¯ pro vÅ¡echny komerÄnÃ­ AI nÃ¡stroje.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.foxnews.com/tech/why-clicking-wrong-copilot-link-could-put-your-data-risk)

**Zdroj:** ğŸ“° Fox News
