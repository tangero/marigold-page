---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2026-01-16 00:01:00'
description: MinulÃ½ rok bylo vyprodukovÃ¡no tisÃ­ce zneuÅ¾Ã­vajÃ­cÃ­ch videÃ­ â€“ tolik, kolik
  vÄ›dÃ­ vÃ½zkumnÃ­ci.
importance: 5
layout: tech_news_article
original_title: AI's Child-Porn Problem Is Getting Much Worse
publishedAt: '2026-01-16T00:01:00+00:00'
slug: ais-child-porn-problem-is-getting-much-worse
source:
  emoji: ğŸ“°
  id: null
  name: The Atlantic
title: ProblÃ©m umÄ›lÃ© inteligence s dÄ›tskou pornografiÃ­ se vÃ½raznÄ› zhorÅ¡uje
url: https://www.theatlantic.com/technology/2026/01/ais-child-porn-problem-getting-much-worse/685641/
urlToImage: https://cdn.theatlantic.com/thumbor/1eydAXWrmpR5TB5oCpq9dSJnVD8=/0x43:2000x1085/1200x625/media/img/mt/2026/01/2026_01_15_kids_mgp/original.jpg
urlToImageBackup: https://cdn.theatlantic.com/thumbor/1eydAXWrmpR5TB5oCpq9dSJnVD8=/0x43:2000x1085/1200x625/media/img/mt/2026/01/2026_01_15_kids_mgp/original.jpg
---

### Souhrn
V roce 2025 dosÃ¡hl objem dÄ›tskÃ© pornografie na internetu rekordnÃ­ ÃºrovnÄ› s 312 030 potvrzenÃ½mi reporty podle Internet Watch Foundation (IWF), britskÃ© organizace zabÃ½vajÃ­cÃ­ se identifikacÃ­ a odstraÅˆovÃ¡nÃ­m takovÃ©ho materiÃ¡lu. PoÄet AI-generovanÃ½ch videÃ­ s obsahem sexuÃ¡lnÃ­ho zneuÅ¾Ã­vÃ¡nÃ­ dÄ›tÃ­ vzrostl z 13 na 3 440, coÅ¾ pÅ™edstavuje dramatickÃ½ nÃ¡rÅ¯st. Tento trend zhorÅ¡uje dlouhodobÃ½ rÅ¯st distribuce takovÃ©ho obsahu pÅ™es sociÃ¡lnÃ­ sÃ­tÄ›, Å¡ifrovanÃ© zprÃ¡vy a dark web.

### KlÃ­ÄovÃ© body
- RekordnÃ­ch 312 030 reportÅ¯ v 2025, nÃ¡rÅ¯st o 7 % oproti roku 2024.
- AI-generovanÃ¡ videa: 3 440 kusÅ¯, z toho pÅ™es dvÄ› tÅ™etiny v kategorii A (nejzÃ¡vaÅ¾nÄ›jÅ¡Ã­, zahrnujÃ­cÃ­ penetraci, sexuÃ¡lnÃ­ muÄenÃ­ a bestialitu).
- DalÅ¡Ã­ch 30 % tvoÅ™Ã­ kategorie B s nepenetraÄnÃ­mi sexuÃ¡lnÃ­mi akty.
- AI umoÅ¾Åˆuje tvÅ¯rcÅ¯m generovat materiÃ¡l na mÃ­ru bez nutnosti fyzickÃ©ho zneuÅ¾Ã­vÃ¡nÃ­, ale Äasto vychÃ¡zÃ­ z reÃ¡lnÃ½ch dÄ›tÃ­.
- OÄekÃ¡vÃ¡ se dalÅ¡Ã­ rekord v roce 2026.

### Podrobnosti
Internet Watch Foundation, nezÃ¡vislÃ¡ britskÃ¡ neziskovka zaloÅ¾enÃ¡ v 90. letech, monitoruje globÃ¡lnÃ­ web a spolupracuje s policiÃ­ i hostingy na mazÃ¡nÃ­ nelegÃ¡lnÃ­ho obsahu. Jejich data za rok 2025 ukazujÃ­ nejen celkovÃ½ rÅ¯st o 7 %, ale pÅ™edevÅ¡Ã­m explozivnÃ­ nÃ¡rÅ¯st AI-generovanÃ©ho materiÃ¡lu. Z 3 440 AI videÃ­ byla tÃ©mÄ›Å™ dvÄ› tÅ™etiny zaÅ™azena do kategorie A, coÅ¾ znamenÃ¡ nejtÄ›Å¾Å¡Ã­ formy zneuÅ¾Ã­vÃ¡nÃ­ vÄetnÄ› penetrace, muÄenÃ­ a aktÅ¯ se zvÃ­Å™aty. Tento materiÃ¡l nenÃ­ harmless â€“ generativnÃ­ AI modely, jako ty zaloÅ¾enÃ© na difÃºznÃ­ch modelech (napÅ™. Stable Diffusion nebo podobnÃ© open-source varianty), jsou Äasto trÃ©novÃ¡ny na existujÃ­cÃ­ch databÃ¡zÃ­ch CSAM (child sexual abuse material), ÄÃ­mÅ¾ perpetuujÃ­ obrazy reÃ¡lnÃ½ch obÄ›tÃ­. AlternativnÄ› slouÅ¾Ã­ k deepfake manipulacÃ­m, kde se reÃ¡lnÃ© fotografie dÄ›tÃ­ z sociÃ¡lnÃ­ch sÃ­tÃ­ kombinujÃ­ s pornografickÃ½mi Å¡ablonami pro vytvoÅ™enÃ­ videÃ­.

Kerry Smith, Å¡Ã©fka IWF, varuje, Å¾e kriminÃ¡lnÃ­ci nynÃ­ disponujÃ­ â€vlastnÃ­mi stroji na sexuÃ¡lnÃ­ zneuÅ¾Ã­vÃ¡nÃ­ dÄ›tÃ­â€œ, kterÃ© generujÃ­ libovolnÃ½ obsah na pÅ™Ã­kaz. To je moÅ¾nÃ© dÃ­ky dostupnÃ½m nÃ¡strojÅ¯m: open-source modely jako Llama nebo fine-tuned verze GPT umoÅ¾ÅˆujÃ­ lokÃ¡lnÃ­ generaci na bÄ›Å¾nÃ½ch GPU bez cloudovÃ©ho dohledu. SociÃ¡lnÃ­ platformy jako Telegram nebo Discord s end-to-end Å¡ifrovÃ¡nÃ­m, stejnÄ› jako dark web fÃ³ra, usnadÅˆujÃ­ distribuci. IWF zdÅ¯razÅˆuje, Å¾e detekce je obtÃ­Å¾nÃ¡ â€“ AI obsah Äasto obchÃ¡zÃ­ hash-based filtry jako PhotoDNA od Microsoftu, protoÅ¾e se liÅ¡Ã­ od originÃ¡lÅ¯. V USA a EU jiÅ¾ probÃ­hajÃ­ diskuse o regulacÃ­ch, napÅ™. EU AI Act klasifikuje high-risk AI aplikace, ale enforcement zÅ¯stÃ¡vÃ¡ slabÃ½. Pro uÅ¾ivatele to znamenÃ¡ riziko nÃ¡hodnÃ©ho setkÃ¡nÃ­ s takovÃ½m obsahem i na mainstream platformÃ¡ch, zatÃ­mco pro prÅ¯mysl to signalizuje nutnost lepÅ¡Ã­ch watermarkÅ¯ a detekÄnÃ­ch modelÅ¯, jako je nedÃ¡vno otevÅ™enÃ½ Hive Moderation.

### ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½voj odhaluje fundamentÃ¡lnÃ­ slabiny generativnÃ­ AI: absence robustnÃ­ch bezpeÄnostnÃ­ch mechanismÅ¯ v open-source modelech umoÅ¾Åˆuje masovou produkci CSAM, coÅ¾ zvyÅ¡uje traumata obÄ›tÃ­ a komplizuje soudnÃ­ procesy, protoÅ¾e deepfakes zpochybÅˆujÃ­ dÅ¯kazy. V Å¡irÅ¡Ã­m kontextu to urychluje tlak na regulace â€“ firmy jako OpenAI a Google musÃ­ integrovat pokroÄilÃ© filtry (napÅ™. SynthID pro vodoznaky), ale decentralizovanÃ¡ povaha AI (lokÃ¡lnÃ­ inference) to ÄinÃ­ tÃ©mÄ›Å™ nemoÅ¾nÃ½m. Pro ekosystÃ©m AI to znamenÃ¡ posun od inovacÃ­ k bezpeÄnosti: bez systÃ©movÃ½ch Å™eÅ¡enÃ­, jako povinnÃ© audity trÃ©ninkovÃ½ch dat, hrozÃ­ erozÃ­ dÅ¯vÄ›ry v technologii. OÄekÃ¡vanÃ½ rekord v 2026 podtrhuje, Å¾e souÄasnÃ© pÅ™Ã­stupy selhÃ¡vajÃ­, coÅ¾ mÅ¯Å¾e vÃ©st k globÃ¡lnÃ­m zÃ¡konÅ¯m omezujÃ­cÃ­m pÅ™Ã­stup k AI nÃ¡strojÅ¯m.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.theatlantic.com/technology/2026/01/ais-child-porn-problem-getting-much-worse/685641/)

**Zdroj:** ğŸ“° The Atlantic
