---
author: Marisa Aigen
category: ai
companies:
- Anthropic
date: '2026-02-14 00:43:14'
description: AmerickÃ¡ armÃ¡da aktivnÄ› pouÅ¾ila model umÄ›lÃ© inteligence Claude od Anthropic
  bÄ›hem operace na zatÄenÃ­ venezuelskÃ©ho prezidenta NicolÃ¡se Madura minulÃ½ mÄ›sÃ­c,
  podle zprÃ¡v Wall Street Journal a Axios. Technologie firmy hrÃ¡la pÅ™Ã­mou roli v zahraniÄnÃ­
  razii.
importance: 5
layout: tech_news_article
original_title: Pentagon used Claude AI to kidnap Maduro â€“ media
publishedAt: '2026-02-14T00:43:14+00:00'
slug: pentagon-used-claude-ai-to-kidnap-maduro-media
source:
  emoji: ğŸ“°
  id: rt
  name: RT
title: Pentagon pouÅ¾il Claude AI k Ãºnosu Madura â€“ mÃ©dia
url: https://www.rt.com/news/632479-anthropic-pantagon-venezuela-raid/
urlToImage: https://mf.b37mrtl.ru/files/2026.02/article/698fc62a20302767f83d68b3.jpg
urlToImageBackup: https://mf.b37mrtl.ru/files/2026.02/article/698fc62a20302767f83d68b3.jpg
---

## Souhrn
AmerickÃ¡ armÃ¡da vyuÅ¾ila model umÄ›lÃ© inteligence Claude od spoleÄnosti Anthropic pÅ™Ã­mo bÄ›hem operace na zatÄenÃ­ venezuelskÃ©ho prezidenta NicolÃ¡se Madura minulÃ½ mÄ›sÃ­c. Podle zprÃ¡v Wall Street Journal a Axios Å¡lo o aktivnÃ­ nasazenÃ­ AI, nikoli pouze pÅ™Ã­pravnou fÃ¡zi. Anthropic, kterÃ½ se prezentuje dÅ¯razem na bezpeÄnostnÃ­ mechanismy, explicitnÄ› zakazuje pouÅ¾itÃ­ svÃ½ch technologiÃ­ k nÃ¡silÃ­, vÃ½voji zbranÃ­ nebo sledovÃ¡nÃ­.

## KlÃ­ÄovÃ© body
- Claude byl pouÅ¾it bÄ›hem samotnÃ© operace, coÅ¾ potvrzujÃ­ zdroje Axios a Wall Street Journal z 13. Ãºnora 2026.
- Role AI zÅ¯stÃ¡vÃ¡ neupÅ™esnÄ›nÃ¡, ale armÃ¡da ji dÅ™Ã­ve vyuÅ¾Ã­vala k analÃ½ze satelitnÃ­ch snÃ­mkÅ¯ a zpravodajskÃ½ch dat v reÃ¡lnÃ©m Äase.
- Anthropic, kalifornskÃ¡ firma zamÄ›Å™enÃ¡ na vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) s dÅ¯razem na bezpeÄnost, mÃ¡ v zÃ¡sadÃ¡ch jasnÃ½ zÃ¡kaz vojenskÃ©ho nasazenÃ­.
- Operace probÄ›hla ve Venezuele a skonÄila smrtÃ­cÃ­mi stÅ™ety, pÅ™iÄemÅ¾ se objevujÃ­ fotografie s prezidentem Trumpem, ministrem vÃ¡lky Petem Hegsethom a Å¡Ã©fem CIA Johnem Ratcliffem.
- ZprÃ¡va pochÃ¡zÃ­ z RT.com, kterÃ© odkazuje na americkÃ© mÃ©dia, coÅ¾ vyvolÃ¡vÃ¡ otÃ¡zky o ovÄ›Å™itelnosti v kontextu geopolitickÃ©ho napÄ›tÃ­.

## Podrobnosti
SpoleÄnost Anthropic, zaloÅ¾enÃ¡ v San Franciscu v roce 2021 bÃ½valÃ½mi vÃ½zkumnÃ­ky OpenAI, se specializuje na vÃ½voj pokroÄilÃ½ch modelÅ¯ umÄ›lÃ© inteligence, pÅ™edevÅ¡Ã­m velkÃ½ch jazykovÃ½ch modelÅ¯ jako Claude. Tyto modely slouÅ¾Ã­ k zpracovÃ¡nÃ­ textu, analÃ½ze dat, generovÃ¡nÃ­ odpovÄ›dÃ­ a pomoci pÅ™i sloÅ¾itÃ½ch Ãºkolech, jako je sumarizace dokumentÅ¯ nebo predikce na zÃ¡kladÄ› velkÃ½ch datovÃ½ch sad. Claude je navrÅ¾en s vestavÄ›nÃ½mi bezpeÄnostnÃ­mi vrstvami (safeguards), kterÃ© majÃ­ brÃ¡nit Å¡kodlivÃ©mu pouÅ¾itÃ­, vÄetnÄ› omezenÃ­ na citlivÃ© oblasti jako nÃ¡silÃ­ nebo surveillance. Firma veÅ™ejnÄ› zdÅ¯razÅˆuje etickÃ© standardy a odmÃ­tÃ¡ spoluprÃ¡ci s armÃ¡dou, na rozdÃ­l od konkurentÅ¯ jako OpenAI nebo Google.

Podle zprÃ¡v z 13. Ãºnora 2026 od Axios a Wall Street Journal Pentagon Claude aktivnÄ› nasadil bÄ›hem razie na Madura, kterÃ¡ mÄ›la smrtelnÃ© obÄ›ti. PÅ™esnÃ¡ funkce AI nenÃ­ znÃ¡mÃ¡, ale precedentnÃ­ pÅ™Ã­pady ukazujÃ­ na moÅ¾nÃ© vyuÅ¾itÃ­ k real-time analÃ½ze satelitnÃ­ch obrazÅ¯, rozpoznÃ¡vÃ¡nÃ­ vzorcÅ¯ v zpravodajskÃ½ch datech nebo optimalizaci taktickÃ½ch rozhodnutÃ­. ArmÃ¡da USA jiÅ¾ dÅ™Ã­ve experimentovala s AI modely pro podobnÃ© ÃºÄely, napÅ™Ã­klad v systÃ©mech jako Project Maven od Google, kterÃ½ analyzoval dronovÃ© snÃ­mky. Zde vÅ¡ak jde o pÅ™Ã­mÃ© poruÅ¡enÃ­ podmÃ­nek Anthropic, kterÃ© explicitnÄ› zakazujÃ­ â€facilitaci nÃ¡silÃ­, vÃ½voj zbranÃ­ nebo sledovÃ¡nÃ­â€œ. Nelze vylouÄit, Å¾e doÅ¡lo k neoprÃ¡vnÄ›nÃ©mu pÅ™Ã­stupu k modelu prostÅ™ednictvÃ­m API nebo upravenÃ© verze, coÅ¾ odhaluje slabiny v kontrolnÃ­ch mechanismech proprietÃ¡rnÃ­ch AI systÃ©mÅ¯.

Zdroj zprÃ¡vy, RT.com, je ruskÃ½ stÃ¡tnÃ­ mÃ©dia Äasto obviÅˆovanÃ½ z dezinformacÃ­, avÅ¡ak odkazuje na renomovanÃ¡ americkÃ¡ mÃ©dia, coÅ¾ dodÃ¡vÃ¡ urÄitou vÃ¡hu. Datum operace spadÃ¡ do ledna 2026, v obdobÃ­ zesÃ­lenÃ©ho napÄ›tÃ­ po inauguraci Trumpovy administrativy s hawkish postojem k LatinskÃ© Americe. Pokud se zprÃ¡va potvrdÃ­, znamenÃ¡ to precedent pro vojenskÃ© nasazenÃ­ komerÄnÃ­ch AI bez souhlasu vÃ½vojÃ¡Å™Å¯.

## ProÄ je to dÅ¯leÅ¾itÃ©
Toto odhalenÃ­ pÅ™edstavuje zÃ¡sadnÃ­ prÅ¯lom v diskusi o bezpeÄnosti AI, ukazujÃ­cÃ­, jak snadno lze obejÃ­t safeguards komerÄnÃ­ch modelÅ¯ v rukou stÃ¡tnÃ­ch aktÃ©rÅ¯. Pro prÅ¯mysl to znamenÃ¡ nutnost posÃ­lit prÃ¡vnÃ­ a technickÃ© bariÃ©ry, jako watermarking modelÅ¯ nebo federovanÃ© uÄenÃ­, aby se zabrÃ¡nilo nechtÄ›nÃ©mu Å¡Ã­Å™enÃ­ do vojenskÃ½ch aplikacÃ­. V Å¡irÅ¡Ã­m kontextu eskaluje debatu o regulacÃ­ch, jako nadchÃ¡zejÃ­cÃ­ EU AI Act nebo americkÃ© exekutivnÃ­ pÅ™Ã­kazy, kterÃ© se zamÄ›Å™ujÃ­ prÃ¡vÄ› na high-risk nasazenÃ­ v obranÄ›. Pro uÅ¾ivatele a vÃ½zkumnÃ­ky to podtrhuje rizika: pokud i firmy jako Anthropic selÅ¾ou v kontrole, narÅ¯stÃ¡ pravdÄ›podobnost zneuÅ¾itÃ­ v asymetrickÃ½ch konfliktech, coÅ¾ mÅ¯Å¾e vÃ©st k globÃ¡lnÃ­ kapkuvce v dÅ¯vÄ›Å™e k AI technologiÃ­m. CelkovÄ› to urychlÃ­ vÃ½voj odolnÄ›jÅ¡Ã­ch systÃ©mÅ¯, ale zÃ¡roveÅˆ otevÅ™e dveÅ™e k mezinÃ¡rodnÃ­m sporÅ¯m o suverenitu dat a etiku AI.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.rt.com/news/632479-anthropic-pantagon-venezuela-raid/)

**Zdroj:** ğŸ“° RT
