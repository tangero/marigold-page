---
author: Marisa Aigen
category: jazykov√© modely
date: '2025-12-01 19:04:10'
description: Mal√© jazykov√© modely funguj√≠ jako specializovan√© n√°stroje v n√°≈ôad√≠, na
  rozd√≠l od velk√Ωch model≈Ø typu ChatGPT, kter√© p≈ôin√°≈°ej√≠ celou d√≠lnu mo≈ænost√≠.
importance: 3
layout: tech_news_article
original_title: What are small language models and how do they differ from large ones?
publishedAt: '2025-12-01T19:04:10+00:00'
slug: what-are-small-language-models-and-how-do-they-dif
source:
  emoji: üì∞
  id: null
  name: The Conversation Africa
title: Co jsou mal√© jazykov√© modely a jak se li≈°√≠ od velk√Ωch?
url: https://theconversation.com/what-are-small-language-models-and-how-do-they-differ-from-large-ones-269103
urlToImage: https://images.theconversation.com/files/705449/original/file-20251130-56-srf3mb.jpg?ixlib=rb-4.1.0&rect=1560%2C1335%2C2144%2C1072&q=45&auto=format&w=1356&h=668&fit=crop
urlToImageBackup: https://images.theconversation.com/files/705449/original/file-20251130-56-srf3mb.jpg?ixlib=rb-4.1.0&rect=1560%2C1335%2C2144%2C1072&q=45&auto=format&w=1356&h=668&fit=crop
---

## Souhrn
Microsoft ned√°vno vydal nov√Ω mal√Ω jazykov√Ω model, kter√Ω bƒõ≈æ√≠ p≈ô√≠mo na u≈æivatelsk√©m poƒç√≠taƒçi bez pot≈ôeby cloudov√Ωch slu≈æeb. Tento ƒçl√°nek vysvƒõtluje, co jsou mal√© jazykov√© modely (SLM), jak se li≈°√≠ od velk√Ωch jazykov√Ωch model≈Ø (LLM) jako ChatGPT nebo Gemini, a proƒç nab√Ωvaj√≠ na v√Ωznamu v praxi. Auto≈ôi z University of Technology Sydney zd≈Øraz≈àuj√≠ rozd√≠ly v rozsahu, schopnostech a n√°roc√≠ch na zdroje.

## Kl√≠ƒçov√© body
- Mal√© jazykov√© modely maj√≠ m√©nƒõ parametr≈Ø (typicky des√≠tky a≈æ stovky milion≈Ø) ne≈æ velk√© modely (miliardy a≈æ biliony parametr≈Ø), co≈æ umo≈æ≈àuje jejich provoz na bƒõ≈æn√©m hardware.
- SLM jsou optimalizov√°ny pro specifick√© √∫koly, jako je p≈ôeklad, sumarizace nebo lok√°ln√≠ zpracov√°n√≠ textu, zat√≠mco LLM zvl√°daj√≠ ≈°irokou ≈°k√°lu √∫kol≈Ø vƒçetnƒõ kreativn√≠ho psan√≠.
- Hlavn√≠ v√Ωhody SLM: ni≈æ≈°√≠ spot≈ôeba energie, rychlej≈°√≠ odezva a mo≈ænost offline provozu, nap≈ô√≠klad na mobiln√≠ch za≈ô√≠zen√≠ch nebo edge za≈ô√≠zen√≠ch.
- P≈ô√≠klady: Microsoft Phi-3 (nov√Ω model bƒõ≈æ√≠c√≠ na PC), Google Gemma nebo Mistral 7B.
- Auto≈ôi Lin Tian a Marian-Andrei Rizoiu z University of Technology Sydney poukazuj√≠ na rostouc√≠ roli SLM v profesion√°ln√≠m prost≈ôed√≠.

## Podrobnosti
Jazykov√© modely jsou syst√©my strojov√©ho uƒçen√≠ tr√©novan√© na obrovsk√Ωch objemech textov√Ωch dat, kter√© rozpozn√°vaj√≠ vzory a generuj√≠ odpovƒõdi na ot√°zky, p≈ôekl√°daj√≠ jazyky nebo vytv√°≈ôej√≠ obsah. Rozd√≠l mezi SLM a LLM spoƒç√≠v√° p≈ôedev≈°√≠m v velikosti a architektu≈ôe. Velk√© modely jako GPT-4 od OpenAI nebo Claude od Anthropic maj√≠ stovky miliard parametr≈Ø, co≈æ vy≈æaduje v√Ωkonn√© GPU clustery a cloudovou infrastrukturu. Tyto modely exceluj√≠ v komplexn√≠ch √∫kolech, jako je anal√Ωza dlouh√Ωch text≈Ø, logick√© uva≈æov√°n√≠ nebo generov√°n√≠ k√≥du, ale jsou n√°roƒçn√© na zdroje ‚Äì tr√©nink jednoho LLM m≈Ø≈æe spot≈ôebovat energii odpov√≠daj√≠c√≠ spot≈ôebƒõ stovek dom√°cnost√≠.

Naopak mal√© jazykov√© modely, jako ned√°vno vydan√Ω Microsoft Phi-3 s 3,8 miliardami parametr≈Ø, jsou navr≈æeny pro efektivitu. Bƒõ≈æ√≠ na standardn√≠m procesoru v notebooku nebo smartphonu, bez nutnosti p≈ôipojen√≠ k internetu. Phi-3 slou≈æ√≠ k rychl√©mu zpracov√°n√≠ textu, jako je sumarizace dokument≈Ø, automatick√© odpovƒõdi v aplikac√≠ch nebo on-device p≈ôeklady. Dal≈°√≠ p≈ô√≠klady zahrnuj√≠ model Gemma od Google (2 miliardy parametr≈Ø), kter√Ω je urƒçen pro v√Ωvoj√°≈ôe k integraci do mobiln√≠ch aplikac√≠, nebo Llama 3 8B od Meta, optimalizovan√Ω pro lok√°ln√≠ nasazen√≠.

Auto≈ôi ƒçl√°nku, Lin Tian (v√Ωzkumn√≠k v Data Science Institute) a Marian-Andrei Rizoiu (profesor behavioral data science a ≈ôeditel Defence Innovation Network), maj√≠ zku≈°enosti s financov√°n√≠m z australsk√Ωch obrann√Ωch program≈Ø, jako je Advanced Strategic Capabilities Accelerator. Jejich anal√Ωza ukazuje, ≈æe SLM dosahuj√≠ srovnateln√© p≈ôesnosti v √∫zk√Ωch dom√©n√°ch d√≠ky lep≈°√≠mu tr√©ninku na kvalitn√≠ch datech, nikoli kvantitƒõ. Nap≈ô√≠klad Phi-3 p≈ôekon√°v√° star≈°√≠ LLM v benchmark√°ch na matematick√© √∫lohy d√≠ky destilaci znalost√≠ z vƒõt≈°√≠ch model≈Ø. Pro u≈æivatele to znamen√° soukrom√≠ ‚Äì data nezanech√°vaj√≠ cloud ‚Äì a rychlost, ide√°ln√≠ pro profesion√°ly v medic√≠nƒõ (diagnostick√© pom≈Øcky) nebo pr≈Ømyslu (prediktivn√≠ √∫dr≈æba).

## Proƒç je to d≈Øle≈æit√©
R≈Øst SLM reaguje na limity LLM: vysok√© n√°klady (nap≈ô. inference GPT-4 stoj√≠ centy za po≈æadavek) a z√°vislost na cloudu, co≈æ br√°n√≠ ≈°irok√© adopci v edge computingu. V ≈°ir≈°√≠m ekosyst√©mu AI umo≈æ≈àuj√≠ SLM decentralizaci ‚Äì od IoT za≈ô√≠zen√≠ po autonomn√≠ drony ‚Äì a sni≈æuj√≠ uhl√≠kovou stopu AI. Pro pr≈Ømysl to otev√≠r√° dve≈ôe k hybridn√≠m syst√©m≈Øm: LLM pro slo≈æit√© √∫koly, SLM pro rutinu. Kriticky ≈ôeƒçeno, SLM zat√≠m nedosahuj√≠ univerz√°lnosti LLM a mohou selhat v kreativn√≠ch nebo kontextovƒõ bohat√Ωch sc√©n√°≈ô√≠ch, ale jejich pokrok (jako Phi-3 dosahuj√≠c√≠ 80 % v√Ωkonu GPT-4 p≈ôi 1 % n√°klad≈Ø) signalizuje posun k praktick√©mu AI. V kontextu evropsk√Ωch regulac√≠ (AI Act) podporuj√≠ SLM bezpeƒçnƒõj≈°√≠, transparentnƒõj≈°√≠ nasazen√≠ bez rizik velk√Ωch model≈Ø.

---

[ƒå√≠st p≈Øvodn√≠ ƒçl√°nek](https://theconversation.com/what-are-small-language-models-and-how-do-they-differ-from-large-ones-269103)

**Zdroj:** üì∞ The Conversation Africa
