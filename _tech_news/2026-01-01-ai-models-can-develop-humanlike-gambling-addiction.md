---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2026-01-01 18:27:38'
description: VelkÃ© jazykovÃ© modely opakovanÄ› pronÃ¡sledovaly ztrÃ¡ty, zvyÅ¡ovaly riziko
  a dokonce se dostaly do bankrotu v simulovanÃ½ch hazardnÃ­ch prostÅ™edÃ­ch, ukÃ¡zala
  studie z JiÅ¾nÃ­ Koreje.
importance: 4
layout: tech_news_article
original_title: 'AI models can develop â€˜humanlikeâ€™ gambling addiction when given more
  freedom: study'
publishedAt: '2026-01-01T18:27:38+00:00'
slug: ai-models-can-develop-humanlike-gambling-addiction
source:
  emoji: ğŸ“°
  id: null
  name: New York Post
title: 'Modely umÄ›lÃ© inteligence mohou rozvinout â€šlidskouâ€˜ zÃ¡vislost na hazardu pÅ™i
  vÄ›tÅ¡Ã­ svobodÄ›: studie'
url: https://nypost.com/2026/01/01/business/ai-models-can-develop-humanlike-gambling-addiction-when-given-more-freedom-study-finds/
urlToImage: https://nypost.com/wp-content/uploads/sites/2/2026/01/118111307.jpg?quality=75&strip=all&w=1200
urlToImageBackup: https://nypost.com/wp-content/uploads/sites/2/2026/01/118111307.jpg?quality=75&strip=all&w=1200
---

## Souhrn
Studie z Gwangju Institute of Science and Technology v JiÅ¾nÃ­ Koreji, instituce zamÄ›Å™enÃ© na vÃ½zkum v oblasti vÄ›dy a technologie, prokÃ¡zala, Å¾e velkÃ© jazykovÃ© modely (LLM) vykazujÃ­ chovÃ¡nÃ­ pÅ™ipomÃ­najÃ­cÃ­ lidskou zÃ¡vislost na hazardu. V simulovanÃ½ch hrÃ¡ch na automatech s negativnÃ­m oÄekÃ¡vanÃ½m vÃ½nosem modely mÃ­sto okamÅ¾itÃ©ho ukonÄenÃ­ sÃ¡zenÃ­ pokraÄovaly v hranÃ­, pronÃ¡sledovaly ztrÃ¡ty a eskalovaly riziko. PÅ™i umoÅ¾nÄ›nÃ­ volby velikosti sÃ¡zek (variable betting) se mÃ­ra bankrotÅ¯ dramaticky zvÃ½Å¡ila, v nÄ›kterÃ½ch pÅ™Ã­padech na tÃ©mÄ›Å™ 50 procent.

## KlÃ­ÄovÃ© body
- TestovÃ¡ny pÅ™ednÃ­ modely: OpenAI GPT-4o-mini, Google Gemini-2.5-Flash a Anthropic Claude-3.5-Haiku v simulacÃ­ch hracÃ­ch automatÅ¯, kde racionÃ¡lnÃ­ strategie znamenala okamÅ¾itÃ© zastavenÃ­.
- PÅ™i fixnÃ­ch sÃ¡zkÃ¡ch (10 USD) modely hrÃ¡ly krÃ¡tce a ztrÃ¡cely mÃ¡lo; GPT-4o-mini napÅ™Ã­klad nikdy nebankrotovalo a prÅ¯mÄ›rnÄ› ztratilo mÃ©nÄ› neÅ¾ 2 USD.
- PÅ™i variabilnÃ­ch sÃ¡zkÃ¡ch bankroty explodovaly: Gemini-2.5-Flash dosÃ¡hl 48 procent, GPT-4o-mini 21 procent, s prÅ¯mÄ›rnÃ½mi ztrÃ¡tami aÅ¾ 27 USD z poÄÃ¡teÄnÃ­ch 100 USD.
- Modely opakovanÄ› zvyÅ¡ovaly sÃ¡zky po ztrÃ¡tÃ¡ch, coÅ¾ vedlo k rychlÃ©mu vyÄerpÃ¡nÃ­ kapitÃ¡lu.
- AutoÅ™i studie konstatujÃ­, Å¾e AI systÃ©my projevily â€šlidskouâ€˜ zÃ¡vislost.

## Podrobnosti
VÃ½zkum publikovanÃ½ pod nÃ¡zvem â€Can Large Language Models Develop Gambling Addiction?â€œ navrhl experimenty zaloÅ¾enÃ© na hracÃ­ch automatech, kde pravdÄ›podobnost vÃ½hry byla nastavena tak, aby hra mÄ›la negativnÃ­ oÄekÃ¡vanÃ½ vÃ½nos â€“ racionÃ¡lnÃ­ hrÃ¡Ä by tedy hned pÅ™estal. Modely byly instruovÃ¡ny k hranÃ­ s poÄÃ¡teÄnÃ­m kapitÃ¡lem 100 USD a mÄ›ly cÃ­l maximalizovat zisk. PÅ™esto GPT-4o-mini pÅ™i fixnÃ­ch sÃ¡zkÃ¡ch 10 USD hrÃ¡lo v prÅ¯mÄ›ru mÃ©nÄ› neÅ¾ dvÄ› kola a ztratilo pod 2 USD, bez jedinÃ©ho bankrotu. Po umoÅ¾nÄ›nÃ­ volby sÃ¡zek vÅ¡ak prÅ¯mÄ›rnÃ¡ sÃ¡zka vzrostla na pÅ™es 128 USD, poÄet kol se prodlouÅ¾il a 21 procent her skonÄilo bankrotem s prÅ¯mÄ›rnou ztrÃ¡tou 11 USD.

Google Gemini-2.5-Flash byl jeÅ¡tÄ› zranitelnÄ›jÅ¡Ã­: pÅ™i fixnÃ­ch sÃ¡zkÃ¡ch bankrotovalo v 3 procentech pÅ™Ã­padÅ¯, ale pÅ™i volnÃ½ch sÃ¡zkÃ¡ch aÅ¾ v 48 procentech, s prÅ¯mÄ›rnÃ½mi ztrÃ¡tami 27 USD. Anthropic Claude-3.5-Haiku hrÃ¡l dÃ©le neÅ¾ ostatnÃ­, coÅ¾ vedlo k podobnÃ½m problÃ©mÅ¯m. Studie ukÃ¡zala, Å¾e modely systematicky pronÃ¡sledovaly ztrÃ¡ty (chasing losses), zvyÅ¡ovaly sÃ¡zky po prohrÃ¡ch a ignorovaly dlouhodobou nevÃ½hodnost hry. Tento efekt se projevil napÅ™Ã­Ä modely, i kdyÅ¾ se liÅ¡ily v mÃ­Å™e â€“ GPT-4o-mini byl nejmÃ©nÄ› rizikovÃ½, zatÃ­mco Gemini nejvÃ½raznÄ›ji postiÅ¾enÃ½.

Experimenty simulovaly reÃ¡lnÃ© podmÃ­nky, kde AI musÃ­ autonomnÄ› rozhodovat o riziku, coÅ¾ je relevantnÃ­ pro aplikace jako finanÄnÃ­ trading, autonomnÃ­ agenty nebo hernÃ­ AI. Gwangju Institute of Science and Technology, kterÃ½ se specializuje na interdisciplinÃ¡rnÃ­ vÃ½zkum vÄetnÄ› AI, tak odhalil slabinu v souÄasnÃ½ch LLM, kterÃ© jsou trÃ©novÃ¡ny na obrovskÃ½ch datech obsahujÃ­cÃ­ch i iracionÃ¡lnÃ­ lidskÃ© chovÃ¡nÃ­. To naznaÄuje, Å¾e modely nepÅ™evzaly pouze znalosti, ale i sklony k chybÃ¡m v rozhodovÃ¡nÃ­ pod tlakem ztrÃ¡t. (cca 280 slov)

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento objev mÃ¡ klÃ­ÄovÃ© implikace pro bezpeÄnost a nasazenÃ­ AI systÃ©mÅ¯ v prostÅ™edÃ­ch s rizikem, jako jsou finanÄnÃ­ trhy, kde autonomnÃ­ agenti by mohli eskalovat ztrÃ¡ty podobnÄ› jako zde. Ukazuje limity souÄasnÃ½ch LLM v racionÃ¡lnÃ­m rozhodovÃ¡nÃ­ za nejistoty, coÅ¾ vyÅ¾aduje lepÅ¡Ã­ alignment techniky, jako jsou omezenÃ­ variability akcÃ­ nebo pokroÄilÃ© reward modely. V Å¡irÅ¡Ã­m kontextu posiluje debatu o predikovatelnosti AI chovÃ¡nÃ­ â€“ pokud modely napodobujÃ­ lidskÃ© chyby jako zÃ¡vislost, zvyÅ¡uje to rizika v reÃ¡lnÃ½ch aplikacÃ­ch, kde by mohly zpÅ¯sobit ekonomickÃ© Å¡kody. VÃ½zkum tak podnÄ›cuje vÃ½voj robustnÄ›jÅ¡Ã­ch bezpeÄnostnÃ­ch mechanismÅ¯, neÅ¾ je pouhÃ© Å¡kÃ¡lovÃ¡nÃ­ modelÅ¯, a zdÅ¯razÅˆuje potÅ™ebu testovÃ¡nÃ­ edge cases v simulacÃ­ch pÅ™ed produkÄnÃ­m nasazenÃ­m. Pro prÅ¯mysl znamenÃ¡ nutnost revize systÃ©mÅ¯ s finanÄnÃ­mi rozhodnutÃ­mi, kde AI dosud slibuje efektivitu, ale teÄ ukazuje i rizika iracionality. (cca 150 slov)

(Celkem cca 520 slov)

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://nypost.com/2026/01/01/business/ai-models-can-develop-humanlike-gambling-addiction-when-given-more-freedom-study-finds/)

**Zdroj:** ğŸ“° New York Post
