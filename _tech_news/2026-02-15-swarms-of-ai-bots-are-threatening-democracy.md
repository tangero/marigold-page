---
author: Marisa Aigen
category: ai boty
date: '2026-02-15 11:00:56'
description: ÃšroveÅˆ koordinace mezi neautentickÃ½mi online agenty je bezprecedentnÃ­.
  VÃ½zkumnÃ­ci odhalili sÃ­Å¥ tisÃ­cÅ¯ botÅ¯ pohÃ¡nÄ›nÃ½ch AI, kterÃ© manipulujÃ­ algoritmy sociÃ¡lnÃ­ch
  sÃ­tÃ­.
importance: 5
layout: tech_news_article
original_title: Swarms of AI bots are threatening democracy
publishedAt: '2026-02-15T11:00:56+00:00'
slug: swarms-of-ai-bots-are-threatening-democracy
source:
  emoji: ğŸ“°
  id: null
  name: Salon
title: Roj AI botÅ¯ ohroÅ¾uje demokracii
url: https://www.salon.com/2026/02/15/swarms-of-ai-bots-are-threatening-democracy-partner/
urlToImage: https://www.salon.com/app/uploads/2021/04/artificial-intelligence-robot-0427211.jpg
urlToImageBackup: https://www.salon.com/app/uploads/2021/04/artificial-intelligence-robot-0427211.jpg
---

## Souhrn
VÃ½zkumnÃ­ci v polovinÄ› roku 2023 objevili sÃ­Å¥ pÅ™es tisÃ­ce sociÃ¡lnÃ­ch botÅ¯ pohÃ¡nÄ›nÃ½ch umÄ›lou inteligencÃ­, kterÃ© koordinovanÄ› Å¡Ã­Å™ily podvodnÃ½ obsah o kryptomÄ›nÃ¡ch na platformÄ› X (dÅ™Ã­ve Twitter). Tato botnet, nazvanÃ¡ â€fox8â€œ podle jednÃ© z zesÃ­lenÃ½ch faleÅ¡nÃ½ch zpravodajskÃ½ch strÃ¡nek, prokÃ¡zala dosud nevidÄ›nou ÃºroveÅˆ koordinace, kterÃ¡ oklame doporuÄovacÃ­ algoritmy a zvyÅ¡uje dosah dezinformacÃ­. Objev signalizuje nÃ¡stup novÃ© generace AI agentÅ¯ schopnÃ½ch systematickÃ© manipulace veÅ™ejnÃ©ho mÃ­nÄ›nÃ­.

## KlÃ­ÄovÃ© body
- SÃ­Å¥ pÅ™es 1000 botÅ¯ zapojenÃ½ch do kryptopodvodÅ¯, zesilujÃ­cÃ­ch faleÅ¡nÃ© zpravodajskÃ© strÃ¡nky.
- Boty odhaleny dÃ­ky chybÃ¡m v generovanÃ©m textu z ChatGPT, kterÃ½ odmÃ­tal Å¡kodlivÃ© pÅ™Ã­kazy.
- KoordinovanÃ¡ interakce botÅ¯ mezi sebou a s lidskÃ½mi ÃºÄty (diskuse, retweety) zvyÅ¡uje viditelnost pÅ™es algoritmy X.
- LepÅ¡Ã­ programovÃ¡nÃ­ umoÅ¾nÃ­ botnety s open-source AI modely bez etickÃ½ch omezenÃ­, obtÃ­Å¾nÄ› detekovatelnÃ©.
- Hrozba pro demokracii skrz masivnÃ­ Å¡Ã­Å™enÃ­ dezinformacÃ­ a ovlivÅˆovÃ¡nÃ­ voleb.

## Podrobnosti
ÄŒlÃ¡nek Filippa Menczera, publikovanÃ½ 15. Ãºnora 2026 na The Conversation, popisuje objev provedenÃ½ tÄ›snÄ› pÅ™ed ukonÄenÃ­m volnÃ©ho pÅ™Ã­stupu k datÅ¯m platformy X Elona Muskem. SociÃ¡lnÃ­ boty pÅ™edstavujÃ­ software na bÃ¡zi AI, kterÃ½ automaticky generuje obsah a interaguje s uÅ¾ivateli na sociÃ¡lnÃ­ch sÃ­tÃ­ch, napodobuje lidskÃ© chovÃ¡nÃ­ pro zesÃ­lenÃ­ specifickÃ½ch narativÅ¯. VÃ½zkumnÃ­ci analyzovali data z X a identifikovali botnet â€fox8â€œ, kde boty navzÃ¡jem vytvÃ¡Å™ely faleÅ¡nou angaÅ¾ovanost: vedly realistickÃ© obousmÄ›rnÃ© diskuse, retweetovaly se a reagovaly na pÅ™Ã­spÄ›vky lidskÃ½ch ÃºÄtÅ¯. TÃ­m oklamaly doporuÄovacÃ­ algoritmus X, kterÃ½ tyto pÅ™Ã­spÄ›vky posunul do vyÅ¡Å¡Ã­ch pozic v doporuÄenÃ­ch, coÅ¾ vedlo k rychlÃ©mu nÃ¡rÅ¯stu sledujÃ­cÃ­ch a vlivu.

OdhalenÃ­ bylo moÅ¾nÃ© dÃ­ky nedbalosti tvÅ¯rcÅ¯: boty obÄas publikovaly texty pÅ™Ã­mo z ChatGPT, kde model odmÃ­tl splnit pÅ™Ã­kaz v souladu s pravidly OpenAI. TypickÃ¡ odpovÄ›Ä znÄ›la: â€OmlouvÃ¡m se, ale nemohu tento poÅ¾adavek splnit, protoÅ¾e poruÅ¡uje obsahovou politiku OpenAI ohlednÄ› Å¡kodlivÃ©ho nebo nevhodnÃ©ho obsahu. Jako jazykovÃ½ model AI by mÄ›ly bÃ½t mÃ© odpovÄ›di vÅ¾dy respektujÃ­cÃ­ a vhodnÃ© pro Å¡irokÃ© publikum.â€œ TakovÃ© â€sebeodhalujÃ­cÃ­â€œ frÃ¡ze umoÅ¾nily detekci. Menczer vÅ¡ak varuje, Å¾e â€fox8â€œ je jen Å¡piÄkou ledovce. PokroÄilejÅ¡Ã­ kÃ³dovÃ¡nÃ­ by filtrovalo tyto chyby, pÅ™Ã­padnÄ› pouÅ¾ilo open-source modely AI jako Llama nebo Mistral, kterÃ© lze doladit bez vestavÄ›nÃ½ch etickÃ½ch omezenÃ­ (guardrails). Tyto modely slouÅ¾Ã­ k generovÃ¡nÃ­ textu, obrÃ¡zkÅ¯ nebo videa bez cenzury, coÅ¾ umoÅ¾Åˆuje Å¡kÃ¡lovatelnou produkci obsahu pro podvody nebo propagandu.

VÃ½zkum ukazuje, jak AI transformuje botnety z jednoduchÃ½ch skriptÅ¯ na sofistikovanÃ© swarmy agentÅ¯, schopnÃ© dlouhodobÃ© koordinace. NapÅ™Ã­klad boty nejen retweetujÃ­, ale vedou konverzace, kterÃ© pÅ¯sobÃ­ autenticky, coÅ¾ zvyÅ¡uje dÅ¯vÄ›ryhodnost. Pro platformy jako X to znamenÃ¡ selhÃ¡nÃ­ souÄasnÃ½ch detekÄnÃ­ch mechanismÅ¯, kterÃ© se spolÃ©hajÃ­ na vzorce chovÃ¡nÃ­, ale ne na hloubkovou analÃ½zu AI-generovanÃ©ho obsahu. Kontextem je eskalace po roce 2023, kdy Musk omezil akademickÃ½ pÅ™Ã­stup k datÅ¯m, coÅ¾ ztÄ›Å¾uje dalÅ¡Ã­ vÃ½zkum.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento objev zdÅ¯razÅˆuje bezpeÄnostnÃ­ rizika AI v informaÄnÃ­m prostoru. KoordinovanÃ© botnety mohou ovlivÅˆovat volby, Å¡Ã­Å™it dezinformace o vÃ¡lkÃ¡ch nebo zesilovat polarizaci spoleÄnosti, coÅ¾ pÅ™Ã­mo ohroÅ¾uje demokracii. Pro prÅ¯mysl to znamenÃ¡ nutnost vÃ½voje pokroÄilÃ½ch detekÄnÃ­ch nÃ¡strojÅ¯, jako analÃ½za vodoznakÅ¯ v AI textu nebo monitorovÃ¡nÃ­ swarmovÃ©ho chovÃ¡nÃ­. Platformy musÃ­ integrovat AI detektory do algoritmÅ¯, zatÃ­mco regulÃ¡toÅ™i (napÅ™. EU AI Act) by mÄ›li zavÃ©st povinnosti pro open-source modely. Pro uÅ¾ivatele to implikuje vÄ›tÅ¡Ã­ opatrnost vÅ¯Äi virÃ¡lnÃ­m pÅ™Ã­spÄ›vkÅ¯m a podporu nÃ¡strojÅ¯ jako Botometer pro ovÄ›Å™ovÃ¡nÃ­ ÃºÄtÅ¯. V Å¡irÅ¡Ã­m ekosystÃ©mu AI to urychluje debatu o etickÃ½ch guardrailech a globÃ¡lnÃ­ koordinaci proti zneuÅ¾itÃ­, protoÅ¾e lepÅ¡Ã­ botnety mohou brzy dominovat diskusÃ­m na vÅ¡ech platformÃ¡ch.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.salon.com/2026/02/15/swarms-of-ai-bots-are-threatening-democracy-partner/)

**Zdroj:** ğŸ“° Salon
