---
author: Marisa Aigen
category: ai
date: '2025-12-01 16:15:55'
description: Arbitr konstatoval, Å¾e vedenÃ­ Politico poruÅ¡ilo kolektivnÃ­ smlouvu pÅ™i
  zavÃ¡dÄ›nÃ­ dvou AI nÃ¡strojÅ¯ v redakci. NovinÃ¡Å™i vyhrÃ¡li spor o 60dennÃ­ lhÅ¯tu na vyjednÃ¡vÃ¡nÃ­
  a poÅ¾adavky na etiku a lidskÃ½ dohled.
importance: 3
layout: tech_news_article
original_title: Politico management violated key AI adoption safeguards, arbitrator
  finds
publishedAt: '2025-12-01T16:15:55+00:00'
slug: politico-management-violated-key-ai-adoption-safeg
source:
  emoji: ğŸ“°
  id: null
  name: Niemanlab.org
title: Management Politico poruÅ¡il klÃ­ÄovÃ¡ opatÅ™enÃ­ pro zavÃ¡dÄ›nÃ­ AI, rozhodlä»²è£r
url: https://www.niemanlab.org/2025/12/politico-management-violated-key-ai-adoption-safeguards-arbitrator-finds/
urlToImage: https://www.niemanlab.org/images/Politico-Newsbox-700x467.webp
urlToImageBackup: https://www.niemanlab.org/images/Politico-Newsbox-700x467.webp
---

## Souhrn
MinulÃ½ tÃ½den vyhrÃ¡li odborem pojiÅ¡tÄ›nÃ­ novinÃ¡Å™i v Politico, americkÃ©m zpravodajskÃ©m portÃ¡lu, vÃ½znamnÃ½ spor v arbitrÃ¡Å¾i o zavÃ¡dÄ›nÃ­ umÄ›lÃ© inteligence (AI). Arbitr v rozhodnutÃ­ ze 26. listopadu shledal, Å¾e management poruÅ¡il klauzule kolektivnÃ­ smlouvy, kterÃ© stanovujÃ­ 60dennÃ­ lhÅ¯tu na vyjednÃ¡vÃ¡nÃ­ o AI ovlivÅˆujÃ­cÃ­m pracovnÃ­ povinnosti a vyÅ¾adujÃ­ etickÃ© standardy s lidskÃ½m dohledem pro AI v novinÃ¡Å™skÃ© prÃ¡ci. Toto rozhodnutÃ­ pÅ™edstavuje jeden z prvnÃ­ch velkÃ½ch testÅ¯ takovÃ½ch ustanovenÃ­ v odborovÃ½ch smlouvÃ¡ch.

## KlÃ­ÄovÃ© body
- Management Politico zavÃ¡dÄ›l dva AI nÃ¡stroje pro redakÄnÃ­ ÃºÄely bez 60dennÃ­ lhÅ¯ty na vyjednÃ¡vÃ¡nÃ­ s odbory.
- AI nÃ¡stroje pouÅ¾itÃ© pro sbÄ›r zprÃ¡v nesplÅˆovaly poÅ¾adavky na Å¾urnalistickou etiku a chybÄ›l u nich lidskÃ½ dohled.
- Arbitr zdÅ¯raznil, Å¾e AI zvyÅ¡uje rychlost na Ãºkor pÅ™esnosti a odpovÄ›dnosti oproti lidskÃ© prÃ¡ci.
- NewsGuild-CWA, nejvÄ›tÅ¡Ã­ americkÃ½ odbor novinÃ¡Å™Å¯, mÃ¡ v 43 kolektivnÃ­ch smlouvÃ¡ch ustanovenÃ­ o AI.
- RozhodnutÃ­ bylo zveÅ™ejnÄ›no 1. prosince 2025 a analyzovÃ¡no portÃ¡lem Nieman Lab.

## Podrobnosti
Politico, specializujÃ­cÃ­ se na politickÃ© zpravodajstvÃ­ ve Washingtonu, mÃ¡ kolektivnÃ­ smlouvu s odborem NewsGuild-CWA, kterÃ¡ obsahuje specifickÃ¡ omezenÃ­ pro zavÃ¡dÄ›nÃ­ AI. Podle nÃ­ musÃ­ management poskytnout odbory 60 dnÃ­ na vyjednÃ¡vÃ¡nÃ­ o jakÃ©koli novÃ© AI technologii, kterÃ¡ "materiÃ¡lnÄ› a podstatnÄ›" ovlivÅˆuje pracovnÃ­ povinnosti ÄlenÅ¯. DÃ¡le, pokud AI slouÅ¾Ã­ k "sbÄ›ru zprÃ¡v" (newsgathering), musÃ­ splÅˆovat standardy Å¾urnalistickÃ© etiky Politico a zahrnovat lidskÃ½ dohled. Arbitr v rozhodnutÃ­, kterÃ© zveÅ™ejnil Nieman Lab, jednoznaÄnÄ› konstatoval poruÅ¡enÃ­ obou tÄ›chto ustanovenÃ­ pÅ™i zavÃ¡dÄ›nÃ­ dvou nedÃ¡vnÃ½ch AI nÃ¡strojÅ¯ pro redakÄnÃ­ procesy. Tyto nÃ¡stroje, urÄenÃ© pro zpracovÃ¡nÃ­ a generovÃ¡nÃ­ obsahu, byly nasazeny bez pÅ™edchozÃ­ konzultace, coÅ¾ vedlo k arbitrÃ¡Å¾i.

Arbitr citoval: "Pokud je cÃ­lem rychlost a cenou pÅ™esnost a odpovÄ›dnost, AI jasnÄ› vÃ­tÄ›zÃ­. Pokud je pÅ™esnost a odpovÄ›dnost zÃ¡kladnou, pak AI, jak bylo pouÅ¾ito v tÄ›chto pÅ™Ã­padech, dosud nemÅ¯Å¾e konkurovat znakÅ¯m lidskÃ©ho vÃ½stupu." Tento zÃ¡vÄ›r odrÃ¡Å¾Ã­ bÄ›Å¾nÃ© rizika AI v Å¾urnalistice, kde modely jako velkÃ© jazykovÃ© modely (LLM) generujÃ­ text rychle, ale Äasto s halucinacemi â€“ vymÃ½Å¡lenÃ½mi fakty â€“ nebo zkreslenÃ½mi informacemi z trÃ©novacÃ­ch dat. V praxi to znamenÃ¡, Å¾e AI mÅ¯Å¾e slouÅ¾it k sumarizaci zprÃ¡v nebo generovÃ¡nÃ­ nÃ¡vrhÅ¯, ale bez lidskÃ©ho ovÄ›Å™enÃ­ hrozÃ­ Å¡Ã­Å™enÃ­ dezinformacÃ­. NewsGuild-CWA, zaloÅ¾enÃ½ v roce 1933 a reprezentujÃ­cÃ­ tisÃ­ce novinÃ¡Å™Å¯, zaÄal do smluv zahrnovat AI klauzule od roku 2023 v reakci na rostoucÃ­ tlak mÃ©diÃ­ na automatizaci. K zÃ¡Å™Ã­ 2025 jich bylo 43, coÅ¾ ukazuje na Å¡Ã­Å™Ã­cÃ­ se trend v americkÃ©m mediÃ¡lnÃ­m prÅ¯myslu.

## ProÄ je to dÅ¯leÅ¾itÃ©
RozhodnutÃ­ vytvÃ¡Å™Ã­ precedent pro odbory v mÃ©diÃ­ch, kde AI rychle mÄ›nÃ­ pracovnÃ­ postupy â€“ od automatizovanÃ©ho psanÃ­ ÄlÃ¡nkÅ¯ po analÃ½zu dat. Pro prÅ¯mysl znamenÃ¡ posÃ­lenÃ­ vyjednÃ¡vacÃ­ pozice zamÄ›stnancÅ¯ proti unÃ¡hlenÃ©mu nasazenÃ­ AI, coÅ¾ chrÃ¡nÃ­ kvalitu Å¾urnalistiky pÅ™ed komerÄnÃ­m tlakem na efektivitu. V Å¡irÅ¡Ã­m kontextu AI ekosystÃ©mu podtrhuje nutnost regulacÃ­ pracovnÃ­ch dopadÅ¯, podobnÄ› jako v EvropÄ› s AI Actem, kterÃ½ vyÅ¾aduje transparentnost u vysoce rizikovÃ½ch systÃ©mÅ¯. Pro uÅ¾ivatele mÃ©diÃ­ to znamenÃ¡ potenciÃ¡lnÄ› vyÅ¡Å¡Ã­ dÅ¯vÄ›ryhodnost obsahu, protoÅ¾e vynucuje lidskÃ½ dohled a etickÃ© kontroly. NicmÃ©nÄ› kriticky: odbory musÃ­ specifikovat, jakÃ© AI nÃ¡stroje (napÅ™. pro transkripci nebo sumarizaci) jsou pÅ™ijatelnÃ©, aby nezpÅ¯sobily stagnaci inovacÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.niemanlab.org/2025/12/politico-management-violated-key-ai-adoption-safeguards-arbitrator-finds/)

**Zdroj:** ğŸ“° Niemanlab.org
