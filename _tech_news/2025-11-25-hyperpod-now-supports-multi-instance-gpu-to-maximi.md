---
author: Marisa Aigen
category: ai infrastruktura
companies:
- Amazon
- NVIDIA
date: '2025-11-25 16:10:39'
description: Amazon SageMaker HyperPod nynÃ­ podporuje technologii NVIDIA Multi-Instance
  GPU (MIG), kterÃ¡ umoÅ¾Åˆuje rozdÄ›lit vÃ½konnÃ© GPU na nÄ›kolik izolovanÃ½ch instancÃ­ pro
  paralelnÃ­ spouÅ¡tÄ›nÃ­ rÅ¯znÃ½ch Ãºloh, jako je inference, vÃ½zkum nebo interaktivnÃ­ prÃ¡ce.
importance: 3
layout: tech_news_article
original_title: HyperPod now supports Multi-Instance GPU to maximize GPU utilization
  for generative AI tasks
publishedAt: '2025-11-25T16:10:39+00:00'
slug: hyperpod-now-supports-multi-instance-gpu-to-maximi
source:
  emoji: ğŸ“°
  id: null
  name: Amazon.com
title: HyperPod nynÃ­ podporuje Multi-Instance GPU pro lepÅ¡Ã­ vyuÅ¾itÃ­ GPU pÅ™i generativnÃ­ch
  AI ÃºlohÃ¡ch
url: https://aws.amazon.com/blogs/machine-learning/hyperpod-now-supports-multi-instance-gpu-to-maximize-gpu-utilization-for-generative-ai-tasks/
urlToImage: https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/24/ML-19983-2-1144x630.png
urlToImageBackup: https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2025/11/24/ML-19983-2-1144x630.png
---

## Souhrn
Amazon SageMaker HyperPod nynÃ­ plnÄ› podporuje technologii NVIDIA Multi-Instance GPU (MIG), dÃ­ky ÄemuÅ¾ lze jednotlivÃ¡ GPU rozdÄ›lit na vÃ­ce izolovanÃ½ch instancÃ­. Tato funkce zvyÅ¡uje vyuÅ¾itÃ­ vÃ½poÄetnÃ­ch a pamÄ›Å¥ovÃ½ch prostÅ™edkÅ¯ pÅ™i bÄ›hu lehkÃ½ch AI Ãºloh, jako je inference jazykovÃ½ch modelÅ¯, prototypovÃ¡nÃ­ modelÅ¯ nebo prÃ¡ce v Jupyter notebooku.

## KlÃ­ÄovÃ© body
- HyperPod nynÃ­ umoÅ¾Åˆuje paralelnÃ­ bÄ›h vÃ­ce Ãºloh na jednom fyzickÃ©m GPU pomocÃ­ MIG.
- Podpora zahrnuje GPU zaloÅ¾enÃ© na architektuÅ™e NVIDIA Ampere, napÅ™Ã­klad A100 (EC2 P4) a A10G (EC2 G5).
- Izolace mezi instancemi zajiÅ¡Å¥uje bezpeÄnost a stabilitu vÃ½konu jednotlivÃ½ch Ãºloh.
- AdministrÃ¡toÅ™i clusterÅ¯ mohou efektivnÄ›ji alokovat zdroje mezi rÅ¯znÃ© tÃ½my (datovÃ­ vÄ›dci, ML inÅ¾enÃ½Å™i, infrastruktura).
- SnÃ­Å¾enÃ­ ÄekacÃ­ch dob na GPU a zkrÃ¡cenÃ­ vÃ½vojovÃ½ch cyklÅ¯.

## Podrobnosti
NVIDIA Multi-Instance GPU (MIG) byla pÅ™edstavena v roce 2020 spolu s architekturou Ampere. UmoÅ¾Åˆuje rozdÄ›lit jedno GPU (napÅ™. A100) na aÅ¾ sedm nezÃ¡vislÃ½ch instancÃ­, z nichÅ¾ kaÅ¾dÃ¡ mÃ¡ vlastnÃ­ pamÄ›Å¥, cache a vÃ½poÄetnÃ­ jednotky. Amazon nynÃ­ tuto technologii integroval do SageMaker HyperPod â€“ spravovanÃ© platformy pro Å¡kÃ¡lovatelnÃ½ vÃ½voj a nasazenÃ­ AI modelÅ¯. DÃ­ky tomu mohou uÅ¾ivatelÃ© spouÅ¡tÄ›t lehkÃ© Ãºlohy, kterÃ© by jinak nevyuÅ¾Ã­valy plnÃ½ vÃ½kon celÃ©ho GPU, na menÅ¡Ã­ch izolovanÃ½ch ÄÃ¡stech. NapÅ™Ã­klad inference jazykovÃ©ho modelu nebo experimenty s klasifikacÃ­ obrazu v Jupyter notebooku mohou bÄ›Å¾et paralelnÄ› na stejnÃ©m hardwaru bez vzÃ¡jemnÃ©ho ovlivnÄ›nÃ­. Platforma zÃ¡roveÅˆ poskytuje pÅ™ehled o vyuÅ¾itÃ­ vÃ½poÄetnÃ­ch a pamÄ›Å¥ovÃ½ch zdrojÅ¯ na Ãºrovni jednotlivÃ½ch MIG instancÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato funkce pÅ™inÃ¡Å¡Ã­ vÃ½znamnÃ© zlepÅ¡enÃ­ efektivity vÃ½poÄetnÃ­ch clusterÅ¯, zejmÃ©na v prostÅ™edÃ­ch, kde bÄ›Å¾Ã­ smÄ›s lehkÃ½ch a nÃ¡roÄnÃ½ch Ãºloh. Pro organizace, kterÃ© provozujÃ­ vlastnÃ­ AI infrastrukturu v cloudu, to znamenÃ¡ niÅ¾Å¡Ã­ nÃ¡klady a lepÅ¡Ã­ vyuÅ¾itÃ­ investic do drahÃ½ch GPU. ZÃ¡roveÅˆ podporuje agilnÄ›jÅ¡Ã­ vÃ½voj â€“ datovÃ­ vÄ›dci nemusÃ­ Äekat na uvolnÄ›nÃ­ celÃ©ho GPU, ale mohou okamÅ¾itÄ› vyuÅ¾Ã­t dostupnou MIG instanci. V kontextu rostoucÃ­ poptÃ¡vky po generativnÃ­ AI jde o pragmatickÃ½ krok k optimalizaci existujÃ­cÃ­ch zdrojÅ¯, nikoli o zÃ¡sadnÃ­ prÅ¯lom, ale jistÄ› o uÅ¾iteÄnÃ© vylepÅ¡enÃ­ pro praxi.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://aws.amazon.com/blogs/machine-learning/hyperpod-now-supports-multi-instance-gpu-to-maximize-gpu-utilization-for-generative-ai-tasks/)

**Zdroj:** ğŸ“° Amazon.com
