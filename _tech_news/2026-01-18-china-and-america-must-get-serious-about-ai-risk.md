---
author: Marisa Aigen
category: ai rizika
date: '2026-01-18 00:15:01'
description: V listopadu 2024 vydali prezidenti Joe Biden a Si Å¤in-pching prvnÃ­ podstatnÃ©
  spoleÄnÃ© prohlÃ¡Å¡enÃ­ k nÃ¡rodnÄ›bezpeÄnostnÃ­m rizikÅ¯m spojenÃ½m s umÄ›lou inteligencÃ­.
  Oba stÃ¡ty uznÃ¡vajÃ­ potÅ™ebu spoluprÃ¡ce pÅ™i Å™eÅ¡enÃ­ tÄ›chto rizik.
importance: 4
layout: tech_news_article
original_title: China and America Must Get Serious About AI Risk
people:
- Joe Biden
- Xi Jinping
publishedAt: '2026-01-18T00:15:01+00:00'
slug: china-and-america-must-get-serious-about-ai-risk
source:
  emoji: ğŸ“°
  id: null
  name: Khabarhub.com
title: ÄŒÃ­na a USA se musÃ­ vÃ¡Å¾nÄ› zabÃ½vat riziky umÄ›lÃ© inteligence
url: https://english.khabarhub.com/2026/18/516408/
urlToImage: https://english.khabarhub.com/wp-content/uploads/2026/01/Khabar-Hub-Article_Jake-Sullivan_1200px-630X-px-Final_2026.01.16-Upload.jpg
urlToImageBackup: https://english.khabarhub.com/wp-content/uploads/2026/01/Khabar-Hub-Article_Jake-Sullivan_1200px-630X-px-Final_2026.01.16-Upload.jpg
---

## Souhrn
V listopadu 2024 se na summitu APEC v Peru shodli prezident USA Joe Biden a prezident ÄŒÃ­ny Si Å¤in-pching na prvnÃ­m substantivnÃ­m spoleÄnÃ©m prohlÃ¡Å¡enÃ­ tÃ½kajÃ­cÃ­m se nÃ¡rodnÄ›bezpeÄnostnÃ­ch rizik umÄ›lÃ© inteligence. Dokument zdÅ¯razÅˆuje, Å¾e obÄ› zemÄ› vidÃ­ v AI potenciÃ¡lnÃ­ hrozby pro stabilitu a bezpeÄnost, a vyzÃ½vÃ¡ k vzÃ¡jemnÃ© spoluprÃ¡ci na jejich mitigaci. Toto prohlÃ¡Å¡enÃ­ pÅ™ichÃ¡zÃ­ v dobÄ› eskalujÃ­cÃ­ soutÄ›Å¾e v rozvoji AI mezi obÄ›ma supervelmocemi.

## KlÃ­ÄovÃ© body
- PrvnÃ­ spoleÄnÃ© uznÃ¡nÃ­ rizik AI pro nÃ¡rodnÃ­ bezpeÄnost obÄ›ma stÃ¡ty.
- ZÃ¡vazek k rozvoji spoleÄnÃ½ch bezpeÄnostnÃ­ch standardÅ¯ a testovacÃ­ch postupÅ¯ pro AI systÃ©my.
- Dohoda o sdÃ­lenÃ­ informacÃ­ o incidentech souvisejÃ­cÃ­ch s AI riziky.
- ZdÅ¯raznÄ›nÃ­ nutnosti udrÅ¾ovÃ¡nÃ­ 'klidnÃ½ch vod' v oblasti vojenskÃ½ch aplikacÃ­ AI.
- PlÃ¡n na pokraÄujÃ­cÃ­ konzultace prostÅ™ednictvÃ­m pracovnÃ­ch skupin.

## Podrobnosti
ProhlÃ¡Å¡enÃ­ bylo vydÃ¡no 16. listopadu 2024 po bilaterÃ¡lnÃ­m setkÃ¡nÃ­ na okraji summitu Asijsko-tichomoÅ™skÃ© ekonomickÃ© spoluprÃ¡ce v LimÄ›. V osmi bodech dokumentu obÄ› strany konstatujÃ­, Å¾e pokroÄilÃ© AI systÃ©my pÅ™inÃ¡Å¡ejÃ­ nejen pÅ™Ã­leÅ¾itosti, ale i zÃ¡vaÅ¾nÃ¡ rizika, vÄetnÄ› ztrÃ¡ty kontroly nad autonomnÃ­mi systÃ©my, manipulace informacÃ­ nebo eskalace konfliktÅ¯ prostÅ™ednictvÃ­m AI podporovanÃ½ch zbranÃ­. KonkrÃ©tnÄ› se shodly na tom, Å¾e je nutnÃ© rozvÃ­jet rÃ¡mce pro posouzenÃ­ rizik, vÄetnÄ› testÅ¯ na robustnost modelÅ¯ vÅ¯Äi chybÃ¡m nebo zneuÅ¾itÃ­. ÄŒÃ­na a USA se zavÃ¡zaly k pravidelnÃ©mu vymÄ›ÅˆovÃ¡nÃ­ dat o incidentech, kde AI selhalo nebo bylo zneuÅ¾ito, coÅ¾ by mohlo zahrnovat pÅ™Ã­pady jako deepfakes ovlivÅˆujÃ­cÃ­ volby nebo chyby v autonomnÃ­ch zbranÃ­ch.

Toto nenÃ­ prvnÃ­ pokus o dialog. USA majÃ­ od Å™Ã­jna 2023 prezidentskÃ½ vÃ½nos Bidena, kterÃ½ naÅ™izuje bezpeÄnostnÃ­ testy pro AI modely nad urÄitou ÃºroveÅˆ vÃ½poÄetnÃ­ho vÃ½konu, vÄetnÄ› red-teamingovÃ½ch simulacÃ­ Ãºtoku. ÄŒÃ­na naopak prosazuje vlastnÃ­ regulace, jako zÃ¡kon o generativnÃ­ AI z roku 2023, kterÃ½ vyÅ¾aduje schvÃ¡lenÃ­ modelÅ¯ stÃ¡tnÃ­mi orgÃ¡ny a zamÄ›Å™uje se na obsahovou cenzuru. PÅ™esto rivalita pÅ™etrvÃ¡vÃ¡: USA omezujÃ­ export ÄipÅ¯ NVIDIA do ÄŒÃ­ny, aby zpomalily jejÃ­ pokrok v trÃ©ninku velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), zatÃ­mco ÄŒÃ­na investuje miliardy do domÃ¡cÃ­ch GPU jako Huawei Ascend. ProhlÃ¡Å¡enÃ­ tedy pÅ™edstavuje opatrnÃ½ krok k deeskalaci, ale bez konkrÃ©tnÃ­ch zÃ¡vazkÅ¯ k omezenÃ­ vÃ½voje, napÅ™Ã­klad v oblasti AGI (umÄ›lÃ© obecnÃ© inteligence), kde obÄ› zemÄ› cÃ­lÃ­ na prvenstvÃ­ do roku 2030.

Pro prÅ¯mysl to znamenÃ¡ potenciÃ¡lnÃ­ harmonizaci standardÅ¯, coÅ¾ by usnadnilo globÃ¡lnÃ­ nasazenÃ­ AI systÃ©mÅ¯. Firmy jako OpenAI nebo Baidu by mohly Äelit spoleÄnÃ½m poÅ¾adavkÅ¯m na transparentnost trÃ©ninkovÃ½ch dat, coÅ¾ by zvÃ½Å¡ilo nÃ¡klady na compliance, ale snÃ­Å¾ilo riziko sankcÃ­. UÅ¾ivatelÃ© by mohli oÄekÃ¡vat bezpeÄnÄ›jÅ¡Ã­ AI nÃ¡stroje, napÅ™Ã­klad chatbota s vestavÄ›nÃ½mi ochranami proti halucinacÃ­m nebo biasÅ¯m.

## ProÄ je to dÅ¯leÅ¾itÃ©
Toto prohlÃ¡Å¡enÃ­ mÄ›nÃ­ dynamiku globÃ¡lnÃ­ho AI ekosystÃ©mu, kde USA a ÄŒÃ­na kontrolujÃ­ pÅ™es 70 procent investic do vÃ½zkumu. Bez spoluprÃ¡ce hrozÃ­ nekontrolovanÃ½ zÃ¡vod v zbrojenÃ­ AI, podobnÃ½ jadernÃ© Ã©Å™e, s rizikem nÃ¡hodnÃ© eskalace â€“ napÅ™Ã­klad autonomnÃ­ drony rozhodujÃ­cÃ­ o ÃºtocÃ­ch bez lidskÃ©ho zÃ¡sahu. V Å¡irÅ¡Ã­m kontextu posiluje tlak na mezinÃ¡rodnÃ­ rÃ¡mce jako EU AI Act nebo iniciativa Bletchley Park, kde 28 stÃ¡tÅ¯ vÄetnÄ› ÄŒÃ­ny diskutovalo rizika v roce 2023. Kriticky Å™eÄeno, slova nestaÄÃ­: absence vymahatelnÃ½ch mechanismÅ¯ a pokraÄujÃ­cÃ­ exportnÃ­ kontroly naznaÄujÃ­, Å¾e skuteÄnÃ¡ spoluprÃ¡ce zÅ¯stane omezenÃ¡ na necitlivÃ© oblasti. PÅ™esto je to precedent, kterÃ½ mÅ¯Å¾e brÃ¡nit nejtemnÄ›jÅ¡Ã­m scÃ©nÃ¡Å™Å¯m, jako je nasazenÃ­ AI v kybernetickÃ½ch vÃ¡lkÃ¡ch, a donutÃ­ firmy k proaktivnÃ­ bezpeÄnosti.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://english.khabarhub.com/2026/18/516408/)

**Zdroj:** ğŸ“° Khabarhub.com
