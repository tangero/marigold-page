---
author: Marisa Aigen
category: rizika ai
date: '2026-01-18 00:15:01'
description: V listopadu 2024 vydali prezidenti USA Joe Biden a ÄŒÃ­ny Si Å¤in-pching
  prvnÃ­ podstatnÃ© spoleÄnÃ© prohlÃ¡Å¡enÃ­ o nÃ¡rodnÄ›bezpeÄnostnÃ­ch rizicÃ­ch spojenÃ½ch s
  umÄ›lou inteligencÃ­. Oba stÃ¡ty uznÃ¡vajÃ­ potÅ™ebu udrÅ¾ovat bezpeÄnost a stabilitu v
  tÃ©to oblasti.
importance: 4
layout: tech_news_article
original_title: China and America Must Get Serious About AI Risk
people:
- Joe Biden
- Xi Jinping
publishedAt: '2026-01-18T00:15:01+00:00'
slug: china-and-america-must-get-serious-about-ai-risk
source:
  emoji: ğŸ“°
  id: null
  name: Khabarhub.com
title: ÄŒÃ­na a USA se musÃ­ vÃ¡Å¾nÄ› zabÃ½vat riziky umÄ›lÃ© inteligence
url: https://english.khabarhub.com/2026/18/516408/
urlToImage: https://english.khabarhub.com/wp-content/uploads/2026/01/Khabar-Hub-Article_Jake-Sullivan_1200px-630X-px-Final_2026.01.16-Upload.jpg
urlToImageBackup: https://english.khabarhub.com/wp-content/uploads/2026/01/Khabar-Hub-Article_Jake-Sullivan_1200px-630X-px-Final_2026.01.16-Upload.jpg
---

## Souhrn
V listopadu 2024 se na summitu APEC v Peru setkali prezident USA Joe Biden a prezident ÄŒÃ­ny Si Å¤in-pching a vydali spoleÄnÃ© prohlÃ¡Å¡enÃ­ o rizicÃ­ch umÄ›lÃ© inteligence pro nÃ¡rodnÃ­ bezpeÄnost. Oba lÃ­dÅ™i zdÅ¯raznili nutnost spoluprÃ¡ce na prevenci zneuÅ¾itÃ­ AI, vÄetnÄ› kybernetickÃ½ch hrozeb a destabilizujÃ­cÃ­ch technologiÃ­. Toto je prvnÃ­ takto konkrÃ©tnÃ­ diplomatickÃ¡ dohoda mezi dvÄ›ma supervelmocemi v oblasti AI bezpeÄnosti.

## KlÃ­ÄovÃ© body
- SpoleÄnÃ© uznÃ¡nÃ­ rizik AI pro nÃ¡rodnÃ­ bezpeÄnost, vÄetnÄ› moÅ¾nÃ©ho zneuÅ¾itÃ­ v kyberÃºtocÃ­ch a Å¡Ã­Å™enÃ­ dezinformacÃ­.
- ZÃ¡vazek k dialogu o bezpeÄnostnÃ­ch standardech pro AI modely, jako jsou velkÃ© jazykovÃ© modely (LLM).
- PlÃ¡n na pokraÄujÃ­cÃ­ konzultace mezi expertÅ¯m z obou zemÃ­.
- OmezenÃ­ na vojenskÃ© aplikace AI, bez detailÅ¯ o civilnÃ­ch sektorech.
- Kontext napÄ›tÃ­ v obchodu s Äipy a exportnÃ­ kontroly USA.

## Podrobnosti
ProhlÃ¡Å¡enÃ­ vyÅ¡lo z bilaterÃ¡lnÃ­ho summitu na okraji fÃ³ra APEC v LimÄ›, kde Biden a Si diskutovali Å¡irokÃ© spektrum tÃ©mat vÄetnÄ› Taiwanu a obchodu. V ÄÃ¡sti vÄ›novanÃ© AI obÄ› strany konstatovaly, Å¾e rychlÃ½ vÃ½voj technologiÃ­ jako LLM pÅ™inÃ¡Å¡Ã­ nejen vÃ½hody, ale i rizika, jako je autonomnÃ­ rozhodovÃ¡nÃ­ systÃ©mÅ¯ schopnÃ½ch manipulovat daty v reÃ¡lnÃ©m Äase. NapÅ™Ã­klad modely jako GPT-4 nebo ÄÃ­nskÃ© ekvivalenty od firem jako Baidu a Alibaba mohou bÃ½t pouÅ¾ity k generovÃ¡nÃ­ sofistikovanÃ½ch phishingovÃ½ch kampanÃ­ nebo deepfake videÃ­ pro dezinformace.

USA v poslednÃ­ch letech zavÃ¡dÄ›jÃ­ exportnÃ­ kontroly na high-end GPU od Nvidia, kterÃ© jsou klÃ­ÄovÃ© pro trÃ©nink velkÃ½ch AI modelÅ¯, aby omezily ÄÃ­nskÃ½ pÅ™Ã­stup k tÄ›mto technologiÃ­m. ÄŒÃ­na naopak investuje miliardy do domÃ¡cÃ­ho vÃ½voje ÄipÅ¯, jako jsou Huawei Ascend sÃ©rie, kterÃ© slouÅ¾Ã­ k akceleraci AI vÃ½poÄtÅ¯. ProhlÃ¡Å¡enÃ­ nenabÃ­zÃ­ konkrÃ©tnÃ­ mechanismy, jako sdÃ­lenÃ­ dat o incidentech nebo spoleÄnÃ© testovÃ¡nÃ­ modelÅ¯ na bezpeÄnostnÃ­ slabiny, ale slibuje pravidelnÃ© konzultace. To navazuje na pÅ™edchozÃ­ dohody, jako Bidenovo vÃ½konnostnÃ­ naÅ™Ã­zenÃ­ z Å™Ã­jna 2023 o bezpeÄnÃ©m vÃ½voji AI, kterÃ© vyÅ¾aduje testovÃ¡nÃ­ na rizika jako bias nebo halucinace v modelech.

V praxi to znamenÃ¡ pro prÅ¯mysl potencionÃ¡lnÃ­ uvolnÄ›nÃ­ napÄ›tÃ­ v dodavatelskÃ½ch Å™etÄ›zcÃ­ch. Firmy jako OpenAI nebo xAI by mohly zÃ­skat lepÅ¡Ã­ pÅ™ehled o ÄÃ­nskÃ½ch postupech, coÅ¾ by urychlilo vÃ½voj obrannÃ½ch nÃ¡strojÅ¯ proti AI zaloÅ¾enÃ½m hrozbÃ¡m. Pro uÅ¾ivatele to pÅ™edstavuje nepÅ™Ã­mou ochranu pÅ™ed globÃ¡lnÃ­mi kybernetickÃ½mi riziky, i kdyÅ¾ bez okamÅ¾itÃ½ch zmÄ›n v produktech.

## ProÄ je to dÅ¯leÅ¾itÃ©
Toto prohlÃ¡Å¡enÃ­ nastavuje precedens pro globÃ¡lnÃ­ governance AI, kde dvÄ› nejvÄ›tÅ¡Ã­ ekonomiky kontrolujÃ­ pÅ™es 70 % vÃ½zkumu v AI. Bez spoluprÃ¡ce hrozÃ­ eskalace zÃ¡vodÅ¯ ve zbranÃ­ch, jako vÃ½voj autonomnÃ­ch dronÅ¯ nebo AI pro elektronickou vÃ¡lku. V Å¡irÅ¡Ã­m ekosystÃ©mu to ovlivnÃ­ regulace v EU (AI Act) a G7 iniciativy, kde USA teÄ majÃ­ diplomatickou pÃ¡ku. Kriticky Å™eÄeno, prohlÃ¡Å¡enÃ­ je spÃ­Å¡ symbolickÃ© neÅ¾ operaÄnÃ­ â€“ chybÃ­ vymahatelnÃ© standardy, jako red-teaming pro vojenskÃ© AI modely. Pokud se dialog rozvine, mÅ¯Å¾e zabrÃ¡nit incidentÅ¯m podobnÃ½m SolarWinds hacku, ale bez detailÅ¯ zÅ¯stÃ¡vÃ¡ riziko, Å¾e obÄ› strany budou pokraÄovat v tajnÃ©m vÃ½voji. Pro ÄeskÃ© firmy v IT sektoru to znamenÃ¡ sledovat zmÄ›ny v exportu technologiÃ­ a pÅ™ipravit se na novÃ© bezpeÄnostnÃ­ poÅ¾adavky v AI aplikacÃ­ch.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://english.khabarhub.com/2026/18/516408/)

**Zdroj:** ğŸ“° Khabarhub.com
