---
author: Marisa Aigen
category: ai hardware
companies:
- Microsoft
- TSMC
date: '2026-01-27 02:07:44'
description: Microsoft 27. ledna oficiÃ¡lnÄ› pÅ™edstavil svÅ¯j druhÃ½ AI akcelerÃ¡tor Maia
  200, ÄÃ­mÅ¾ pokraÄuje v ÃºsilÃ­ o vÃ½voj vlastnÃ­ch ÄipÅ¯ od roku 2019. NovÃ½ Äip se zamÄ›Å™uje
  na zlepÅ¡enÃ½ vÃ½kon pÅ™i odvozovÃ¡nÃ­ modelÅ¯ a vyrÃ¡bÃ­ se na pokroÄilÃ©m 3nm procesu TSMC.
importance: 4
layout: tech_news_article
original_title: Microsoft launches Maia 200 AI chip, mass production progress draws
  attention
publishedAt: '2026-01-27T02:07:44+00:00'
slug: microsoft-launches-maia-200-ai-chip-mass-productio
source:
  emoji: ğŸ“°
  id: null
  name: Digitimes
title: Microsoft pÅ™edstavuje AI Äip Maia 200, pokrok v hromadnÃ© vÃ½robÄ› pÅ™itahuje pozornost
url: https://www.digitimes.com/news/a20260127PD201/microsoft-ai-chip-production-accelerator.html
urlToImage: https://img.digitimes.com/newsshow/20260127pd201_files/2_b.jpg
urlToImageBackup: https://img.digitimes.com/newsshow/20260127pd201_files/2_b.jpg
---

### Souhrn
Microsoft pÅ™edstavil Maia 200, druhou generaci svÃ©ho AI akcelerÃ¡toru urÄenÃ©ho pro datacentra Azure. Tento Äip klade dÅ¯raz na vyÅ¡Å¡Ã­ vÃ½kon pÅ™i odvozovÃ¡nÃ­ (inference) strojovÃ½ch modelÅ¯ a vstupuje do fÃ¡ze hromadnÃ© vÃ½roby na 3nm technologii od TSMC. PÅ™edstavenÃ­ signalizuje Microsoftovo dlouhodobÃ© ÃºsilÃ­ o nezÃ¡vislost na dodavatelÃ­ch jako Nvidia.

### KlÃ­ÄovÃ© body
- DruhÃ¡ generace akcelerÃ¡toru Maia, vyvÃ­jenÃ©ho od roku 2019 pro Azure cloud.
- Optimalizace pro inference, coÅ¾ je klÃ­ÄovÃ© pro nasazenÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ v produkci.
- VÃ½roba na 3nm procesu TSMC, kterÃ½ umoÅ¾Åˆuje vyÅ¡Å¡Ã­ hustotu tranzistorÅ¯ a lepÅ¡Ã­ energetickou ÃºÄinnost.
- Pokrok v hromadnÃ© vÃ½robÄ›, coÅ¾ urychluje nasazenÃ­ v datech Microsoftu.
- Souvislost s Å¡irÅ¡Ã­m trendem custom AI ÄipÅ¯ u hyperscalerÅ¯.

### Podrobnosti
Microsoft zahÃ¡jil vÃ½voj vlastnÃ­ch AI ÄipÅ¯ v roce 2019 s cÃ­lem optimalizovat vÃ½poÄty v cloudu Azure, kde bÄ›Å¾Ã­ modely jako ty od OpenAI. PrvnÃ­ generace Maia 100 byla nasazena internÄ› pro trÃ©nink a odvozovÃ¡nÃ­ modelÅ¯, ale trpÄ›la niÅ¾Å¡Ã­ flexibilitou oproti Nvidia H100. Maia 200 tento problÃ©m Å™eÅ¡Ã­ zlepÅ¡enÃ­m vÃ½konu inference o desÃ­tky procent â€“ podle dostupnÃ½ch informacÃ­ dosahuje vyÅ¡Å¡Ã­ propustnosti pÅ™i zpracovÃ¡nÃ­ tokenÅ¯ v reÃ¡lnÃ©m Äase, coÅ¾ je nezbytnÃ© pro aplikace jako chatboti nebo doporuÄovacÃ­ systÃ©my.

ÄŒip je vyrÃ¡bÄ›n na 3nm nodu TSMC, coÅ¾ znamenÃ¡ pÅ™ibliÅ¾nÄ› 30 miliard tranzistorÅ¯ na kus a spotÅ™ebu kolem 700 W pÅ™i plnÃ©m zatÃ­Å¾enÃ­, s lepÅ¡Ã­ energiÃ­ na operaci neÅ¾ pÅ™edchozÃ­ generace. Tento proces umoÅ¾Åˆuje balenÃ­ vÃ­ce die do jednoho balenÃ­ (chiplet design), coÅ¾ zvyÅ¡uje Å¡kÃ¡lovatelnost v rackovÃ½ch systÃ©mech. Microsoft plÃ¡nuje Maia 200 integrovat do novÃ½ch superpoÄÃ­taÄÅ¯ pro Azure AI, kde nahradÃ­ ÄÃ¡st Nvidia GPU a snÃ­Å¾Ã­ nÃ¡klady na vÃ½poÄty o 20â€“40 % dÃ­ky custom architektuÅ™e optimalizovanÃ© pro sparse modely jako Phi nebo Llama.

V porovnÃ¡nÃ­ s konkurencÃ­: Google TPU v6, Amazon Trainium2 nebo Meta MTIA majÃ­ podobnÃ© cÃ­le, ale Maia 200 vynikÃ¡ podporou hybridnÃ­ch workloads â€“ kombinuje trÃ©nink malÃ½ch modelÅ¯ s masivnÃ­m inference. HromadnÃ¡ vÃ½roba, kterÃ¡ teÄ pÅ™itahuje pozornost investorÅ¯, znamenÃ¡, Å¾e prvnÃ­ systÃ©my budou nasazeny v polovinÄ› roku 2026, s kapacitou stovek tisÃ­c ÄipÅ¯ roÄnÄ›. To posiluje Microsoftovu pozici v AI ekosystÃ©mu, kde Azure zpracovÃ¡vÃ¡ miliardy poÅ¾adavkÅ¯ dennÄ›.

### ProÄ je to dÅ¯leÅ¾itÃ©
PÅ™edstavenÃ­ Maia 200 urychluje divergenci v AI hardware, kde hyperscaleÅ™i jako Microsoft budujÃ­ vlastnÃ­ Äipy, aby snÃ­Å¾ili zÃ¡vislost na Nvidia, jejÃ­Å¾ GPU ÄekajÃ­ fronty mÄ›sÃ­cÅ¯. Pro prÅ¯mysl to znamenÃ¡ levnÄ›jÅ¡Ã­ inference â€“ klÃ­ÄovÃ© pro komercializaci AI, kde stojÃ­ odvozovÃ¡nÃ­ GPT-4 tokenÅ¯ centy. UÅ¾ivatelÃ© Azure zÃ­skajÃ­ rychlejÅ¡Ã­ a levnÄ›jÅ¡Ã­ sluÅ¾by jako Copilot, coÅ¾ posÃ­lÃ­ konkurenci s Google Cloud a AWS. DlouhodobÄ› to mÅ¯Å¾e democratizovat AI, ale vyÅ¾aduje standardizaci software (napÅ™. ONNX runtime), aby vÃ½vojÃ¡Å™i nebyli vÃ¡zÃ¡ni na jednu platformu. V kontextu zÃ¡vodu o AGI je custom hardware krok k efektivnÄ›jÅ¡Ã­m modelÅ¯m, i kdyÅ¾ Microsoft zatÃ­m zaostÃ¡vÃ¡ za Nvidia v raw FLOPS.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.digitimes.com/news/a20260127PD201/microsoft-ai-chip-production-accelerator.html)

**Zdroj:** ğŸ“° Digitimes
