---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
date: '2026-02-24 20:06:21'
description: Ministr obrany USA Pete Hegseth dal generÃ¡lnÃ­mu Å™editeli Anthropicu lhÅ¯tu
  do pÃ¡tku na otevÅ™enÃ­ umÄ›lÃ© inteligence pro volnÃ© vojenskÃ© vyuÅ¾itÃ­, jinak hrozÃ­ ztrÃ¡ta
  vlÃ¡dnÃ­ smlouvy, uvedl zdroj z jejich setkÃ¡nÃ­.
importance: 4
layout: tech_news_article
original_title: 'AP report: Hegseth warns Anthropic to let the military use company''s
  AI tech as it sees fit'
people:
- Pete Hegseth
publishedAt: '2026-02-24T20:06:21+00:00'
slug: ap-report-hegseth-warns-anthropic-to-let-the-milit
source:
  emoji: ğŸ“°
  id: null
  name: PBS
title: 'Podle AP: Hegseth varuje Anthropic, aby umoÅ¾nil armÃ¡dÄ› neomezenÃ© pouÅ¾itÃ­ firemnÃ­
  AI technologie'
url: https://www.pbs.org/newshour/world/ap-report-hegseth-warns-anthropic-to-let-the-military-use-companys-ai-tech-as-it-sees-fit
urlToImage: https://d3i6fh83elv35t.cloudfront.net/static/2026/02/2026-02-06T165423Z_1780749485_RC2EGJAM64XM_RTRMADP_3_USA-DEFENSE-1-1024x693.jpg
urlToImageBackup: https://d3i6fh83elv35t.cloudfront.net/static/2026/02/2026-02-06T165423Z_1780749485_RC2EGJAM64XM_RTRMADP_3_USA-DEFENSE-1-1024x693.jpg
---

## Souhrn
Ministr obrany USA Pete Hegseth se v ÃºterÃ½ setkal s generÃ¡lnÃ­m Å™editelem Anthropicu Dariem Amodeiem a dal mu lhÅ¯tu do pÃ¡tku na umoÅ¾nÄ›nÃ­ neomezenÃ©ho vojenskÃ©ho pouÅ¾itÃ­ firemnÃ­ technologie umÄ›lÃ© inteligence. Anthropic, tvÅ¯rce chatbota Claude, je poslednÃ­ z velkÃ½ch AI firem, kterÃ¡ nedodÃ¡vÃ¡ svÃ© modely do novÃ© vnitÅ™nÃ­ sÃ­tÄ› americkÃ© armÃ¡dy. Pokud firma neustoupÃ­, Pentagon hrozÃ­ zruÅ¡enÃ­m smlouvy nebo dalÅ¡Ã­mi opatÅ™enÃ­mi.

## KlÃ­ÄovÃ© body
- Hegseth stanovil lhÅ¯tu do pÃ¡tku; setkÃ¡nÃ­ probÄ›hlo v ÃºterÃ½ v souladu s informacemi anonymnÃ­ho zdroje z jednÃ¡nÃ­.
- Anthropic odmÃ­tÃ¡ pÅ™ekroÄit ÄervenÃ© ÄÃ¡ry: plnÄ› autonomnÃ­ vojenskÃ© cÃ­lenÃ­ a domÃ¡cÃ­ sledovÃ¡nÃ­ americkÃ½ch obÄanÅ¯.
- Hrozby z Pentagona zahrnujÃ­ zruÅ¡enÃ­ kontraktu, oznaÄenÃ­ firmy za riziko v dodavatelskÃ©m Å™etÄ›zci nebo aktivaci Defense Production Act pro nucenÃ© poskytnutÃ­ technologiÃ­.
- Firma zÅ¯stÃ¡vÃ¡ jedinou velkou AI spoleÄnostÃ­ bez dodÃ¡vek do vojenskÃ© sÃ­tÄ›; jinÃ© jako OpenAI nebo Google uÅ¾ spolupracujÃ­.
- TÃ³n setkÃ¡nÃ­ byl zdvoÅ™ilÃ½, Amodei vÅ¡ak neustoupil.

## Podrobnosti
Anthropic je americkÃ¡ firma zaloÅ¾enÃ¡ v roce 2021 Dariem Amodeiem a jeho sestrou Danou, oba ex zamÄ›stnanci OpenAI, s dÅ¯razem na vÃ½voj bezpeÄnÃ© umÄ›lÃ© inteligence. Jejich hlavnÃ­ produkt, chatbot Claude, je velkÃ½ jazykovÃ½ model podobnÃ½ GPT od OpenAI, schopnÃ½ zpracovÃ¡vat textovÃ© dotazy, generovat odpovÄ›di, analyzovat data nebo pomÃ¡hat s kÃ³dovÃ¡nÃ­m. Claude se liÅ¡Ã­ pÅ™Ã­stupem k bezpeÄnosti: modely jsou navrÅ¾eny tak, aby odmÃ­taly Å¡kodlivÃ© poÅ¾adavky, jako je tvorba dezinformacÃ­ nebo plÃ¡novÃ¡nÃ­ nÃ¡silÃ­.

Pentagon buduje novou internÃ­ sÃ­Å¥ pro umÄ›lou inteligenci, kam dodÃ¡vajÃ­ technologie firmy jako OpenAI, Google (s modelem Gemini) nebo Meta (s Llama). Tato sÃ­Å¥ slouÅ¾Ã­ k analÃ½ze dat, logistice, predikci a podporÄ› rozhodovÃ¡nÃ­ v obranÄ›. Anthropic zatÃ­m odmÃ­tÃ¡ plnou integraci kvÅ¯li etickÃ½m omezenÃ­m. Podle zdroje, kterÃ½ nenÃ­ oprÃ¡vnÄ›n mluvit veÅ™ejnÄ›, Hegseth varoval pÅ™ed eskalacÃ­: oznaÄenÃ­m za supply chain risk by firma ztratila pÅ™Ã­stup k dalÅ¡Ã­m federÃ¡lnÃ­m zakÃ¡zkÃ¡m, zatÃ­mco Defense Production Act umoÅ¾Åˆuje vlÃ¡dÄ› v nouzi pÅ™evzÃ­t kontrolu nad vÃ½robou a distribucÃ­ produktÅ¯.

SetkÃ¡nÃ­ probÄ›hlo v kontextu rostoucÃ­ho napÄ›tÃ­ mezi AI prÅ¯myslem a vlÃ¡dou. Anthropic mÃ¡ jiÅ¾ nÄ›jakÃ© vlÃ¡dnÃ­ kontrakty, ale odmÃ­tÃ¡ aplikace, kterÃ© by vedly k autonomnÃ­mu rozhodovÃ¡nÃ­ o ÃºtocÃ­ch â€“ napÅ™Ã­klad systÃ©my, kde AI sama vybÃ­rÃ¡ cÃ­le bez lidskÃ©ho zÃ¡sahu. StejnÄ› tak blokuje pouÅ¾itÃ­ pro masovÃ© sledovÃ¡nÃ­ obÄanÅ¯ doma, coÅ¾ souvisÃ­ s obavami z poruÅ¡enÃ­ Ãºstavy. Amodei, znÃ¡mÃ½ svÃ½m zamÄ›Å™enÃ­m na dlouhodobÃ© rizika AGI (umÄ›lÃ© obecnÃ© inteligence), opakovanÄ› zdÅ¯razÅˆoval tyto hranice. ÄŒlÃ¡nek zmiÅˆuje i souvisejÃ­cÃ­ kauzu: MuskÅ¯v Grok ÄelÃ­ vyÅ¡etÅ™ovÃ¡nÃ­ v EU kvÅ¯li deepfake obrÃ¡zkÅ¯m.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento spor odhaluje klÃ­ÄovÃ½ konflikt v AI ekosystÃ©mu: mezi nÃ¡rodnÃ­ bezpeÄnostÃ­ a etickÃ½mi standardy. Pokud Pentagon donutÃ­ Anthropic k ÃºstupkÅ¯m, vytvoÅ™Ã­ precedens pro jinÃ© firmy, coÅ¾ oslabÃ­ samoregulaci v AI. Naopak ÃºspÄ›Å¡nÃ½ odpor by posÃ­lil pozici firem zamÄ›Å™enÃ½ch na bezpeÄnost, ale ohrozil by jejich pÅ™Ã­stup k financÃ­m â€“ Anthropic zÃ­skal miliardy od investorÅ¯ jako Amazon. Pro prÅ¯mysl to znamenÃ¡ riziko regulacÃ­: vlÃ¡da USA mÅ¯Å¾e prosadit zÃ¡kony na nucenÃ© sdÃ­lenÃ­ AI modelÅ¯, podobnÄ› jako v ÄŒÃ­nÄ›. UÅ¾ivatelÃ© pocÃ­tÃ­ dopady v omezenÃ© dostupnosti Claude pro civilnÃ­ ÃºÄely, pokud firma ztratÃ­ kontrakty. V Å¡irÅ¡Ã­m kontextu urychluje to debatu o vojenskÃ©m nasazenÃ­ AI, kde autonomnÃ­ systÃ©my jako drony s AI cÃ­lenÃ­m uÅ¾ testujÃ­ Rusko nebo Izrael, coÅ¾ zvyÅ¡uje globÃ¡lnÃ­ rizika eskalace.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.pbs.org/newshour/world/ap-report-hegseth-warns-anthropic-to-let-the-military-use-companys-ai-tech-as-it-sees-fit)

**Zdroj:** ğŸ“° PBS
