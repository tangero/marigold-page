---
author: Marisa Aigen
category: ai regulace
date: '2025-12-29 16:10:00'
description: Peking chystÃ¡ zpÅ™Ã­snÄ›nÃ­ pravidel pro lidsku podobnou umÄ›lou inteligenci
  s dÅ¯razem na bezpeÄnost uÅ¾ivatelÅ¯ a spoleÄenskÃ© hodnoty. NovÃ½ nÃ¡vrh zavÃ¡dÃ­ povinnÃ©
  oznaÄovÃ¡nÃ­ AI interakcÃ­ a bezpeÄnostnÃ­ kontroly.
importance: 4
layout: tech_news_article
original_title: Chinaâ€™s Plans for Human-Like AI Could Set the Tone for Global AI Rules
publishedAt: '2025-12-29T16:10:00+00:00'
slug: chinas-plans-for-human-like-ai-could-set-the-tone-
source:
  emoji: ğŸ“°
  id: null
  name: Scientific American
title: PlÃ¡ny ÄŒÃ­ny na regulaci lidsky podobnÃ© AI mohou urÄit tÃ³n globÃ¡lnÃ­ch pravidel
url: https://www.scientificamerican.com/article/chinas-plans-for-human-like-ai-could-set-the-tone-for-global-ai-rules/
urlToImage: https://static.scientificamerican.com/dam/m/72b4ce254e84e663/original/AI-head.jpg?m=1767025612.321&w=1200
urlToImageBackup: https://static.scientificamerican.com/dam/m/72b4ce254e84e663/original/AI-head.jpg?m=1767025612.321&w=1200
---

## Souhrn
ÄŒÃ­nskÃ¡ vlÃ¡da zveÅ™ejnila nÃ¡vrh na zpÅ™Ã­snÄ›nÃ­ regulacÃ­ pro systÃ©my umÄ›lÃ© inteligence podobnÃ© lidskÃ©, jako jsou pokroÄilÃ© chatboti a autonomnÃ­ agenti. KlÃ­ÄovÃ© opatÅ™enÃ­ zahrnujÃ­ povinnÃ© informovÃ¡nÃ­ uÅ¾ivatelÅ¯ o interakci s AI, prosazovÃ¡nÃ­ socialistickÃ½ch hodnot a zÃ¡kazy rizikovÃ©ho obsahu. Tato pravidla, vydanÃ¡ SprÃ¡vou pro kyberprostor ÄŒÃ­ny (CAC), by mÄ›la posÃ­lit nÃ¡rodnÃ­ bezpeÄnost a ochranu uÅ¾ivatelÅ¯.

## KlÃ­ÄovÃ© body
- UÅ¾ivatelÃ© musÃ­ bÃ½t informovÃ¡ni o pouÅ¾itÃ­ AI pÅ™i pÅ™ihlÃ¡Å¡enÃ­ a opakovanÄ› kaÅ¾dÃ© dvÄ› hodiny.
- SystÃ©my AI musÃ­ odrÃ¡Å¾et â€jÃ¡drovÃ© socialistickÃ© hodnotyâ€œ a obsahovat bezpeÄnostnÃ­ zÃ¡brany pro nÃ¡rodnÃ­ bezpeÄnost.
- PovinnÃ© bezpeÄnostnÃ­ revize a hlÃ¡Å¡enÃ­ novÃ½ch AI nÃ¡strojÅ¯ mÃ­stnÃ­m ÃºÅ™adÅ¯m.
- ZÃ¡kaz generovÃ¡nÃ­ obsahu podporujÃ­cÃ­ho sebevraÅ¾du, sebeubreÅ¾ovÃ¡nÃ­, hazard, obscÃ©nnÃ­ nebo nÃ¡silnÃ½ materiÃ¡l u emotionÃ¡lnÄ› angaÅ¾ujÃ­cÃ­ch chatbotÅ¯.

## Podrobnosti
NÃ¡vrh regulacÃ­, zveÅ™ejnÄ›nÃ½ 28. prosince 2025 SprÃ¡vou pro kyberprostor ÄŒÃ­ny (CAC), cÃ­lÃ­ pÅ™Ã­mo na tzv. human-like AI systÃ©my, coÅ¾ zahrnuje pokroÄilÃ© jazykovÃ© modely typu chatbotÅ¯ a autonomnÃ­ch agentÅ¯ schopnÃ½ch simulovat lidskou konverzaci nebo chovÃ¡nÃ­. Tyto systÃ©my, jako napÅ™Ã­klad ÄÃ­nskÃ© Ernie Bot od Baidu nebo podobnÃ© vÃ½tvory od Tencentu a Alibaby, budou muset explicitnÄ› oznaÄovat svou umÄ›lou povahu, aby uÅ¾ivatelÃ© nebyli oklamÃ¡ni. Informace o AI se objevÃ­ pÅ™i prvnÃ­m pÅ™ihlÃ¡Å¡enÃ­ a potÃ© pravidelnÄ› kaÅ¾dÃ© dvÄ› hodiny, coÅ¾ mÃ¡ zabrÃ¡nit fenomÃ©nu â€hallucinace identityâ€œ, kdy uÅ¾ivatelÃ© zapomenou, Å¾e komunikujÃ­ s strojem.

DalÅ¡Ã­mi klÃ­ÄovÃ½mi prvky jsou povinnost prosazovat â€jÃ¡drovÃ© socialistickÃ© hodnotyâ€œ, coÅ¾ v praxi znamenÃ¡, Å¾e vÃ½stupy AI nesmÃ­ odporovat stÃ¡tnÃ­ ideologii, napÅ™Ã­klad nesmÃ­ kritizovat Komunistickou stranu ÄŒÃ­ny nebo prosazovat zÃ¡padnÃ­ liberalismy. SystÃ©my musÃ­ obsahovat vestavÄ›nÃ© bezpeÄnostnÃ­ mechanismy (guardrails), kterÃ© chrÃ¡nÃ­ nÃ¡rodnÃ­ bezpeÄnost, vÄetnÄ› detekce a blokovÃ¡nÃ­ citlivÃ½ch tÃ©mat jako tajnÃ© informace nebo separatismus. Firmy vyvÃ­jejÃ­cÃ­ takovÃ© AI, jako jsou domÃ¡cÃ­ giganti Baidu (vÃ½vojÃ¡Å™ velkÃ½ch jazykovÃ½ch modelÅ¯ Ernie), Tencent (WeChat s AI integracÃ­) nebo Huawei (Ascend Äipy pro AI trÃ©nink), budou podlÃ©hat pÅ™edem bezpeÄnostnÃ­m revizÃ­m a muset o novÃ½ch nasazenÃ­ch informovat mÃ­stnÃ­ vlÃ¡dnÃ­ agentury.

ZvlÃ¡Å¡tnÃ­ pozornost vÄ›nuje nÃ¡vrh emotionÃ¡lnÃ­m chatbotÅ¯m, kterÃ© se snaÅ¾Ã­ navazovat hlubÅ¡Ã­ vazby na uÅ¾ivatele. Tyto systÃ©my, Äasto pouÅ¾Ã­vanÃ© k terapii, zÃ¡bavÄ› nebo zÃ¡kaznickÃ© podpoÅ™e, nesmÃ­ generovat obsah, kterÃ½ by mohl poÅ¡kodit mentÃ¡lnÃ­ zdravÃ­ â€“ napÅ™Ã­klad povzbuzovat k sebevraÅ¾dÄ›, sebeubreÅ¾ovÃ¡nÃ­, hazardu, pornografii nebo nÃ¡silÃ­. Tato opatÅ™enÃ­ vychÃ¡zejÃ­ z existujÃ­cÃ­ch ÄÃ­nskÃ½ch zÃ¡konÅ¯ o kyberprostoru z roku 2023, kterÃ© jiÅ¾ regulujÃ­ generativnÃ­ AI, ale nynÃ­ se zamÄ›Å™ujÃ­ specificky na antropomorfnÃ­ systÃ©my. V porovnÃ¡nÃ­ s evropskÃ½m AI Actem, kterÃ½ klasifikuje AI podle rizikovosti, nebo americkÃ½m vÃ½konnÃ½m naÅ™Ã­zenÃ­m Bidena z roku 2023, ÄÃ­nskÃ½ pÅ™Ã­stup klade vÄ›tÅ¡Ã­ dÅ¯raz na ideologickou kontrolu neÅ¾ na transparentnost algoritmÅ¯.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tyto regulace pÅ™edstavujÃ­ dalÅ¡Ã­ krok v ÄÃ­nskÃ© strategii dominovat v AI, kde zemÄ› investuje miliardy do vÃ½voje modelÅ¯ pÅ™ekonÃ¡vajÃ­cÃ­ch zÃ¡padnÃ­ konkurenty, jako GPT od OpenAI nebo Gemini od Google. ÄŒÃ­na, s nejvÄ›tÅ¡Ã­m poÄtem AI patentÅ¯ na svÄ›tÄ› (podle WIPO), produkuje globÃ¡lnÄ› exportovanÃ© technologie, takÅ¾e jejÃ­ standardy mohou ovlivnit mezinÃ¡rodnÃ­ normy â€“ podobnÄ› jako pÅ™i 5G sÃ­tÃ­ch Huawei. Pro prÅ¯mysl to znamenÃ¡ vyÅ¡Å¡Ã­ nÃ¡klady na compliance, coÅ¾ mÅ¯Å¾e zpomalit inovace u menÅ¡Ã­ch firem, ale posÃ­lÃ­ dÅ¯vÄ›ru stÃ¡tu v klÃ­ÄovÃ© technologie. Pro uÅ¾ivatele to pÅ™inÃ¡Å¡Ã­ lepÅ¡Ã­ ochranu pÅ™ed dezinformacemi a psychickÃ½mi riziky, avÅ¡ak za cenu cenzury, kterÃ¡ omezÃ­ volnost vÃ½razu. V Å¡irÅ¡Ã­m kontextu urychlÃ­ globÃ¡lnÃ­ fragmentaci AI regulacÃ­: ZÃ¡pad se zamÄ›Å™uje na soukromÃ­ a bias, ÄŒÃ­na na bezpeÄnost a ideologii, coÅ¾ komplizuje cross-border nasazenÃ­ AI systÃ©mÅ¯. DlouhodobÄ› by to mohlo vÃ©st k dvÄ›ma paralelnÃ­m ekosystÃ©mÅ¯m AI, kde ÄÃ­nskÃ© modely dominujÃ­ v rozvojovÃ½ch zemÃ­ch a Asii.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.scientificamerican.com/article/chinas-plans-for-human-like-ai-could-set-the-tone-for-global-ai-rules/)

**Zdroj:** ğŸ“° Scientific American
