---
category: deepfake detekce
companies:
- OpenAI
- The Verge
date: '2025-10-27 16:00:00'
description: Videogenerátor OpenAI používá metadata C2PA pro označení AI obsahu, ale
  systém v praxi selhává a platformy deepfake videa neoznačují.
importance: 4
layout: tech_news_article
original_title: Sora is showing us how broken deepfake detection is - The Verge
publishedAt: '2025-10-27T16:00:00+00:00'
slug: sora-is-showing-us-how-broken-deepfake-detection-i
source:
  emoji: ⚡
  id: the-verge
  name: The Verge
title: Sora odhaluje, jak nefunkční je detekce deepfake videí
url: https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials
urlToImage: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
urlToImageBackup: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
---

## Souhrn

OpenAI Sora, nový generátor AI videí, demonstruje zásadní selhání současných systémů pro detekci deepfake obsahu. Přestože platforma používá standard C2PA pro označování AI generovaných videí pomocí metadat, sociální sítě a další platformy tato označení ve většině případů nezobrazují, což uživatele vystavuje riziku dezinformací.

## Klíčové body

- Sora vytváří vysoce realistická videa celebrit (Martin Luther King Jr., Michael Jackson, Bryan Cranston) a chráněných postav (SpongeBob, Pikachu)
- Platforma využívá standard C2PA (Content Credentials) pro vkládání neviditelných, ale ověřitelných metadat do videí
- Sociální sítě a další platformy tato metadata ve většině případů ignorují nebo nezobrazují koncovým uživatelům
- Uživatelé Sory se stali terčem zneužití - jejich podobizny byly použity k vytváření videí s rasistickými výroky nebo pro fetišistické účely
- OpenAI je přitom jedním z hlavních podporovatelů standardu C2PA, který v praxi nefunguje

## Podrobnosti

C2PA (Coalition for Content Provenance and Authenticity) je systém vyvinutý s podporou Adobe, který má za cíl rozlišit skutečný obsah od AI generovaných falešných videí a obrázků. Funguje na principu vkládání kryptograficky podepsaných metadat přímo do mediálních souborů. Tato metadata obsahují informace o původu obsahu, použitých nástrojích a případných úpravách.

Problém nastává ve chvíli, kdy uživatelé sdílejí videa vytvořená v Sora na jiné platformy. Zatímco v samotné aplikaci Sora je jasné, že veškerý obsah je umělý, po exportu a sdílení na sociálních sítích tato informace často zmizí. Většina platforem buď metadata C2PA vůbec nečte, nebo je nezobrazuje uživatelům dostatečně viditelným způsobem.

Situaci komplikuje fakt, že Sora dokáže vytvářet mimořádně přesvědčivá videa. Model Sora 2 generuje detailní záběry, které mohou snadno zmást běžné diváky. Objevily se případy problematického obsahu - od videí historických osobností v nevhodných kontextech až po zneužití podobizen skutečných uživatelů, kteří dobrovolně sdíleli své fotografie s platformou.

Adobe, hlavní propagátor systému Content Credentials, implementoval podporu C2PA do svých produktů jako Photoshop a Premiere Pro. Některé sociální sítě, včetně částečné podpory na platformách jako Instagram, začaly metadata zobrazovat, ale implementace je nekonzistentní a často nedostatečná.

## Proč je to důležité

Případ Sora ukazuje zásadní mezeru mezi technickými možnostmi detekce deepfake obsahu a jejich praktickým nasazením. OpenAI, jako jeden z hlavních podporovatelů C2PA, paradoxně svým produktem demonstruje, že tento systém v současné podobě nestačí k ochraně uživatelů před dezinformacemi.

Jde o varování pro celý technologický průmysl. S tím, jak se AI generátory videí stávají dostupnějšími a kvalitnějšími, roste riziko zneužití pro dezinformační kampaně, podvody nebo poškození reputace. Pokud platformy nebudou aktivně implementovat a zobrazovat informace o původu obsahu, stanou se nevědomými distributory potenciálně škodlivého materiálu.

Problém vyžaduje koordinované řešení zahrnující jak tvůrce AI nástrojů, tak provozovatele platforem a případně i legislativní rámec. Samotná existence technického standardu nestačí - je potřeba zajistit jeho důsledné používání napříč celým ekosystémem online obsahu.

---

[Číst původní článek](https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials)

**Zdroj:** ⚡ The Verge
