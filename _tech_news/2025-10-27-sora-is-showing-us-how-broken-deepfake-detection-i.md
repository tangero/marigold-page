---
category: deepfake detekce
companies:
- OpenAI
- The Verge
date: '2025-10-27 16:00:00'
description: Videogenerátor OpenAI používá metadata C2PA pro označení AI obsahu, ale
  systém v praxi selhává a platformy deepfaky nerozpoznávají.
importance: 4
layout: tech_news_article
original_title: Sora is showing us how broken deepfake detection is - The Verge
publishedAt: '2025-10-27T16:00:00+00:00'
slug: sora-is-showing-us-how-broken-deepfake-detection-i
source:
  emoji: ⚡
  id: the-verge
  name: The Verge
title: Sora odhaluje, jak nefunkční je detekce deepfake videí
url: https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials
urlToImage: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
urlToImageBackup: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
---

## Souhrn

OpenAI spustilo videogenerátor Sora založený na modelu Sora 2, který vytváří přesvědčivá deepfake videa celebrit i chráněných postav. Přestože aplikace používá standard C2PA pro označení AI obsahu metadata, systém detekce v praxi selhává a platformy sdílená videa jako deepfaky nerozpoznávají. Situace odhaluje zásadní nedostatky v současných technologiích pro ověřování autenticity obsahu.

## Klíčové body

- Sora vytváří detailní deepfake videa známých osobností (Martin Luther King Jr., Michael Jackson, Bryan Cranston) i chráněných postav (SpongeBob, Pikachu)
- Uživatelé, kteří dobrovolně sdíleli své podobizny, se objevují ve videích s rasistickými výroky nebo v obsahu pro fetišistické účty
- OpenAI implementovalo standard C2PA (Content Credentials), který přidává neviditelná ověřitelná metadata k videím
- Systém C2PA v praxi nefunguje - jakmile videa opustí aplikaci Sora, platformy je nedokážou rozpoznat jako AI obsah
- Problém demonstruje systémové selhání technologií pro označování AI obsahu, včetně standardu, který OpenAI samo pomáhá spravovat

## Podrobnosti

C2PA (Coalition for Content Provenance and Authenticity) představuje jeden z nejpokročilejších systémů pro rozlišení skutečného a AI generovaného obsahu. Standard, který propaguje především Adobe a jehož vývoj podporuje i OpenAI, funguje na principu připojení neviditelných, ale ověřitelných metadat k obrázkům a videím. Tato metadata by měla platformám a uživatelům umožnit zjistit původ obsahu a rozpoznat, zda byl vytvořen umělou inteligencí.

V případě Sory však systém selhává v okamžiku, kdy uživatelé sdílejí vygenerovaná videa na jiné platformy. Přestože aplikace metadata C2PA do videí vkládá, sociální sítě a další služby je buď nedokážou přečíst, nebo je ignorují. Výsledkem je, že přesvědčivá deepfake videa cirkulují internetem bez jakéhokoli označení, že jde o AI obsah.

Problém je o to závažnější, že Sora vytváří mimořádně kvalitní deepfaky. Uživatelé aplikace vytvořili videa zobrazující historické osobnosti v nevhodných kontextech, celebrity v kompromitujících situacích a chráněné postavy z populární kultury. Zvláště problematické jsou případy, kdy lidé dobrovolně nahrají své fotografie do aplikace a následně se objeví ve videích, která je zobrazují při rasistických výrocích nebo v sexuálně zaměřeném obsahu.

Adobe a další zastánci C2PA argumentují, že standard má své opodstatnění, ale současná implementace jasně ukazuje, že samotná metadata nestačí k ochraně uživatelů před dezinformacemi a zneužitím AI generovaného obsahu.

## Proč je to důležité

Situace kolem Sory odhaluje zásadní rozpor mezi technologickými možnostmi AI a systémy pro její regulaci. OpenAI vytvořilo nástroj schopný generovat přesvědčivá falešná videa, ale zároveň se ukázalo, že standard pro jejich označování, který firma sama pomáhá vyvíjet, v praxi nefunguje. Jde o konkrétní důkaz, že současné přístupy k detekci deepfaků jsou nedostatečné.

Problém má širší dopady na celý ekosystém online obsahu. S rostoucí kvalitou AI generátorů se stává stále těžší rozlišit skutečnost od fikce, přičemž ochranné mechanismy zaostávají. Selhání C2PA naznačuje, že potřebujeme fundamentálně odlišný přístup - nestačí spoléhat na dobrovolné označování obsahu ze strany tvůrců AI nástrojů, když platformy tyto značky stejně nerespektují nebo nedokážou zpracovat.

---

[Číst původní článek](https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials)

**Zdroj:** ⚡ The Verge
