---
category: deepfake detekce
companies:
- OpenAI
- The Verge
date: '2025-10-27 16:00:00'
description: Generátor videí od OpenAI používá metadata C2PA pro označení AI obsahu,
  ale systém zjevně nefunguje na ostatních platformách.
importance: 4
layout: tech_news_article
original_title: Sora is showing us how broken deepfake detection is - The Verge
publishedAt: '2025-10-27T16:00:00+00:00'
slug: sora-is-showing-us-how-broken-deepfake-detection-i
source:
  emoji: ⚡
  id: the-verge
  name: The Verge
title: Sora odhaluje, jak nefunkční je detekce deepfake videí
url: https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials
urlToImage: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
urlToImageBackup: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
---

## Souhrn

OpenAI spustilo videogenerátor Sora založený na modelu Sora 2, který dokáže vytvářet přesvědčivá falešná videa celebrit a chráněných postav. Přestože aplikace používá standard C2PA pro označení AI obsahu metadaty, tento systém selhává v okamžiku, kdy se videa sdílí mimo platformu Sora, což odhaluje zásadní nedostatky v současných metodách detekce deepfake obsahu.

## Klíčové body

- Sora vytváří detailní AI videa známých osobností jako Martin Luther King Jr., Michael Jackson nebo Bryan Cranston, stejně jako chráněných postav typu SpongeBob a Pikachu
- Uživatelé, kteří dobrovolně sdíleli své podobizny, se stali terčem zneužití - objevili se ve videích s rasistickými výroky nebo v obsahu pro fetišistické účty
- Aplikace implementuje standard C2PA (Content Credentials), který přidává neviditelná metadata k videím pro jejich identifikaci jako AI obsahu
- Systém C2PA, který OpenAI samo pomáhá spravovat, se ukazuje jako nedostatečný pro ochranu uživatelů před dezinformacemi
- Jakmile videa opustí aplikaci Sora, prakticky neexistuje ochrana zajišťující, že diváci poznají jejich umělý původ

## Podrobnosti

Sora představuje novou generaci nástrojů pro tvorbu deepfake videí, která dosahují alarmující úrovně realismu. Aplikace využívá model Sora 2 a dokázala vytvořit řadu kontroverzních videí, která často překračují etické hranice. Problém není jen v kvalitě generovaného obsahu, ale především v tom, jak snadno může tento obsah klamat diváky po sdílení na jiné platformy.

C2PA (Coalition for Content Provenance and Authenticity) je standard pro autentizaci obsahu, který prosazuje především Adobe pod marketingovým názvem Content Credentials. Systém funguje tak, že k obrázkům a videím připojuje ověřitelná metadata, která by měla pomoci rozlišit skutečný obsah od AI generovaného. OpenAI je součástí iniciativy, která tento standard spravuje.

Problém spočívá v tom, že většina online platforem tato metadata buď ignoruje, nebo je při nahrávání obsahu odstraňuje. Zatímco uvnitř aplikace Sora je jasné, že veškerý obsah je umělý, po exportu a sdílení na sociálních sítích či jiných platformách tato informace mizí. Uživatelé tak nemají prakticky žádnou možnost poznat, že sledují deepfake.

Situace je o to problematičtější, že Sora dokáže vytvářet nejen zábavný obsah, ale i potenciálně škodlivá videa. Objevily se případy, kdy uživatelé zneužili podobizny jiných lidí k tvorbě kompromitujícího materiálu, včetně videí s rasistickými výroky nebo sexuálně zaměřeného obsahu.

## Proč je to důležité

Případ Sory demonstruje zásadní rozpor mezi technologickými možnostmi AI a ochrannými mechanismy proti zneužití. Ukazuje se, že současné systémy pro označování AI obsahu, včetně C2PA, jsou v praxi neúčinné. To má vážné důsledky pro šíření dezinformací, ochranu osobních práv a důvěryhodnost online obsahu obecně.

Jde o varování, že technologie pro detekci deepfake videí zaostává za schopnostmi generativní AI. Zatímco OpenAI a další firmy implementují dobrovolné standardy označování, absence jejich univerzálního vynucování na všech platformách činí tyto snahy prakticky bezcennými. Problém vyžaduje systémové řešení zahrnující jak technologické platformy, tak potenciálně i legislativní rámec.

---

[Číst původní článek](https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials)

**Zdroj:** ⚡ The Verge
