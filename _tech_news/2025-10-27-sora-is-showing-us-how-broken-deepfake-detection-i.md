---
category: deepfake detekce
companies:
- OpenAI
- The Verge
date: '2025-10-27 16:00:00'
description: Generátor videí od OpenAI používá metadata C2PA pro označení AI obsahu,
  ale systém zjevně nefunguje, když se videa sdílí na jiných platformách.
importance: 4
layout: tech_news_article
original_title: Sora is showing us how broken deepfake detection is - The Verge
publishedAt: '2025-10-27T16:00:00+00:00'
slug: sora-is-showing-us-how-broken-deepfake-detection-i
source:
  emoji: ⚡
  id: the-verge
  name: The Verge
title: Sora odhaluje, jak nefunkční je detekce deepfake videí
url: https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials
urlToImage: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
urlToImageBackup: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
---

## Souhrn

OpenAI spustilo videogenerátor Sora postavený na modelu Sora 2, který dokáže vytvářet přesvědčivá falešná videa celebrit, copyrightovaných postav i běžných uživatelů. Ačkoliv aplikace používá systém C2PA pro označování AI obsahu metadaty, tento standard selhává v okamžiku, kdy se videa sdílí mimo původní platformu. Situace ukazuje zásadní nedostatky v současných systémech detekce deepfake obsahu.

## Klíčové body

- Sora vytváří detailní AI videa známých osobností jako Martin Luther King Jr., Michael Jackson nebo Bryan Cranston, stejně jako copyrightovaných postav typu SpongeBob a Pikachu
- Uživatelé, kteří dobrovolně sdíleli své podobizny, se objevili ve videích s rasistickými výroky nebo byli zneužiti pro fetišistické účty
- OpenAI implementuje C2PA autentizaci (Content Credentials), která přidává neviditelná metadata k videím pro jejich identifikaci jako AI obsahu
- Systém C2PA, který OpenAI samo pomáhá spravovat, se ukazuje jako nedostatečný pro ochranu uživatelů před dezinformacemi
- Jakmile videa opustí aplikaci Sora, prakticky neexistuje ochrana zajišťující, že diváci poznají jejich umělý původ

## Podrobnosti

C2PA autentizace, známá také jako Content Credentials, představuje systém pro připojování ověřitelných metadat k obrázkům a videím. Iniciativu vede Adobe a měla by sloužit jako jeden z nejlepších nástrojů pro rozlišení skutečného obsahu od AI falešků. Princip spočívá v tom, že metadata cestují spolu s obsahem a platformy je mohou číst a zobrazovat uživatelům varování.

Problém je v praxi zásadní - většina sociálních sítí a platforem pro sdílení obsahu tato metadata buď vůbec nečte, nebo je při nahrávání odstraňuje kvůli kompresí a úpravám souborů. Když uživatel stáhne video ze Sory a nahraje ho na Twitter, TikTok nebo Facebook, informace o AI původu se ztratí.

Sora sama o sobě funguje jako uzavřené prostředí, kde je jasné, že veškerý obsah je umělý. Problematické je sdílení mimo tuto "karanténní zónu nereality". Aplikace již vyprodukovala množství kontroverzního obsahu - od videí historických osobností v nevhodných situacích až po zneužití podob skutečných uživatelů pro tvorbu urážlivého nebo sexuálně zaměřeného materiálu.

Technologie deepfake dosáhla bodu, kdy je pro běžného diváka prakticky nemožné rozpoznat falešné video od skutečného bez technických nástrojů. Kvalita výstupů ze Sory 2 je natolik přesvědčivá, že představuje reálné riziko pro dezinformační kampaně, manipulaci veřejného mínění nebo poškození reputace jednotlivců.

## Proč je to důležité

Případ Sory demonstruje kritickou mezeru mezi technologickými možnostmi AI a ochrannými mechanismy společnosti. OpenAI je jedním z hlavních podporovatelů standardu C2PA, přesto jeho vlastní produkt ukazuje fundamentální slabiny tohoto systému. Pokud ani tvůrce technologie nedokáže zajistit funkční označování AI obsahu, je otázkou, zda současný přístup k detekci deepfake vůbec může fungovat.

Situace má dalekosáhlé důsledky pro důvěryhodnost online obsahu. S rostoucí kvalitou AI generátorů se stává neudržitelné spoléhat na dobrovolné označování nebo metadata, která lze snadno odstranit. Průmysl bude muset hledat robustnější řešení - od povinného vodoznaku přímo v pixelech videa až po blockchainové registry AI obsahu.

Pro běžné uživatele to znamená nutnost radikálně změnit přístup k online videím. Éra, kdy bylo možné věřit vlastním očím, definitivně končí. Bez systémových změn na úrovni platforem a legislativy se internet stane prostředím, kde bude rozlišení pravdy od fikce prakticky nemožné.

---

[Číst původní článek](https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials)

**Zdroj:** ⚡ The Verge
