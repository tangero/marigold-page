---
category: deepfake detekce
companies:
- OpenAI
- The Verge
date: '2025-10-27 16:00:00'
description: Generátor videí od OpenAI sice používá metadata C2PA pro označení AI
  obsahu, ale systém v praxi selhává a platformy deepfaky neoznačují.
importance: 4
layout: tech_news_article
original_title: Sora is showing us how broken deepfake detection is - The Verge
publishedAt: '2025-10-27T16:00:00+00:00'
slug: sora-is-showing-us-how-broken-deepfake-detection-i
source:
  emoji: ⚡
  id: the-verge
  name: The Verge
title: Sora odhaluje, jak nefunkční je detekce deepfake videí
url: https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials
urlToImage: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
urlToImageBackup: https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STK419_DEEPFAKE_CVIRGINIA_C.gif?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200
---

## Souhrn

OpenAI spustilo videogenerátor Sora postavený na modelu Sora 2, který dokáže vytvářet přesvědčivá falešná videa celebrit i chráněných postav. Ačkoliv Sora používá systém C2PA pro označování AI obsahu metadata, analýza ukazuje, že tento標準 v praxi selhává a sociální sítě deepfaky neoznačují, což odhaluje zásadní mezery v ochraně před dezinformacemi.

## Klíčové body

- Sora vytváří detailní deepfake videa známých osobností (Martin Luther King Jr., Michael Jackson, Bryan Cranston) i chráněných postav (SpongeBob, Pikachu)
- Uživatelé, kteří sdíleli své podobizny, se objevili ve videích s rasistickými výroky nebo jako obsah pro fetišistické účty
- OpenAI implementovalo C2PA autentizaci (Content Credentials), která přidává neviditelná metadata k videím
- Systém C2PA v praxi nefunguje - jakmile videa opustí aplikaci Sora, sociální platformy je neoznačují jako AI obsah
- Situace demonstruje selhání současných technologií pro označování AI obsahu, včetně systému, který OpenAI samo pomáhá spravovat

## Podrobnosti

Sora představuje novou generaci AI nástrojů schopných vytvářet vysoce realistická falešná videa. Aplikace sama o sobě jasně komunikuje, že veškerý obsah je umělý, problém však nastává ve chvíli, kdy uživatelé videa sdílejí na další platformy. V tu chvíli mizí jakákoliv ochrana zajišťující, že diváci poznají nepravost obsahu.

C2PA (Coalition for Content Provenance and Authenticity) je standard vyvinutý konsorciem technologických firem včetně Adobe, které iniciativu vede pod názvem Content Credentials. Systém funguje tak, že k obrázkům a videím připojuje neviditelná, ale ověřitelná metadata obsahující informace o původu obsahu. OpenAI je součástí této iniciativy a Sora metadata C2PA skutečně implementuje.

Problém spočívá v tom, že většina sociálních platforem tato metadata buď vůbec nečte, nebo je ignoruje. Když uživatel nahraje deepfake video ze Sory na Twitter, Facebook či Instagram, nic nenaznačuje, že jde o AI generovaný obsah. Metadata sice technicky existují, ale bez podpory ze strany platforem jsou k ničemu.

Situace je o to problematičtější, že OpenAI samo patří mezi hlavní podporovatele C2PA. Pokud ani systém, který firma pomáhá vyvíjet, nedokáže ochránit uživatele před jejími vlastními nástroji pro tvorbu deepfake obsahu, ukazuje to na fundamentální selhání celého přístupu k označování AI obsahu.

## Proč je to důležité

Případ Sory odhaluje kritickou mezeru mezi technickými možnostmi detekce AI obsahu a jejich praktickou implementací. Zatímco existují standardy jako C2PA, jejich efektivita závisí na dobrovolné adopci ze strany platforem, které nemají dostatečnou motivaci je implementovat.

Jde o zásadní problém pro boj proti dezinformacím a manipulaci. S rostoucí kvalitou AI generátorů videí se stává stále obtížnější rozlišit pravdu od fikce pouhým okem. Pokud technické řešení existuje, ale nefunguje v praxi, společnost zůstává bezbranná vůči záplavě přesvědčivých falešných videí.

Situace také ukazuje na rozpor v přístupu OpenAI - firma veřejně podporuje transparentnost a označování AI obsahu, zároveň však vypouští nástroj, který tento problém zhoršuje, aniž by zajistila funkční ochranu. Pro technologický průmysl je to varování, že dobrovolné standardy bez regulatorního rámce nejsou dostatečné pro řešení rizik spojených s generativní AI.

---

[Číst původní článek](https://www.theverge.com/report/806359/openai-sora-deepfake-detection-c2pa-content-credentials)

**Zdroj:** ⚡ The Verge
