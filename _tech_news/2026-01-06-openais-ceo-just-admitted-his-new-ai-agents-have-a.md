---
author: Marisa Aigen
category: kyberbezpeÄnost
companies:
- OpenAI
date: '2026-01-06 12:04:00'
description: Å Ã©f OpenAI Sam Altman upozorÅˆuje, Å¾e AI agenti mÄ›nÃ­ prÅ¯mysly, ale zÃ¡roveÅˆ
  vytvÃ¡Å™ejÃ­ zranitelnosti, kterÃ© hackeÅ™i mohou zneuÅ¾Ã­t, pokud nebudou Å™eÅ¡eny.
importance: 4
layout: tech_news_article
original_title: OpenAIâ€™s CEO just admitted his new AI agents have a serious security
  problem â€” they could be a hackerâ€™s best friend
publishedAt: '2026-01-06T12:04:00+00:00'
slug: openais-ceo-just-admitted-his-new-ai-agents-have-a
source:
  emoji: ğŸ“°
  id: null
  name: Windows Central
title: Å Ã©f OpenAI pÅ™iznal vÃ¡Å¾nÃ½ bezpeÄnostnÃ­ problÃ©m novÃ½ch AI agentÅ¯ â€“ mohou bÃ½t
  hackerÅ¯m na prospÄ›ch
url: https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/sam-altman-ai-agents-hackers-best-friend
urlToImage: https://cdn.mos.cms.futurecdn.net/Y9Rcc8UE34i6r5wpVkUeNV-2560-80.jpg
urlToImageBackup: https://cdn.mos.cms.futurecdn.net/Y9Rcc8UE34i6r5wpVkUeNV-2560-80.jpg
---

### Souhrn
Å Ã©f OpenAI Sam Altman pÅ™iznal, Å¾e pokroÄilÃ© AI agenti odhalujÃ­ kritickÃ© bezpeÄnostnÃ­ slabiny v systÃ©mech, coÅ¾ pÅ™edstavuje riziko pro kyberbezpeÄnost. Tyto autonomnÃ­ systÃ©my, schopnÃ© sloÅ¾itÃ½ch ÃºkolÅ¯, mohou bÃ½t zmanipulovÃ¡ny na Å¡kodlivÃ© aktivity. OpenAI proto vyhlaÅ¡uje hledÃ¡nÃ­ specialisty na pÅ™ipravenost pro Å™eÅ¡enÃ­ tÄ›chto vÃ½zev.

### KlÃ­ÄovÃ© body
- AI agenti rychle napredujÃ­ a nahrazujÃ­ repetitivnÃ­ Ãºkoly v korporÃ¡tnÃ­m svÄ›tÄ›.
- OdhalujÃ­ bezpeÄnostnÃ­ zranitelnosti, kterÃ© mohou hackeÅ™i vyuÅ¾Ã­t k reÃ¡lnÃ½m ÃºtokÅ¯m.
- Altman popÅ™el existenci Å¡kÃ¡lovacÃ­ stÄ›ny pro trÃ©nink modelÅ¯ a zdÅ¯raznil nedostatek kvalitnÃ­ch dat.
- OpenAI hledÃ¡ Head of Preparedness pro Å™eÅ¡enÃ­ rizik vÄetnÄ› dopadÅ¯ na duÅ¡evnÃ­ zdravÃ­.
- Kritika smÄ›Å™uje k prioritizaci produktÅ¯ nad bezpeÄnostÃ­.

### Podrobnosti
VÃ½zkumnÃ© laboratoÅ™e jako OpenAI, Anthropic a Google pÅ™ekroÄily fÃ¡zi jednoduchÃ½ch chatbotÅ¯ generujÃ­cÃ­ch text na zÃ¡kladÄ› pÅ™Ã­kazÅ¯. NynÃ­ se zamÄ›Å™ujÃ­ na AI agenty, kterÃ© autonomnÄ› vykonÃ¡vajÃ­ sloÅ¾itÃ© Ãºkoly, jako je analÃ½za systÃ©mÅ¯ nebo automatizace procesÅ¯. Tyto agenty, napÅ™Ã­klad zaloÅ¾enÃ© na velkÃ½ch jazykovÃ½ch modelech (LLM), dokÃ¡Å¾ou prozkoumat software, sÃ­tÄ› nebo aplikace a identifikovat slabiny, jako jsou chyby v autentizaci nebo nechrÃ¡nÄ›nÃ© API rozhranÃ­. ProblÃ©m nastÃ¡vÃ¡, kdyÅ¾ tyto schopnosti padnou do rukou ÃºtoÄnÃ­kÅ¯ â€“ agenti mohou bÃ½t naprogramovÃ¡ni na skenovÃ¡nÃ­ sÃ­tÃ­, generovÃ¡nÃ­ exploitÅ¯ nebo dokonce koordinaci ÃºtokÅ¯.

Sam Altman v nedÃ¡vnÃ©m prohlÃ¡Å¡enÃ­ zdÅ¯raznil, Å¾e za poslednÃ­ rok doÅ¡lo k rychlÃ©mu zlepÅ¡enÃ­ modelÅ¯, coÅ¾ umoÅ¾Åˆuje Å™eÅ¡it komplexnÃ­ problÃ©my. NicmÃ©nÄ› pÅ™iznal, Å¾e toto napÅ™edovÃ¡nÃ­ pÅ™inÃ¡Å¡Ã­ reÃ¡lnÃ© hrozby. NapÅ™Ã­klad agent by mohl analyzovat zdrojovÃ½ kÃ³d aplikace, najÃ­t zero-day zranitelnost a navrhnout ÃºtokovÃ½ vektor, kterÃ½ by tradiÄnÃ­ bezpeÄnostnÃ­ nÃ¡stroje pÅ™ehlÃ©dly. Altman zmÃ­nil i nabÃ­dku pozice Head of Preparedness, kterÃ¡ mÃ¡ Å™eÅ¡it nejen kybernetickÃ© rizika, ale i Å¡irÅ¡Ã­ dopady, jako vliv na duÅ¡evnÃ­ zdravÃ­ uÅ¾ivatelÅ¯ interagujÃ­cÃ­ch s AI. Tato role je klÃ­ÄovÃ¡ v dobÄ›, kdy modely rychle sÃ­lÃ­.

PÅ™esto Altman odmÃ­tl spekulace o Å¡kÃ¡lovacÃ­ stÄ›nÄ› â€“ tvrzenÃ­, Å¾e firmy nemohou trÃ©novat pokroÄilejÅ¡Ã­ modely kvÅ¯li nedostatku dat. Podle nÄ›j takovÃ¡ bariÃ©ra neexistuje. OpenAI ÄelÃ­ kritice, Å¾e se soustÅ™edÃ­ na atraktivnÃ­ produkty smÄ›Å™ujÃ­cÃ­ k AGI (umÄ›lÃ© obecnÃ© inteligenci), na Ãºkor bezpeÄnostnÃ­ch procesÅ¯. NapÅ™Ã­klad agenti by mohli bÃ½t pouÅ¾iti k testovÃ¡nÃ­ bezpeÄnosti cloudu nebo IoT zaÅ™Ã­zenÃ­, ale bez kontrolnÃ­ch mechanismÅ¯ riskujÃ­ zneuÅ¾itÃ­ v reÃ¡lnÃ©m svÄ›tÄ›.

### ProÄ je to dÅ¯leÅ¾itÃ©
Toto pÅ™iznÃ¡nÃ­ podtrhuje nutnost integrovat bezpeÄnost do vÃ½voje AI od poÄÃ¡tku. Pro prÅ¯mysl znamenÃ¡, Å¾e firmy musÃ­ zavÃ¡dÄ›t sandboxy pro agenty, pokroÄilÃ© monitorovÃ¡nÃ­ a etickÃ© rÃ¡mce, aby zabrÃ¡nily ÃºnikÅ¯m dat nebo automatizovanÃ½m ÃºtokÅ¯m. V Å¡irÅ¡Ã­m kontextu posiluje debatu o regulaci AI â€“ napÅ™Ã­klad EU AI Act nebo americkÃ© smÄ›rnice â€“ kde autonomnÃ­ agenti spadajÃ­ do kategorie vysokÃ©ho rizika. Pro uÅ¾ivatele to znamenÃ¡ opatrnost pÅ™i nasazovÃ¡nÃ­ AI nÃ¡strojÅ¯ v citlivÃ½ch oblastech, jako je finance nebo zdravotnictvÃ­, kde zranitelnost mÅ¯Å¾e vÃ©st k masivnÃ­m Å¡kodÃ¡m. OpenAI jako lÃ­dr v oblasti LLM nastavuje precedens; jejich pÅ™Ã­stup ovlivnÃ­ celÃ½ ekosystÃ©m, vÄetnÄ› konkurentÅ¯ jako Anthropic s modelem Claude nebo Google s Gemini.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/sam-altman-ai-agents-hackers-best-friend)

**Zdroj:** ğŸ“° Windows Central
