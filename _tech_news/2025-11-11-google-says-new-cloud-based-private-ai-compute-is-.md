---
author: Marisa Aigen
category: ai bezpeÄnost
companies:
- Google
- Apple
date: '2025-11-11 21:34:10'
description: Google zavÃ¡dÃ­ systÃ©m Private AI Compute, kterÃ½ umoÅ¾Åˆuje zaÅ¡ifrovanÃ© zpracovÃ¡nÃ­
  dat v cloudu na specializovanÃ© infrastruktuÅ™e s cÃ­lem nabÃ­dnout vÃ½kon pokroÄilÃ½ch
  modelÅ¯ Gemini pÅ™i Ãºrovni ochrany blÃ­zkÃ© lokÃ¡lnÃ­mu vÃ½poÄtu.
importance: 4
layout: tech_news_article
original_title: Google says new cloud-based â€œPrivate AI Computeâ€ is just as secure
  as local processing - Ars Technica
publishedAt: '2025-11-11T21:34:10+00:00'
slug: google-says-new-cloud-based-private-ai-compute-is-
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: 'Google pÅ™edstavuje Private AI Compute: cloudovÃ© zpracovÃ¡nÃ­ dat mÃ¡ bÃ½t stejnÄ›
  bezpeÄnÃ© jako lokÃ¡lnÃ­'
url: https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg
---

## Souhrn
Google pÅ™edstavil Private AI Compute, novÃ½ systÃ©m pro bezpeÄnÃ© cloudovÃ© zpracovÃ¡nÃ­ dat, kterÃ½ mÃ¡ uÅ¾ivatelÅ¯m umoÅ¾nit vyuÅ¾Ã­vat vÃ½konnÃ© modely Gemini bez toho, aby k datÅ¯m mÄ›l pÅ™Ã­stup samotnÃ½ Google. Å˜eÅ¡enÃ­ kombinuje vlastnÃ­ Äipy Tensor Processing Units (TPU), Å¡ifrovanÃ© spojenÃ­ a Trusted Execution Environment (TEE) a mÃ­Å™Ã­ na scÃ©nÃ¡Å™, kdy lokÃ¡lnÃ­ vÃ½kon telefonÅ¯ a notebookÅ¯ nestaÄÃ­.

## KlÃ­ÄovÃ© body
- Private AI Compute vyuÅ¾Ã­vÃ¡ chrÃ¡nÄ›nÃ© bÄ›hovÃ© prostÅ™edÃ­ (TEE) nad TPU s oddÄ›lenou a Å¡ifrovanou pamÄ›tÃ­.
- Google tvrdÃ­, Å¾e k datÅ¯m zpracovÃ¡vanÃ½m v Private AI Compute nemÃ¡ pÅ™Ã­stup ani internÄ›, podobnÄ› jako u konceptu Apple Private Cloud Compute.
- SystÃ©m mÃ¡ umoÅ¾nit pouÅ¾Ã­vÃ¡nÃ­ velkÃ½ch modelÅ¯ Gemini v situacÃ­ch, kde onâ€‘device AI (napÅ™. Gemini Nano) vÃ½konovÄ› nestaÄÃ­.
- BezpeÄnostnÃ­ architekturu posuzovala nezÃ¡vislÃ¡ spoleÄnost NCC Group, Google se odvolÃ¡vÃ¡ na shodu s vlastnÃ­mi pÅ™Ã­snÄ›jÅ¡Ã­mi zÃ¡sadami ochrany soukromÃ­.
- Google se strategicky snaÅ¾Ã­ sjednotit edge AI a cloud AI do jednÃ© architektury a tÃ­m snÃ­Å¾it obavy z odesÃ­lÃ¡nÃ­ osobnÃ­ch dat do cloudu.

## Podrobnosti
Private AI Compute je navrÅ¾en jako vyhrazenÃ©, izolovanÃ© prostÅ™edÃ­ v datovÃ½ch centrech Googlu, postavenÃ© na vlastnÃ­ch Äipech TPU a bezpeÄnostnÃ­ch funkcÃ­ch procesorÅ¯ AMD. Trusted Execution Environment (TEE) zde funguje jako hardwarovÄ› vynucenÃ© oddÄ›lenÃ­, kde jsou data i bÄ›Å¾Ã­cÃ­ modely Å¡ifrovÃ¡ny v pamÄ›ti a majÃ­ bÃ½t nepÅ™Ã­stupnÃ© hostitelskÃ©mu systÃ©mu, administrÃ¡torÅ¯m i jinÃ½m sluÅ¾bÃ¡m. KlientskÃ© zaÅ™Ã­zenÃ­ se pÅ™ipojuje k tomuto prostÅ™edÃ­ pÅ™es koncovÃ© Å¡ifrovÃ¡nÃ­, takÅ¾e Google deklaruje, Å¾e nedisponuje ÄitelnÃ½mi vstupy ani vÃ½stupy mimo TEE.

Z hlediska pouÅ¾itÃ­ mÃ¡ Private AI Compute slouÅ¾it jako rozÅ¡Ã­Å™enÃ­ edge AI. Na zaÅ™Ã­zenÃ­ bÄ›Å¾Ã­ menÅ¡Ã­ modely, jako Gemini Nano v telefonech Pixel, kterÃ© zvlÃ¡dajÃ­ jednoduÅ¡Å¡Ã­ Ãºlohy pÅ™Ã­mo lokÃ¡lnÄ›: sumarizace textu, offline pÅ™epis, zÃ¡kladnÃ­ asistent. Jakmile je potÅ™eba vÄ›tÅ¡Ã­ kontext, multimodÃ¡lnÃ­ zpracovÃ¡nÃ­ Äi komplexnÄ›jÅ¡Ã­ generovÃ¡nÃ­, mÅ¯Å¾e se poÅ¾adavek pÅ™esmÄ›rovat do Private AI Compute, kde bÄ›Å¾Ã­ vÄ›tÅ¡Ã­ modely Gemini s vÃ½raznÄ› vyÅ¡Å¡Ã­m vÃ½poÄetnÃ­m vÃ½konem. UÅ¾ivatel tak formÃ¡lnÄ› neopouÅ¡tÃ­ â€privÃ¡tnÃ­ reÅ¾imâ€œ, ale technicky dochÃ¡zÃ­ k odeslÃ¡nÃ­ dat do cloudovÃ© infrastruktury.

Google se tÃ­mto pÅ™ibliÅ¾uje konceptu Apple Private Cloud Compute: cloud jako rozÅ¡Ã­Å™enÃ­ zaÅ™Ã­zenÃ­, nikoliv jako plnÄ› dÅ¯vÄ›ryhodnÃ½ prostÅ™ednÃ­k. RozdÃ­l je v implementaci a v tom, Å¾e Google explicitnÄ› stavÃ­ na svÃ© AI infrastruktuÅ™e (TPU stack) a chce tento pÅ™Ã­stup pouÅ¾Ã­t napÅ™Ã­Ä produkty â€“ od Pixel zaÅ™Ã­zenÃ­ po podnikovÃ© sluÅ¾by Google Cloud. NezÃ¡vislÃ© posouzenÃ­ NCC Group mÃ¡ dodat dÅ¯vÄ›ryhodnost tvrzenÃ­, Å¾e ani Google jako provozovatel nemÃ¡ mÃ­t realistickou moÅ¾nost data ÄÃ­st nebo zneuÅ¾Ã­t.

Pro uÅ¾ivatele a firmy mÅ¯Å¾e bÃ½t praktickÃ½ pÅ™Ã­nos v tom, Å¾e zÃ­skajÃ­ pÅ™Ã­stup k vÃ½konnÃ½m AI funkcÃ­m bez nutnosti rezignovat na zÃ¡kladnÃ­ principy ochrany dat. V praxi vÅ¡ak pÅ™ijde na detailnÃ­ implementaci: jak transparentnÃ­ bude auditovatelnost, jak budou omezeny logy, jak se zabrÃ¡nÃ­ kombinaci metadat s jinÃ½mi zdroji, a do jakÃ© mÃ­ry budou tyto zÃ¡ruky zÃ¡vaznÄ› zakotveny v podmÃ­nkÃ¡ch sluÅ¾eb.

## ProÄ je to dÅ¯leÅ¾itÃ©
Private AI Compute je dÅ¯leÅ¾itÃ½ krok ve sporu mezi dvÄ›ma modely vÃ½voje AI sluÅ¾eb: ÄistÄ› lokÃ¡lnÃ­ zpracovÃ¡nÃ­ vs. centralizovanÃ½ cloud. Google se snaÅ¾Ã­ zavÃ©st tÅ™etÃ­ cestu: cloudovÃ½ vÃ½kon s deklarovanÄ› lokÃ¡lnÃ­ ÃºrovnÃ­ soukromÃ­. Pokud bude architektura skuteÄnÄ› technicky i smluvnÄ› vynutitelnÃ¡, mÅ¯Å¾e to snÃ­Å¾it bariÃ©ru pro nasazenÃ­ generativnÃ­ AI v regulovanÃ½ch sektorech (finance, zdravotnictvÃ­, veÅ™ejnÃ¡ sprÃ¡va), kde je dnes odesÃ­lÃ¡nÃ­ dat do cloudu problematickÃ©.

ZÃ¡roveÅˆ jde o konkurenÄnÃ­ reakci na Apple a dalÅ¡Ã­ hrÃ¡Äe, kteÅ™Ã­ propagujÃ­ onâ€‘device AI jako bezpeÄnÄ›jÅ¡Ã­ alternativu. Google tÃ­m uznÃ¡vÃ¡, Å¾e bez dÅ¯vÄ›ry v ochranu dat nebude masovÃ© pÅ™ijÃ­mÃ¡nÃ­ generativnÃ­ AI udrÅ¾itelnÄ› rÅ¯st. Kriticky je vÅ¡ak nutnÃ© sledovat, zda â€bez pÅ™Ã­stupu Googlu k datÅ¯mâ€œ zÅ¯stane pouze marketingovÃ½m tvrzenÃ­m, nebo bude podloÅ¾eno otevÅ™enou dokumentacÃ­, nezÃ¡vislÃ½m auditem, moÅ¾nostÃ­ kryptografickÃ© verifikace a transparentnÃ­ regulacÃ­. Pro celÃ½ ekosystÃ©m AI bezpeÄnosti je tento model testem, zda lze velkÃ© cloudovÃ© modely provozovat zpÅ¯sobem, kterÃ½ respektuje minimÃ¡lnÃ­ nutnost dÅ¯vÄ›ry v poskytovatele.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/)

**Zdroj:** ğŸ”¬ Ars Technica
