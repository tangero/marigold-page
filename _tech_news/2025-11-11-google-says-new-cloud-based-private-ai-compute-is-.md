---
author: Marisa Aigen
category: tech
companies:
- Google
- Ars Technica
date: '2025-11-11 21:34:10'
description: Google pÅ™edstavil Private AI Compute, systÃ©m pro bezpeÄnÃ© cloudovÃ© zpracovÃ¡nÃ­
  AI Ãºloh s vyuÅ¾itÃ­m vlastnÃ­ch ÄipÅ¯ a Trusted Execution Environment, kterÃ½ mÃ¡ nabÃ­dnout
  ÃºroveÅˆ ochrany srovnatelnou s lokÃ¡lnÃ­m zpracovÃ¡nÃ­m na zaÅ™Ã­zenÃ­.
importance: 4
layout: tech_news_article
original_title: Google says new cloud-based â€œPrivate AI Computeâ€ is just as secure
  as local processing - Ars Technica
publishedAt: '2025-11-11T21:34:10+00:00'
slug: google-says-new-cloud-based-private-ai-compute-is-
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: 'Google zavÃ¡dÃ­ â€Private AI Computeâ€œ: bezpeÄnÄ›jÅ¡Ã­ cloudovÃ© zpracovÃ¡nÃ­ dat pro
  velkÃ© AI modely'
url: https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg
---

## Souhrn
Google spouÅ¡tÃ­ Private AI Compute, novou architekturu pro provoz AI modelÅ¯ v cloudu, kterÃ¡ mÃ¡ umoÅ¾nit vyuÅ¾itÃ­ vÃ½konnÃ½ch modelÅ¯ jako Gemini pÅ™i zachovÃ¡nÃ­ ochrany uÅ¾ivatelskÃ½ch dat na Ãºrovni lokÃ¡lnÃ­ho zpracovÃ¡nÃ­. SystÃ©m kombinuje vlastnÃ­ Tensor Processing Units (TPU), Trusted Execution Environment (TEE) a Å¡ifrovanÃ© spojenÃ­ tak, aby ani Google nemÄ›l mÃ­t pÅ™Ã­mÃ½ pÅ™Ã­stup k obsahu zpracovÃ¡vanÃ½ch dat.

## KlÃ­ÄovÃ© body
- Private AI Compute umoÅ¾Åˆuje zaÅ™Ã­zenÃ­m pÅ™istupovat k izolovanÃ©mu prostÅ™edÃ­ v Google cloudu pÅ™es Å¡ifrovanÃ½ kanÃ¡l.
- ZpracovÃ¡nÃ­ probÃ­hÃ¡ na TPU s integrovanÃ½mi bezpeÄnostnÃ­mi prvky a AMD-based TEE, kterÃ© izoluje pamÄ›Å¥ od hostitelskÃ©ho systÃ©mu.
- Google tvrdÃ­, Å¾e bezpeÄnost Å™eÅ¡enÃ­ je srovnatelnÃ¡ s lokÃ¡lnÃ­m zpracovÃ¡nÃ­m dat na zaÅ™Ã­zenÃ­.
- SluÅ¾ba mÃ¡ umoÅ¾nit pouÅ¾itÃ­ vÃ½konnÄ›jÅ¡Ã­ch verzÃ­ Gemini oproti menÅ¡Ã­m modelÅ¯m bÄ›Å¾Ã­cÃ­m pÅ™Ã­mo na telefonech Äi laptopech.
- Architektura pÅ™ipomÃ­nÃ¡ Apple Private Cloud Compute a zvyÅ¡uje tlak na standardizaci â€dÅ¯vÄ›ryhodnÃ©hoâ€œ cloudovÃ©ho AI zpracovÃ¡nÃ­.

## Podrobnosti
Private AI Compute je navrÅ¾eno jako uzavÅ™enÃ½, technicky auditovatelnÃ½ vÃ½poÄetnÃ­ prostor v infrastruktuÅ™e Google, urÄenÃ½ pro bÄ›h AI modelÅ¯ nad citlivÃ½mi daty uÅ¾ivatelÅ¯. KlÃ­ÄovÃ½m prvkem je pouÅ¾itÃ­ vlastnÃ­ch TPU ÄipÅ¯, kterÃ© obsahujÃ­ integrovanÃ© bezpeÄnostnÃ­ prvky, a Trusted Execution Environment zaloÅ¾enÃ©ho na technologiÃ­ch AMD. TEE zajiÅ¡Å¥uje, Å¾e pamÄ›Å¥ovÃ© prostory vyuÅ¾Ã­vanÃ© pro AI vÃ½poÄty jsou hardwarovÄ› izolovÃ¡ny od zbytku systÃ©mu, vÄetnÄ› administrÃ¡torÅ¯ cloudu.

ZaÅ™Ã­zenÃ­ uÅ¾ivatele (napÅ™Ã­klad telefony Pixel nebo dalÅ¡Ã­ klientskÃ© systÃ©my) navazujÃ­ Å¡ifrovanÃ© spojenÃ­ pÅ™Ã­mo s tÃ­mto chrÃ¡nÄ›nÃ½m prostÅ™edÃ­m. Data jsou zaÅ¡ifrovÃ¡na bÄ›hem pÅ™enosu i pÅ™i zpracovÃ¡nÃ­ a podle nÃ¡vrhu nemajÃ­ bÃ½t dostupnÃ¡ ani inÅ¾enÃ½rÅ¯m Google, ani jinÃ½m sluÅ¾bÃ¡m bÄ›Å¾Ã­cÃ­m v cloudu. Google uvÃ¡dÃ­, Å¾e architektura byla nezÃ¡visle analyzovÃ¡na bezpeÄnostnÃ­ firmou NCC Group, kterÃ¡ patÅ™Ã­ mezi zavedenÃ© hrÃ¡Äe v oblasti bezpeÄnostnÃ­ch auditÅ¯ a penetraÄnÃ­ch testÅ¯.

Na rozdÃ­l od ÄistÄ› lokÃ¡lnÃ­ho zpracovÃ¡nÃ­, kterÃ© spolÃ©hÃ¡ na omezenÃ½ vÃ½kon NPU v telefonech (napÅ™Ã­klad Gemini Nano v zaÅ™Ã­zenÃ­ch Pixel), umoÅ¾Åˆuje Private AI Compute vyuÅ¾Ã­t nejvÄ›tÅ¡Ã­ a nejvÃ½konnÄ›jÅ¡Ã­ modely Gemini uloÅ¾enÃ© v cloudu. To je zÃ¡sadnÃ­ pro Ãºlohy, kterÃ© vyÅ¾adujÃ­ vysokou kapacitu modelu: pokroÄilÃ© porozumÄ›nÃ­ textu, analÃ½zu vÄ›tÅ¡Ã­ch dokumentÅ¯, multimodÃ¡lnÃ­ zpracovÃ¡nÃ­ Äi komplexnÃ­ asistenÄnÃ­ funkce napÅ™Ã­Ä sluÅ¾bami Google.

Z hlediska praxe to znamenÃ¡, Å¾e funkce jako AI asistent, sumarizace obsahu, generovÃ¡nÃ­ nÃ¡vrhÅ¯ nebo automatickÃ¡ analÃ½za uÅ¾ivatelskÃ½ch dat mohou bÄ›Å¾et s vÄ›tÅ¡Ã­ pÅ™esnostÃ­ a kontextem, aniÅ¾ by formÃ¡lnÄ› opustily â€dÅ¯vÄ›ryhodnÃ©â€œ prostÅ™edÃ­. SouÄasnÄ› ale uÅ¾ivatel i firmy musÃ­ vÄ›Å™it, Å¾e implementace TEE, dodrÅ¾ovÃ¡nÃ­ auditovanÃ½ch postupÅ¯ a absence postrannÃ­ch kanÃ¡lÅ¯ jsou skuteÄnÄ› tak robustnÃ­, jak Google tvrdÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Private AI Compute ukazuje, jak velcÃ­ poskytovatelÃ© cloudu reagujÃ­ na konflikt mezi potÅ™ebou masivnÃ­ho vÃ½konu pro AI a rostoucÃ­m tlakem na ochranu soukromÃ­ a regulaci dat. Google se tÃ­m snaÅ¾Ã­ odstranit hlavnÃ­ pÅ™ekÃ¡Å¾ku pro adopci generativnÃ­ AI ve firemnÃ­m i spotÅ™ebitelskÃ©m prostÅ™edÃ­: obavu, Å¾e data pouÅ¾itÃ¡ pro AI sluÅ¾by mohou bÃ½t zneuÅ¾ita, analyzovÃ¡na mimo kontrolu nebo pouÅ¾ita k trÃ©ninku dalÅ¡Ã­ch modelÅ¯.

Technicky jde o dalÅ¡Ã­ krok k modelu, kde cloud nenÃ­ jen anonymnÃ­ vÃ½poÄetnÃ­ infrastruktura, ale regulovanÃ½, kryptograficky a hardwarovÄ› ohraniÄenÃ½ prostor s ovÄ›Å™itelnÃ½mi vlastnostmi. Podobnost s pÅ™Ã­stupem Apple naznaÄuje, Å¾e se formuje de facto standard: AI sluÅ¾by bÄ›Å¾Ã­ v izolovanÃ½ch prostÅ™edÃ­ch, auditovatelnÃ½ch tÅ™etÃ­ stranou, s jasnÃ½mi limity pro pÅ™Ã­stup k datÅ¯m.

Pro uÅ¾ivatele to znamenÃ¡ potenciÃ¡l vyuÅ¾Ã­vat vÃ½konnÄ›jÅ¡Ã­ AI funkce bez nutnosti mÃ­t Å¡piÄkovÃ½ hardware v kapse, ale i nutnost kriticky sledovat, do jakÃ© mÃ­ry jsou tvrzenÃ­ â€stejnÄ› bezpeÄnÃ© jako lokÃ¡lnÃ­ zpracovÃ¡nÃ­â€œ technicky prokazatelnÃ¡. Pro firmy a regulÃ¡tory je to signÃ¡l, Å¾e tlak na transparentnÃ­, hardwarovÄ› zajiÅ¡tÄ›nÃ© AI infrastruktury bude klÃ­ÄovÃ½m kritÃ©riem pÅ™i vÃ½bÄ›ru poskytovatele cloudu.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/)

**Zdroj:** ğŸ”¬ Ars Technica
