---
author: Marisa Aigen
category: ai bezpeÄnost
companies:
- Google
- Apple
- OpenAI
date: '2025-11-11 21:34:10'
description: Google zavÃ¡dÃ­ Private AI Compute, zabezpeÄenÃ© cloudovÃ© prostÅ™edÃ­ pro
  AI vÃ½poÄty, kterÃ© mÃ¡ dÃ­ky hardwarovÄ› chrÃ¡nÄ›nÃ©mu provozu nabÃ­dnout stejnou ÃºroveÅˆ
  soukromÃ­ jako lokÃ¡lnÃ­ zpracovÃ¡nÃ­ na zaÅ™Ã­zenÃ­ a souÄasnÄ› zpÅ™Ã­stupnit vÃ½konnÄ›jÅ¡Ã­ modely
  Gemini.
importance: 4
layout: tech_news_article
original_title: Google says new cloud-based â€œPrivate AI Computeâ€ is just as secure
  as local processing - Ars Technica
publishedAt: '2025-11-11T21:34:10+00:00'
slug: google-says-new-cloud-based-private-ai-compute-is-
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: 'Google pÅ™edstavuje cloudovÃ© â€Private AI Computeâ€œ: bezpeÄnost na Ãºrovni lokÃ¡lnÃ­ho
  zpracovÃ¡nÃ­?'
url: https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Private_Inference-1152x648.jpg
---

## Souhrn
Google zavÃ¡dÃ­ Private AI Compute, novÃ© cloudovÃ© prostÅ™edÃ­ pro provoz generativnÃ­ AI, kterÃ© mÃ¡ umoÅ¾nit zpracovÃ¡nÃ­ citlivÃ½ch dat na vzdÃ¡lenÃ© infrastruktuÅ™e bez pÅ™Ã­stupu provozovatele k obsahu. Å˜eÅ¡enÃ­ kombinuje vlastnÃ­ Äipy TPU, Å¡ifrovanÃ© spojenÃ­ z koncovÃ©ho zaÅ™Ã­zenÃ­ a Trusted Execution Environment zaloÅ¾enÃ© na technologiÃ­ch AMD a mÃ¡ nabÃ­dnout bezpeÄnost srovnatelnou s lokÃ¡lnÃ­m zpracovÃ¡nÃ­m.

## KlÃ­ÄovÃ© body
- Private AI Compute je izolovanÃ© cloudovÃ© prostÅ™edÃ­ pro provoz modelÅ¯ Gemini s dÅ¯razem na ochranu dat uÅ¾ivatelÅ¯.
- VyuÅ¾Ã­vÃ¡ vlastnÃ­ TPU s integrovanÃ½mi bezpeÄnostnÃ­mi prvky a Trusted Execution Environment (TEE), kterÃ½ mÃ¡ brÃ¡nit pÅ™Ã­stupu i ze strany Googlu.
- Data jsou pÅ™enÃ¡Å¡ena pÅ™es Å¡ifrovanÃ½ kanÃ¡l pÅ™Ã­mo do chrÃ¡nÄ›nÃ©ho prostoru a nemajÃ­ bÃ½t dostupnÃ¡ bÄ›Å¾nÃ½m cloudovÃ½m sluÅ¾bÃ¡m ani administrÃ¡torÅ¯m.
- Google tvrdÃ­, Å¾e bezpeÄnost Private AI Compute odpovÃ­dÃ¡ lokÃ¡lnÃ­mu zpracovÃ¡nÃ­ na zaÅ™Ã­zenÃ­, ale umoÅ¾Åˆuje vÃ½raznÄ› vyÅ¡Å¡Ã­ vÃ½poÄetnÃ­ vÃ½kon neÅ¾ NPU v telefonech Äi laptopech.
- SystÃ©m cÃ­lÃ­ na spojenÃ­ vÃ½hod edge AI (soukromÃ­) a cloudu (vÃ½kon), podobnÄ› jako koncept Apple Private Cloud Compute.

## Podrobnosti
Private AI Compute je navrÅ¾eno jako oddÄ›lenÃ¡ ÄÃ¡st cloudovÃ© infrastruktury Googlu, urÄenÃ¡ k provozu velkÃ½ch modelÅ¯ Gemini nad citlivÃ½mi vstupy uÅ¾ivatele, aniÅ¾ by doÅ¡lo k bÄ›Å¾nÃ©mu sdÃ­lenÃ­ dat v rÃ¡mci internÃ­ch systÃ©mÅ¯. ZÃ¡kladem jsou specializovanÃ© Äipy Tensor Processing Units (TPU), kterÃ© integrujÃ­ bezpeÄnostnÃ­ prvky pro ovÄ›Å™ovÃ¡nÃ­ firmware a kryptografickÃ© operace. Nad nimi bÄ›Å¾Ã­ Trusted Execution Environment (TEE) zaloÅ¾enÃ½ na technologiÃ­ch AMD, kterÃ½ Å¡ifruje a izoluje pamÄ›Å¥ vÅ¯Äi hostitelskÃ©mu systÃ©mu a infrastruktuÅ™e provozovatele.

Z koncovÃ©ho zaÅ™Ã­zenÃ­ (napÅ™Ã­klad telefonu Pixel nebo klientskÃ© aplikace) je navÃ¡zÃ¡no Å¡ifrovanÃ© spojenÃ­ pÅ™Ã­mo do tohoto TEE. Data by nemÄ›la bÃ½t dostupnÃ¡ standardnÃ­m administrÃ¡torskÃ½m nÃ¡strojÅ¯m, logovacÃ­m systÃ©mÅ¯m ani modelÅ¯m mimo definovanÃ½ ÃºÄel. Google tvrdÃ­, Å¾e ani internÃ­ zamÄ›stnanci nemajÃ­ mÃ­t pÅ™Ã­stup k nezaÅ¡ifrovanÃ½m vstupÅ¯m. Architektura tak mÃ¡ zabrÃ¡nit typickÃ©mu riziku centralizovanÃ©ho AI cloudu, kde je uÅ¾ivatel nucen vÄ›Å™it poskytovateli, Å¾e s daty nebude dÃ¡le pracovat.

SluÅ¾ba mÃ¡ umoÅ¾nit vyuÅ¾itÃ­ velkÃ½ch modelÅ¯ Gemini, kterÃ© nelze efektivnÄ› provozovat lokÃ¡lnÄ› na NPU v telefonech Äi noteboocÃ­ch. Na rozdÃ­l od menÅ¡Ã­ho modelu Gemini Nano, bÄ›Å¾Ã­cÃ­ho pÅ™Ã­mo na zaÅ™Ã­zenÃ­ pro jednoduÅ¡Å¡Ã­ Ãºlohy (lokÃ¡lnÃ­ sumarizace, chytrÃ© odpovÄ›di, offline asistenti), mÃ¡ Private AI Compute obslouÅ¾it nÃ¡roÄnÄ›jÅ¡Ã­ scÃ©nÃ¡Å™e: komplexnÃ­ analÃ½zu dokumentÅ¯, multimodÃ¡lnÃ­ zpracovÃ¡nÃ­, firemnÃ­ asistenty nebo pokroÄilÃ© generovÃ¡nÃ­ obsahu, aniÅ¾ by firma Äi uÅ¾ivatel museli rezignovat na pÅ™Ã­snÄ›jÅ¡Ã­ reÅ¾im naklÃ¡dÃ¡nÃ­ s daty.

Google se odvolÃ¡vÃ¡ na nezÃ¡vislÃ½ audit od bezpeÄnostnÃ­ spoleÄnosti NCC Group, kterÃ¡ mÃ¡ potvrzovat soulad s deklarovanÃ½mi zÃ¡sadami. KlÃ­ÄovÃ¡ ale bude transparentnost technickÃ© dokumentace, moÅ¾nosti nezÃ¡vislÃ© verifikace implementace a jasnÃ¡ smluvnÃ­ omezenÃ­ vyuÅ¾itÃ­ dat k trÃ©novÃ¡nÃ­ modelÅ¯.

## ProÄ je to dÅ¯leÅ¾itÃ©
Private AI Compute ukazuje, jak velcÃ­ poskytovatelÃ© AI reagujÃ­ na rostoucÃ­ tlak trhu: uÅ¾ivatelÃ© a firmy chtÄ›jÃ­ vyuÅ¾Ã­t velkÃ© modely, ale nechtÄ›jÃ­ odevzdat kontrolu nad svÃ½mi daty. Pokud je architektura skuteÄnÄ› navrÅ¾ena tak, jak Google popisuje, jde o posun k modelu, kde cloudovÃ© AI nemusÃ­ automaticky znamenat datovÃ© riziko.

Z hlediska prÅ¯myslu to vytvÃ¡Å™Ã­ novÃ½ standard: kombinace hardwarovÄ› vynucenÃ© izolace (TEE), Å¡ifrovanÃ©ho pÅ™enosu pÅ™Ã­mo do zabezpeÄenÃ©ho prostÅ™edÃ­ a deklarovanÃ©ho zÃ¡kazu internÃ­ho pÅ™Ã­stupu. Tento pÅ™Ã­stup bude relevantnÃ­ pro banky, zdravotnictvÃ­, stÃ¡tnÃ­ sprÃ¡vu i technologickÃ© firmy, kterÃ© doposud upÅ™ednostÅˆovaly on-premise Å™eÅ¡enÃ­ Äi lokÃ¡lnÃ­ inference. SouÄasnÄ› ale platÃ­, Å¾e uÅ¾ivatelÃ© i regulÃ¡toÅ™i musÃ­ poÅ¾adovat ovÄ›Å™itelnou implementaci â€“ bez nezÃ¡visle kontrolovatelnÃ½ch dÅ¯kazÅ¯ zÅ¯stane ÄÃ¡st tvrzenÃ­ pouze marketingem.

Private AI Compute takÃ© posiluje trend, kdy se hranice mezi "edge" a "cloud" stÃ­rÃ¡. PoskytovatelÃ© se snaÅ¾Ã­ nabÃ­dnout vÃ½kon cloudu s bezpeÄnostnÃ­m narativem lokÃ¡lnÃ­ho zpracovÃ¡nÃ­. Pro ekosystÃ©m AI bezpeÄnosti je zÃ¡sadnÃ­, zda se z tÄ›chto tvrzenÃ­ stanou reÃ¡lnÄ› vymahatelnÃ© technickÃ© a prÃ¡vnÃ­ zÃ¡vazky, nebo jen novÃ½ slovnÃ­k pro tradiÄnÃ­ centralizovanÃ½ sbÄ›r dat.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/google/2025/11/google-says-new-cloud-based-private-ai-compute-is-just-as-secure-as-local-processing/)

**Zdroj:** ğŸ”¬ Ars Technica
