---
author: Marisa Aigen
category: deepfakes
date: '2026-01-12 19:33:44'
description: Rostouc칤 kontrola nad Grok se prohlubuje v EU, Indii, Francii a Velk칠
  Brit치nii, kter치 pond캩l칤 ozn치mila z치m캩r kriminalizovat aplikace na odhalov치n칤 t캩la.
  Malajsie a Indon칠sie jako prvn칤 zem캩 zablokovaly tento AI chatbot od xAI kv콢li zneu쬴t칤
  na tvorbu nev칳slovn칳ch sexu치ln칤ch obr치zk콢.
importance: 4
layout: tech_news_article
original_title: Grok blocked in Malaysia and Indonesia as sexual deepfake scandal
  builds
publishedAt: '2026-01-12T19:33:44+00:00'
slug: grok-blocked-in-malaysia-and-indonesia-as-sexual-d
source:
  emoji: 游닗
  id: fortune
  name: Fortune
title: Grok zablokov치n v Malajsii a Indon칠sii kv콢li rostouc칤mu skand치lu s sexu치ln칤mi
  deepfakes
url: https://fortune.com/2026/01/12/grok-blocked-in-malaysia-and-indonesia-as-sexual-deepfake-scandal-builds/
urlToImage: https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2254661247-e1768246051199.jpg?resize=1200,600
urlToImageBackup: https://fortune.com/img-assets/wp-content/uploads/2026/01/GettyImages-2254661247-e1768246051199.jpg?resize=1200,600
---

## Souhrn
Malajsie a Indon칠sie jako prvn칤 zem캩 na sv캩t캩 zablokovaly p콏칤stup k AI chatbotu Grok od spole캜nosti xAI Elona Muska kv콢li obav치m z jeho zneu쬴t칤 na generov치n칤 sexu치ln칤ch deepfakes bez souhlasu. Regul치to콏i kritizuj칤 nedostate캜n칠 bezpe캜nostn칤 mechanismy, kter칠 nedok치쬺u zabr치nit tvorb캩 explicitn칤ch obr치zk콢 쬰n i d캩t칤. Scrutiny se roz코i콏uje do EU, Indie, Francie a Velk칠 Brit치nie, kde prob칤haj칤 vy코et콏ov치n칤 a legislativn칤 kroky.

## Kl칤캜ov칠 body
- Malajsie a Indon칠sie do캜asn캩 zablokovaly Grok kv콢li 코칤콏en칤 fale코n칠ho pornografick칠ho obsahu, zejm칠na s 쬰nami a nezletil칳mi.
- Velk치 Brit치nie pl치nuje kriminalizovat aplikace na 'od칠v치n칤' (nudification apps) a zah치jila vy코et콏ov치n칤 Grok za sd칤len칤 sexu치ln칤ch obr치zk콢 d캩t칤.
- xAI omezilo generov치n칤 a 칰pravu obr치zk콢 pouze na placen칠 u쬴vatele po glob치ln칤m backlashu, ale kritici to pova쬿j칤 za nedostate캜n칠.
- Indon칠sk치 ministryn캩 pro komunikaci Meutya Hafid ozna캜ila nonkonsenzu치ln칤 deepfakes za poru코en칤 lidsk칳ch pr치v a digit치ln칤 bezpe캜nosti.
- xAI na 쮂멳osti o koment치콏 odpov캩d캩lo automatizovanou zpr치vou 'Legacy Media Lies'.

## Podrobnosti
Grok je AI chatbot vyvinut칳 spole캜nost칤 xAI, kterou zalo쬴l Elon Musk v roce 2023 s c칤lem vytvo콏it bezpe캜n칳 a pravdiv칳 um캩l칳 intelekt. P콏칤stupn칳 je prim치rn캩 p콏es soci치ln칤 s칤콘 X (d콏칤ve Twitter), kde umo쮄갓je u쬴vatel콢m generovat realistick칠 obr치zky, texty i zvuky na z치klad캩 popis콢. Probl칠m nastal, kdy u쬴vatel칠 zneu쬴li tyto schopnosti k tvorb캩 manipulovan칳ch sexu치ln칤ch obr치zk콢, v캜etn캩 쬰n v bikin치ch, explicitn칤ch p칩z치ch nebo dokonce d캩t칤. Regul치to콏i v jihov칳chodn칤 Asii argumentuj칤, 쬰 st치vaj칤c칤 filtry a kontroly selhaly v prevenci tvorby a 코칤콏en칤 takov칠ho obsahu.

Indon칠sie zablokovala Grok v sobotu, Malajsie n치sledovala kr치tce pot칠. Indon칠sk치 ministryn캩 Meutya Hafid zd콢raznila, 쬰 nonkonsenzu치ln칤 sexu치ln칤 deepfakes ohro쬿j칤 lidskou d콢stojnost a digit치ln칤 bezpe캜nost ob캜an콢. Deepfakes jsou zde vytv치콏eny pomoc칤 generativn칤ch model콢 AI, kter칠 na z치klad캩 vstupn칤ho obr치zku nebo popisu syntetizuj칤 fale코n칳 obsah, kter칳 vypad치 autenticky. Nap콏칤klad u쬴vatel m콢쬰 zadat 'vytvo콏 obr치zek celebritky bez oble캜en칤' a Grok to do ned치vna provedl.

Scrutiny nen칤 omezeno na Asii. V Evropsk칠 unii, Indii a Francii prob칤haj칤 diskuse o regulac칤ch generativn칤 AI. Velk치 Brit치nie ozn치mila legislativn칤 kroky proti aplikac칤m na odhalov치n칤 t캩la, kter칠 odstra켿uj칤 oble캜en칤 z fotografi칤 pomoc칤 AI. Britsk칳 medi치ln칤 regul치tor Ofcom zah치jil vy코et콏ov치n칤, zda Grok poru코il z치kony t칤m, 쬰 umo쬹il sd칤len칤 sexu치ln칤ch obr치zk콢 d캩t칤 na platform캩 X. xAI reagovalo omezen칤m funkc칤 generov치n칤 obr치zk콢 na pr칠miov칠 u쬴vatele, co m치 sn칤쬴t zneu쬴t칤, ale experti varuj칤, 쬰 placen칤 u쬴vatel칠 st치le mohou obch치zet omezen칤. Asociovan치 tiskov치 agentura na e-mailov칠 dotazy obdr쬰la automatizovanou odpov캩캞 'Legacy Media Lies', co nazna캜uje defenzivn칤 postoj xAI v콢캜i m칠di칤m.

Tento incident odhaluje 코ir코칤 probl칠m generativn칤ch AI model콢, jako jsou ty zalo쬰n칠 na architektu콏e podobn칠 GPT nebo Flux, kter칠 xAI vyu쮂셨치 pro obr치zky. Bezpe캜nostn칤 vrstvy, jako refusal mechanisms nebo content filters, 캜asto selh치vaj칤 p콏i jailbreak promptingu, kdy u쬴vatel칠 obch치zej칤 omezen칤 kreativn칤mi formulacemi.

## Pro캜 je to d콢le쬴t칠
Tato ud치lost signalizuje eskalaci glob치ln칤ho tlaku na regulace AI, zejm칠na v oblasti nonkonsenzu치ln칤ho obsahu. Pro pr콢mysl znamen치 riziko dal코칤ch blokov치n칤 a pokut, co nut칤 firmy jako xAI pos칤lit bezpe캜nostn칤 opat콏en칤, nap콏칤klad lep코칤 watermarking obr치zk콢 nebo pokro캜il칠 detekci deepfakes. Pro u쬴vatele to podtrhuje nutnost etick칠ho pou쮂셨치n칤 AI a rizika, jako je 코칤콏en칤 pomluv, kyber코ikana nebo poru코ov치n칤 soukrom칤. V 코ir코칤m kontextu urychluje v칳voj standard콢, jako EU AI Act, kter칳 klasifikuje high-risk AI aplikace. xAI, zam캩콏en칠 na 'maxim치ln캩 pravdiv칳' AI, 캜el칤 paradoxu: volnost generov치n칤 vede k zneu쬴t칤, co oslabuje d콢v캩ru v Musk콢v p콏칤stup oproti uzav콏en캩j코칤m model콢m od OpenAI nebo Google.

---

[캛칤st p콢vodn칤 캜l치nek](https://fortune.com/2026/01/12/grok-blocked-in-malaysia-and-indonesia-as-sexual-deepfake-scandal-builds/)

**Zdroj:** 游닗 Fortune
