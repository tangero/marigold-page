---
author: Marisa Aigen
category: regulace ai
date: '2025-12-27 21:32:49'
description: ÄŒÃ­nskÃ¡ sprÃ¡va kyberprostoru zveÅ™ejnila nÃ¡vrh na regulaci AI systÃ©mÅ¯ s
  personifikovanou interakcÃ­, jako jsou chatboti a virtuÃ¡lnÃ­ spoleÄnÃ­ci. CÃ­lem je
  zajistit bezpeÄnost a soulad s nÃ¡rodnÃ­mi zÃ¡jmy pÅ™i sbÄ›ru veÅ™ejnÃ½ch pÅ™ipomÃ­nek.
importance: 4
layout: tech_news_article
original_title: China issues draft rules to regulate AI with human-like interaction
  - Reuters
publishedAt: '2025-12-27T21:32:49+00:00'
slug: china-issues-draft-rules-to-regulate-ai-with-human
source:
  emoji: ğŸ“°
  id: null
  name: Slashdot.org
title: ÄŒÃ­na vydÃ¡vÃ¡ nÃ¡vrhovÃ© pravidla pro regulaci AI s lidskou interakcÃ­ - Reuters
url: https://slashdot.org/firehose.pl?op=view&amp;id=180466203
---

## Souhrn
ÄŒÃ­nskÃ¡ Cyberspace Administration of China (CAC) vydala nÃ¡vrhovÃ© pravidla pro Å™Ã­zenÃ­ AI personifikovanÃ½ch interaktivnÃ­ch sluÅ¾eb, kterÃ© simulujÃ­ lidskou interakci. Tato opatÅ™enÃ­ reagujÃ­ na rychlÃ½ rÅ¯st technologiÃ­ jako pokroÄilÃ© chatboti a virtuÃ¡lnÃ­ asistenti s osobnostÃ­. Dokument je otevÅ™en pro veÅ™ejnÃ© pÅ™ipomÃ­nky a navazuje na pÅ™edchozÃ­ regulace generativnÃ­ AI.

## KlÃ­ÄovÃ© body
- CAC vyÅ¾aduje registraci a schvÃ¡lenÃ­ pro provozovatele takovÃ½ch AI sluÅ¾eb.
- PovinnÃ© oznaÄovÃ¡nÃ­ AI-generovanÃ©ho obsahu a ochrana dat uÅ¾ivatelÅ¯.
- ZÃ¡kaz Å¡Ã­Å™enÃ­ Å¡kodlivÃ©ho obsahu, kterÃ½ by ohrozil nÃ¡rodnÃ­ bezpeÄnost nebo veÅ™ejnÃ½ poÅ™Ã¡dek.
- SpecifickÃ© poÅ¾adavky na bezpeÄnostnÃ­ testy a algoritmickou transparentnost.
- Souvislost s obavami z vlivu AI na politickou stabilitu komunistickÃ© strany.

## Podrobnosti
NÃ¡vrh pravidel se zamÄ›Å™uje na AI personifikovanÃ© interaktivnÃ­ sluÅ¾by, coÅ¾ zahrnuje systÃ©my schopnÃ© emulovat lidskÃ© chovÃ¡nÃ­, emoce a konverzaci v reÃ¡lnÃ©m Äase. Tyto technologie, podobnÃ© modelÅ¯m jako ChatGPT nebo domÃ¡cÃ­m ÄÃ­nskÃ½m ekvivalentÅ¯m od firem Baidu (Ernie Bot) nebo Tencentu, slouÅ¾Ã­ k tvorbÄ› virtuÃ¡lnÃ­ch spoleÄnÃ­kÅ¯, terapeutÅ¯ nebo zÃ¡bavnÃ­ch partnerÅ¯. CAC, kterÃ¡ dohlÃ­Å¾Ã­ na kyberprostor a internetovou regulaci v ÄŒÃ­nÄ›, nynÃ­ poÅ¾aduje, aby provozovatelÃ© takovÃ½ch sluÅ¾eb zÃ­skali oficiÃ¡lnÃ­ schvÃ¡lenÃ­ pÅ™ed spuÅ¡tÄ›nÃ­m. To znamenÃ¡ podrobnÃ© bezpeÄnostnÃ­ hodnocenÃ­ algoritmÅ¯, vÄetnÄ› testÅ¯ na halucinace, bias a potenciÃ¡l k Å¡Ã­Å™enÃ­ dezinformacÃ­.

Dokument navazuje na loÅˆskou regulaci generativnÃ­ AI z srpna 2023, kterÃ¡ uvalila povinnost registrace modelÅ¯ s vÃ­ce neÅ¾ milionem uÅ¾ivatelÅ¯. Novinka rozÅ¡iÅ™uje dosah na interaktivnÃ­ prvky, kde AI pÅ™ebÃ­rÃ¡ roli "osobnosti". NapÅ™Ã­klad sluÅ¾by jako Xiaoice od Microsoftu (nynÃ­ pod ÄÃ­nskou kontrolou) nebo Soul App musÃ­ splnit poÅ¾adavky na ochranu soukromÃ­ dat, vÄetnÄ› lokalizace dat v ÄŒÃ­nÄ› a zÃ¡kazu pÅ™enosu citlivÃ½ch informacÃ­ do zahraniÄÃ­. VeÅ™ejnÃ© pÅ™ipomÃ­nky majÃ­ probÃ­hat po omezenou dobu, coÅ¾ je standardnÃ­ postup pÅ™ed finÃ¡lnÃ­m schvÃ¡lenÃ­m.

V Å¡irÅ¡Ã­m kontextu toto odrÃ¡Å¾Ã­ ÄÃ­nskou strategii â€AI s charakterem socialismu s ÄÃ­nskÃ½mi rysyâ€œ. ZprÃ¡vy jako ty z Wall Street Journal naznaÄujÃ­, Å¾e motivacÃ­ je obava z AI, kterÃ© by mohlo oslabit kontrolu KomunistickÃ© strany, napÅ™Ã­klad prostÅ™ednictvÃ­m nespokojenÃ½ch konverzacÃ­ nebo propagace zÃ¡padnÃ­ch hodnot. Firmy jako XinDao Technology, prvnÃ­ na Å¡anghajskÃ©m STAR Market, kterÃ¡ zveÅ™ejnila vÃ½roÄnÃ­ zprÃ¡vu o AI technologiÃ­ch, budou muset tyto pravidla integrovat do svÃ½ch operacÃ­. Pro uÅ¾ivatele to znamenÃ¡ mÃ©nÄ› volnosti v interakci s AI, ale vyÅ¡Å¡Ã­ bezpeÄnost proti podvodÅ¯m, jako deepfakes v konverzaci.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato regulace posiluje ÄÃ­nskou dominanci v AI, kde zemÄ› investuje miliardy do vÃ½voje, ale pod pÅ™Ã­snou stÃ¡tnÃ­ kontrolou. Pro globÃ¡lnÃ­ prÅ¯mysl nastavuje precedens pro regulaci human-like AI, podobnÄ› jako EU AI Act, kterÃ½ klasifikuje high-risk systÃ©my. ÄŒÃ­nskÃ© firmy, kterÃ© tvoÅ™Ã­ tÃ©mÄ›Å™ polovinu svÄ›tovÃ½ch AI patentÅ¯, budou muset upravit modely, coÅ¾ ovlivnÃ­ export technologiÃ­. Pro uÅ¾ivatele a vÃ½vojÃ¡Å™e znamenÃ¡ to nutnost zamÄ›Å™it se na etickÃ© aspekty, jako explainable AI a bias mitigation, aby se vyhnuli sankcÃ­m. V dlouhodobÃ©m horizontu to mÅ¯Å¾e zpomalit inovace v konzumernÃ­ch aplikacÃ­ch, ale urychlit vÃ½voj bezpeÄnostnÃ­ch standardÅ¯, kterÃ© se stanou globÃ¡lnÃ­m benchmarkem.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://slashdot.org/firehose.pl?op=view&amp;id=180466203)

**Zdroj:** ğŸ“° Slashdot.org
