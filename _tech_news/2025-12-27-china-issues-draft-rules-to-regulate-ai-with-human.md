---
author: Marisa Aigen
category: regulace ai
date: '2025-12-27 21:32:49'
description: ÄŒÃ­nskÃ¡ sprÃ¡va kyberprostoru zveÅ™ejnila nÃ¡vrh na regulaci umÄ›lÃ© inteligence,
  kterÃ¡ napodobuje lidskÃ© chovÃ¡nÃ­ a interakce. CÃ­lem je kontrolovat personifikovanÃ©
  AI sluÅ¾by, aby neohrozily ideologickou stabilitu komunistickÃ© strany.
importance: 4
layout: tech_news_article
original_title: China issues draft rules to regulate AI with human-like interaction
  - Reuters
publishedAt: '2025-12-27T21:32:49+00:00'
slug: china-issues-draft-rules-to-regulate-ai-with-human
source:
  emoji: ğŸ“°
  id: null
  name: Slashdot.org
title: ÄŒÃ­na vydÃ¡vÃ¡ nÃ¡vrh pravidel pro regulaci AI s lidskou interakcÃ­
url: https://slashdot.org/firehose.pl?op=view&amp;id=180466203
---

## Souhrn
ÄŒÃ­nskÃ¡ sprÃ¡va kyberprostoru (Cyberspace Administration of China, CAC) zveÅ™ejnila nÃ¡vrh pravidel pro sprÃ¡vu AI sluÅ¾eb s personifikovanÃ½mi interaktivnÃ­mi funkcemi, kterÃ© napodobujÃ­ lidskÃ© emoce, vÃ½razy a chovÃ¡nÃ­. Tento krok navazuje na pÅ™edchozÃ­ regulace generativnÃ­ AI a reaguje na rostoucÃ­ popularitu AI spoleÄnÃ­kÅ¯. NÃ¡vrh je veÅ™ejnÃ© konzultaci do 11. kvÄ›tna 2024.

## KlÃ­ÄovÃ© body
- PovinnÃ¡ registrace vÅ¡ech AI sluÅ¾eb s lidskou interakcÃ­ u CAC pÅ™ed spuÅ¡tÄ›nÃ­m.
- OznaÄovÃ¡nÃ­ obsahu generovanÃ©ho AI jako syntetickÃ©ho, aby uÅ¾ivatelÃ© vÄ›dÄ›li o umÄ›lÃ©m pÅ¯vodu.
- ZÃ¡kaz Å¡Ã­Å™enÃ­ Å¡kodlivÃ©ho obsahu, vÄetnÄ› dezinformacÃ­, extremismu nebo naruÅ¡enÃ­ nÃ¡rodnÃ­ bezpeÄnosti.
- BezpeÄnostnÃ­ hodnocenÃ­ systÃ©mÅ¯, vÄetnÄ› ochrany dat uÅ¾ivatelÅ¯ a prevence zÃ¡vislosti.
- Aplikace na sluÅ¾by jako hlasovÃ­ asistenti, virtuÃ¡lnÃ­ spoleÄnÃ­ci nebo AI avatary.

## Podrobnosti
NÃ¡vrh se zamÄ›Å™uje na AI systÃ©my, kterÃ© generujÃ­ interakce pÅ™ipomÃ­najÃ­cÃ­ lidskÃ© â€“ napÅ™Ã­klad hlasovÃ© modely s emocionÃ¡lnÃ­mi tÃ³ny, textovÃ© chaty s osobnostÃ­ nebo vizuÃ¡lnÃ­ avatary s vÃ½razy tvÃ¡Å™e. Tyto technologie se staly populÃ¡rnÃ­mi v ÄŒÃ­nÄ› dÃ­ky aplikacÃ­m jako AI pÅ™Ã­telkynÄ› nebo virtuÃ¡lnÃ­ terapeuti, kterÃ© pÅ™itahujÃ­ miliony uÅ¾ivatelÅ¯. CAC definuje personifikovanou interakci jako funkci, kde AI simuluje antropomorfnÃ­ vlastnosti, coÅ¾ zahrnuje nejen konverzaci, ale i multimodÃ¡lnÃ­ vÃ½stupy jako video nebo zvuk.

Podle nÃ¡vrhu musÃ­ provozovatelÃ© sluÅ¾eb nejprve zaregistrovat svÃ© systÃ©my u CAC, poskytnout technickÃ© detaily o trÃ©novacÃ­ch datech, modelech a bezpeÄnostnÃ­ch opatÅ™enÃ­ch. To umoÅ¾nÃ­ stÃ¡tnÃ­ dohled nad vÃ½vojem. Obsah generovanÃ½ tÄ›mito AI musÃ­ bÃ½t oznaÄen vodoznaky nebo Å¡tÃ­tky, podobnÄ› jako u deepfake videÃ­. ZÃ¡kaz platÃ­ pro materiÃ¡ly, kterÃ© by mohly podnÄ›covat nepokoje, Å¡Ã­Å™it faleÅ¡nÃ© zprÃ¡vy nebo oslabovat autoritu komunistickÃ© strany â€“ napÅ™Ã­klad AI, kterÃ© kritizujÃ­ vlÃ¡du nebo propagujÃ­ zÃ¡padnÃ­ hodnoty.

Tento nÃ¡vrh navazuje na Å¡irÅ¡Ã­ rÃ¡mec z roku 2023, kdy ÄŒÃ­na zavedla pravidla pro generativnÃ­ AI, vyÅ¾adujÃ­cÃ­ schvÃ¡lenÃ­ modelÅ¯ jako Ernie od Baidu nebo podobnÃ½ch od Tencentu. CAC zdÅ¯razÅˆuje potÅ™ebu etickÃ½ch standardÅ¯, vÄetnÄ› ochrany soukromÃ­ dat a prevence psychologickÃ½ch rizik, jako je zÃ¡vislost na AI spoleÄnÃ­cÃ­ch. Firmy jako XinDao Technology, kterÃ¡ se zabÃ½vÃ¡ AI technologiemi a nedÃ¡vno zveÅ™ejnila vÃ½roÄnÃ­ zprÃ¡vu na burze STAR, budou mezi prvnÃ­mi postiÅ¾enÃ½mi. Konzultace s veÅ™ejnostÃ­ probÃ­hÃ¡ do poloviny kvÄ›tna, coÅ¾ naznaÄuje rychlÃ© zavedenÃ­.

V praxi to znamenÃ¡, Å¾e vÃ½vojÃ¡Å™i v ÄŒÃ­nÄ› budou muset integrovat bezpeÄnostnÃ­ vrstvy do svÃ½ch modelÅ¯ LLM (large language models), jako jsou filtry obsahu a mechanismy detekce. Pro uÅ¾ivatele to pÅ™inese jasnÄ›jÅ¡Ã­ oznaÄenÃ­ AI obsahu, coÅ¾ sniÅ¾uje riziko podvodu, ale omezÃ­ svobodu inovacÃ­. MezinÃ¡rodnÃ­ firmy operujÃ­cÃ­ v ÄŒÃ­nÄ›, jako Google nebo OpenAI partneÅ™i, budou muset pÅ™izpÅ¯sobit svÃ© sluÅ¾by.

## ProÄ je to dÅ¯leÅ¾itÃ©
Regulace ukazuje rostoucÃ­ obavy ÄŒÃ­ny z AI, kterÃ© by mohlo ohrozit ideologickou kontrolu â€“ Bloomberg mluvÃ­ o snaze â€zkrotit AI, aby neohrozila vlÃ¡du stranyâ€œ. ÄŒÃ­na je druhÃ½m nejvÄ›tÅ¡Ã­m trhem pro AI po USA, s investicemi pÅ™es 10 miliard dolarÅ¯ roÄnÄ›, a tato pravidla ovlivnÃ­ globÃ¡lnÃ­ dodavatelskÃ© Å™etÄ›zce ÄipÅ¯ i datovÃ½ch center. Pro prÅ¯mysl znamenÃ¡ vyÅ¡Å¡Ã­ compliance nÃ¡klady, ale i standardy, kterÃ© by mohly inspirovat EU AI Act. Pro uÅ¾ivatele posiluje bezpeÄnost, ale brzdÃ­ experimenty s pokroÄilÃ½mi interakcemi, jako jsou empatickÃ© AI asistenti v terapii nebo vzdÄ›lÃ¡vÃ¡nÃ­. V Å¡irÅ¡Ã­m kontextu to urychluje globÃ¡lnÃ­ zÃ¡vod o AI governance, kde ÄŒÃ­na stavÃ­ na stÃ¡tnÃ­ kontrole oproti americkÃ©mu modelu trÅ¾nÃ­ho dohledu.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://slashdot.org/firehose.pl?op=view&amp;id=180466203)

**Zdroj:** ğŸ“° Slashdot.org
