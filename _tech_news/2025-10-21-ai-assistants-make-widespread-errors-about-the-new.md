---
category: ai asistenti
companies:
- Na základě poskytnutého textu (pouze nadpisu a popisu) nemohu identifikovat žádné
  konkrétní technologické firmy. Text zmiňuje "AI assistants" obecně
- 'ale neuvádí názvy konkrétních firem.


  žádné'
date: '2025-10-21 22:08:41'
description: Studie Evropské vysílací unie a BBC analyzovala 3000 odpovědí od předních
  AI asistentů a zjistila, že 45 % obsahuje závažné problémy a 81 % má nějakou formu
  chyby.
importance: 4
layout: tech_news_article
original_title: AI assistants make widespread errors about the news, new research
  shows - Yahoo News Canada
publishedAt: '2025-10-21T22:08:41+00:00'
slug: ai-assistants-make-widespread-errors-about-the-new
source:
  emoji: 📰
  id: null
  name: Yahoo Entertainment
title: AI asistenti dělají chyby v téměř polovině odpovědí o aktualitách, ukazuje
  nový výzkum
url: https://www.yahoo.com/news/articles/ai-assistants-widespread-errors-news-220841474.html
urlToImage: https://media.zenfs.com/en/reuters.com/04d386da9d90fe8d38735368ec5748c6
urlToImageBackup: https://media.zenfs.com/en/reuters.com/04d386da9d90fe8d38735368ec5748c6
---

## Souhrn

Vedoucí AI asistenti jako ChatGPT, Copilot, Gemini a Perplexity poskytují nepřesné nebo zavádějící informace o aktualitách v téměř polovině svých odpovědí. Mezinárodní výzkum Evropské vysílací unie (EBU) a BBC analyzoval 3000 odpovědí ve 14 jazycích a odhalil závažné problémy s přesností, citováním zdrojů a rozlišováním faktů od názorů.

## Klíčové body

- 45 % odpovědí AI asistentů obsahovalo alespoň jeden závažný problém, celkem 81 % mělo nějakou formu chyby
- Třetina odpovědí vykazovala vážné chyby v citování zdrojů - chybějící, zavádějící nebo nesprávné uvedení původu informací
- Gemini od Googlu měl nejhorší výsledky v oblasti zdrojů - 72 % odpovědí obsahovalo závažné problémy s citacemi
- Problémy s přesností se objevily v 20 % odpovědí napříč testovanými asistenty
- Studie testovala schopnost AI rozlišovat fakta od názorů a správně citovat zdroje informací

## Podrobnosti

Výzkum se zaměřil na analýzu toho, jak AI asistenti zpracovávají a prezentují zpravodajský obsah uživatelům. Testování probíhalo ve 14 různých jazycích, což umožnilo posoudit kvalitu odpovědí v mezinárodním kontextu. Studie hodnotila tři klíčové oblasti: přesnost poskytovaných informací, správnost citování zdrojů a schopnost rozlišit mezi objektivními fakty a subjektivními názory.

Zvláště alarmující je zjištění, že pouze 19 % odpovědí bylo zcela bez problémů. To znamená, že uživatelé spoléhající na AI asistenty pro získávání informací o aktuálním dění mají vysokou pravděpodobnost, že obdrží nějakým způsobem problematickou odpověď.

Největší slabinou se ukázalo být citování zdrojů. Třetina všech odpovědí měla závažné problémy s atribucí - buď zdroje zcela chybí, jsou uvedeny zavádějícím způsobem, nebo jsou přímo nesprávné. Gemini od Googlu v této oblasti výrazně zaostával za konkurencí s 72 % problematických odpovědí, zatímco ostatní asistenti se drželi pod 25 %.

Společnosti za těmito produkty problém uznávají. Google uvádí, že vítá zpětnou vazbu pro zlepšování platformy. OpenAI a Microsoft dříve přiznaly, že halucinace - situace, kdy AI model generuje nesprávné nebo zavádějící informace kvůli nedostatečným datům nebo jiným faktorům - jsou problém, který se snaží řešit. Perplexity na svých webových stránkách uvádí, že jeden z jeho režimů "Deep Research" dosahuje 93,9% přesnosti z hlediska faktičnosti.

## Proč je to důležité

Tento výzkum přichází v době, kdy stále více lidí používá AI asistenty jako primární zdroj informací o aktuálním dění. Zjištění, že téměř polovina odpovědí obsahuje závažné problémy, vyvolává vážné otázky o spolehlivosti těchto nástrojů pro zpravodajské účely.

Problémy s citováním zdrojů jsou obzvláště znepokojivé, protože uživatelé nemohou ověřit původ informací ani posoudit jejich důvěryhodnost. V době dezinformací a fake news je schopnost trasovat informace k jejich původnímu zdroji klíčová pro kritické myšlení.

Výzkum také ukazuje, že i když technologické společnosti investují miliardy do vývoje AI, základní problémy s přesností a spolehlivostí přetrvávají. To má důsledky nejen pro koncové uživatele, ale i pro mediální organizace a žurnalisty, kteří musí čelit tomu, že jejich obsah je AI systémy často nesprávně interpretován nebo citován.

Pro uživatele to znamená jasné doporučení: informace z AI asistentů o aktuálním dění by měly být vždy ověřovány z primárních zdrojů. AI asistenti mohou být užitečným výchozím bodem, ale neměli by být považováni za spolehlivý zdroj zpravodajství.

---

[Číst původní článek](https://www.yahoo.com/news/articles/ai-assistants-widespread-errors-news-220841474.html)

**Zdroj:** 📰 Yahoo Entertainment
