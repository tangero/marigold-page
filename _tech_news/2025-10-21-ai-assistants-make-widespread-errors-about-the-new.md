---
category: ai asistenti
companies:
- Na zÃ¡kladÄ› poskytnutÃ©ho textu (pouze nadpisu a popisu) nemohu identifikovat Å¾Ã¡dnÃ©
  konkrÃ©tnÃ­ technologickÃ© firmy. Text zmiÅˆuje "AI assistants" obecnÄ›
- 'ale neuvÃ¡dÃ­ nÃ¡zvy konkrÃ©tnÃ­ch firem.


  Å¾Ã¡dnÃ©'
date: '2025-10-21 22:08:41'
description: Studie EvropskÃ© vysÃ­lacÃ­ unie a BBC analyzovala 3000 odpovÄ›dÃ­ od pÅ™ednÃ­ch
  AI asistentÅ¯ a zjistila, Å¾e 45 % obsahuje zÃ¡vaÅ¾nÃ© problÃ©my a 81 % mÃ¡ nÄ›jakou formu
  chyby.
importance: 4
layout: tech_news_article
original_title: AI assistants make widespread errors about the news, new research
  shows - Yahoo News Canada
publishedAt: '2025-10-21T22:08:41+00:00'
slug: ai-assistants-make-widespread-errors-about-the-new
source:
  emoji: ğŸ“°
  id: null
  name: Yahoo Entertainment
title: AI asistenti dÄ›lajÃ­ chyby v tÃ©mÄ›Å™ polovinÄ› odpovÄ›dÃ­ o aktualitÃ¡ch, ukazuje
  novÃ½ vÃ½zkum
url: https://www.yahoo.com/news/articles/ai-assistants-widespread-errors-news-220841474.html
urlToImage: https://media.zenfs.com/en/reuters.com/04d386da9d90fe8d38735368ec5748c6
urlToImageBackup: https://media.zenfs.com/en/reuters.com/04d386da9d90fe8d38735368ec5748c6
---

## Souhrn

VedoucÃ­ AI asistenti jako ChatGPT, Copilot, Gemini a Perplexity poskytujÃ­ nepÅ™esnÃ© nebo zavÃ¡dÄ›jÃ­cÃ­ informace o aktualitÃ¡ch v tÃ©mÄ›Å™ polovinÄ› svÃ½ch odpovÄ›dÃ­. MezinÃ¡rodnÃ­ vÃ½zkum EvropskÃ© vysÃ­lacÃ­ unie (EBU) a BBC analyzoval 3000 odpovÄ›dÃ­ ve 14 jazycÃ­ch a odhalil zÃ¡vaÅ¾nÃ© problÃ©my s pÅ™esnostÃ­, citovÃ¡nÃ­m zdrojÅ¯ a rozliÅ¡ovÃ¡nÃ­m faktÅ¯ od nÃ¡zorÅ¯.

## KlÃ­ÄovÃ© body

- 45 % odpovÄ›dÃ­ AI asistentÅ¯ obsahovalo alespoÅˆ jeden zÃ¡vaÅ¾nÃ½ problÃ©m, celkem 81 % mÄ›lo nÄ›jakou formu chyby
- TÅ™etina odpovÄ›dÃ­ vykazovala vÃ¡Å¾nÃ© chyby v citovÃ¡nÃ­ zdrojÅ¯ - chybÄ›jÃ­cÃ­, zavÃ¡dÄ›jÃ­cÃ­ nebo nesprÃ¡vnÃ© uvedenÃ­ pÅ¯vodu informacÃ­
- Gemini od Googlu mÄ›l nejhorÅ¡Ã­ vÃ½sledky v oblasti zdrojÅ¯ - 72 % odpovÄ›dÃ­ obsahovalo zÃ¡vaÅ¾nÃ© problÃ©my s citacemi
- ProblÃ©my s pÅ™esnostÃ­ se objevily v 20 % odpovÄ›dÃ­ napÅ™Ã­Ä testovanÃ½mi asistenty
- Studie testovala schopnost AI rozliÅ¡ovat fakta od nÃ¡zorÅ¯ a sprÃ¡vnÄ› citovat zdroje informacÃ­

## Podrobnosti

VÃ½zkum se zamÄ›Å™il na analÃ½zu toho, jak AI asistenti zpracovÃ¡vajÃ­ a prezentujÃ­ zpravodajskÃ½ obsah uÅ¾ivatelÅ¯m. TestovÃ¡nÃ­ probÃ­halo ve 14 rÅ¯znÃ½ch jazycÃ­ch, coÅ¾ umoÅ¾nilo posoudit kvalitu odpovÄ›dÃ­ v mezinÃ¡rodnÃ­m kontextu. Studie hodnotila tÅ™i klÃ­ÄovÃ© oblasti: pÅ™esnost poskytovanÃ½ch informacÃ­, sprÃ¡vnost citovÃ¡nÃ­ zdrojÅ¯ a schopnost rozliÅ¡it mezi objektivnÃ­mi fakty a subjektivnÃ­mi nÃ¡zory.

ZvlÃ¡Å¡tÄ› alarmujÃ­cÃ­ je zjiÅ¡tÄ›nÃ­, Å¾e pouze 19 % odpovÄ›dÃ­ bylo zcela bez problÃ©mÅ¯. To znamenÃ¡, Å¾e uÅ¾ivatelÃ© spolÃ©hajÃ­cÃ­ na AI asistenty pro zÃ­skÃ¡vÃ¡nÃ­ informacÃ­ o aktuÃ¡lnÃ­m dÄ›nÃ­ majÃ­ vysokou pravdÄ›podobnost, Å¾e obdrÅ¾Ã­ nÄ›jakÃ½m zpÅ¯sobem problematickou odpovÄ›Ä.

NejvÄ›tÅ¡Ã­ slabinou se ukÃ¡zalo bÃ½t citovÃ¡nÃ­ zdrojÅ¯. TÅ™etina vÅ¡ech odpovÄ›dÃ­ mÄ›la zÃ¡vaÅ¾nÃ© problÃ©my s atribucÃ­ - buÄ zdroje zcela chybÃ­, jsou uvedeny zavÃ¡dÄ›jÃ­cÃ­m zpÅ¯sobem, nebo jsou pÅ™Ã­mo nesprÃ¡vnÃ©. Gemini od Googlu v tÃ©to oblasti vÃ½raznÄ› zaostÃ¡val za konkurencÃ­ s 72 % problematickÃ½ch odpovÄ›dÃ­, zatÃ­mco ostatnÃ­ asistenti se drÅ¾eli pod 25 %.

SpoleÄnosti za tÄ›mito produkty problÃ©m uznÃ¡vajÃ­. Google uvÃ¡dÃ­, Å¾e vÃ­tÃ¡ zpÄ›tnou vazbu pro zlepÅ¡ovÃ¡nÃ­ platformy. OpenAI a Microsoft dÅ™Ã­ve pÅ™iznaly, Å¾e halucinace - situace, kdy AI model generuje nesprÃ¡vnÃ© nebo zavÃ¡dÄ›jÃ­cÃ­ informace kvÅ¯li nedostateÄnÃ½m datÅ¯m nebo jinÃ½m faktorÅ¯m - jsou problÃ©m, kterÃ½ se snaÅ¾Ã­ Å™eÅ¡it. Perplexity na svÃ½ch webovÃ½ch strÃ¡nkÃ¡ch uvÃ¡dÃ­, Å¾e jeden z jeho reÅ¾imÅ¯ "Deep Research" dosahuje 93,9% pÅ™esnosti z hlediska faktiÄnosti.

## ProÄ je to dÅ¯leÅ¾itÃ©

Tento vÃ½zkum pÅ™ichÃ¡zÃ­ v dobÄ›, kdy stÃ¡le vÃ­ce lidÃ­ pouÅ¾Ã­vÃ¡ AI asistenty jako primÃ¡rnÃ­ zdroj informacÃ­ o aktuÃ¡lnÃ­m dÄ›nÃ­. ZjiÅ¡tÄ›nÃ­, Å¾e tÃ©mÄ›Å™ polovina odpovÄ›dÃ­ obsahuje zÃ¡vaÅ¾nÃ© problÃ©my, vyvolÃ¡vÃ¡ vÃ¡Å¾nÃ© otÃ¡zky o spolehlivosti tÄ›chto nÃ¡strojÅ¯ pro zpravodajskÃ© ÃºÄely.

ProblÃ©my s citovÃ¡nÃ­m zdrojÅ¯ jsou obzvlÃ¡Å¡tÄ› znepokojivÃ©, protoÅ¾e uÅ¾ivatelÃ© nemohou ovÄ›Å™it pÅ¯vod informacÃ­ ani posoudit jejich dÅ¯vÄ›ryhodnost. V dobÄ› dezinformacÃ­ a fake news je schopnost trasovat informace k jejich pÅ¯vodnÃ­mu zdroji klÃ­ÄovÃ¡ pro kritickÃ© myÅ¡lenÃ­.

VÃ½zkum takÃ© ukazuje, Å¾e i kdyÅ¾ technologickÃ© spoleÄnosti investujÃ­ miliardy do vÃ½voje AI, zÃ¡kladnÃ­ problÃ©my s pÅ™esnostÃ­ a spolehlivostÃ­ pÅ™etrvÃ¡vajÃ­. To mÃ¡ dÅ¯sledky nejen pro koncovÃ© uÅ¾ivatele, ale i pro mediÃ¡lnÃ­ organizace a Å¾urnalisty, kteÅ™Ã­ musÃ­ Äelit tomu, Å¾e jejich obsah je AI systÃ©my Äasto nesprÃ¡vnÄ› interpretovÃ¡n nebo citovÃ¡n.

Pro uÅ¾ivatele to znamenÃ¡ jasnÃ© doporuÄenÃ­: informace z AI asistentÅ¯ o aktuÃ¡lnÃ­m dÄ›nÃ­ by mÄ›ly bÃ½t vÅ¾dy ovÄ›Å™ovÃ¡ny z primÃ¡rnÃ­ch zdrojÅ¯. AI asistenti mohou bÃ½t uÅ¾iteÄnÃ½m vÃ½chozÃ­m bodem, ale nemÄ›li by bÃ½t povaÅ¾ovÃ¡ni za spolehlivÃ½ zdroj zpravodajstvÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.yahoo.com/news/articles/ai-assistants-widespread-errors-news-220841474.html)

**Zdroj:** ğŸ“° Yahoo Entertainment
