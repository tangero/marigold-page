---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
date: '2026-02-24 00:51:11'
description: AmerickÃ½ ministr obrany Pete Hegseth svolal generÃ¡lnÃ­ho Å™editele Anthropic
  Dario Amodei do Pentagonu na setkÃ¡nÃ­, kterÃ© vyÅ¡Å¡Ã­ pÅ™edstavitelÃ© oznaÄili za nezdvoÅ™ilostnÃ­.
  Jde o prasklinu mezi armÃ¡dou a firmou za modelem Claude, jedinÃ½m AI v klasifikovanÃ½ch
  systÃ©mech, ohlednÄ› pravidel pouÅ¾itÃ­ v bojovÃ½ch operacÃ­ch.
importance: 5
layout: tech_news_article
original_title: 'Pentagon Delivers Ultimatum to Anthropic: Remove AI Guardrails or
  Lose Military Contracts'
people:
- Pete Hegseth
- Dario Amodei
publishedAt: '2026-02-24T00:51:11+00:00'
slug: pentagon-delivers-ultimatum-to-anthropic-remove-ai
source:
  emoji: ğŸ“°
  id: null
  name: Freerepublic.com
title: 'Pentagon dal Anthropic ultimÃ¡tum: OdstraÅˆte bezpeÄnostnÃ­ mechanismy AI nebo
  ztratÃ­te vojenskÃ© zakÃ¡zky'
url: https://freerepublic.com/focus/f-news/4368049/posts
---

### Souhrn
AmerickÃ½ Pentagon vydal spoleÄnosti Anthropic ultimÃ¡tum: odstranit bezpeÄnostnÃ­ mechanismy z modelu Claude, kterÃ½ je jedinÃ½m umÄ›lÃ½m modelem inteligence nasazenÃ½m v armÃ¡dnÃ­ch klasifikovanÃ½ch systÃ©mech, nebo riskovat ztrÃ¡tu vÅ¡ech vojenskÃ½ch kontraktÅ¯. Spor se soustÅ™edÃ­ na podmÃ­nky pouÅ¾itÃ­ AI v obranÄ›, kde Anthropic poÅ¾aduje zÃ¡ruky proti masovÃ©mu sledovÃ¡nÃ­ americkÃ½ch obÄanÅ¯ a vÃ½voji autonomnÃ­ch zbranÃ­ bez lidskÃ©ho zÃ¡sahu. Pentagon trvÃ¡ na volnÃ©m nasazenÃ­ v souladu se zÃ¡kony.

### KlÃ­ÄovÃ© body
- Ministr obrany Pete Hegseth svolal CEO Anthropic Dario Amodei do Pentagonu v ÃºterÃ½ rÃ¡no na ultimÃ¡tnÃ­ jednÃ¡nÃ­.
- Anthropic omezuje Claude proti masovÃ©mu sledovÃ¡nÃ­ obÄanÅ¯ a autonomnÃ­m zbranÃ­m bez lidskÃ©ho rozhodnutÃ­.
- Pentagon hrozÃ­ oznaÄenÃ­m Anthropic za â€riziko v dodavatelskÃ©m Å™etÄ›zciâ€œ, coÅ¾ by zruÅ¡ilo kontrakty a zakÃ¡zalo pouÅ¾itÃ­ Claude v pracÃ­ch pro armÃ¡du.
- Claude, dostupnÃ½ pÅ™es partnerstvÃ­ s obrannou firmou Palantir Technologies, je jedinÃ½m AI schopnÃ½m pro citlivÃ© obrannÃ© a zpravodajskÃ© Ãºlohy.
- Å½Ã¡dnÃ½ konkurenÄnÃ­ model nenabÃ­zÃ­ srovnatelnou vÃ½konnost v utajovanÃ½ch prostÅ™edÃ­ch.

### Podrobnosti
Anthropic, kalifornskÃ¡ firma zamÄ›Å™enÃ¡ na vÃ½voj bezpeÄnÃ½ch velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), jako je Claude â€“ konkurent modelÅ¯ GPT od OpenAI nebo Gemini od Google â€“ se dostala do konfliktu s americkou armÃ¡dou. Claude slouÅ¾Ã­ k analÃ½ze dat, zpracovÃ¡nÃ­ informacÃ­ a podpÅ¯rnÃ½m ÃºkolÅ¯m v utajovanÃ½ch sÃ­tÃ­ch, kde pÅ™ekonÃ¡vÃ¡ jinÃ© modely dÃ­ky svÃ© robustnosti a schopnosti zpracovÃ¡vat sloÅ¾itÃ© bezpeÄnostnÃ­ kontexty. Model je integrovÃ¡n pÅ™es platformu Palantir, spoleÄnosti specializujÃ­cÃ­ se na big data analytics pro obranu a zpravodajstvÃ­, kterÃ¡ jiÅ¾ dlouho spolupracuje s Pentagonem na projektech jako DCGS (Distributed Common Ground System) pro sbÄ›r a analÃ½zu zpravodajskÃ½ch dat.

Pentagon, prostÅ™ednictvÃ­m mluvÄÃ­ho Seana Parnella, jasnÄ› uvedl, Å¾e chce nasadit Claude podle svÃ½ch potÅ™eb, pokud to neporuÅ¡uje zÃ¡kony. Anthropic naopak poÅ¾aduje formÃ¡lnÃ­ zÃ¡ruky, aby se technologie nepouÅ¾Ã­vala k masovÃ©mu sledovÃ¡nÃ­ civilistÅ¯ â€“ napÅ™Ã­klad k automatizovanÃ© analÃ½ze sociÃ¡lnÃ­ch sÃ­tÃ­ nebo kamerovÃ½ch systÃ©mÅ¯ na domÃ¡cÃ­ pÅ¯dÄ› â€“ ani k vÃ½voji smrtÃ­cÃ­ch autonomnÃ­ch systÃ©mÅ¯, kde by AI rozhodovala o stÅ™elbÄ› bez lidskÃ©ho dohledu. TakovÃ© systÃ©my, znÃ¡mÃ© jako lethal autonomous weapons systems (LAWS), jsou pÅ™edmÄ›tem mezinÃ¡rodnÃ­ch debat, ale USA je zatÃ­m nerozvinuly plnÄ›.

Hegseth, nominovanÃ½ Donaldem Trumpem na post ministra obrany, pÅ™ijel na jednÃ¡nÃ­ s jasnou hrozbou: oznaÄenÃ­ Anthropic za â€supply chain riskâ€œ podle federÃ¡lnÃ­ch pÅ™edpisÅ¯ (DFARS 252.204-7018). To by okamÅ¾itÄ› zruÅ¡ilo stÃ¡vajÃ­cÃ­ kontrakty, vÄetnÄ› tÄ›ch s Palantirem, a vyÅ¾adovalo by od vÅ¡ech dodavatelÅ¯ certifikaci, Å¾e Claude nepouÅ¾Ã­vajÃ­. Wall Street Journal zmÃ­nil nasazenÃ­ Claude v speciÃ¡lnÃ­ch operacÃ­ch, coÅ¾ podtrhuje jeho klÃ­Äovou roli. Å½Ã¡dnÃ½ jinÃ½ model, jako Llama od Meta nebo otevÅ™enÃ© varianty, nedosahuje potÅ™ebnÃ© ÃºrovnÄ› pro utajovanÃ© prostÅ™edÃ­ kvÅ¯li bezpeÄnostnÃ­m slabinÃ¡m nebo niÅ¾Å¡Ã­ pÅ™esnosti.

Jako expert na AI vidÃ­m zde napÄ›tÃ­ mezi komerÄnÃ­mi bezpeÄnostnÃ­mi standardy a vojenskÃ½mi poÅ¾adavky. Anthropic, zaloÅ¾enÃ½ bÃ½valÃ½mi vÃ½zkumnÃ­ky OpenAI s dÅ¯razem na alignment (sladÄ›nÃ­ AI s lidskÃ½mi hodnotami), tak ÄelÃ­ dilematu: kapitulace by oslabila jejich misi, ale ztrÃ¡ta kontraktÅ¯ by ohrozila financovÃ¡nÃ­ vÃ½voje.

### ProÄ je to dÅ¯leÅ¾itÃ©
Tento spor nastavuje precedent pro budoucÃ­ nasazenÃ­ AI v obranÄ› a ovlivÅˆuje celÃ½ ekosystÃ©m LLM. Pokud Pentagon prosadÃ­ odstranÄ›nÃ­ guardrails â€“ mechanismÅ¯ brÃ¡nÃ­cÃ­ch Å¡kodlivÃ©mu chovÃ¡nÃ­ â€“, otevÅ™e to dveÅ™e k Å¡irÅ¡Ã­mu vojenskÃ©mu vyuÅ¾itÃ­ AI bez etickÃ½ch omezenÃ­, coÅ¾ by mohlo urychlit vÃ½voj autonomnÃ­ch systÃ©mÅ¯ a zesÃ­lit globÃ¡lnÃ­ zÃ¡vody v AI zbranÃ­ch mezi USA, ÄŒÃ­nou a Ruskem. Pro prÅ¯mysl znamenÃ¡ riziko fragmentace: firmy jako Anthropic by musely volit mezi civilnÃ­m trhem a obranou, zatÃ­mco armÃ¡da by mohla spolÃ©hat na mÃ©nÄ› schopnÃ© alternativy, coÅ¾ by zpomalilo inovace v zpravodajstvÃ­. DlouhodobÄ› to testuje, zda mohou soukromÃ© firmy diktovat pravidla stÃ¡tnÃ­m aktÃ©rÅ¯m v kritickÃ½ch technologiÃ­ch, a posiluje debatu o regulaci AI safety na nÃ¡rodnÃ­ Ãºrovni.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://freerepublic.com/focus/f-news/4368049/posts)

**Zdroj:** ğŸ“° Freerepublic.com
