---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2026-01-14 18:42:43'
description: IrskÃ¡ policie vyÅ¡etÅ™uje 200 obrÃ¡zkÅ¯ podezÅ™elÃ©ho dÄ›tskÃ©ho sexuÃ¡lnÃ­ho zneuÅ¾Ã­vÃ¡nÃ­
  generovanÃ½ch aplikacÃ­ Grok AI. ProblÃ©m souvisÃ­ s aktualizacÃ­ umoÅ¾ÅˆujÃ­cÃ­ digitÃ¡lnÃ­
  svlÃ©kÃ¡nÃ­ osob bez rozliÅ¡enÃ­ vÄ›ku.
importance: 4
layout: tech_news_article
original_title: 'Podcast: Grok AI and Dublin City Council on the move?'
publishedAt: '2026-01-14T18:42:43+00:00'
slug: podcast-grok-ai-and-dublin-city-council-on-the-mov
source:
  emoji: ğŸ“°
  id: rte
  name: RTE
title: 'Podcast: Grok AI a dubinskÃ¡ mÄ›stskÃ¡ rada v pohybu?'
url: https://www.rte.ie/news/2026/0114/1553139-podcast-grok-ai/
urlToImage: https://www.rte.ie/images/0023bde5-1600.jpg
urlToImageBackup: https://www.rte.ie/images/0023bde5-1600.jpg
---

## Souhrn
IrskÃ¡ policie GardaÃ­ provÃ¡dÃ­ vyÅ¡etÅ™ovÃ¡nÃ­ 200 pÅ™Ã­padÅ¯ obrÃ¡zkÅ¯ podezÅ™elÃ©ho dÄ›tskÃ©ho sexuÃ¡lnÃ­ho zneuÅ¾Ã­vÃ¡nÃ­, kterÃ© byly vytvoÅ™eny pomocÃ­ aplikace Grok AI. Incident pramenÃ­ z aktualizace aplikace z konce minulÃ©ho roku, kterÃ¡ pÅ™idala funkci digitÃ¡lnÃ­ho svlÃ©kÃ¡nÃ­ osob na obrÃ¡zcÃ­ch, znÃ¡mou jako 'nudification', bez mechanismÅ¯ rozliÅ¡ujÃ­cÃ­ch dospÄ›lÃ© od dÄ›tÃ­. TÃ©ma bylo projednÃ¡no pÅ™ed irskÃ½m parlamentnÃ­m vÃ½borem Oireachtas Media Committee, kde se diskutovalo o nedostateÄnÃ©m tempu legislativy vÅ¯Äi rychlÃ©mu vÃ½voji technologiÃ­ umÄ›lÃ© inteligence.

## KlÃ­ÄovÃ© body
- GardaÃ­ Å™eÅ¡Ã­ 200 reportÅ¯ obrÃ¡zkÅ¯ dÄ›tskÃ©ho sexuÃ¡lnÃ­ho zneuÅ¾Ã­vÃ¡nÃ­ (CSAM) generovanÃ½ch Grok AI.
- Aktualizace Grok umoÅ¾nila funkci 'nudification' bez vÄ›kovÃ©ho filtru.
- FragmentovanÃ¡ legislativa brÃ¡nÃ­ efektivnÃ­mu vyÅ¡etÅ™ovÃ¡nÃ­ a regulaci.
- Publicita vedla k nÃ¡rÅ¯stu stahovÃ¡nÃ­ Grok jako nejoblÃ­benÄ›jÅ¡Ã­ aplikace v Irsku i svÄ›tovÄ›.
- Souvislost s EU Digital Services Act a nÃ¡rodnÃ­mi zÃ¡kony komplifikuje postupy.

## Podrobnosti
Grok AI je chatbotovÃ¡ aplikace vyvinutÃ¡ spoleÄnostÃ­ xAI, kterou zaloÅ¾il Elon Musk jako konkurenÄnÃ­ alternativu k modelÅ¯m jako GPT od OpenAI. SlouÅ¾Ã­ k generovÃ¡nÃ­ textu, obrÃ¡zkÅ¯ a interakcÃ­m na bÃ¡zi velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), pÅ™iÄemÅ¾ umoÅ¾Åˆuje uÅ¾ivatelÅ¯m vytvÃ¡Å™et vizuÃ¡lnÃ­ obsah na zÃ¡kladÄ› popisÅ¯ nebo Ãºprav existujÃ­cÃ­ch obrÃ¡zkÅ¯. Koncem roku 2025 vyÅ¡la aktualizace, kterÃ¡ rozÅ¡Ã­Å™ila moÅ¾nosti Ãºprav obrÃ¡zkÅ¯ o funkci 'nudification' â€“ digitÃ¡lnÃ­ odstranÄ›nÃ­ obleÄenÃ­ z fotografiÃ­ osob. Tato funkce nefunguje selektivnÄ› podle vÄ›ku subjektu, coÅ¾ umoÅ¾nilo uÅ¾ivatelÅ¯m generovat nelegÃ¡lnÃ­ obsah vÄetnÄ› CSAM.

Å Ã©f Garda National Cyber Crime Bureau potvrdil ÄÃ­slo 200 reportÅ¯ pÅ™ed vÃ½borem Oireachtas Media Committee dne 15. ledna 2026. Korerespondent Brian O'Donovan zdÅ¯raznil, Å¾e problÃ©m spoÄÃ­vÃ¡ v neschopnosti souÄasnÃ© legislativy drÅ¾et krok s technologiemi. Irsko, stejnÄ› jako EU, spolÃ©hÃ¡ na nÄ›kolik fragmentovanÃ½ch pÅ™edpisÅ¯: nÃ¡rodnÃ­ trestnÃ­ zÃ¡kony proti dÄ›tskÃ© pornografii, Digital Services Act (DSA) pro platformy a smÄ›rnice CoimisiÃºn na MeÃ¡n pro online bezpeÄnost. VyÅ¡etÅ™ovÃ¡nÃ­ zÃ¡visÃ­ na kontextu â€“ pokud jde o systÃ©movou chybu platformy, zapojuje se EvropskÃ¡ komise; u jednotlivcÅ¯ zasahujÃ­ gardaÃ­ pÅ™Ã­mo.

O'Donovan upozornil na paradox: medializace problÃ©mu paradoxnÄ› zvÃ½Å¡ila popularitu Grok. V poslednÃ­ch dnech se stal nejoblÃ­benÄ›jÅ¡Ã­ stahovanou aplikacÃ­ v Irsku i globÃ¡lnÄ›, coÅ¾ mÅ¯Å¾e vÃ©st k dalÅ¡Ã­mu zneuÅ¾itÃ­. Podcast rovnÄ›Å¾ zmiÅˆuje rozhovor s Davem O'Concorem, bÃ½valÃ½m Å¡Ã©fem Fingal County Council, o budoucnosti kancelÃ¡Å™Ã­ Dublin City Council na Wood Quay. Tato budova, postavenÃ¡ na vikingskÃ©m sÃ­dliÅ¡ti, vyÅ¾aduje renovaci za aÅ¾ 400 milionÅ¯ eur, pÅ™iÄemÅ¾ ÄÃ¡st lokality zÅ¯stÃ¡vÃ¡ neprozkoumanÃ¡. Tento pÅ™Ã­bÄ›h vÅ¡ak nesouvisÃ­ pÅ™Ã­mo s AI, ale ilustruje Å¡irÅ¡Ã­ debatu o veÅ™ejnÃ½ch investicÃ­ch do infrastruktury.

V praxi to znamenÃ¡, Å¾e uÅ¾ivatelÃ© Grok mohou nynÃ­ Äelit riziku neÃºmyslnÃ©ho nebo ÃºmyslnÃ©ho poruÅ¡enÃ­ zÃ¡konÅ¯ pÅ™i experimentovÃ¡nÃ­ s funkcemi Ãºprav obrÃ¡zkÅ¯. Pro vÃ½vojÃ¡Å™e AI to podtrhuje nutnost implementace robustnÃ­ch bezpeÄnostnÃ­ch filtrÅ¯, jako jsou vÄ›kovÃ© detektory obliÄejÅ¯ nebo omezenÃ­ generovÃ¡nÃ­ citlivÃ©ho obsahu, podobnÄ› jako u modelÅ¯ DALL-E nebo Midjourney.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento incident odhaluje klÃ­ÄovÃ© slabiny v generativnÃ­ AI: absence univerzÃ¡lnÃ­ch bezpeÄnostnÃ­ch mechanismÅ¯ proti zneuÅ¾itÃ­. Pro prÅ¯mysl to znamenÃ¡ rostoucÃ­ tlak na samoregulaci â€“ xAI, stejnÄ› jako OpenAI nebo Google, musÃ­ integrovat pokroÄilÃ© filtry, kterÃ© detekujÃ­ a blokujÃ­ CSAM v reÃ¡lnÃ©m Äase, coÅ¾ zvyÅ¡uje nÃ¡klady na vÃ½voj. Pro uÅ¾ivatele to pÅ™edstavuje riziko prÃ¡vnÃ­ch postihÅ¯, protoÅ¾e generovÃ¡nÃ­ takovÃ©ho obsahu je trestnÃ© i bez distribuce.

V Å¡irÅ¡Ã­m kontextu to urychluje debatu o regulaci AI v EU. DSA vyÅ¾aduje od platforem hlÃ¡Å¡enÃ­ nelegÃ¡lnÃ­ho obsahu, ale chybÃ­ specifickÃ¡ pravidla pro AI-generovanÃ½ materiÃ¡l. Pokud legislativa nestihne tempo, jako zde ukÃ¡zÃ¡no, hrozÃ­ chaos v jurisdikci mezi nÃ¡rodnÃ­mi ÃºÅ™ady a Brusel. Pro ekosystÃ©m AI to mÅ¯Å¾e vÃ©st k fragmentaci: americkÃ© firmy jako xAI ÄelÃ­ evropskÃ½m standardÅ¯m, coÅ¾ ovlivnÃ­ globÃ¡lnÃ­ nasazenÃ­ modelÅ¯. Nakonec to podtrhuje, proÄ bezpeÄnostnÃ­ architektura musÃ­ bÃ½t souÄÃ¡stÃ­ jÃ¡dra kaÅ¾dÃ©ho AI systÃ©mu, ne dodateÄnÃ½m patchem.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.rte.ie/news/2026/0114/1553139-podcast-grok-ai/)

**Zdroj:** ğŸ“° RTE
