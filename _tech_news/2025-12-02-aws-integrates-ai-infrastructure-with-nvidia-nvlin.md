---
author: Marisa Aigen
category: ai hardware
companies:
- AWS
- NVIDIA
date: '2025-12-02 06:16:06'
description: S rostouc√≠ popt√°vkou po AI hledaj√≠ hyperscalers zp≈Øsoby, jak urychlit
  nasazen√≠ specializovan√© AI infrastruktury s vysok√Ωm v√Ωkonem. AWS spolupracuje s
  NVIDIA na integraci NVLink Fusion pro Trainium4 AI ƒçipy, Graviton CPU a dal≈°√≠ komponenty.
importance: 4
layout: tech_news_article
original_title: AWS Integrates AI Infrastructure with NVIDIA NVLink Fusion for Trainium4
  Deployment
publishedAt: '2025-12-02T06:16:06+00:00'
slug: aws-integrates-ai-infrastructure-with-nvidia-nvlin
source:
  emoji: üì∞
  id: null
  name: Nvidia.com
title: AWS integruje AI infrastrukturu s NVIDIA NVLink Fusion pro nasazen√≠ Trainium4
url: https://developer.nvidia.com/blog/aws-integrates-ai-infrastructure-with-nvidia-nvlink-fusion-for-trainium4-deployment/
urlToImage: https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/grace-corp-blog-gb300-nvl72-1280x680-r1-2.png
urlToImageBackup: https://developer-blogs.nvidia.com/wp-content/uploads/2025/12/grace-corp-blog-gb300-nvl72-1280x680-r1-2.png
---

## Souhrn
Amazon Web Services ozn√°mil na konferenci AWS re:Invent spolupr√°ci s NVIDIA na integraci platformy NVLink Fusion. Tato rackov√° ≈ôe≈°en√≠ umo≈æn√≠ rychlej≈°√≠ nasazen√≠ Trainium4 AI ƒçip≈Ø, Graviton CPU, Elastic Fabric Adapters (EFA) a virtualizaƒçn√≠ infrastruktury Nitro System. C√≠lem je zefektivnit v√Ωstavbu custom AI rack≈Ø s vysokou propustnost√≠ a n√≠zkou latenc√≠.

## Kl√≠ƒçov√© body
- AWS navrhuje Trainium4 pro kompatibilitu s NVLink 6 a rackovou architekturou NVIDIA MGX, co≈æ je prvn√≠ krok v dlouhodob√© spolupr√°ci.
- NVLink Fusion poskytuje scale-up s√≠≈•ov√°n√≠ pro propojen√≠ cel√Ωch rack≈Ø akceler√°tor≈Ø v jedin√© fabric.
- ≈òe≈°en√≠ sni≈æuje v√Ωvojov√© cykly pro custom AI k≈ôem√≠ky, zvy≈°uje n√°vratnost investic a minimalizuje rizika nasazen√≠.
- Podporuje rostouc√≠ AI √∫lohy jako pl√°nov√°n√≠, uva≈æov√°n√≠ a agentickou AI na modelech s stovkami miliard a≈æ biliony parametr≈Ø.
- Ekosyst√©m partner≈Ø NVIDIA usnad≈àuje v√Ωvoj a nasazen√≠.

## Podrobnosti
Trainium4 p≈ôedstavuje ƒçtvrtou generaci AI akceler√°tor≈Ø od AWS, urƒçen√Ωch prim√°rnƒõ pro tr√©nink velk√Ωch jazykov√Ωch model≈Ø a jin√Ωch n√°roƒçn√Ωch AI √∫loh. Na rozd√≠l od NVIDIA GPU, kter√© dominuj√≠ trhu, Trainium ƒçipy optimalizuj√≠ n√°klady na tr√©nink v cloudu AWS, kde slou≈æ√≠ k v√Ωpoƒçt≈Øm v paraleln√≠ch clusterech. Nov√° integrace s NVLink Fusion, co≈æ je rackov√° platforma NVIDIA, umo≈æ≈àuje propojit tyto ƒçipy s vysokorychlostn√≠ interconnect technologiemi NVLink. NVLink 6 nab√≠z√≠ vy≈°≈°√≠ propustnost ne≈æ p≈ôedchoz√≠ verze a slou≈æ√≠ k scale-up propojen√≠ akceler√°tor≈Ø v r√°mci jednoho racku, co≈æ je kl√≠ƒçov√© pro modely typu mixture-of-experts (MoE) nebo agentick√© syst√©my.

AWS kombinuje Trainium4 s vlastn√≠mi Graviton CPU (ARM-based procesory pro obecn√© v√Ωpoƒçty), EFA (s√≠≈•ov√© adapt√©ry pro scale-out komunikaci mezi uzly) a Nitro System (virtualizaƒçn√≠ vrstva pro bezpeƒçn√© izolovan√© instance). NVIDIA MGX je modul√°rn√≠ rackov√° architektura, kter√° umo≈æ≈àuje hyperscaler≈Øm jako AWS sestavovat custom ≈ôe≈°en√≠ z komponent NVIDIA a partner≈Ø. Tato spolupr√°ce ≈ôe≈°√≠ hlavn√≠ v√Ωzvy: dlouh√© v√Ωvojov√© cykly pro rackovou architekturu, nutnost vyv√≠jet vlastn√≠ scale-up a scale-out s√≠tƒõ i √∫lo≈æi≈°tƒõ. Bez takov√©ho propojen√≠ by nasazen√≠ stovek akceler√°tor≈Ø v paraleln√≠m fabric trvalo mƒõs√≠ce nebo roky.

Hyperscalers ƒçel√≠ tlaku od rostouc√≠ch AI workload≈Ø ‚Äì modely s biliony parametr≈Ø vy≈æaduj√≠ tis√≠ce akceler√°tor≈Ø propojen√Ωch n√≠zkou latenc√≠. NVLink Fusion toto umo≈æ≈àuje p≈ô√≠mo v racku, co≈æ zkracuje ƒças na trh a sni≈æuje n√°klady oproti plnƒõ propriet√°rn√≠m ≈ôe≈°en√≠m. AWS tak posiluje svou pozici v AI cloudu, kde konkuruje NVIDIA H100 nebo Blackwell GPU, ale nab√≠z√≠ levnƒõj≈°√≠ alternativu pro z√°kazn√≠ky.

## Proƒç je to d≈Øle≈æit√©
Tato integrace urychl√≠ nasazen√≠ custom AI infrastruktury pro hyperscalery a enterprise z√°kazn√≠ky, co≈æ ovlivn√≠ cenu tr√©ninku velk√Ωch model≈Ø. AWS sni≈æuje z√°vislost na NVIDIA GPU t√≠m, ≈æe Trainium4 kombinuje s NVLink, co≈æ zvy≈°uje efektivitu oproti ƒçistƒõ NVIDIA stack≈Øm. V ≈°ir≈°√≠m kontextu posiluje to soutƒõ≈æ v AI hardware, kde hyperscalers jako AWS, Google (TPU) nebo Microsoft (Azure Cobalt) buduj√≠ vlastn√≠ k≈ôem√≠ky. Pro pr≈Ømysl znamen√° rychlej≈°√≠ v√Ωvoj agentick√Ωch AI a MoE model≈Ø, men≈°√≠ rizika v√Ωpadk≈Ø a vy≈°≈°√≠ ROI. Dlouhodobƒõ to m≈Ø≈æe democratizovat p≈ô√≠stup k v√Ωkonn√© AI infrastruktu≈ôe, ale z√°vis√≠ na re√°ln√Ωch benchmark√°ch Trainium4 oproti konkurenci.

---

[ƒå√≠st p≈Øvodn√≠ ƒçl√°nek](https://developer.nvidia.com/blog/aws-integrates-ai-infrastructure-with-nvidia-nvlink-fusion-for-trainium4-deployment/)

**Zdroj:** üì∞ Nvidia.com
