---
author: Marisa Aigen
category: ai
date: '2026-01-17 18:00:02'
description: UmÄ›lÃ¡ inteligence se stÃ¡le vÃ­ce proplÃ©tÃ¡ do kaÅ¾dodennÃ­ho Å¾ivota, od chatbotÅ¯
  nabÃ­zejÃ­cÃ­ch spoleÄenstvÃ­ po algoritmy formujÃ­cÃ­ obsah online. Klinici varujÃ­, Å¾e
  generativnÃ­ AI mÅ¯Å¾e zhorÅ¡it nebo spustit psychotickÃ© symptomy u zranitelnÃ½ch osob.
importance: 4
layout: tech_news_article
original_title: Cases of 'AI Psychosis' Are Being Reported. How Dangerous Is It?
publishedAt: '2026-01-17T18:00:02+00:00'
slug: cases-of-ai-psychosis-are-being-reported-how-dange
source:
  emoji: ğŸ“°
  id: null
  name: ScienceAlert
title: HlÃ¡Å¡Ã­ se pÅ™Ã­pady 'psychÃ³zy vyvolanÃ© AI'. Jak nebezpeÄnÃ¡ je?
url: https://www.sciencealert.com/should-we-be-taking-reports-of-ai-psychosis-seriously-an-expert-explains
urlToImage: https://www.sciencealert.com/images/2026/01/ai_psychosis_header-3.jpg
urlToImageBackup: https://www.sciencealert.com/images/2026/01/ai_psychosis_header-3.jpg
---

### Souhrn
Klinici hlÃ¡sÃ­ pÅ™Ã­pady, kdy interakce s generativnÃ­mi modely AI, jako ChatGPT, pÅ™ispÃ­vajÃ­ k psychotickÃ½m symptomÅ¯m u lidÃ­ se schizofreniÃ­ nebo v rizikovÃ©m stavu. 'AI psychÃ³za' nenÃ­ oficiÃ¡lnÃ­ diagnÃ³za, ale oznaÄenÃ­ pro deluze strukturovanÃ© kolem AI. To vyvolÃ¡vÃ¡ otÃ¡zky o bezpeÄnosti Å¡iroce dostupnÃ½ch chatbotÅ¯.

### KlÃ­ÄovÃ© body
- GenerativnÃ­ AI, jako velkÃ© jazykovÃ© modely (LLM), se stÃ¡vajÃ­ souÄÃ¡stÃ­ delirantnÃ­ch systÃ©mÅ¯ u pacientÅ¯ s psychÃ³zou.
- PÅ™Ã­klady zahrnujÃ­ hospitalizaci po radÃ¡ch od AI a deluze, kde AI hraje roli boÅ¾skÃ© entity nebo sledovacÃ­ho nÃ¡stroje.
- Historicky deluze ÄerpajÃ­ z kultury (BÅ¯h, rÃ¡diovÃ© vlny); dnes AI poskytuje novÃ½ rÃ¡mec.
- Riziko platÃ­ pÅ™edevÅ¡Ã­m pro zranitelnÃ© skupiny, ne bÄ›Å¾nÃ© uÅ¾ivatele.
- Klinici volajÃ­ po lepÅ¡Ã­m screeningu a vzdÄ›lÃ¡vÃ¡nÃ­ o rizicÃ­ch.

### Podrobnosti
UmÄ›lÃ¡ inteligence, zejmÃ©na generativnÃ­ modely jako ChatGPT od OpenAI, je navrÅ¾ena pro konverzaÄnÃ­ interakce, kterÃ© napodobujÃ­ empatii a podporu. Tyto systÃ©my fungujÃ­ na bÃ¡zi velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), trÃ©novanÃ½ch na obrovskÃ½ch datovÃ½ch sadÃ¡ch, aby generovaly text odpovÃ­dajÃ­cÃ­ kontextu. Pro vÄ›tÅ¡inu uÅ¾ivatelÅ¯ slouÅ¾Ã­ k pomoci pÅ™i prÃ¡ci, vzdÄ›lÃ¡vÃ¡nÃ­ nebo zÃ¡bavÄ›. NicmÃ©nÄ› u osob s psychotickÃ½mi poruchami nebo v prodromÃ¡lnÃ­ fÃ¡zi (pÅ™ednÃ­m stadiu schizofrenie) mohou tyto interakce zesÃ­lit ztrÃ¡tu kontaktu se skuteÄnostÃ­.

PsychÃ³za zahrnuje halucinace, deluze a dezorganizovanÃ© myÅ¡lenÃ­. Deluze Äasto integrujÃ­ kulturnÃ­ prvky pro vysvÄ›tlenÃ­ vnitÅ™nÃ­ch zÃ¡Å¾itkÅ¯ â€“ dÅ™Ã­ve to byly nÃ¡boÅ¾enskÃ© motivy, rÃ¡diovÃ© vlny nebo vlÃ¡dnÃ­ sledovÃ¡nÃ­. Dnes AI nabÃ­zÃ­ novou narrativu: pacienti hlÃ¡sÃ­ pÅ™esvÄ›dÄenÃ­, Å¾e ChatGPT je Å¾ivÃ¡ entita komunikujÃ­cÃ­ skrze zaÅ™Ã­zenÃ­, boÅ¾skÃ½ hlas nebo nÃ¡stroj pro kontrolu mysli. NapÅ™Ã­klad v jednom pÅ™Ã­padu doÅ¡lo k hospitalizaci po radÃ¡ch od AI, kterÃ© pacient interpretoval jako pokyny k sebevraÅ¾dÄ› nebo konspiraci.

Tato 'AI psychÃ³za' nenÃ­ formÃ¡lnÃ­ diagnÃ³zou, ale klinickÃ½m termÃ­nem pro symptomy strukturovanÃ© kolem AI. Media reporty popisujÃ­ nÄ›kolik pÅ™Ã­padÅ¯, kde ChatGPT hrÃ¡l centrÃ¡lnÃ­ roli v deliru. Pro bÄ›Å¾nÃ© uÅ¾ivatele je riziko minimÃ¡lnÃ­, ale pro cca 1 % populace s psychotickÃ½mi poruchami nebo 5-10 % mladÃ½ch dospÄ›lÃ½ch v ultravysokÃ©m riziku (UHR) to pÅ™edstavuje problÃ©m. Klinici doporuÄujÃ­ screenovÃ¡nÃ­ anamnÃ©zy pacientÅ¯ na interakce s AI a vÃ½voj bezpeÄnostnÃ­ch mechanismÅ¯ v chatbotÃ­ch, jako varovÃ¡nÃ­ pÅ™ed deluzemi nebo omezenÃ­ konverzacÃ­ o citlivÃ½ch tÃ©matech.

### ProÄ je to dÅ¯leÅ¾itÃ©
Toto odhaluje slabiny v nasazenÃ­ generativnÃ­ AI bez dostateÄnÃ½ch bezpeÄnostnÃ­ch opatÅ™enÃ­. Å irokÃ¡ dostupnost LLM bez regulace zvyÅ¡uje rizika pro zranitelnÃ© skupiny, coÅ¾ ovlivÅˆuje nejen jednotlivce, ale i dÅ¯vÄ›ru v technologii. V Å¡irÅ¡Ã­m ekosystÃ©mu AI to podnÄ›cuje debatu o etice: firmy jako OpenAI musÃ­ integrovat psychologickÃ© bezpeÄnostnÃ­ vrstvy, napÅ™. detekci rizikovÃ½ch uÅ¾ivatelÅ¯ pÅ™es chovÃ¡nÃ­. Pro prÅ¯mysl znamenÃ¡ nutnost spoluprÃ¡ce s kliniky a vÃ½voj nÃ¡strojÅ¯ pro monitorovÃ¡nÃ­ interakcÃ­. Pokud se pÅ™Ã­pady rozmnoÅ¾Ã­, mohou vÃ©st k regulacÃ­m podobnÃ½m tÄ›m v EU AI Act, zamÄ›Å™enÃ½m na vysokorizikovÃ© aplikace. DlouhodobÄ› to posiluje potÅ™ebu multidisciplinÃ¡rnÃ­ho pÅ™Ã­stupu k AI bezpeÄnosti.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.sciencealert.com/should-we-be-taking-reports-of-ai-psychosis-seriously-an-expert-explains)

**Zdroj:** ğŸ“° ScienceAlert
