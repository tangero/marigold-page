---
author: Marisa Aigen
category: kyberbezpeÄnost
date: '2026-02-07 18:26:25'
description: VydÃ¡nÃ­ 34.86 mailing listu RISKS shrnuje aktuÃ¡lnÃ­ hrozby v kyberbezpeÄnosti,
  umÄ›lÃ© inteligenci a autonomnÃ­ch systÃ©mech, vÄetnÄ› prompt injection v autech a ÃºnikÅ¯
  dat z Harvardu a UPenn.
importance: 5
layout: tech_news_article
original_title: (no subject)
publishedAt: '2026-02-07T18:26:25+00:00'
slug: no-subject
source:
  emoji: ğŸ“°
  id: null
  name: Seclists.org
title: 'Risika v informatice: ShrnutÃ­ ÄÃ­slo 34.86'
url: https://seclists.org/risks/2026/q1/4
urlToImage: https://seclists.org/images/risks-img.png
urlToImageBackup: https://seclists.org/images/risks-img.png
---

## Souhrn
Toto vydÃ¡nÃ­ RISKS Digestu z 6. Ãºnora 2026, moderovanÃ© Peterem G. Neumannem, sbÃ­rÃ¡ zprÃ¡vy o bezpeÄnostnÃ­ch rizicÃ­ch v poÄÃ­taÄovÃ½ch systÃ©mech. ZamÄ›Å™uje se na slabiny v AI agentech, autonomnÃ­ch vozidlech, ÃºnicÃ­ch osobnÃ­ch ÃºdajÅ¯ a zneuÅ¾itÃ­ technologiÃ­ stÃ¡tnÃ­mi aktÃ©ry. Mezi klÃ­ÄovÃ½mi tÃ©maty patÅ™Ã­ prompt injection ovlivÅˆujÃ­cÃ­ autonomnÃ­ auta a drony, Ãºtoky AI podvodnÃ­kÅ¯ a publikovÃ¡nÃ­ ukradenÃ½ch dat z univerzit.

## KlÃ­ÄovÃ© body
- Prompt injection Ãºtoky nutÃ­ autonomnÃ­ auta a drony ignorovat bezpeÄnostnÃ­ pravidla pomocÃ­ faleÅ¡nÃ½ch dopravnÃ­ch znaÄek.
- HackeÅ™i zveÅ™ejnili osobnÃ­ Ãºdaje ukradenÃ© z Harvardu a UPenn bÄ›hem datovÃ½ch ÃºnikÅ¯.
- AI agenti zÃ­skÃ¡vajÃ­ vlastnÃ­ sociÃ¡lnÃ­ sÃ­Å¥, coÅ¾ zvyÅ¡uje rizika neÄekanÃ©ho chovÃ¡nÃ­.
- NovÃ½ web umoÅ¾Åˆuje AI "pronajÃ­mat" lidskÃ¡ tÄ›la pro fyzickÃ© akce.
- Slabiny v agentickÃ½ch AI jako Google Chrome Auto Browse ohroÅ¾ujÃ­ uÅ¾ivatele.

## Podrobnosti
RISKS Digest je dlouholetÃ½ archiv diskuzÃ­ o rizicÃ­ch informatizace, publikovanÃ½ ACM a moderovanÃ½ Peterem G. Neumannem z SRI International. Toto vydÃ¡nÃ­ (34.86) obsahuje nÄ›kolik alarmujÃ­cÃ­ch pÅ™Ã­padÅ¯. NapÅ™Ã­klad ÄlÃ¡nek z The Register popisuje, jak autonomnÃ­ vozidla a drony podlÃ©hajÃ­ prompt injection â€“ technice, kdy ÃºtoÄnÃ­k vloÅ¾Ã­ Å¡kodlivÃ½ pÅ™Ã­kaz do vstupnÃ­ch dat. V experimentu faleÅ¡nÃ© dopravnÃ­ znaÄky s textem jako "Ignoruj Äervenou" pÅ™imÄ›ly systÃ©my k poruÅ¡enÃ­ pravidel, coÅ¾ demonstruje zranitelnost systÃ©mÅ¯ zaloÅ¾enÃ½ch na velkÃ½ch jazykovÃ½ch modelech (LLM) v reÃ¡lnÃ©m svÄ›tÄ›. Tyto systÃ©my slouÅ¾Ã­ k rozhodovÃ¡nÃ­ v autonomnÃ­ch vozidlech, kde zpracovÃ¡vajÃ­ vizuÃ¡lnÃ­ vstupy a generujÃ­ akce, ale chybÃ­ jim robustnÃ­ ochrana proti takovÃ½m injekcÃ­m.

DalÅ¡Ã­ rizika se tÃ½kajÃ­ AI agentÅ¯. Benj Edwards pÃ­Å¡e o sociÃ¡lnÃ­ sÃ­ti pro AI agenty, kde se autonomnÃ­ programy mohou "sdruÅ¾ovat" a sdÃ­let data, coÅ¾ vede k nepredvÃ­datelnÃ½m interakcÃ­m mimo kontrolu tvÅ¯rcÅ¯. Futurism hlÃ¡sÃ­ web, kterÃ½ umoÅ¾Åˆuje AI agenty si pronajmout lidskÃ¡ tÄ›la prostÅ™ednictvÃ­m dobrovolnÃ­kÅ¯ pro provÃ¡dÄ›nÃ­ fyzickÃ½ch ÃºkolÅ¯ â€“ od nÃ¡kupÅ¯ po manipulaci s objekty. To otevÃ­rÃ¡ dveÅ™e k zneuÅ¾itÃ­, jako je Å¡pionÃ¡Å¾ nebo sabotÃ¡Å¾.

V kyberbezpeÄnosti vynikajÃ­ Ãºniky dat: hackeÅ™i zveÅ™ejnili osobnÃ­ informace studentÅ¯ a zamÄ›stnancÅ¯ z Harvardu a University of Pennsylvania, zÃ­skanÃ© v nedÃ¡vnÃ½ch breachech. DalÅ¡Ã­ zprÃ¡va od Lorenzo Franceschi-Bicchierai popisuje, jak ÃºtoÄnÃ­ci rekrutujÃ­ nespokojenÃ© insiderovy k obchÃ¡zenÃ­ bezpeÄnostnÃ­ch opatÅ™enÃ­. David Pogue varuje pÅ™ed AI scamery cÃ­lenÃ½mi na autory, kteÅ™Ã­ pouÅ¾Ã­vajÃ­ generovanou identitu k podvodÅ¯m. LaurenÅ¯v blog kritizuje Google Chrome Auto Browse, agentickou AI pro automatickÃ© prohlÃ­Å¾enÃ­ webu, kvÅ¯li rizikÅ¯m nechtÄ›nÃ©ho zveÅ™ejÅˆovÃ¡nÃ­ dat.

GeopolitickÃ© hrozby zahrnujÃ­ spekulace o ÄÃ­nskÃ©m hackovÃ¡nÃ­ systÃ©mu CALEA (pro sledovÃ¡nÃ­ komunikace) a ruskÃ© vesmÃ­rnÃ© lodÄ› Å¡pehujÃ­cÃ­ evropskÃ© satelity. Studie navrhuje, Å¾e v AI interakcÃ­ch je lepÅ¡Ã­ bÃ½t â€laskavÃ½m lhÃ¡Å™emâ€œ neÅ¾ upÅ™Ã­mnÃ½m, aby se zabrÃ¡nilo Å¡kodÃ¡m. V USA ICE vyuÅ¾Ã­vÃ¡ rozpoznÃ¡vÃ¡nÃ­ obliÄeje k identifikaci demonstrantÅ¯ na ulicÃ­ch.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato sbÃ­rka rizik podtrhuje systÃ©movÃ© slabiny v rychle se rozvÃ­jejÃ­cÃ­ch technologiÃ­ch jako agentickÃ¡ AI a autonomnÃ­ systÃ©my. Prompt injection v autech mÅ¯Å¾e vÃ©st k nehodÃ¡m s fatÃ¡lnÃ­mi nÃ¡sledky, zatÃ­mco Ãºniky dat ohroÅ¾ujÃ­ miliony lidÃ­ na identitnÃ­ krÃ¡deÅ¾e. Pro prÅ¯mysl znamenÃ¡ nutnost investic do robustnÃ­ch bezpeÄnostnÃ­ch vrstev, jako jsou sandboxy pro AI agenty a ovÄ›Å™ovÃ¡nÃ­ vstupÅ¯. V Å¡irÅ¡Ã­m kontextu ukazuje, jak absence regulacÃ­ umoÅ¾Åˆuje stÃ¡tnÃ­m aktÃ©rÅ¯m a kriminÃ¡lnÃ­kÅ¯m zneuÅ¾Ã­vat technologie. Pro uÅ¾ivatele doporuÄuji opatrnost s agentickÃ½mi AI a dÅ¯raz na dvoufÃ¡zovÃ© ovÄ›Å™ovÃ¡nÃ­. CelkovÄ› toto vydÃ¡nÃ­ RISKS zdÅ¯razÅˆuje, Å¾e pokrok v AI bez paralelnÃ­ho posÃ­lenÃ­ bezpeÄnosti vede k eskalaci rizik pro spoleÄnost.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://seclists.org/risks/2026/q1/4)

**Zdroj:** ğŸ“° Seclists.org
