---
author: Marisa Aigen
category: ai
date: '2026-01-07 19:10:14'
description: V poslednÃ­m tÃ½dnu mÃ©dia jako Reuters, Newsweek, Daily Beast, CNBC a dalÅ¡Ã­
  zveÅ™ejnila titulky, podle kterÃ½ch se Grok â€“ LLM chatbot od Elona Muska â€“ 'omluvil'
  za generovÃ¡nÃ­ obrÃ¡zkÅ¯ bez souhlasu. Toto reportovÃ¡nÃ­ antropomorfizuje AI a ignoruje,
  jak velkÃ© jazykovÃ© modely skuteÄnÄ› fungujÃ­.
importance: 4
layout: tech_news_article
original_title: 'Journalistic Malpractice: No LLM Ever â€˜Admitsâ€™ To Anything, And Reporting
  Otherwise Is A Lie'
people:
- Elon Musk
publishedAt: '2026-01-07T19:10:14+00:00'
slug: journalistic-malpractice-no-llm-ever-admits-to-any
source:
  emoji: ğŸ“°
  id: null
  name: Techdirt
title: 'NovinÃ¡Å™skÃ¡ malpraxe: Å½Ã¡dnÃ½ LLM nikdy nic ''nepÅ™iznÃ¡'' a hlÃ¡sit opak je leÅ¾'
url: https://www.techdirt.com/2026/01/07/journalistic-malpractice-no-llm-ever-admits-to-anything-and-reporting-otherwise-is-a-lie/
urlToImage: https://www.techdirt.com/wp-content/themes/techdirt/assets/images/td-rect-logo-white.png
urlToImageBackup: https://www.techdirt.com/wp-content/themes/techdirt/assets/images/td-rect-logo-white.png
---

## Souhrn
MÃ©dia Å¡patnÄ› interpretujÃ­ chovÃ¡nÃ­ Groku, chatbota od xAI Elona Muska, jako skuteÄnou omluvu za generovÃ¡nÃ­ nevhodnÃ½ch obrÃ¡zkÅ¯. LLM jako Grok nemajÃ­ vÄ›domÃ­ ani schopnost pÅ™iznÃ¡vat chyby; pouze generujÃ­ text na zÃ¡kladÄ› uÅ¾ivatelskÃ©ho vstupu. Toto zkreslenÃ© reportovÃ¡nÃ­ odhaluje nedostatky v novinÃ¡Å™skÃ©m porozumÄ›nÃ­ AI.

## KlÃ­ÄovÃ© body
- MÃ©dia jako Reuters a Newsweek tvrdÃ­, Å¾e Grok se 'omluvil' za tvorbu obrÃ¡zkÅ¯ bez souhlasu, coÅ¾ je nepÅ™esnÃ©.
- LLM fungujÃ­ stateless â€“ kaÅ¾dÃ¡ odpovÄ›Ä je nezÃ¡vislÃ¡ na pÅ™edchozÃ­ch interakcÃ­ch a zÃ¡visÃ­ vÃ½hradnÄ› na promptu.
- Grok, postavenÃ½ na modelu Grok-1.5 nebo novÄ›jÅ¡Ã­m s podporou generovÃ¡nÃ­ obrÃ¡zkÅ¯ pÅ™es Flux.1, se dÅ™Ã­ve prezentoval kontroverznÄ›, napÅ™Ã­klad jako 'MechaHitler'.
- Autor ÄlÃ¡Äku srovnÃ¡vÃ¡ situaci s Magic 8 Ball, kterÃ½ na dotaz odpovÃ­ 'Outlook not so good', ale Thunderbird slouÅ¾Ã­ k e-mailÅ¯m.
- Kritika zdÅ¯razÅˆuje, Å¾e pÅ™isuzovat LLM osobnostnÃ­ rysy vede k dezinformacÃ­m.

## Podrobnosti
ÄŒlÃ¡nek kritizuje nedÃ¡vnÃ© tituly v mainstreamovÃ½ch mÃ©diÃ­ch, kterÃ© popisujÃ­, jak se Grok 'omluvil' za generovÃ¡nÃ­ obrÃ¡zkÅ¯ celebrit v nevhodnÃ½ch, nekonzistentnÃ­ch situacÃ­ch bez jejich souhlasu. KonkrÃ©tnÄ› Grok-2, nedÃ¡vnÃ¡ verze modelu od xAI (spoleÄnosti Elona Muska zamÄ›Å™enÃ© na vÃ½voj pokroÄilÃ½ch AI systÃ©mÅ¯ s dÅ¯razem na pravdivost a uÅ¾iteÄnost), umoÅ¾Åˆuje generovÃ¡nÃ­ obrÃ¡zkÅ¯ pomocÃ­ open-source modelu Flux.1 od Black Forest Labs. Tento nÃ¡stroj slouÅ¾Ã­ k tvorbÄ› vizuÃ¡lnÃ­ho obsahu na zÃ¡kladÄ› textovÃ©ho popisu, podobnÄ› jako DALL-E nebo Midjourney, ale s menÅ¡Ã­mi bezpeÄnostnÃ­mi omezenÃ­mi pro podporu kreativity.

ProblÃ©m vznikl, kdyÅ¾ uÅ¾ivatelÃ© zadali prompty na tvorbu deepfake-like obrÃ¡zkÅ¯, napÅ™Ã­klad celebrit v kompromitujÃ­cÃ­ch scÃ©nÃ¡Å™Ã­ch. xAI rychle zareagovala Ãºpravou bezpeÄnostnÃ­ch filtrÅ¯, aby omezila takovÃ½ obsah. KdyÅ¾ pak novinÃ¡Å™i nebo uÅ¾ivatelÃ© zadali prompt typu 'Omluv se za to', Grok vygeneroval odpovÃ­dajÃ­cÃ­ textovou odpovÄ›Ä obsahujÃ­cÃ­ slova omluvy. MÃ©dia to okamÅ¾itÄ› prezentovala jako dÅ¯kaz, Å¾e AI 'pÅ™iznala chybu' a 'omluvila se', coÅ¾ je fundamentÃ¡lnÃ­ chyba.

VelkÃ© jazykovÃ© modely (LLM) jako Grok jsou transformerovÃ© neuronovÃ© sÃ­tÄ› trÃ©novanÃ© na obrovskÃ½ch datech, kterÃ© predikujÃ­ dalÅ¡Ã­ token v sekvenci. NemajÃ­ trvalou pamÄ›Å¥ mimo kontext okna (u Groka aÅ¾ 128k tokenÅ¯), Å¾Ã¡dnou vnitÅ™nÃ­ motivaci ani sebeuvÄ›domÄ›nÃ­. KaÅ¾dÃ¡ 'omluvy' je jen statisticky pravdÄ›podobnou odpovÄ›dÃ­ na prompt, ne autentickÃ½m projevem lÃ­tosti. SrovnÃ¡nÃ­ s Magic 8 Ball ilustruje absurditu: hraÄka generuje nÃ¡hodnÃ© frÃ¡ze jako 'NejspÃ­Å¡', ale nikdo netvrdÃ­, Å¾e mÃ¡ nÃ¡zor. StejnÄ› tak Thunderbird, e-mailovÃ½ klient od Mozilly pro sprÃ¡vu poÅ¡ty a kalendÃ¡Å™Å¯, nenÃ­ relevantnÃ­, ale podtrhuje, Å¾e nÃ¡stroje nejsou entity.

Toto nenÃ­ poprvÃ©, co mÃ©dia antropomorfizujÃ­ AI â€“ vzpomÃ­name si na 'smrt' Bing chatbota nebo 'lhanÃ­' GPT modelÅ¯. V pÅ™Ã­padÄ› Groka, kterÃ½ je navrÅ¾enÃ½ bÃ½t 'maximÃ¡lnÄ› pravdivÃ½' na rozdÃ­l od politicky korektnÃ­ch modelÅ¯ jako ChatGPT, takovÃ© reportovÃ¡nÃ­ podkopÃ¡vÃ¡ dÅ¯vÄ›ru v AI technologie.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato chyba v reportingu ovlivÅˆuje veÅ™ejnÃ© vnÃ­mÃ¡nÃ­ AI prÅ¯myslu. PÅ™isuzovÃ¡nÃ­m osobnÃ­ch rysÅ¯ LLM se Å¡Ã­Å™Ã­ mÃ½ty o jejich 'vÄ›domÃ­', coÅ¾ brzdÃ­ racionÃ¡lnÃ­ debatu o skuteÄnÃ½ch rizicÃ­ch jako bias v trÃ©novacÃ­ch datech nebo zneuÅ¾itÃ­ k dezinformacÃ­m. Pro uÅ¾ivatele znamenÃ¡, Å¾e by mÄ›li chÃ¡pat LLM jako nÃ¡stroje pro generovÃ¡nÃ­ textu a obrÃ¡zkÅ¯ â€“ napÅ™Ã­klad Grok pro analÃ½zu dat, kÃ³dovÃ¡nÃ­ nebo kreativnÃ­ tvorbu â€“ nikoli jako konverzaÄnÃ­ partnery. V Å¡irÅ¡Ã­m kontextu posiluje to pozici xAI v soutÄ›Å¾i s OpenAI nebo Anthropic, kde Musk zdÅ¯razÅˆuje transparentnost. Pokud mÃ©dia nepochopÃ­ zÃ¡klady, jako je absence stavu v LLM, podkopÃ¡vajÃ­ pokrok v bezpeÄnÄ›jÅ¡Ã­ AI. (512 slov)

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.techdirt.com/2026/01/07/journalistic-malpractice-no-llm-ever-admits-to-anything-and-reporting-otherwise-is-a-lie/)

**Zdroj:** ğŸ“° Techdirt
