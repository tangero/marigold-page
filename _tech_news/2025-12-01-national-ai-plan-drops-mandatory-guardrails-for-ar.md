---
author: Marisa Aigen
category: ai
date: '2025-12-01 19:00:20'
description: AustralskÃ¡ federÃ¡lnÃ­ vlÃ¡da zveÅ™ejnila nÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci,
  kterÃ½ mÃ¡ urychlit jejÃ­ rozvoj v zemi a spolÃ©hat se pÅ™evÃ¡Å¾nÄ› na stÃ¡vajÃ­cÃ­ zÃ¡kony
  k ochranÄ› pÅ™ed riziky. PlÃ¡n odmÃ­tÃ¡ pÅ¯vodnÃ­ myÅ¡lenku na povinnÃ© regulace a zavÃ¡dÃ­
  institut pro bezpeÄnost AI.
importance: 3
layout: tech_news_article
original_title: National AI Plan drops 'mandatory guardrails' for artificial intelligence
publishedAt: '2025-12-01T19:00:20+00:00'
slug: national-ai-plan-drops-mandatory-guardrails-for-ar
source:
  emoji: ğŸ“°
  id: abc-news-au
  name: ABC News (AU)
title: NÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci opouÅ¡tÃ­ povinnÃ© bezpeÄnostnÃ­ opatÅ™enÃ­
url: https://www.abc.net.au/news/2025-12-02/national-artificial-intelligence-plan-growth-existing-laws/106086474
urlToImage: https://live-production.wcms.abc-cdn.net.au/5bd9af8f4a64030f7ff7526c854fd4d4?impolicy=wcms_watermark_news&cropH=1687&cropW=3000&xPos=0&yPos=157&width=862&height=485&imformat=generic
urlToImageBackup: https://live-production.wcms.abc-cdn.net.au/5bd9af8f4a64030f7ff7526c854fd4d4?impolicy=wcms_watermark_news&cropH=1687&cropW=3000&xPos=0&yPos=157&width=862&height=485&imformat=generic
---

## Souhrn
AustralskÃ¡ federÃ¡lnÃ­ vlÃ¡da zveÅ™ejnila nÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci, kterÃ½ se zamÄ›Å™uje na podporu investic do datovÃ½ch center a Å¡kolenÃ­ pracovnÃ­kÅ¯, mÃ­sto zavÃ¡dÄ›nÃ­ novÃ½ch povinnÃ½ch bezpeÄnostnÃ­ch opatÅ™enÃ­. Tento pÅ™Ã­stup znamenÃ¡ odklon od dÅ™Ã­vÄ›jÅ¡Ã­ho nÃ¡vrhu bÃ½valÃ©ho ministra prÅ¯myslu Eda Husica na deset "povinnÃ½ch zÃ¡bradlÃ­", kterÃ¡ mÄ›la regulovat vysoce rizikovÃ© systÃ©my AI. Od pÅ™Ã­Å¡tÃ­ho roku zaÄne fungovat institut pro bezpeÄnost AI s rozpoÄtem 30 milionÅ¯ dolarÅ¯, kterÃ½ bude monitorovat vÃ½voj technologie.

## KlÃ­ÄovÃ© body
- OdmÃ­tnutÃ­ povinnÃ½ch zÃ¡bradlÃ­: VlÃ¡da se rozhodla vyuÅ¾Ã­t stÃ¡vajÃ­cÃ­ zÃ¡kony a expertnÃ­ znalosti regulÃ¡torÅ¯ mÃ­sto novÃ©ho samostatnÃ©ho zÃ¡kona o AI.
- Podpora rÅ¯stu: PlÃ¡n zdÅ¯razÅˆuje investice do datovÃ½ch center a pÅ™Ã­pravu pracovnÃ­ sÃ­ly na Ã©ru AI.
- NovÃ½ institut: AI Safety Institute zaÄne od roku 2026 monitorovat AI a identifikovat mezery v legislativÄ›.
- HistorickÃ½ kontext: PlÃ¡n vychÃ¡zÃ­ z konzultacÃ­ spuÅ¡tÄ›nÃ½ch v roce 2023, kterÃ© reagovaly na obavy veÅ™ejnosti z rychlÃ©ho Å¡Ã­Å™enÃ­ AI.
- Firmy vÃ­tÃ¡ny: PodnikatelskÃ© kruhy prosazovaly odloÅ¾enÃ­ tvrdÃ½ch regulacÃ­.

## Podrobnosti
NÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci, zveÅ™ejnÄ›nÃ½ 1. prosince 2025, pÅ™edstavuje vÃ½znamnÃ½ obrat v australskÃ© politice vÅ¯Äi tÃ©to technologii. PÅ¯vodnÄ› mÄ›l plÃ¡n zahrnovat deset povinnÃ½ch bezpeÄnostnÃ­ch opatÅ™enÃ­ navrÅ¾enÃ½ch v zÃ¡Å™Ã­ pÅ™edchozÃ­ho roku bÃ½valÃ½m ministrem prÅ¯myslu Edem Husicem. Tyto opatÅ™enÃ­ byla zamÃ½Å¡lena pro vÃ½vojÃ¡Å™e vysoce rizikovÃ½ch systÃ©mÅ¯ AI a zahrnovala tvorbu plÃ¡nÅ¯ Å™Ã­zenÃ­ rizik, testovÃ¡nÃ­ systÃ©mÅ¯ pÅ™ed nasazenÃ­m i po nÄ›m, zÅ™Ã­zenÃ­ mechanismÅ¯ pro stÃ­Å¾nosti, sdÃ­lenÃ­ dat po incidentech a umoÅ¾nÄ›nÃ­ kontroly tÅ™etÃ­mi stranami. TakovÃ½ rÃ¡mec mÄ›l fungovat pod samostatnÃ½m zÃ¡konem o AI, kterÃ½ by kategorizoval technologie podle rizikovosti â€“ striktnÃ­ pravidla pro vysokorizikovÃ© aplikace a volnÄ›jÅ¡Ã­ prostor pro nÃ­zkorizikovÃ© nÃ¡stroje, jako jsou jednoduchÃ© chatboti nebo generativnÃ­ modely pro kreativnÃ­ Ãºkoly.

VlÃ¡da vÅ¡ak tento smÄ›r opustila po tlaku podnikatelskÃ½ch skupin a rozhodla se pro krÃ¡tkodobÃ© Å™Ã­zenÃ­ AI prostÅ™ednictvÃ­m "silnÃ½ch stÃ¡vajÃ­cÃ­ch, vÄ›tÅ¡inou technologie neutrÃ¡lnÃ­ch prÃ¡vnÃ­ch rÃ¡mcÅ¯". To znamenÃ¡, Å¾e existujÃ­cÃ­ regulÃ¡toÅ™i, jako napÅ™Ã­klad ÃšÅ™ad pro konkurenci a spotÅ™ebitele (ACCC) nebo Komise pro soukromÃ­ (OAIC), budou vyuÅ¾Ã­vat svÃ© stÃ¡vajÃ­cÃ­ pravomoci k Å™eÅ¡enÃ­ rizik, jako jsou dezinformace, diskriminace nebo bezpeÄnostnÃ­ zranitelnosti v AI systÃ©mech. PlÃ¡n tak navazuje na pÅ™Ã­stup podobnÃ½ evropskÃ©mu AI Actu, ale bez jeho rigidnÃ­ kategorizace.

KlÃ­Äovou novinkou je zÅ™Ã­zenÃ­ AI Safety Institute s rozpoÄtem 30 milionÅ¯ australskÃ½ch dolarÅ¯, kterÃ½ od roku 2026 bude sledovat globÃ¡lnÃ­ trendy v AI, analyzovat rizika a radit vlÃ¡dÄ›, firmÃ¡m i agentuÅ™e, kde legislativnÃ­ rÃ¡mec selhÃ¡vÃ¡. Institut nebude mÃ­t sankÄnÃ­ pravomoci, ale poslouÅ¾Ã­ jako poradnÃ­ orgÃ¡n. PlÃ¡n zÃ¡roveÅˆ podporuje investice do infrastruktury, jako jsou datovÃ¡ centra pro trÃ©nink velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), kterÃ© vyÅ¾adujÃ­ obrovskÃ© vÃ½poÄetnÃ­ kapacity na GPU, a programy rekvalifikace pracovnÃ­kÅ¯ pro role v AI, napÅ™Ã­klad datovÃ­ anotÃ¡toÅ™i nebo etiÄtÃ­ auditori systÃ©mÅ¯.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento plÃ¡n odrÃ¡Å¾Ã­ globÃ¡lnÃ­ dilema regulace AI: vyvÃ¡Å¾enÃ­ inovacÃ­ a rizik. AustrÃ¡lie, jako stÅ™ednÄ› velkÃ¡ ekonomika zÃ¡vislÃ¡ na tech exportu, se pÅ™idÃ¡vÃ¡ k zemÃ­m jako USA, kterÃ© preferujÃ­ dobrovolnÃ© smÄ›rnice pÅ™ed tvrdÃ½mi pravidly, na rozdÃ­l od EU s jejÃ­m AI Actem. Pro prÅ¯mysl to znamenÃ¡ mÃ©nÄ› byrokracie a rychlejÅ¡Ã­ nasazenÃ­ AI v oblastech jako zdravotnictvÃ­ nebo finance, ale zvyÅ¡uje riziko incidentÅ¯, jako jsou biasy v rozhodovacÃ­ch systÃ©mech nebo deepfakes. Pro uÅ¾ivatele to pÅ™ineslo mÃ©nÄ› okamÅ¾itÃ© ochrany, ale potenciÃ¡lnÄ› levnÄ›jÅ¡Ã­ AI nÃ¡stroje. DlouhodobÄ› bude institut klÃ­ÄovÃ½ pro identifikovÃ¡nÃ­ mezer, zejmÃ©na v kontextu rychlÃ©ho pokroku v modelech jako GPT nebo Gemini, kde souÄasnÃ© zÃ¡kony nestaÄÃ­ na specifickÃ¡ rizika, jako je halucinace nebo autonomnÃ­ rozhodovÃ¡nÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.abc.net.au/news/2025-12-02/national-artificial-intelligence-plan-growth-existing-laws/106086474)

**Zdroj:** ğŸ“° ABC News (AU)
