---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Nvidia
- Groq
date: '2025-12-25 05:04:39'
description: Nvidia uzavÃ­rÃ¡ partnerstvÃ­ s Groq za ÃºÄelem rozÅ¡Ã­Å™enÃ­ pÅ™Ã­stupu k technologii
  pro odvozovÃ¡nÃ­ v umÄ›lÃ© inteligenci a ÃºdajnÄ› zÃ­skÃ¡vÃ¡ aktiva tÃ©to firmy. ManaÅ¾eÅ™i
  Groq, vÄetnÄ› generÃ¡lnÃ­ho Å™editele, se pÅ™ipojÃ­ k Nvidia.
importance: 4
layout: tech_news_article
original_title: Nvidia licenses Groq inference technology, Groq executives join chipmaker
publishedAt: '2025-12-25T05:04:39+00:00'
slug: nvidia-licenses-groq-inference-technology-groq-exe
source:
  emoji: ğŸ“°
  id: null
  name: Seeking Alpha
title: Nvidia licencuje technologii inference od Groq, klÃ­ÄovÃ­ manaÅ¾eÅ™i Groq pÅ™echÃ¡zejÃ­
  do ÄipovÃ©ho vÃ½robce
url: https://seekingalpha.com/news/4535300-nvidia-licenses-groq-inference-technology-groq-executives-join-chipmaker
urlToImage: https://static.seekingalpha.com/cdn/s3/uploads/getty_images/657543518/image_657543518.jpg?io=getty-c-w630
urlToImageBackup: https://static.seekingalpha.com/cdn/s3/uploads/getty_images/657543518/image_657543518.jpg?io=getty-c-w630
---

## Souhrn
Nvidia oznÃ¡mila licenci na technologii pro odvozovÃ¡nÃ­ (inference) od spoleÄnosti Groq, specializujÃ­cÃ­ se na hardwarovÃ© akcelerÃ¡tory pro umÄ›lou inteligenci. KlÃ­ÄovÃ­ manaÅ¾eÅ™i Groq, vÄetnÄ› zakladatele a generÃ¡lnÃ­ho Å™editele Jonathana Rossa, pÅ™echÃ¡zejÃ­ do Nvidia. Tento krok mÃ¡ rozÅ¡Ã­Å™it dostupnost Groq technologie pro Å¡irÅ¡Ã­ ekosystÃ©m AI a potenciÃ¡lnÄ› zahrnuje akvizici aktiv.

## KlÃ­ÄovÃ© body
- Nvidia licencuje proprietÃ¡rnÃ­ technologii Language Processing Unit (LPU) od Groq pro rychlÃ© odvozovÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
- Jonathan Ross a dalÅ¡Ã­ top manaÅ¾eÅ™i Groq se stÃ¡vajÃ­ zamÄ›stnanci Nvidia.
- PartnerstvÃ­ cÃ­lÃ­ na zlepÅ¡enÃ­ efektivity inference v AI aplikacÃ­ch.
- ÃšdajnÄ› dochÃ¡zÃ­ k pÅ™evzetÃ­ ÄÃ¡sti aktiv Groq, coÅ¾ posiluje pozici Nvidia na trhu.
- Groq LPU je optimalizovÃ¡no pro sekvenÄnÃ­ zpracovÃ¡nÃ­ dat, coÅ¾ umoÅ¾Åˆuje vyÅ¡Å¡Ã­ propustnost neÅ¾ tradiÄnÃ­ GPU.

## Podrobnosti
Groq, startup zaloÅ¾enÃ½ v roce 2016 bÃ½valÃ½mi vÃ½vojÃ¡Å™i Google, se zamÄ›Å™uje na vÃ½voj specializovanÃ½ch ÄipÅ¯ pro odvozovÃ¡nÃ­ v umÄ›lÃ© inteligenci. Jejich klÃ­ÄovÃ½m produktem je LPU, architektura zaloÅ¾enÃ¡ na tensorovÃ©m streamovacÃ­m procesoru, kterÃ½ zpracovÃ¡vÃ¡ data v lineÃ¡rnÃ­m toku bez zbyteÄnÃ©ho pÅ™Ã­stupu k pamÄ›ti. Tato technologie umoÅ¾Åˆuje odvozovÃ¡nÃ­ LLM, jako jsou modely Llama nebo Mixtral, s propustnostÃ­ aÅ¾ desetkrÃ¡t vyÅ¡Å¡Ã­ neÅ¾ u Nvidia H100 GPU pÅ™i niÅ¾Å¡Ã­ spotÅ™ebÄ› energie. LPU slouÅ¾Ã­ k nasazenÃ­ AI modelÅ¯ v produkÄnÃ­m prostÅ™edÃ­, kde je dÅ¯leÅ¾itÃ¡ nÃ­zkÃ¡ latence a vysokÃ½ vÃ½kon pro aplikace jako chatboti, generovÃ¡nÃ­ kÃ³du nebo analÃ½za textu.

Nvidia, dominantnÃ­ hrÃ¡Ä v oblasti grafickÃ½ch procesorÅ¯ (GPU) pro trÃ©nink AI modelÅ¯, nynÃ­ licencuje tuto technologii, aby rozÅ¡Ã­Å™ila svÃ© portfolio o specializovanÃ© Å™eÅ¡enÃ­ pro inference. Podle zprÃ¡v se k Nvidia pÅ™ipojÃ­ nejen Jonathan Ross, kterÃ½ vede Groq od zaloÅ¾enÃ­ a pÅ™inesl zkuÅ¡enosti z Google TPU projektu, ale i dalÅ¡Ã­ klÃ­ÄovÃ­ inÅ¾enÃ½Å™i. Tento pÅ™evod personÃ¡lu naznaÄuje hlubÅ¡Ã­ integraci, moÅ¾nÃ¡ v podobÄ› akvizice intelektuÃ¡lnÃ­ho vlastnictvÃ­ nebo celÃ©ho tÃ½mÅ¯. Nvidia tak zÃ­skÃ¡vÃ¡ pÅ™Ã­stup k architektuÅ™e, kterÃ¡ Å™eÅ¡Ã­ klÃ­ÄovÃ© limity GPU v inference â€“ zejmÃ©na u velkÃ½ch modelÅ¯ s miliardami parametrÅ¯, kde je potÅ™eba efektivnÃ­ sekvenÄnÃ­ zpracovÃ¡nÃ­ tokenÅ¯.

V praxi to znamenÃ¡, Å¾e vÃ½vojÃ¡Å™i budou moci integrovat Groq technologii pÅ™es Nvidia platformy, jako je CUDA nebo NVLink, pro hybridnÃ­ nasazenÃ­ AI. NapÅ™Ã­klad cloudovÃ­ poskytovatelÃ© jako AWS nebo Azure by mohli nabÃ­zet instance s LPU akcelerÃ¡tory, coÅ¾ snÃ­Å¾Ã­ nÃ¡klady na inference o 50â€“80 % oproti ÄistÄ› GPU Å™eÅ¡enÃ­m. Groq jiÅ¾ dÅ™Ã­ve demonstroval svÃ© schopnosti na platformÄ› GroqCloud, kde odvozuje model Llama 2 70B za mÃ©nÄ› neÅ¾ 100 milisekund na token.

## ProÄ je to dÅ¯leÅ¾itÃ©
Toto partnerstvÃ­ posiluje monopol Nvidia na AI hardwarovÃ©m trhu, kde inference tvoÅ™Ã­ aÅ¾ 90 % provoznÃ­ch nÃ¡kladÅ¯ AI systÃ©mÅ¯ oproti trÃ©ninku. ZÃ­skÃ¡nÃ­m Groq technologie Nvidia neutralizuje konkurenta, kterÃ½ ohroÅ¾oval jejÃ­ GPU prodej v oblasti nasazenÃ­ modelÅ¯. Pro prÅ¯mysl to znamenÃ¡ standardizaci na jednu platformu, coÅ¾ usnadnÃ­ vÃ½voj, ale omezÃ­ diverzitu â€“ mÃ©nÄ› prostoru pro alternativy jako AMD nebo ÄÃ­nskÃ© Äipy. UÅ¾ivatelÃ©, jako firmy nasazujÃ­cÃ­ LLM, zÃ­skajÃ­ rychlejÅ¡Ã­ a levnÄ›jÅ¡Ã­ inference, coÅ¾ urychlÃ­ adopci AI v obchodech, zdravotnictvÃ­ nebo autonomnÃ­ch systÃ©mech. DlouhodobÄ› to mÅ¯Å¾e vÃ©st k vertikÃ¡lnÃ­ integraci, kde Nvidia ovlÃ¡dne celÃ½ AI stack od ÄipÅ¯ po software.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://seekingalpha.com/news/4535300-nvidia-licenses-groq-inference-technology-groq-executives-join-chipmaker)

**Zdroj:** ğŸ“° Seeking Alpha
