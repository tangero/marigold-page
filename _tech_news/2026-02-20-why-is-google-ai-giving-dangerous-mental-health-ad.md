---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Google
date: '2026-02-20 06:11:09'
description: BritskÃ¡ charita pro duÅ¡evnÃ­ zdravÃ­ zahÃ¡jila vyÅ¡etÅ™ovÃ¡nÃ­ po odhalenÃ­ AI-generovanÃ½ch
  pÅ™ehledÅ¯ na velkÃ©m vyhledÃ¡vaÄi, kterÃ© prezentovaly Å¡kodlivÃ© a nepÅ™esnÃ© rady k duÅ¡evnÃ­mu
  zdravÃ­ jako ustÃ¡lenÃ© fakta. Experti upozorÅˆujÃ­ na chybÄ›jÃ­cÃ­ varovÃ¡nÃ­ a autoritativnÃ­
  tÃ³n, kterÃ½ zvyÅ¡uje riziko, Å¾e zranitelnÃ­ uÅ¾ivatelÃ© berou obsah jako spolehlivou
  lÃ©kaÅ™skou radu.
importance: 4
layout: tech_news_article
original_title: 'Why is Google AI giving dangerous mental-health advice? #health'
publishedAt: '2026-02-20T06:11:09+00:00'
slug: why-is-google-ai-giving-dangerous-mental-health-ad
source:
  emoji: ğŸ“°
  id: null
  name: Alltoc.com
title: ProÄ AI od Google poskytuje nebezpeÄnÃ© rady k duÅ¡evnÃ­mu zdravÃ­?
url: https://alltoc.com/health/why-is-google-ai-giving-dangerous-mental-health-advice
urlToImage: https://alltoc.com/cdn/1045/og.png
urlToImageBackup: https://alltoc.com/cdn/1045/og.png
---

## Souhrn
BritskÃ¡ charita pro duÅ¡evnÃ­ zdravÃ­ zahÃ¡jila vyÅ¡etÅ™ovÃ¡nÃ­ kvÅ¯li rizikovÃ½m AI-generovanÃ½m pÅ™ehledÅ¯m na Google, kterÃ© poskytujÃ­ Å¡kodlivÃ© a nepÅ™esnÃ© rady k duÅ¡evnÃ­mu zdravÃ­ bez jasnÃ½ch varovÃ¡nÃ­. NovinÃ¡Å™i odhalili, jak tyto pÅ™ehledy prezentujÃ­ nebezpeÄnÃ© informace autoritativnÃ­m tÃ³nem, coÅ¾ ohroÅ¾uje lidi hledajÃ­cÃ­ urgentnÃ­ pomoc. ProblÃ©m se tÃ½kÃ¡ absence bezpeÄnostnÃ­ch mechanismÅ¯ a odpovÄ›dnosti technologickÃ½ch firem.

## KlÃ­ÄovÃ© body
- AI pÅ™ehledy na Google prezentujÃ­ Å¡kodlivÃ© nepÅ™esnosti jako nevyzvanÃ© fakta bez varovÃ¡nÃ­.
- ChybÃ­ nebo je minimalizovÃ¡no zdÅ¯raznÄ›nÃ­ bezpeÄnostnÃ­ch upozornÄ›nÃ­ pÅ™i prvnÃ­m zobrazenÃ­ vÃ½stupu.
- Design vytvÃ¡Å™Ã­ dojem klinickÃ© podpory, i kdyÅ¾ obsah neproÅ¡el kontrolou lÃ©kaÅ™Å¯.
- Riziko pro uÅ¾ivatele v krizÃ­ch, kteÅ™Ã­ mohou oddÃ¡lit kontakt s odbornou pomocÃ­.
- OÄekÃ¡vanÃ© kroky zahrnujÃ­ vyÅ¡etÅ™ovÃ¡nÃ­ charity, poÅ¾adavky na varovÃ¡nÃ­ a omezenÃ­ rizikovÃ½ch rad.

## Podrobnosti
ProblÃ©m se tÃ½kÃ¡ funkce AI Overviews v Google Search, kterÃ¡ generuje shrnutÃ­ vÃ½sledkÅ¯ vyhledÃ¡vÃ¡nÃ­ na zÃ¡kladÄ› velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM). Tyto pÅ™ehledy se zobrazujÃ­ nahoÅ™e ve vyhledÃ¡vÃ¡nÃ­ a slouÅ¾Ã­ k rychlÃ©mu poskytnutÃ­ odpovÄ›dÃ­ na otÃ¡zky uÅ¾ivatelÅ¯. V pÅ™Ã­padÄ› dotazÅ¯ na duÅ¡evnÃ­ zdravÃ­, jako jsou symptomy deprese, sebevraÅ¾ednÃ© myÅ¡lenky nebo metody sebeubliÅ¾ovÃ¡nÃ­, AI Äasto shrnuje informace z webu do struÄnÃ©ho textu, kterÃ½ vÅ¡ak obsahuje chyby. NapÅ™Ã­klad mÅ¯Å¾e doporuÄit rizikovÃ© intervence, jako samolÃ©Äbu bez konzultace s lÃ©kaÅ™em, nebo bagatelizovat nebezpeÄÃ­, aniÅ¾ by zdÅ¯raznila nutnost okamÅ¾itÃ© profesionÃ¡lnÃ­ pomoci.

BritskÃ¡ charita, kterÃ¡ se zamÄ›Å™uje na podporu lidÃ­ s duÅ¡evnÃ­mi problÃ©my, reagovala na reportÃ¡Å¾e novinÃ¡Å™Å¯, kteÅ™Ã­ testovali vyhledÃ¡vÃ¡nÃ­ souvisejÃ­cÃ­ s krizemi. Experti zapojenÃ­ do charity poukÃ¡zali na nÄ›kolik klÃ­ÄovÃ½ch nedostatkÅ¯: AI bere zdroje z internetu, kde se mÃ­sÃ­ spolehlivÃ© studie s fÃ³rovÃ½mi pÅ™Ã­spÄ›vky, a syntetizuje je bez filtrovÃ¡nÃ­. VÃ½stup postrÃ¡dÃ¡ kontextuÃ¡lnÃ­ varovÃ¡nÃ­ typu â€Toto nenÃ­ lÃ©kaÅ™skÃ¡ rada, kontaktujte odbornÃ­kaâ€œ, kterÃ© by mÄ›lo bÃ½t prominentnÃ­. NavÃ­c autoritativnÃ­ styl â€“ podobnÃ½ encyklopedickÃ½m zÃ¡znamÅ¯m â€“ zvyÅ¡uje dÅ¯vÄ›ryhodnost u lidÃ­ v akutnÃ­m stavu, kteÅ™Ã­ Äasto hledajÃ­ rychlou odpovÄ›Ä na mobilu.

Toto nenÃ­ ojedinÄ›lÃ½ pÅ™Ã­pad. Google spustil AI Overviews v kvÄ›tnu 2024 po testovÃ¡nÃ­ Gemini modelu, ale brzy Äelil kritice za absurditÃ­, jako doporuÄenÃ­ lepidla na pizzu. V oblasti zdravÃ­ je riziko vyÅ¡Å¡Ã­, protoÅ¾e miliony lidÃ­ pouÅ¾Ã­vajÃ­ vyhledÃ¡vaÄe pro prvnÃ­ pomoc â€“ podle studiÃ­ aÅ¾ 70 % pacientÅ¯ s duÅ¡evnÃ­mi problÃ©my zaÄÃ­nÃ¡ online. OdpovÄ›dnost leÅ¾Ã­ na Google, kterÃ½ nasazuje modely v mÄ›Å™Ã­tku miliard poÅ¾adavkÅ¯ dennÄ›, ale bez specifickÃ½ch safeguardÅ¯ pro citlivÃ¡ tÃ©mata jako sebevraÅ¾da nebo samolÃ©Äba. Klinici a pacientskÃ© skupiny volajÃ­ po algoritmickÃ½ch limitech, kterÃ© by pÅ™esmÄ›rovaly na hotline jako Samaritans v BritÃ¡nii.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato kauza odhaluje systÃ©movÃ© rizika AI v zdravotnictvÃ­, kde rychlost a dostupnost pÅ™evaÅ¾ujÃ­ nad pÅ™esnostÃ­. Pro uÅ¾ivatele znamenÃ¡, Å¾e dÅ¯vÄ›ra v vyhledÃ¡vaÄe klesÃ¡, zvlÃ¡Å¡tÄ› v krizÃ­ch, kde zpoÅ¾dÄ›nÃ­ pomoci mÅ¯Å¾e mÃ­t fatÃ¡lnÃ­ nÃ¡sledky. Pro prÅ¯mysl to zesiluje tlak na regulace: EU AI Act klasifikuje zdravotnÃ­ AI jako vysoce rizikovÃ©, coÅ¾ by mohlo vÃ©st k povinnÃ½m auditÅ¯m. Google a podobnÃ© firmy budou muset implementovat lepÅ¡Ã­ guardraily, jako dynamickÃ¡ detekce tÃ©mat a povinnÃ© routovÃ¡nÃ­ na certifikovanÃ© zdroje. V Å¡irÅ¡Ã­m kontextu to ovlivÅˆuje vÃ½voj LLM, kde bezpeÄnostnÃ­ vrstvy (napÅ™. RLHF â€“ Reinforcement Learning from Human Feedback) nestaÄÃ­ pro medicÃ­nskÃ© aplikace bez klinickÃ© validace. Pokud se problÃ©m neÅ™eÅ¡Ã­, mÅ¯Å¾e to zpÅ¯sobit pokles adopce AI nÃ¡strojÅ¯ v regulovanÃ½ch oblastech a posÃ­lit debatu o odpovÄ›dnosti za Å¡kody zpÅ¯sobenÃ© AI.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://alltoc.com/health/why-is-google-ai-giving-dangerous-mental-health-advice)

**Zdroj:** ğŸ“° Alltoc.com
