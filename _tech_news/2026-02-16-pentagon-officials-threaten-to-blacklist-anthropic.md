---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
date: '2026-02-16 23:37:32'
description: AmerickÃ© ministerstvo obrany zvaÅ¾uje pÅ™eruÅ¡enÃ­ vÅ¡ech obchodnÃ­ vazeb s
  firmou Anthropic a oznaÄenÃ­ ji za riziko v dodavatelskÃ©m Å™etÄ›zci kvÅ¯li sporÅ¯m o
  pouÅ¾itÃ­ chatbota Claude pro vojenskÃ© ÃºÄely. Tento krok by donutil vÅ¡echny kontrakty
  Pentagonu pÅ™estat pouÅ¾Ã­vat technologie Anthropic.
importance: 4
layout: tech_news_article
original_title: Pentagon officials threaten to blacklist Anthropic over its military
  chatbot policies
publishedAt: '2026-02-16T23:37:32+00:00'
slug: pentagon-officials-threaten-to-blacklist-anthropic
source:
  emoji: ğŸ“°
  id: null
  name: SiliconANGLE News
title: PÅ™edstavitelÃ© Pentagonu hrozÃ­ zaÅ™azenÃ­m Anthropic na Äernou listinu kvÅ¯li jeho
  politikÃ¡m vojenskÃ©ho chatbota
url: https://siliconangle.com/2026/02/16/pentagon-officials-threaten-blacklist-anthropic-military-chatbot-policies/
urlToImage: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/Screenshot-from-2026-02-17-06-36-59.png
urlToImageBackup: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/Screenshot-from-2026-02-17-06-36-59.png
---

## Souhrn
PÅ™edstavitelÃ© Pentagonu zvaÅ¾ujÃ­ zaÅ™azenÃ­ startupu Anthropic na Äernou listinu kvÅ¯li neshodÃ¡m ohlednÄ› vojenskÃ©ho nasazenÃ­ jeho chatbota Claude. Firma, kterÃ¡ vyvinula model Claude Gov speciÃ¡lnÄ› pro nÃ¡rodnÃ­ bezpeÄnost, ÄelÃ­ tlaku na obnovenÃ­ kontraktu, jinak pÅ™ijde o klÃ­ÄovÃ© zakÃ¡zky. RozhodnutÃ­ by mohlo nastat po mÄ›sÃ­cÃ­ch neÃºspÄ›Å¡nÃ½ch jednÃ¡nÃ­.

## KlÃ­ÄovÃ© body
- Pentagon oznaÄil Anthropic za potenciÃ¡lnÃ­ 'riziko v dodavatelskÃ©m Å™etÄ›zci', coÅ¾ by zakÃ¡zalo jeho technologie vÅ¡em vojenskÃ½m dodavatelÅ¯m.
- Claude Gov, chatbot urÄenÃ½ pro americkÃ© bezpeÄnostnÃ­ sloÅ¾ky, byl chvÃ¡len a pouÅ¾it v operaci na zatÄenÃ­ venezuelskÃ©ho prezidenta NicolÃ¡ Madura.
- Anthropic je jedinou firmou s kontraktem na AI model pro Pentagon, ale spor se tÃ½kÃ¡ podmÃ­nek obnovenÃ­.
- Zdroje tvrdÃ­, Å¾e disentangle od Anthropic bude nÃ¡roÄnÃ© a firma za to zaplatÃ­.
- Pentagon zdÅ¯razÅˆuje, Å¾e partneÅ™i musÃ­ podporovat 'bojovÃ© sÃ­ly v kaÅ¾dÃ©m konfliktu'.

## Podrobnosti
Anthropic PBC, kalifornskÃ½ startup specializujÃ­cÃ­ se na vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯ s dÅ¯razem na bezpeÄnost a etiku, se dostal do konfliktu s americkÃ½m ministerstvem obrany (Pentagonem). Firma vyvinula Claude Gov, upravenou verzi svÃ©ho chatbota Claude, kterÃ½ slouÅ¾Ã­ k analÃ½ze dat, generovÃ¡nÃ­ zprÃ¡v a podpÅ¯rÄ› rozhodovÃ¡nÃ­ v nÃ¡rodnÃ­m bezpeÄnostnÃ­m prostÅ™edÃ­. Tento nÃ¡stroj, deployovanÃ½ vÃ½hradnÄ› pro vlÃ¡dnÃ­ uÅ¾ivatele, umoÅ¾Åˆuje zpracovÃ¡vat citlivÃ© informace s vysokou mÃ­rou pÅ™esnosti a bezpeÄnosti, coÅ¾ ho ÄinÃ­ uÅ¾iteÄnÃ½m pro plÃ¡novÃ¡nÃ­ operacÃ­ nebo inteligence.

Podle zprÃ¡vy Axios z 16. Ãºnora 2026 ministr obrany Pete Hegseth a dalÅ¡Ã­ pÅ™edstavitelÃ© po mÄ›sÃ­cÃ­ch jednÃ¡nÃ­ zvaÅ¾ujÃ­ radikÃ¡lnÃ­ krok: oznaÄenÃ­ Anthropic za 'riziko v dodavatelskÃ©m Å™etÄ›zci'. Toto oznaÄenÃ­, obvykle rezervovanÃ© pro zahraniÄnÃ­ aktÃ©ry jako ÄŒÃ­na nebo Rusko, by automaticky vylouÄilo firmu ze vÅ¡ech dodÃ¡vek pro Pentagon a jeho dodavatele. JakÃ©koli pouÅ¾itÃ­ technologiÃ­ Anthropic by ohrozilo kontrakty tÅ™etÃ­ch stran. AnonymnÃ­ zdroj prohlÃ¡sil: 'Bude to obrovskÃ¡ bolest zad disentanglovat a zajistÃ­me, aby za nucenÃ­ naÅ¡Ã­ ruky zaplatili.'

Claude Gov si zÃ­skal uznÃ¡nÃ­ â€“ napÅ™Ã­klad Wall Street Journal zmÃ­nil jeho roli v loÅˆskÃ© operaci speciÃ¡lnÃ­ch sil, kdy americkÃ© jednotky unesly venezuelskÃ©ho prezidenta NicolÃ¡ Madura z jeho rezidence v Caracasu. Chatbot pomohl s plÃ¡novÃ¡nÃ­m, analÃ½zou rizik a logistickou koordinacÃ­. PÅ™esto Anthropic, znÃ¡mÃ½ svÃ½m pÅ™Ã­stupem 'Constitutional AI' â€“ kde modely dodrÅ¾ujÃ­ pÅ™edem definovanÃ© etickÃ© principy â€“ pravdÄ›podobnÄ› odmÃ­tÃ¡ rozÅ¡Ã­Å™it pouÅ¾itÃ­ na Å¡irÅ¡Ã­ vojenskÃ© scÃ©nÃ¡Å™e, jako jsou autonomnÃ­ zbranÄ› nebo agresivnÃ­ operace. Pentagon naopak poÅ¾aduje plnou podporu pro 'vÃ­tÄ›zstvÃ­ v jakÃ©mkoli boji', coÅ¾ zahrnuje i kontroverznÃ­ aplikace AI.

PentagonskÃ½ mluvÄÃ­ potvrdil, Å¾e vÅ¡echny AI partnerstvÃ­ jsou v revizi. Anthropic tak zatÃ­m ztrÃ¡cÃ­ svou unikÃ¡tnÃ­ pozici â€“ je jedinÃ½m poskytovatelem AI modelu pro armÃ¡du, na rozdÃ­l od konkurentÅ¯ jako OpenAI, kterÃ½ jiÅ¾ spolupracuje na projektech jako ChatGPT Enterprise pro obranu.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento spor odhaluje napÄ›tÃ­ mezi etickÃ½mi standardy v AI a nÃ¡rodnÃ­ bezpeÄnostÃ­. Anthropic, financovanÃ½ Amazona a Googlem s hodnotou pÅ™es 18 miliard dolarÅ¯, pÅ™edstavuje Å¡piÄku v bezpeÄnÃ©m AI vÃ½voji, ale blacklist by ho oslabil ekonomicky a donutil k ÃºstupkÅ¯m. Pro prÅ¯mysl to znamenÃ¡ riziko fragmentace: armÃ¡da by se obrÃ¡tila k mÃ©nÄ› restriktivnÃ­m hrÃ¡ÄÅ¯m jako OpenAI nebo xAI Elona Muska, coÅ¾ urychlÃ­ militarizaci AI. UÅ¾ivatelÃ© v obranÄ› by ztratili specializovanÃ½ nÃ¡stroj jako Claude Gov, coÅ¾ by zpÅ¯sobilo provoznÃ­ problÃ©my. Å irÅ¡Ã­ kontext ukazuje, jak USA tlaÄÃ­ na domÃ¡cÃ­ AI firmy k plnÃ© loajalitÄ›, coÅ¾ ovlivnÃ­ globÃ¡lnÃ­ trendy v regulaci AI â€“ od EU AI Act po ÄÃ­nskÃ© investice do vojenskÃ© AI. DlouhodobÄ› to mÅ¯Å¾e vÃ©st k bifurkaci trhu: etickÃ© AI pro civilnÃ­ pouÅ¾itÃ­ versus neomezenÃ© pro stÃ¡tnÃ­ aktÃ©ry.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://siliconangle.com/2026/02/16/pentagon-officials-threaten-blacklist-anthropic-military-chatbot-policies/)

**Zdroj:** ğŸ“° SiliconANGLE News
