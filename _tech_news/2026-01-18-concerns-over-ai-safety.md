---
author: Marisa Aigen
category: bezpeÄnost ai
date: '2026-01-18 02:35:03'
description: AustralskÃ½ eSafety komisaÅ™ upozorÅˆuje na zneuÅ¾itÃ­ generativnÃ­ umÄ›lÃ© inteligence
  Grok na sociÃ¡lnÃ­ sÃ­ti X k tvorbÄ› sexualizovanÃ½ch nebo exploatativnÃ­ch obrÃ¡zkÅ¯ lidÃ­.
  Regulator poÅ¾aduje od X informace o bezpeÄnostnÃ­ch opatÅ™enÃ­ch a pÅ™ipravuje se na
  pouÅ¾itÃ­ prÃ¡vnÃ­ch nÃ¡strojÅ¯.
importance: 4
layout: tech_news_article
original_title: Concerns over AI safety
publishedAt: '2026-01-18T02:35:03+00:00'
slug: concerns-over-ai-safety
source:
  emoji: ğŸ“°
  id: null
  name: Starweekly.com.au
title: Obavy z bezpeÄnosti AI
url: https://northern.starweekly.com.au/news/concerns-over-ai-safety/
urlToImage: https://northern.starweekly.com.au/wp-content/uploads/sites/5/2026/01/computer_519231_01.jpg
urlToImageBackup: https://northern.starweekly.com.au/wp-content/uploads/sites/5/2026/01/computer_519231_01.jpg
---

## Souhrn
AustralskÃ½ eSafety komisaÅ™ varuje pÅ™ed zneuÅ¾itÃ­m generativnÃ­ AI Grok na platformÄ› X, kde uÅ¾ivatelÃ© generujÃ­ sexualizovanÃ© nebo exploatativnÃ­ obrÃ¡zky. PoÄet stÃ­Å¾nostÃ­ sice zÅ¯stÃ¡vÃ¡ nÃ­zkÃ½, ale rychle roste, coÅ¾ vede k regulaÄnÃ­mu tlaku vÄetnÄ› dopisu X a hrozby odstranÄ›nÃ­ obsahu. PÅ™ichÃ¡zejÃ­ novÃ© povinnÃ© bezpeÄnostnÃ­ kÃ³dy pro AI sluÅ¾by.

## KlÃ­ÄovÃ© body
- eSafety komisaÅ™ zaznamenal pÅ™echod od nulovÃ½ch k nÄ›kolika stÃ­Å¾nostem za poslednÃ­ dva tÃ½dny.
- X byl kontaktovÃ¡n s Å¾Ã¡dostÃ­ o detaily bezpeÄnostnÃ­ch mechanismÅ¯ proti zneuÅ¾itÃ­ Grok.
- RegulÃ¡tor pouÅ¾ije prÃ¡vnÃ­ pravomoci podle Online Safety Act, vÄetnÄ› pÅ™Ã­kazÅ¯ k odstranÄ›nÃ­ obsahu.
- NovÃ© regulace od 9. bÅ™ezna 2026 omezÃ­ pÅ™Ã­stup dÄ›tÃ­ k explicitnÃ­mu, nÃ¡silnÃ©mu materiÃ¡lu, sebevraÅ¾dÃ¡m a sebeubliÅ¾ovÃ¡nÃ­.
- PÅ™edchozÃ­ akce v roce 2025 donutila nudify sluÅ¾by (nÃ¡stroje pro odhalovÃ¡nÃ­ obleÄenÃ­ na fotkÃ¡ch) opustit australskÃ½ trh.

## Podrobnosti
Grok je generativnÃ­ model umÄ›lÃ© inteligence vyvinutÃ½ spoleÄnostÃ­ xAI Elona Muska, kterÃ½ je integrovÃ¡n pÅ™Ã­mo do sociÃ¡lnÃ­ sÃ­tÄ› X (dÅ™Ã­ve Twitter). SlouÅ¾Ã­ k generovÃ¡nÃ­ textu i obrÃ¡zkÅ¯ na zÃ¡kladÄ› uÅ¾ivatelskÃ½ch popisÅ¯, vyuÅ¾Ã­vÃ¡ pokroÄilÃ© modely jako Flux pro tvorbu realistickÃ½ch vizuÃ¡lÅ¯. Na rozdÃ­l od konkurentÅ¯ jako ChatGPT nebo Gemini je Grok navrÅ¾enÃ½ s menÅ¡Ã­mi restrikcemi, coÅ¾ umoÅ¾Åˆuje volnÄ›jÅ¡Ã­ generovÃ¡nÃ­ obsahu, vÄetnÄ› kontroverznÃ­ch tÃ©mat, aby byl â€maximÃ¡lnÄ› pravdivÃ½â€œ a mÃ©nÄ› politicky korektnÃ­. Tato volnost vÅ¡ak vede k rizikÅ¯m zneuÅ¾itÃ­, jako je tvorba deepfake obrÃ¡zkÅ¯ s sexualizovanÃ½mi prvky, vÄetnÄ› potenciÃ¡lnÄ› dÄ›tskÃ©ho obsahu.

AustralskÃ½ eSafety komisaÅ™, nezÃ¡vislÃ½ regulaÄnÃ­ orgÃ¡n zodpovÄ›dnÃ½ za online bezpeÄnost, reaguje na rostoucÃ­ stÃ­Å¾nosti. ZatÃ­m jich nenÃ­ mnoho, ale trend od nuly k nÄ›kolika za dva tÃ½dny signalizuje problÃ©m. Podle Online Safety Act musÃ­ platformy jako X proaktivnÄ› detekovat a odstraÅˆovat materiÃ¡l s dÄ›tskou sexuÃ¡lnÃ­ exploatacÃ­ nebo jinÃ½ nezÃ¡konnÃ½ obsah. KomisaÅ™ uÅ¾ v roce 2025 zasÃ¡hl proti nudify sluÅ¾bÃ¡m â€“ aplikacÃ­m, kterÃ© umÄ›le odhalujÃ­ obleÄenÃ­ na reÃ¡lnÃ½ch fotografiÃ­ch pomocÃ­ AI â€“, kterÃ© cÃ­lily na Å¡kolnÃ­ dÄ›ti, a donutil je stÃ¡hnout se z australskÃ©ho trhu.

NynÃ­ byl X oficiÃ¡lnÄ› kontaktovÃ¡n dopisem s poÅ¾adavkem na podrobnosti o ochrannÃ½ch mechanismusech Grok, jako jsou filtry obsahu, detekce promptÅ¯ nebo omezenÃ­ generovÃ¡nÃ­ citlivÃ½ch obrÃ¡zkÅ¯. Platformy jsou v souladu s prÅ¯myslovÃ½mi kodexy povinny brÃ¡nit Å¡Ã­Å™enÃ­ Å¡kodlivÃ©ho obsahu. Od 9. bÅ™ezna 2026 vstoupÃ­ v platnost novÃ© povinnÃ© kÃ³dy, kterÃ© AI sluÅ¾by donutÃ­ omezit pÅ™Ã­stup dÄ›tÃ­ k explicitnÃ­mu, nÃ¡silnÃ©mu materiÃ¡lu, obsahu o sebeubliÅ¾ovÃ¡nÃ­ nebo sebevraÅ¾dÃ¡ch. Tyto pravidla se tÃ½kajÃ­ nejen X, ale vÅ¡ech podobnÃ½ch platforem.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato situace odhaluje slabiny mÃ©nÄ› restriktivnÃ­ch AI modelÅ¯ jako Grok, kde snaha o otevÅ™enost vede k snadnÃ©mu zneuÅ¾itÃ­ pro tvorbu non-consensual intimate imagery (NCII), coÅ¾ ohroÅ¾uje soukromÃ­ a bezpeÄnost uÅ¾ivatelÅ¯, zejmÃ©na mladÃ½ch. Pro prÅ¯mysl znamenÃ¡ rostoucÃ­ globÃ¡lnÃ­ regulaÄnÃ­ tlak â€“ AustrÃ¡lie vede v prosazovÃ¡nÃ­ povinnÃ½ch bezpeÄnostnÃ­ch standardÅ¯, coÅ¾ ovlivnÃ­ xAI i jinÃ© firmy jako OpenAI nebo Meta. UÅ¾ivatelÃ© mohou oÄekÃ¡vat tvrdÅ¡Ã­ filtry, omezenÃ­ funkcÃ­ generovÃ¡nÃ­ obrÃ¡zkÅ¯ a vÄ›tÅ¡Ã­ odpovÄ›dnost platforem, coÅ¾ zpomalÃ­ inovace, ale zvÃ½Å¡Ã­ bezpeÄnost. V Å¡irÅ¡Ã­m kontextu AI ekosystÃ©mu to podtrhuje nutnost vyvÃ¡Å¾enÃ­ svobody a kontroly, protoÅ¾e bez regulacÃ­ hrozÃ­ eskalace k masivnÃ­mu Å¡Ã­Å™enÃ­ exploatativnÃ­ho obsahu.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://northern.starweekly.com.au/news/concerns-over-ai-safety/)

**Zdroj:** ğŸ“° Starweekly.com.au
