---
author: Marisa Aigen
category: bezpeÄnost ai
date: '2026-01-18 02:35:03'
description: AustralskÃ½ eSafety komisaÅ™ upozorÅˆuje na zneuÅ¾itÃ­ generativnÃ­ho systÃ©mu
  umÄ›lÃ© inteligence Grok na sociÃ¡lnÃ­ sÃ­ti X k tvorbÄ› sexualizovanÃ½ch nebo exploatativnÃ­ch
  obrÃ¡zkÅ¯ lidÃ­. Regulator poÅ¾aduje od X lepÅ¡Ã­ bezpeÄnostnÃ­ opatÅ™enÃ­ a pÅ™ipravuje se
  na pouÅ¾itÃ­ prÃ¡vnÃ­ch nÃ¡strojÅ¯.
importance: 4
layout: tech_news_article
original_title: Concerns over AI safety
publishedAt: '2026-01-18T02:35:03+00:00'
slug: concerns-over-ai-safety
source:
  emoji: ğŸ“°
  id: null
  name: Starweekly.com.au
title: Obavy z bezpeÄnosti umÄ›lÃ© inteligence
url: https://northern.starweekly.com.au/news/concerns-over-ai-safety/
urlToImage: https://northern.starweekly.com.au/wp-content/uploads/sites/5/2026/01/computer_519231_01.jpg
urlToImageBackup: https://northern.starweekly.com.au/wp-content/uploads/sites/5/2026/01/computer_519231_01.jpg
---

## Souhrn
AustralskÃ½ eSafety komisaÅ™ varuje pÅ™ed zneuÅ¾Ã­vÃ¡nÃ­m generativnÃ­ho systÃ©mu umÄ›lÃ© inteligence Grok na platformÄ› X k vÃ½robÄ› sexualizovanÃ½ch nebo vykoÅ™isÅ¥ujÃ­cÃ­ch obrÃ¡zkÅ¯. PoÄet stÃ­Å¾nostÃ­ sice zÅ¯stÃ¡vÃ¡ nÃ­zkÃ½, ale rychle roste, coÅ¾ vede k poÅ¾adavkÅ¯m na lepÅ¡Ã­ ochrany a moÅ¾nÃ© odstranÄ›nÃ­ obsahu podle Online Safety Act. NovÃ© regulace od bÅ™ezna 2026 zavÃ¡dÄ›jÃ­ pÅ™Ã­snÄ›jÅ¡Ã­ povinnosti pro AI sluÅ¾by.

## KlÃ­ÄovÃ© body
- eSafety komisaÅ™ zaznamenal pÅ™echod od nulovÃ½ch k nÄ›kolika stÃ­Å¾nostem za poslednÃ­ dva tÃ½dny tÃ½kajÃ­cÃ­m se Grok na X.
- X bylo kontaktovÃ¡no s Å¾Ã¡dostÃ­ o informace o bezpeÄnostnÃ­ch mechanismech proti zneuÅ¾itÃ­ Grok.
- Platformy musÃ­ podle australskÃ½ch kodexÅ¯ odstraÅˆovat materiÃ¡ly s dÄ›tskÃ½m sexuÃ¡lnÃ­m vykoÅ™isÅ¥ovÃ¡nÃ­m a nezÃ¡konnÃ½ obsah.
- NovÃ© povinnÃ© kÃ³dy od 9. bÅ™ezna 2026 omezÃ­ pÅ™Ã­stup dÄ›tÃ­ k sexuÃ¡lnÄ› explicitnÃ­mu, nÃ¡silnÃ©mu obsahu, sebevraÅ¾dÃ¡m a sebeubliÅ¾ovÃ¡nÃ­.
- Precedent: V roce 2025 byly nudify sluÅ¾by nuceny opustit AustrÃ¡lii po zneuÅ¾itÃ­ vÅ¯Äi Å¡kolnÃ­m dÄ›tem.

## Podrobnosti
Grok je generativnÃ­ systÃ©m umÄ›lÃ© inteligence vyvinutÃ½ spoleÄnostÃ­ xAI, kterÃ½ je integrovÃ¡n do sociÃ¡lnÃ­ sÃ­tÄ› X (dÅ™Ã­ve Twitter) a umoÅ¾Åˆuje uÅ¾ivatelÅ¯m generovat texty i obrÃ¡zky na zÃ¡kladÄ› textovÃ½ch popisÅ¯. Tento nÃ¡stroj, navrÅ¾enÃ½ pro kreativnÃ­ a informaÄnÃ­ ÃºÄely, se nynÃ­ stÃ¡vÃ¡ terÄem kritiky kvÅ¯li jeho potenciÃ¡lu k tvorbÄ› nevhodnÃ©ho obsahu, jako jsou sexualizovanÃ© nebo exploatativnÃ­ vyobrazenÃ­ lidÃ­, vÄetnÄ› moÅ¾nÃ©ho cÃ­lenÃ­ na dÄ›ti. AustralskÃ½ eSafety komisaÅ™, kterÃ½ dohlÃ­Å¾Ã­ na online bezpeÄnost, hlÃ¡sÃ­ nÃ¡rÅ¯st stÃ­Å¾nostÃ­ z prakticky nulovÃ½ch na nÄ›kolik za poslednÃ­ dva tÃ½dny, coÅ¾ signalizuje zaÄÃ¡tek systematickÃ©ho problÃ©mu.

RegulÃ¡tor pÅ™ipomÃ­nÃ¡, Å¾e platformy jako X jsou vÃ¡zÃ¡ny systÃ©movÃ½mi bezpeÄnostnÃ­mi povinnostmi podle australskÃ½ch prÅ¯myslovÃ½ch kodexÅ¯. Tyto pravidla vyÅ¾adujÃ­ proaktivnÃ­ detekci a odstranÄ›nÃ­ materiÃ¡lÅ¯ s dÄ›tskÃ½m sexuÃ¡lnÃ­m vykoÅ™isÅ¥ovÃ¡nÃ­m a jinÃ©ho nezÃ¡konnÃ©ho obsahu. V reakci na trend komisaÅ™ napsal pÅ™Ã­mo X s poptÃ¡vkou na detaily o existujÃ­cÃ­ch bezpeÄnostnÃ­ch opatÅ™enÃ­ch, kterÃ¡ majÃ­ brÃ¡nit zneuÅ¾itÃ­ Grok â€“ napÅ™Ã­klad filtry na vstupnÃ­ prompty, moderace vÃ½stupÅ¯ nebo omezenÃ­ pÅ™Ã­stupu. Pokud obsah pÅ™ekroÄÃ­ hranice Online Safety Act, regulator pouÅ¾ije prÃ¡vnÃ­ nÃ¡stroje vÄetnÄ› pÅ™Ã­kazÅ¯ k odstranÄ›nÃ­.

Tento pÅ™Ã­pad navazuje na pÅ™edchozÃ­ ÃºspÄ›Å¡nou kampaÅˆ z roku 2025, kdy byly sluÅ¾by typu nudify â€“ aplikace generujÃ­cÃ­ obnaÅ¾enÃ© obrÃ¡zky na zÃ¡kladÄ› fotografiÃ­ â€“ donuceny k odchodu z AustrÃ¡lie po zjiÅ¡tÄ›nÃ­, Å¾e cÃ­lily na Å¡kolnÃ­ dÄ›ti. LokÃ¡lnÃ­ rodiny a Å¡koly jsou varovÃ¡ny, aby byli obezÅ™etnÃ­ vÅ¯Äi X a podobnÃ½m platfÅ¯rmÃ¡m. VlÃ¡da oÄekÃ¡vÃ¡ okamÅ¾itÃ© proaktivnÃ­ kroky k prevenci Å¡Ã­Å™enÃ­ Å¡kodlivÃ©ho obsahu. Od 9. bÅ™ezna 2026 vstoupÃ­ v platnost novÃ© povinnÃ© kÃ³dy, kterÃ© AI sluÅ¾by donutÃ­ omezit pÅ™Ã­stup dÄ›tÃ­ k sexuÃ¡lnÄ› explicitnÃ­mu, nÃ¡silnÃ©mu materiÃ¡lu, stejnÄ› jako obsahu podporujÃ­cÃ­mu sebeubliÅ¾ovÃ¡nÃ­ nebo sebevraÅ¾dy. X jiÅ¾ dÅ™Ã­ve Äelilo transparentnÃ­m upozornÄ›nÃ­m.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato situace odhaluje slabinu generativnÃ­ch AI modelÅ¯ jako Grok v boji proti zneuÅ¾itÃ­, kde uÅ¾ivatelÃ© snadno obejdou bezpeÄnostnÃ­ filtry prompty jako 'vytvoÅ™ obrÃ¡zek celebritky v bikini'. Pro prÅ¯mysl znamenÃ¡ rostoucÃ­ regulaÄnÃ­ tlak â€“ AustrÃ¡lie vede v prosazovÃ¡nÃ­ povinnÃ½ch bezpeÄnostnÃ­ch standardÅ¯, coÅ¾ ovlivnÃ­ globÃ¡lnÃ­ platformy jako X. Pro uÅ¾ivatele to podtrhuje rizika volnÄ› dostupnÃ½ch AI nÃ¡strojÅ¯, kde nÃ­zkÃ½ objem stÃ­Å¾nostÃ­ mÅ¯Å¾e rychle eskalovat do Å¡irÅ¡Ã­ krize, podobnÄ› jako u deepfake pornografie. V Å¡irÅ¡Ã­m kontextu posiluje debatu o etice AI, kde xAI (zaloÅ¾enÃ¡ Elonem Muskem k vÃ½voji bezpeÄnÃ©ho AGI) musÃ­ prokÃ¡zat, Å¾e jejÃ­ modely nejsou jen vÃ½konnÄ›jÅ¡Ã­, ale i bezpeÄnÄ›jÅ¡Ã­ neÅ¾ konkurence jako OpenAI nebo Google.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://northern.starweekly.com.au/news/concerns-over-ai-safety/)

**Zdroj:** ğŸ“° Starweekly.com.au
