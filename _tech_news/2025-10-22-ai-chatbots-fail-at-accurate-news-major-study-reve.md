---
category: ai chatboti
companies:
- OpenAI
- Microsoft
date: '2025-10-22 10:12:46'
description: Studie 22 veřejnoprávních médií včetně DW odhalila, že AI asistenti jako
  ChatGPT a Copilot zkreslují zpravodajský obsah v 45 % případů a mají problémy s
  rozlišením faktů od názorů.
importance: 4
layout: tech_news_article
original_title: AI chatbots fail at accurate news, major study reveals - DW
publishedAt: '2025-10-22T10:12:46+00:00'
slug: ai-chatbots-fail-at-accurate-news-major-study-reve
source:
  emoji: 📰
  id: null
  name: DW (English)
title: AI chatboti selhávají při zprostředkování zpráv, ukazuje rozsáhlá studie
url: https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921
urlToImage: https://static.dw.com/image/74390458_6.jpg
urlToImageBackup: https://static.dw.com/image/74390458_6.jpg
---

## Souhrn

Rozsáhlá mezinárodní studie zahrnující 22 veřejnoprávních médií prokázala, že čtyři nejpoužívanější AI chatboti poskytují nepřesné nebo zkreslené informace ve 45 % případů při zprostředkování zpravodajského obsahu. Výzkum testoval ChatGPT, Microsoft Copilot, Google Gemini a Perplexity AI napříč různými jazyky a regiony s alarmujícími výsledky.

## Klíčové body

- 45 % odpovědí AI asistentů obsahovalo alespoň jeden významný problém při zprostředkování zpravodajského obsahu
- 31 % odpovědí mělo vážné problémy se zdrojováním informací
- 20 % odpovědí obsahovalo zásadní faktické chyby
- Německá DW zaznamenala problémy u 53 % odpovědí, přičemž 29 % mělo specifické problémy s přesností
- Podle Reuters Institute Digital News Report 2025 využívá AI chatboty pro zprávy 7 % online konzumentů zpravodajství, u uživatelů mladších 25 let to je 15 %

## Podrobnosti

Novinářské týmy z veřejnoprávních médií včetně BBC, NPR a německé DW systematicky testovaly odpovědi čtyř hlavních AI asistentů podle několika kritérií: přesnost informací, správné uvádění zdrojů, poskytování kontextu, schopnost vhodně editorizovat a rozlišovat fakta od názorů.

Výsledky jsou znepokojivé zejména proto, že problémy se objevovaly konzistentně bez ohledu na jazyk nebo geografickou oblast. Studie tak vyvrací představu, že jde o izolované incidenty nebo problémy specifické pro určité jazykové mutace.

Konkrétní příklady chyb z testování DW zahrnují označení Olafa Scholze za německého kancléře měsíc poté, co byl kancléřem jmenován Friedrich Merz. Jiný případ uvedl Jense Stoltenberga jako generálního tajemníka NATO i po nástupu Marka Rutteho do této funkce. Tyto chyby ukazují na zásadní problém s aktuálností informací, které AI modely poskytují.

Problémy se zdrojováním se projevovaly v téměř třetině případů, což znamená, že AI asistenti buď neuváděli zdroje vůbec, odkazovali na neexistující nebo nesprávné zdroje, nebo nedokázali rozlišit důvěryhodné zdroje od nedůvěryhodných.

Studie přichází v době, kdy se AI chatboti stávají stále populárnějším způsobem přístupu k informacím, zejména mezi mladšími uživateli. Každý sedmý uživatel mladší 25 let již využívá AI asistenty jako zdroj zpravodajství, což činí zjištění studie ještě relevantnějšími.

## Proč je to důležité

Tato studie představuje první rozsáhlý systematický výzkum spolehlivosti AI chatbotů při zprostředkování zpravodajského obsahu. Zapojení 22 renomovaných veřejnoprávních médií z různých zemí dává výsledkům značnou váhu a důvěryhodnost.

Zjištění mají zásadní dopady pro rostoucí počet lidí, kteří se spoléhají na AI asistenty jako na zdroj informací o aktuálním dění. Míra chybovosti 45 % je alarmující zejména v kontextu dezinformací a potřeby spolehlivých zpravodajských zdrojů.

Pro vývojáře velkých jazykových modelů jako OpenAI, Microsoft, Google a Perplexity AI představuje studie výzvu k zásadnímu zlepšení přesnosti a spolehlivosti jejich systémů při práci se zpravodajským obsahem. Ukazuje také limity současných AI technologií v oblasti, kde je faktická přesnost a aktuálnost informací kritická.

Výsledky by měly vést k opatrnějšímu přístupu uživatelů k informacím z AI chatbotů a k nutnosti ověřování údajů z primárních zdrojů, zejména u aktuálního zpravodajství a politických událostí.

---

[Číst původní článek](https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921)

**Zdroj:** 📰 DW (English)
