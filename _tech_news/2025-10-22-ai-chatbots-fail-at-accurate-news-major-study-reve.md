---
category: ai chatboti
companies:
- OpenAI
- Microsoft
date: '2025-10-22 10:12:46'
description: Studie 22 veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ vÄetnÄ› DW odhalila, Å¾e AI asistenti jako
  ChatGPT a Copilot zkreslujÃ­ zpravodajskÃ½ obsah v 45 % pÅ™Ã­padÅ¯ a majÃ­ problÃ©my s
  rozliÅ¡enÃ­m faktÅ¯ od nÃ¡zorÅ¯.
importance: 4
layout: tech_news_article
original_title: AI chatbots fail at accurate news, major study reveals - DW
publishedAt: '2025-10-22T10:12:46+00:00'
slug: ai-chatbots-fail-at-accurate-news-major-study-reve
source:
  emoji: ğŸ“°
  id: null
  name: DW (English)
title: AI chatboti selhÃ¡vajÃ­ pÅ™i zprostÅ™edkovÃ¡nÃ­ zprÃ¡v, ukazuje rozsÃ¡hlÃ¡ studie
url: https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921
urlToImage: https://static.dw.com/image/74390458_6.jpg
urlToImageBackup: https://static.dw.com/image/74390458_6.jpg
---

## Souhrn

RozsÃ¡hlÃ¡ mezinÃ¡rodnÃ­ studie zahrnujÃ­cÃ­ 22 veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ prokÃ¡zala, Å¾e ÄtyÅ™i nejpouÅ¾Ã­vanÄ›jÅ¡Ã­ AI chatboti poskytujÃ­ nepÅ™esnÃ© nebo zkreslenÃ© informace ve 45 % pÅ™Ã­padÅ¯ pÅ™i zprostÅ™edkovÃ¡nÃ­ zpravodajskÃ©ho obsahu. VÃ½zkum testoval ChatGPT, Microsoft Copilot, Google Gemini a Perplexity AI napÅ™Ã­Ä rÅ¯znÃ½mi jazyky a regiony s alarmujÃ­cÃ­mi vÃ½sledky.

## KlÃ­ÄovÃ© body

- 45 % odpovÄ›dÃ­ AI asistentÅ¯ obsahovalo alespoÅˆ jeden vÃ½znamnÃ½ problÃ©m pÅ™i zprostÅ™edkovÃ¡nÃ­ zpravodajskÃ©ho obsahu
- 31 % odpovÄ›dÃ­ mÄ›lo vÃ¡Å¾nÃ© problÃ©my se zdrojovÃ¡nÃ­m informacÃ­
- 20 % odpovÄ›dÃ­ obsahovalo zÃ¡sadnÃ­ faktickÃ© chyby
- NÄ›meckÃ¡ DW zaznamenala problÃ©my u 53 % odpovÄ›dÃ­, pÅ™iÄemÅ¾ 29 % mÄ›lo specifickÃ© problÃ©my s pÅ™esnostÃ­
- Podle Reuters Institute Digital News Report 2025 vyuÅ¾Ã­vÃ¡ AI chatboty pro zprÃ¡vy 7 % online konzumentÅ¯ zpravodajstvÃ­, u uÅ¾ivatelÅ¯ mladÅ¡Ã­ch 25 let to je 15 %

## Podrobnosti

NovinÃ¡Å™skÃ© tÃ½my z veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ vÄetnÄ› BBC, NPR a nÄ›meckÃ© DW systematicky testovaly odpovÄ›di ÄtyÅ™ hlavnÃ­ch AI asistentÅ¯ podle nÄ›kolika kritÃ©riÃ­: pÅ™esnost informacÃ­, sprÃ¡vnÃ© uvÃ¡dÄ›nÃ­ zdrojÅ¯, poskytovÃ¡nÃ­ kontextu, schopnost vhodnÄ› editorizovat a rozliÅ¡ovat fakta od nÃ¡zorÅ¯.

VÃ½sledky jsou znepokojivÃ© zejmÃ©na proto, Å¾e problÃ©my se objevovaly konzistentnÄ› bez ohledu na jazyk nebo geografickou oblast. Studie tak vyvracÃ­ pÅ™edstavu, Å¾e jde o izolovanÃ© incidenty nebo problÃ©my specifickÃ© pro urÄitÃ© jazykovÃ© mutace.

KonkrÃ©tnÃ­ pÅ™Ã­klady chyb z testovÃ¡nÃ­ DW zahrnujÃ­ oznaÄenÃ­ Olafa Scholze za nÄ›meckÃ©ho kanclÃ©Å™e mÄ›sÃ­c potÃ©, co byl kanclÃ©Å™em jmenovÃ¡n Friedrich Merz. JinÃ½ pÅ™Ã­pad uvedl Jense Stoltenberga jako generÃ¡lnÃ­ho tajemnÃ­ka NATO i po nÃ¡stupu Marka Rutteho do tÃ©to funkce. Tyto chyby ukazujÃ­ na zÃ¡sadnÃ­ problÃ©m s aktuÃ¡lnostÃ­ informacÃ­, kterÃ© AI modely poskytujÃ­.

ProblÃ©my se zdrojovÃ¡nÃ­m se projevovaly v tÃ©mÄ›Å™ tÅ™etinÄ› pÅ™Ã­padÅ¯, coÅ¾ znamenÃ¡, Å¾e AI asistenti buÄ neuvÃ¡dÄ›li zdroje vÅ¯bec, odkazovali na neexistujÃ­cÃ­ nebo nesprÃ¡vnÃ© zdroje, nebo nedokÃ¡zali rozliÅ¡it dÅ¯vÄ›ryhodnÃ© zdroje od nedÅ¯vÄ›ryhodnÃ½ch.

Studie pÅ™ichÃ¡zÃ­ v dobÄ›, kdy se AI chatboti stÃ¡vajÃ­ stÃ¡le populÃ¡rnÄ›jÅ¡Ã­m zpÅ¯sobem pÅ™Ã­stupu k informacÃ­m, zejmÃ©na mezi mladÅ¡Ã­mi uÅ¾ivateli. KaÅ¾dÃ½ sedmÃ½ uÅ¾ivatel mladÅ¡Ã­ 25 let jiÅ¾ vyuÅ¾Ã­vÃ¡ AI asistenty jako zdroj zpravodajstvÃ­, coÅ¾ ÄinÃ­ zjiÅ¡tÄ›nÃ­ studie jeÅ¡tÄ› relevantnÄ›jÅ¡Ã­mi.

## ProÄ je to dÅ¯leÅ¾itÃ©

Tato studie pÅ™edstavuje prvnÃ­ rozsÃ¡hlÃ½ systematickÃ½ vÃ½zkum spolehlivosti AI chatbotÅ¯ pÅ™i zprostÅ™edkovÃ¡nÃ­ zpravodajskÃ©ho obsahu. ZapojenÃ­ 22 renomovanÃ½ch veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ z rÅ¯znÃ½ch zemÃ­ dÃ¡vÃ¡ vÃ½sledkÅ¯m znaÄnou vÃ¡hu a dÅ¯vÄ›ryhodnost.

ZjiÅ¡tÄ›nÃ­ majÃ­ zÃ¡sadnÃ­ dopady pro rostoucÃ­ poÄet lidÃ­, kteÅ™Ã­ se spolÃ©hajÃ­ na AI asistenty jako na zdroj informacÃ­ o aktuÃ¡lnÃ­m dÄ›nÃ­. MÃ­ra chybovosti 45 % je alarmujÃ­cÃ­ zejmÃ©na v kontextu dezinformacÃ­ a potÅ™eby spolehlivÃ½ch zpravodajskÃ½ch zdrojÅ¯.

Pro vÃ½vojÃ¡Å™e velkÃ½ch jazykovÃ½ch modelÅ¯ jako OpenAI, Microsoft, Google a Perplexity AI pÅ™edstavuje studie vÃ½zvu k zÃ¡sadnÃ­mu zlepÅ¡enÃ­ pÅ™esnosti a spolehlivosti jejich systÃ©mÅ¯ pÅ™i prÃ¡ci se zpravodajskÃ½m obsahem. Ukazuje takÃ© limity souÄasnÃ½ch AI technologiÃ­ v oblasti, kde je faktickÃ¡ pÅ™esnost a aktuÃ¡lnost informacÃ­ kritickÃ¡.

VÃ½sledky by mÄ›ly vÃ©st k opatrnÄ›jÅ¡Ã­mu pÅ™Ã­stupu uÅ¾ivatelÅ¯ k informacÃ­m z AI chatbotÅ¯ a k nutnosti ovÄ›Å™ovÃ¡nÃ­ ÃºdajÅ¯ z primÃ¡rnÃ­ch zdrojÅ¯, zejmÃ©na u aktuÃ¡lnÃ­ho zpravodajstvÃ­ a politickÃ½ch udÃ¡lostÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921)

**Zdroj:** ğŸ“° DW (English)
