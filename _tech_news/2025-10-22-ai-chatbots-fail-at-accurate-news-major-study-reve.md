---
category: ai chatboti
companies:
- OpenAI
- Microsoft
date: '2025-10-22 10:12:46'
description: Studie 22 veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ vÄetnÄ› DW odhalila, Å¾e AI asistenti jako
  ChatGPT a Copilot zkreslujÃ­ zpravodajskÃ½ obsah v 45 % pÅ™Ã­padÅ¯ a nedokÃ¡Å¾Ã­ rozliÅ¡it
  fakta od nÃ¡zorÅ¯.
importance: 4
layout: tech_news_article
original_title: AI chatbots fail at accurate news, major study reveals - DW
publishedAt: '2025-10-22T10:12:46+00:00'
slug: ai-chatbots-fail-at-accurate-news-major-study-reve
source:
  emoji: ğŸ“°
  id: null
  name: DW (English)
title: AI chatboti selhÃ¡vajÃ­ pÅ™i zprostÅ™edkovÃ¡nÃ­ zprÃ¡v, ukazuje rozsÃ¡hlÃ¡ studie
url: https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921
urlToImage: https://static.dw.com/image/74390458_6.jpg
urlToImageBackup: https://static.dw.com/image/74390458_6.jpg
---

## Souhrn

RozsÃ¡hlÃ¡ mezinÃ¡rodnÃ­ studie zahrnujÃ­cÃ­ 22 veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­, vÄetnÄ› nÄ›meckÃ© DW, zjistila, Å¾e ÄtyÅ™i nejpouÅ¾Ã­vanÄ›jÅ¡Ã­ AI chatboti poskytujÃ­ nepÅ™esnÃ© nebo zkreslenÃ© informace ve 45 % pÅ™Ã­padÅ¯ pÅ™i zprostÅ™edkovÃ¡nÃ­ zpravodajskÃ©ho obsahu. ProblÃ©my se objevujÃ­ napÅ™Ã­Ä jazyky i regiony a tÃ½kajÃ­ se faktickÃ½ch chyb, problÃ©mÅ¯ se zdroji i neschopnosti rozliÅ¡it fakta od nÃ¡zorÅ¯.

## KlÃ­ÄovÃ© body

- ÄŒtyÅ™i testovanÃ© AI asistenty (ChatGPT, Microsoft Copilot, Google Gemini a Perplexity AI) zkreslujÃ­ zpravodajskÃ½ obsah v 45 % odpovÄ›dÃ­
- 31 % odpovÄ›dÃ­ obsahovalo vÃ¡Å¾nÃ© problÃ©my se zdroji informacÃ­, 20 % mÄ›lo zÃ¡vaÅ¾nÃ© faktickÃ© chyby
- DW zaznamenala problÃ©my v 53 % odpovÄ›dÃ­, pÅ™iÄemÅ¾ 29 % mÄ›lo konkrÃ©tnÃ­ problÃ©my s pÅ™esnostÃ­
- Mezi chybami bylo napÅ™Ã­klad oznaÄenÃ­ Olafa Scholze za kanclÃ©Å™e mÄ›sÃ­c potÃ©, co se jÃ­m stal Friedrich Merz
- Podle Reuters Institute pouÅ¾Ã­vÃ¡ AI chatboty k zÃ­skÃ¡vÃ¡nÃ­ zprÃ¡v 7 % online ÄtenÃ¡Å™Å¯, u uÅ¾ivatelÅ¯ mladÅ¡Ã­ch 25 let to je 15 %

## Podrobnosti

NovinÃ¡Å™skÃ© tÃ½my z veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­, vÄetnÄ› BBC a NPR, systematicky vyhodnocovaly odpovÄ›di ÄtyÅ™ hlavnÃ­ch AI asistentÅ¯ podle kritÃ©riÃ­ jako pÅ™esnost, uvÃ¡dÄ›nÃ­ zdrojÅ¯, poskytovÃ¡nÃ­ kontextu, schopnost vhodnÄ› editorizovat a rozliÅ¡ovat fakta od nÃ¡zorÅ¯. VÃ½sledky ukazujÃ­, Å¾e tÃ©mÄ›Å™ polovina vÅ¡ech odpovÄ›dÃ­ mÄ›la alespoÅˆ jeden vÃ½znamnÃ½ problÃ©m.

NÄ›meckÃ¡ DW zaznamenala jeÅ¡tÄ› horÅ¡Ã­ vÃ½sledky neÅ¾ prÅ¯mÄ›r studie - problÃ©my se objevily v 53 % odpovÄ›dÃ­. Mezi konkrÃ©tnÃ­mi chybami bylo napÅ™Ã­klad tvrzenÃ­, Å¾e Olaf Scholz je nÄ›meckÃ½m kanclÃ©Å™em, pÅ™estoÅ¾e tuto pozici mÄ›sÃ­c pÅ™edtÃ­m pÅ™evzal Friedrich Merz. JinÃ½ pÅ™Ã­pad zahrnoval oznaÄenÃ­ Jense Stoltenberga za generÃ¡lnÃ­ho tajemnÃ­ka NATO potÃ©, co ho jiÅ¾ nahradil Mark Rutte.

Studie se zamÄ›Å™ila na ÄtyÅ™i nejpouÅ¾Ã­vanÄ›jÅ¡Ã­ AI asistenty - ChatGPT od OpenAI, Microsoft Copilot, Google Gemini a Perplexity AI. VÅ¡echny tyto nÃ¡stroje se stÃ¡vajÃ­ stÃ¡le populÃ¡rnÄ›jÅ¡Ã­mi zpÅ¯soby, jak lidÃ© pÅ™istupujÃ­ k informacÃ­m a zpravodajstvÃ­. Podle Digital News Report 2025 od Reuters Institute vyuÅ¾Ã­vÃ¡ AI chatboty k zÃ­skÃ¡vÃ¡nÃ­ zprÃ¡v 7 % online ÄtenÃ¡Å™Å¯, pÅ™iÄemÅ¾ u mladÅ¡Ã­ch uÅ¾ivatelÅ¯ do 25 let tento podÃ­l stoupÃ¡ na 15 %.

AutoÅ™i studie zdÅ¯razÅˆujÃ­, Å¾e zjiÅ¡tÄ›nÃ­ potvrzujÃ­ systematickÃ© zkreslovÃ¡nÃ­ zpravodajskÃ©ho obsahu vÅ¡eho druhu ze strany AI asistentÅ¯. Nejde tedy o izolovanÃ© incidenty, ale o strukturÃ¡lnÃ­ problÃ©m tÄ›chto technologiÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©

Studie pÅ™ichÃ¡zÃ­ v dobÄ›, kdy AI chatboti zÃ­skÃ¡vajÃ­ stÃ¡le vÄ›tÅ¡Ã­ podÃ­l na zprostÅ™edkovÃ¡nÃ­ informacÃ­, zejmÃ©na mezi mladÅ¡Ã­mi uÅ¾ivateli. ZjiÅ¡tÄ›nÃ­, Å¾e tÃ©mÄ›Å™ polovina odpovÄ›dÃ­ obsahuje vÃ½znamnÃ© problÃ©my, vyvolÃ¡vÃ¡ vÃ¡Å¾nÃ© otÃ¡zky ohlednÄ› spolehlivosti tÄ›chto nÃ¡strojÅ¯ jako zdrojÅ¯ zpravodajstvÃ­.

ProblÃ©my s pÅ™esnostÃ­ a uvÃ¡dÄ›nÃ­ zdrojÅ¯ jsou obzvlÃ¡Å¡tÄ› znepokojivÃ© v kontextu dezinformacÃ­ a dÅ¯vÄ›ry v mÃ©dia. Pokud AI asistenti nedokÃ¡Å¾Ã­ sprÃ¡vnÄ› rozliÅ¡it fakta od nÃ¡zorÅ¯ nebo aktuÃ¡lnÃ­ informace od zastaralÃ½ch, mohou pÅ™ispÃ­vat k Å¡Ã­Å™enÃ­ nepÅ™esnÃ½ch informacÃ­ ve velkÃ©m mÄ›Å™Ã­tku.

Pro technologickÃ© spoleÄnosti vyvÃ­jejÃ­cÃ­ tyto nÃ¡stroje pÅ™edstavuje studie vÃ½zvu k zÃ¡sadnÃ­mu zlepÅ¡enÃ­ spolehlivosti pÅ™i zpracovÃ¡nÃ­ zpravodajskÃ©ho obsahu. Pro uÅ¾ivatele je to varovÃ¡nÃ­, Å¾e AI chatboty nelze povaÅ¾ovat za dÅ¯vÄ›ryhodnÃ½ primÃ¡rnÃ­ zdroj aktuÃ¡lnÃ­ch informacÃ­ a je nutnÃ© ovÄ›Å™ovat Ãºdaje z vÃ­ce zdrojÅ¯.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921)

**Zdroj:** ğŸ“° DW (English)
