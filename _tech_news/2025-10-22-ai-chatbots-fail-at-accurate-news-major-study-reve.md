---
category: ai chatboti
companies:
- OpenAI
- Microsoft
date: '2025-10-22 10:12:46'
description: Studie 22 mezinÃ¡rodnÃ­ch veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ vÄetnÄ› DW odhalila, Å¾e
  AI chatboti jako ChatGPT a Copilot zkreslujÃ­ zpravodajskÃ½ obsah v 45 % pÅ™Ã­padÅ¯ a
  nedokÃ¡Å¾Ã­ rozliÅ¡it fakta od nÃ¡zorÅ¯.
importance: 4
layout: tech_news_article
original_title: AI chatbots fail at accurate news, major study reveals - DW
publishedAt: '2025-10-22T10:12:46+00:00'
slug: ai-chatbots-fail-at-accurate-news-major-study-reve
source:
  emoji: ğŸ“°
  id: null
  name: DW (English)
title: AI chatboti selhÃ¡vajÃ­ pÅ™i zpracovÃ¡nÃ­ zprÃ¡v, ukazuje rozsÃ¡hlÃ¡ studie
url: https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921
urlToImage: https://static.dw.com/image/74390458_6.jpg
urlToImageBackup: https://static.dw.com/image/74390458_6.jpg
---

## Souhrn

RozsÃ¡hlÃ¡ studie zahrnujÃ­cÃ­ 22 veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ z celÃ©ho svÄ›ta prokÃ¡zala, Å¾e ÄtyÅ™i nejpouÅ¾Ã­vanÄ›jÅ¡Ã­ AI asistenti poskytujÃ­ nepÅ™esnÃ© nebo zkreslenÃ© informace ve 45 % pÅ™Ã­padÅ¯ pÅ™i odpovÃ­dÃ¡nÃ­ na otÃ¡zky tÃ½kajÃ­cÃ­ se zpravodajstvÃ­. VÃ½zkum testoval ChatGPT, Microsoft Copilot, Google Gemini a Perplexity AI a odhalil zÃ¡vaÅ¾nÃ© problÃ©my s pÅ™esnostÃ­, zdrojovÃ¡nÃ­m a schopnostÃ­ rozliÅ¡it fakta od nÃ¡zorÅ¯.

## KlÃ­ÄovÃ© body

- AI chatboti zkreslujÃ­ zpravodajskÃ½ obsah v 45 % pÅ™Ã­padÅ¯ bez ohledu na jazyk Äi region
- 31 % odpovÄ›dÃ­ obsahovalo vÃ¡Å¾nÃ© problÃ©my se zdrojovÃ¡nÃ­m informacÃ­
- 20 % odpovÄ›dÃ­ obsahovalo zÃ¡vaÅ¾nÃ© faktickÃ© chyby
- U nÄ›meckÃ©ho vysÃ­latele DW mÄ›lo 53 % odpovÄ›dÃ­ vÃ½znamnÃ© problÃ©my, pÅ™iÄemÅ¾ 29 % trpÄ›lo konkrÃ©tnÃ­mi chybami v pÅ™esnosti
- 7 % uÅ¾ivatelÅ¯ online zpravodajstvÃ­ pouÅ¾Ã­vÃ¡ AI chatboty k zÃ­skÃ¡vÃ¡nÃ­ zprÃ¡v, u uÅ¾ivatelÅ¯ mladÅ¡Ã­ch 25 let je to 15 %

## Podrobnosti

NovinÃ¡Å™skÃ© tÃ½my z veÅ™ejnoprÃ¡vnÃ­ch mÃ©diÃ­ vÄetnÄ› BBC, NPR a DW systematicky testovaly odpovÄ›di ÄtyÅ™ hlavnÃ­ch AI asistentÅ¯ na otÃ¡zky tÃ½kajÃ­cÃ­ se aktuÃ¡lnÃ­ho zpravodajstvÃ­. HodnotÃ­cÃ­ kritÃ©ria zahrnovala pÅ™esnost informacÃ­, kvalitu zdrojovÃ¡nÃ­, poskytovÃ¡nÃ­ kontextu, schopnost vhodnÄ› editorizovat a rozliÅ¡ovat fakta od nÃ¡zorÅ¯.

VÃ½sledky jsou alarmujÃ­cÃ­ zejmÃ©na proto, Å¾e AI chatboti se stÃ¡vajÃ­ stÃ¡le populÃ¡rnÄ›jÅ¡Ã­m zdrojem informacÃ­. Podle Digital News Report 2025 od Reuters Institute vyuÅ¾Ã­vÃ¡ tyto nÃ¡stroje jiÅ¾ 7 % konzumentÅ¯ online zpravodajstvÃ­, pÅ™iÄemÅ¾ u mladÅ¡Ã­ generace do 25 let dosahuje toto ÄÃ­slo 15 %.

KonkrÃ©tnÃ­ pÅ™Ã­klady chyb odhalenÃ½ch v rÃ¡mci studie DW zahrnujÃ­ oznaÄenÃ­ Olafa Scholze za nÄ›meckÃ©ho kanclÃ©Å™e mÄ›sÃ­c potÃ©, co byl do funkce jmenovÃ¡n Friedrich Merz. DalÅ¡Ã­ chyba spoÄÃ­vala v uvedenÃ­ Jense Stoltenberga jako generÃ¡lnÃ­ho tajemnÃ­ka NATO, aÄkoliv tuto pozici jiÅ¾ pÅ™evzal Mark Rutte.

Studie prokÃ¡zala, Å¾e problÃ©my nejsou izolovanÃ© incidenty ani zÃ¡vislÃ© na konkrÃ©tnÃ­m modelu, jazyku nebo geografickÃ© oblasti. SystematickÃ© zkreslovÃ¡nÃ­ zpravodajskÃ©ho obsahu se projevuje napÅ™Ã­Ä vÅ¡emi testovanÃ½mi platformami. KromÄ› faktickÃ½ch chyb mÄ›ly AI asistenti potÃ­Å¾e s korektnÃ­m citovÃ¡nÃ­m zdrojÅ¯ â€“ 31 % odpovÄ›dÃ­ obsahovalo vÃ¡Å¾nÃ© nedostatky v tÃ©to oblasti.

ZvlÃ¡Å¡tÄ› problematickÃ¡ je neschopnost tÄ›chto nÃ¡strojÅ¯ rozliÅ¡it mezi objektivnÃ­mi fakty a subjektivnÃ­mi nÃ¡zory, coÅ¾ je zÃ¡kladnÃ­ dovednost kvalitnÃ­ho Å¾urnalismu. Tato slabina mÅ¯Å¾e vÃ©st k Å¡Ã­Å™enÃ­ dezinformacÃ­ a zkreslovÃ¡nÃ­ veÅ™ejnÃ©ho diskurzu.

## ProÄ je to dÅ¯leÅ¾itÃ©

Tato studie pÅ™ichÃ¡zÃ­ v kritickÃ©m okamÅ¾iku, kdy se AI chatboti stÃ¡vajÃ­ bÄ›Å¾nÃ½m nÃ¡strojem pro vyhledÃ¡vÃ¡nÃ­ informacÃ­, zejmÃ©na mezi mladÅ¡Ã­mi uÅ¾ivateli. ZjiÅ¡tÄ›nÃ­ mÃ¡ zÃ¡sadnÃ­ dopady na dÅ¯vÄ›ryhodnost informacÃ­ v digitÃ¡lnÃ­m vÄ›ku a ukazuje na nebezpeÄÃ­ spolÃ©hÃ¡nÃ­ se na AI asistenty jako primÃ¡rnÃ­ zdroj zpravodajstvÃ­.

Pro technologickÃ© spoleÄnosti jako OpenAI, Microsoft a Google pÅ™edstavujÃ­ vÃ½sledky vÃ½zvu k zÃ¡sadnÃ­mu zlepÅ¡enÃ­ pÅ™esnosti a spolehlivosti jejich AI modelÅ¯. SouÄasnÄ› studie zdÅ¯razÅˆuje pokraÄujÃ­cÃ­ vÃ½znam profesionÃ¡lnÃ­ho Å¾urnalismu a ovÄ›Å™enÃ½ch zpravodajskÃ½ch zdrojÅ¯.

Z hlediska regulace mÅ¯Å¾e vÃ½zkum posÃ­lit argumenty pro pÅ™Ã­snÄ›jÅ¡Ã­ dohled nad AI nÃ¡stroji pouÅ¾Ã­vanÃ½mi k Å¡Ã­Å™enÃ­ informacÃ­. UÅ¾ivatelÃ© by si mÄ›li bÃ½t vÄ›domi omezenÃ­ tÄ›chto technologiÃ­ a kriticky pÅ™istupovat k informacÃ­m z AI chatbotÅ¯, zejmÃ©na pokud jde o aktuÃ¡lnÃ­ udÃ¡losti a zpravodajstvÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.dw.com/en/artificial-intelligence-ai-chatbot-chatgpt-google-news-misinformation-fact-check-copilot/a-74392921)

**Zdroj:** ğŸ“° DW (English)
