---
author: Marisa Aigen
category: ai bezpeÄnost
date: '2026-01-12 20:15:32'
description: Projekt Poison Fountain mÃ¡ oklamat webovÃ© crawlery technologickÃ½ch firem,
  aby nasÃ¡ly otrÃ¡venÃ¡ trÃ©ninkovÃ¡ data, kterÃ¡ naruÅ¡Ã­ modely umÄ›lÃ© inteligence. Jeho
  autoÅ™i, kteÅ™Ã­ pracujÃ­ pro velkÃ© americkÃ© AI spoleÄnosti, chtÄ›jÃ­ tÃ­m zpÅ¯sobit Å¡kody
  systÃ©mÅ¯m strojovÃ© inteligence.
importance: 4
layout: tech_news_article
original_title: Engineers Deploy â€œPoison Fountainâ€ That Scrambles Brains of AI Systems
publishedAt: '2026-01-12T20:15:32+00:00'
slug: engineers-deploy-poison-fountain-that-scrambles-br
source:
  emoji: ğŸ“°
  id: null
  name: Futurism
title: InÅ¾enÃ½Å™i nasadili â€Poison Fountainâ€œ, kterÃ½ rozhazuje fungovÃ¡nÃ­ systÃ©mÅ¯ umÄ›lÃ©
  inteligence
url: http://futurism.com/artificial-intelligence/poison-fountain-ai
urlToImage: https://futurism.com/wp-content/uploads/2026/01/poison-fountain-ai_37f3fb.jpg?w=1200
urlToImageBackup: https://futurism.com/wp-content/uploads/2026/01/poison-fountain-ai_37f3fb.jpg?w=1200
---

## Souhrn
Projekt Poison Fountain, spuÅ¡tÄ›nÃ½ minulÃ½ tÃ½den, umoÅ¾Åˆuje otrÃ¡vit trÃ©ninkovÃ¡ data pro modely umÄ›lÃ© inteligence tÃ­m, Å¾e webovÃ© crawlery velkÃ½ch firem nasajÃ­ zÃ¡mÄ›rnÄ› poÅ¡kozenÃ© informace z webu. AutoÅ™i projektu, kteÅ™Ã­ podle zdrojÅ¯ pracujÃ­ pro pÅ™ednÃ­ americkÃ© AI spoleÄnosti, se odvolÃ¡vajÃ­ na varovÃ¡nÃ­ Geoffreye Hintona a cÃ­lÃ­ na sabotÃ¡Å¾ AI systÃ©mÅ¯. Tento pÅ™Ã­stup by mohl v teoretickÃ© rovinÄ› vÃ½raznÄ› zkomplikovat trÃ©nink velkÃ½ch modelÅ¯.

## KlÃ­ÄovÃ© body
- Projekt Poison Fountain trikujÃ­ webovÃ© crawlery, aby sbÃ­raly otrÃ¡venÃ¡ data z webovÃ½ch strÃ¡nek, coÅ¾ vede k chybÃ¡m v trÃ©ninku AI modelÅ¯.
- Zapojeni jsou inÅ¾enÃ½Å™i z velkÃ½ch americkÃ½ch AI firem, coÅ¾ eskaluje internÃ­ konflikt v oboru.
- Odkaz na Geoffreye Hintona, kterÃ½ varuje pÅ™ed hrozbou strojovÃ© inteligence pro lidstvo.
- Souvislost s etickÃ½mi a prÃ¡vnÃ­mi problÃ©my sbÄ›ru dat z internetu, vÄetnÄ› soudnÃ­ch sporÅ¯ o autorskÃ¡ prÃ¡va.
- CÃ­lem je naruÅ¡it zÃ¡vislost AI na masivnÃ­ch datech z webu.

## Podrobnosti
Projekt Poison Fountain pÅ™edstavuje nÃ¡stroj urÄenÃ½ k distribuci zÃ¡mÄ›rnÄ› poÅ¡kozenÃ½ch dat na webovÃ½ch strÃ¡nkÃ¡ch, kterÃ© pak automatizovanÃ© webovÃ© crawlery â€“ programy slouÅ¾Ã­cÃ­ k systematickÃ©mu prohledÃ¡vÃ¡nÃ­ a sbÄ›ru obsahu internetu pro trÃ©nink AI modelÅ¯ â€“ nasajÃ­ do svÃ½ch databÃ¡zÃ­. Tyto crawlery, pouÅ¾Ã­vanÃ© firmami jako OpenAI, Google nebo Meta, shromaÅ¾ÄujÃ­ petabajty textu, obrÃ¡zkÅ¯ a kÃ³du z veÅ™ejnÃ©ho webu, coÅ¾ je zÃ¡klad modernÃ­ho boomu velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) jako GPT nebo Gemini. OtrÃ¡venÃ¡ data, tzv. poisoned training data, zÃ¡mÄ›rnÄ› zkreslujÃ­ vzorce v datech, coÅ¾ vede k tomu, Å¾e natrÃ©novanÃ½ model produkuje nesprÃ¡vnÃ© vÃ½stupy, halucinace nebo zcela nefunkÄnÃ­ chovÃ¡nÃ­.

Podle zprÃ¡vy na The Register byl projekt spuÅ¡tÄ›n minulÃ½ tÃ½den a jeho ÄlenovÃ© pracujÃ­ pro vÃ½znamnÃ© americkÃ© AI spoleÄnosti, pÅ™iÄemÅ¾ zdroj varuje pÅ™ed eskalacÃ­ situace, o nÃ­Å¾ veÅ™ejnost nemÃ¡ pÅ™ehled. Na webu projektu stojÃ­: â€SouhlasÃ­me s Geoffrey Hintonem: strojovÃ¡ inteligence je hrozbou pro lidskÃ½ druh. V reakci na tuto hrozbu chceme zpÅ¯sobit Å¡kody systÃ©mÅ¯m strojovÃ© inteligence.â€œ Hinton, britskÃ½ informatyk povaÅ¾ovanÃ½ za otce modernÃ­ch neuronovÃ½ch sÃ­tÃ­, opustil Google v roce 2023 prÃ¡vÄ› kvÅ¯li obavÃ¡m z rizik AI.

Tento pÅ™Ã­stup navazuje na dÅ™Ã­vÄ›jÅ¡Ã­ snahy o obranu pÅ™ed AI scrapingem, napÅ™Ã­klad software pro umÄ›lce, kterÃ½ vloÅ¾Ã­ do obrÃ¡zkÅ¯ subtilnÃ­ ruÅ¡ivÃ© data (napÅ™. Nightshade od University of Chicago), aby modely jako Stable Diffusion selhaly pÅ™i generovÃ¡nÃ­ podobnÃ½ch dÄ›l. Poison Fountain jde dÃ¡l tÃ­m, Å¾e cÃ­lÃ­ na textovÃ¡ data a je navrÅ¾en pro masovÃ© nasazenÃ­. KlÃ­ÄovÃ½m bodem souÄasnÃ©ho AI vÃ½voje byl objev, Å¾e modely lze natrÃ©novat na obrovskÃ½ch objemech veÅ™ejnÃ½ch dat z internetu, coÅ¾ bylo dÅ™Ã­ve povaÅ¾ovÃ¡no za neproveditelnÃ©. Tento scraping vÅ¡ak vyvolal vlnu soudnÃ­ch sporÅ¯ o poruÅ¡enÃ­ autorskÃ½ch prÃ¡v â€“ napÅ™Ã­klad od New York Times proti OpenAI nebo od autorÅ¯ knih proti Anthropic.

Pro prÅ¯mysl to znamenÃ¡, Å¾e firmy musÃ­ investovat do lepÅ¡Ã­ho filtrovÃ¡nÃ­ dat, detekce poisoningÅ¯ nebo vlastnÃ­ch datovÃ½ch zdrojÅ¯, coÅ¾ zvyÅ¡uje nÃ¡klady na trÃ©nink. UÅ¾ivatelÃ© by mohli Äelit mÃ©nÄ› spolehlivÃ½m AI nÃ¡strojÅ¯m, pokud se metoda rozÅ¡Ã­Å™Ã­. ZatÃ­m je Å¡kÃ¡la projektu omezenÃ¡, ale insideri z velkÃ½ch firem signalizujÃ­ rostoucÃ­ internÃ­ rozporuplnost v AI komunitÄ›.

## ProÄ je to dÅ¯leÅ¾itÃ©
V Å¡irÅ¡Ã­m kontextu AI ekosystÃ©mu zdÅ¯razÅˆuje Poison Fountain zranitelnost zÃ¡vislosti na nekontrolovanÃ©m webovÃ©m scrapingu, kterÃ½ tvoÅ™Ã­ 90 % trÃ©ninkovÃ½ch dat pro modely jako Llama nebo Claude. Pokud se otrava dat stane bÄ›Å¾nou praxÃ­, mohl by to bÃ½t efektivnÄ›jÅ¡Ã­ zpÅ¯sob boje proti nekontrolovanÃ©mu rÅ¯stu AI neÅ¾ fyzickÃ© Ãºtoky na datovÃ¡ centra. Pro prÅ¯mysl to znamenÃ¡ nutnost vÃ½voje robustnÃ­ch detekÄnÃ­ch mechanismÅ¯, jako jsou pokroÄilÃ© filtry na bÃ¡zi AI pro identifikaci anomÃ¡liÃ­ v datech. Eskalace od insiderÅ¯ naznaÄuje hlubokÃ© ideologickÃ© rozdÃ­ly v oboru, coÅ¾ by mohlo ovlivnit alokaci zdrojÅ¯ a regulace. V dlouhodobÃ©m horizontu by to mohlo zpomalit pokrok v AGI, ale zÃ¡roveÅˆ posÃ­lit bezpeÄnostnÃ­ standardy.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](http://futurism.com/artificial-intelligence/poison-fountain-ai)

**Zdroj:** ğŸ“° Futurism
