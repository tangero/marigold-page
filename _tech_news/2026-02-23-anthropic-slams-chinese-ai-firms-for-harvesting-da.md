---
author: Marisa Aigen
category: ai
companies:
- Anthropic
date: '2026-02-23 23:45:50'
description: SpoleÄnost Anthropic obviÅˆuje tÅ™i ÄÃ­nskÃ© firmy v oblasti umÄ›lÃ© inteligence
  z nelegÃ¡lnÃ­ho sbÃ­rÃ¡nÃ­ velkÃ©ho mnoÅ¾stvÃ­ dat z jejich chatbota Claude za ÃºÄelem urychlenÃ­
  vÃ½voje vlastnÃ­ch platforem. V blogovÃ©m pÅ™Ã­spÄ›vku dnes upozornila na DeepSeek, Moonshot
  a MiniMax, kterÃ© ÃºdajnÄ› vytvoÅ™ily tisÃ­ce faleÅ¡nÃ½ch ÃºÄtÅ¯ pro generovÃ¡nÃ­ milionÅ¯ konverzacÃ­.
importance: 4
layout: tech_news_article
original_title: Anthropic slams Chinese AI firms for harvesting data from its Claude
  chatbot
publishedAt: '2026-02-23T23:45:50+00:00'
slug: anthropic-slams-chinese-ai-firms-for-harvesting-da
source:
  emoji: ğŸ“°
  id: null
  name: SiliconANGLE News
title: Anthropic obviÅˆuje ÄÃ­nskÃ© AI firmy z krÃ¡deÅ¾e dat z chatbota Claude
url: https://siliconangle.com/2026/02/23/anthropic-slams-chinese-ai-firms-harvesting-data-claude-chatbot/
urlToImage: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/Screenshot-from-2026-02-24-06-45-03.png
urlToImageBackup: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/Screenshot-from-2026-02-24-06-45-03.png
---

## Souhrn
SpoleÄnost Anthropic, tvÅ¯rce chatbota Claude, obviÅˆuje tÅ™i ÄÃ­nskÃ© AI firmy â€“ DeepSeek, Moonshot a MiniMax â€“ z nelegÃ¡lnÃ­ho sbÃ­rÃ¡nÃ­ dat prostÅ™ednictvÃ­m tisÃ­cÅ¯ faleÅ¡nÃ½ch ÃºÄtÅ¯. Tyto firmy prÃ½ provedly miliony interakcÃ­ s Claude, aby data pouÅ¾ily k distilaci, tedy k trÃ©ninku vlastnÃ­ch modelÅ¯ umÄ›lÃ© inteligence. Anthropic to oznaÄuje za poruÅ¡enÃ­ podmÃ­nek sluÅ¾by a potenciÃ¡lnÃ­ riziko pro nÃ¡rodnÃ­ bezpeÄnost USA.

## KlÃ­ÄovÃ© body
- DeepSeek: 150 000 interakcÃ­ s Claude.
- Moonshot: pÅ™es 3,4 milionu interakcÃ­.
- MiniMax: 13 milionÅ¯ interakcÃ­.
- Technika distilace umoÅ¾Åˆuje pÅ™evÃ©st znalosti z jednoho modelu do druhÃ©ho, coÅ¾ je bÄ›Å¾nÃ©, ale zakÃ¡zanÃ© podmÃ­nkami Anthropicu.
- PodobnÃ© obvinÄ›nÃ­ vznesla i OpenAI vÅ¯Äi ÄÃ­nskÃ½m firmÃ¡m ohlednÄ› ChatGPT, vÄetnÄ› stÃ­Å¾nosti u americkÃ©ho Kongresu.

## Podrobnosti
Anthropic v blogovÃ©m pÅ™Ã­spÄ›vku z 23. Ãºnora 2026 upozornil na systematickÃ© poruÅ¡ovÃ¡nÃ­ svÃ½ch podmÃ­nek sluÅ¾by tÅ™emi ÄÃ­nskÃ½mi spoleÄnostmi. DeepSeek Ltd. se specializuje na open-source modely velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), Moonshot provozuje chatbot Kimi zamÄ›Å™enÃ½ na pokroÄilÃ© konverzace a MiniMax vyvÃ­jÃ­ multimodÃ¡lnÃ­ AI pro text, obrÃ¡zky a hlas. Tyto firmy prÃ½ vytvoÅ™ily tisÃ­ce automatizovanÃ½ch ÃºÄtÅ¯ na platformÄ› Claude, ÄÃ­mÅ¾ vygenerovaly miliony konverzacÃ­. KonkrÃ©tnÄ› DeepSeek dosÃ¡hl 150 000 interakcÃ­, Moonshot 3,4 milionu a MiniMax aÅ¾ 13 milionÅ¯.

Distilace je technika, pÅ™i kterÃ© se vÃ½stupy jednoho AI modelu pouÅ¾Ã­vajÃ­ jako trÃ©ninkovÃ¡ data pro jinÃ½ model, coÅ¾ umoÅ¾Åˆuje rychlejÅ¡Ã­ a levnÄ›jÅ¡Ã­ vÃ½voj bez nutnosti sbÃ­rat data od nuly. Anthropic vÅ¡ak v podmÃ­nkÃ¡ch sluÅ¾by explicitnÄ› zakazuje sbÃ­rÃ¡nÃ­ odpovÄ›dÃ­ Claude pro takovÃ© ÃºÄely a navÃ­c blokuje pÅ™Ã­stup z ÄŒÃ­ny. PÅ™es tyto omezenÃ­ ÄÃ­nskÃ© firmy podle Anthropicu pouÅ¾ily proxy servery a obfuskaci k obejitÃ­ blokÃ¡d.

Toto nenÃ­ ojedinÄ›lÃ½ pÅ™Ã­pad. Rival OpenAI nedÃ¡vno podal memorandum VÃ½boru pro ÄŒÃ­nu v SnÄ›movnÄ› reprezentantÅ¯ USA, kde popsali podobnÃ© aktivity DeepSeeka a dalÅ¡Ã­ch firem vÅ¯Äi ChatGPT. OpenAI mluvÃ­ o "novÃ½ch a zamaskovanÃ½ch" technikÃ¡ch distilace, kterÃ© umoÅ¾ÅˆujÃ­ ÄÃ­nskÃ½m firmÃ¡m "jezdit zdarma" na americkÃ½ch technologiÃ­ch. Anthropic zdÅ¯razÅˆuje, Å¾e i kdyÅ¾ Claude mÃ¡ vestavÄ›nÃ© bezpeÄnostnÃ­ zÃ¡brany proti zneuÅ¾itÃ­ v oblasti vojenskÃ½ch aplikacÃ­ nebo sledovÃ¡nÃ­, distilace tyto zÃ¡brany odstranÃ­, coÅ¾ vede k rizikÅ¯m jako vÃ½voj pokroÄilÃ½ch zbranÃ­ nebo nÃ¡strojÅ¯ pro masovÃ© sledovÃ¡nÃ­.

Anthropic jiÅ¾ implementoval dalÅ¡Ã­ ochrany, jako detekci automatizovanÃ½ch interakcÃ­ a omezenÃ­ API, ale pÅ™iznÃ¡vÃ¡, Å¾e ÃºplnÃ¡ prevence je obtÃ­Å¾nÃ¡ kvÅ¯li Å¡kÃ¡lovatelnosti ÃºtokÅ¯.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento spor odhaluje rostoucÃ­ napÄ›tÃ­ v globÃ¡lnÃ­ soutÄ›Å¾i o vedenÃ­ v AI mezi USA a ÄŒÃ­nou. Distilace umoÅ¾Åˆuje ÄÃ­nskÃ½m firmÃ¡m rychle dohÃ¡nÄ›t zpoÅ¾dÄ›nÃ­ v kvalitÄ› modelÅ¯, aniÅ¾ by investovaly do vlastnÃ­ho sbÄ›ru dat, coÅ¾ oslabuje konkurenÄnÃ­ vÃ½hodu americkÃ½ch firem jako Anthropic nebo OpenAI. Pro prÅ¯mysl to znamenÃ¡ nutnost posÃ­lit ochranu modelÅ¯, napÅ™Ã­klad watermarkingem vÃ½stupÅ¯ nebo pokroÄilÃ½mi detekÄnÃ­mi systÃ©my.

Z hlediska nÃ¡rodnÃ­ bezpeÄnosti jde o reÃ¡lnÃ© riziko: distilovanÃ© modely bez bezpeÄnostnÃ­ch omezenÃ­ lze integrovat do vojenskÃ½ch systÃ©mÅ¯ pro autonomnÃ­ zbranÄ› nebo do nÃ¡strojÅ¯ pro kybernetickÃ½ prÅ¯zkum. RegulÃ¡toÅ™i v USA by mohli reagovat exportnÃ­mi kontrolami na AI technologie, podobnÄ› jako u ÄipÅ¯ GPU. Pro uÅ¾ivatele to zatÃ­m nemÃ¡ pÅ™Ã­mÃ½ dopad, ale mÅ¯Å¾e vÃ©st k pÅ™Ã­snÄ›jÅ¡Ã­m omezenÃ­m pÅ™Ã­stupu k modelÅ¯m jako Claude nebo ChatGPT z urÄitÃ½ch zemÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://siliconangle.com/2026/02/23/anthropic-slams-chinese-ai-firms-harvesting-data-claude-chatbot/)

**Zdroj:** ğŸ“° SiliconANGLE News
