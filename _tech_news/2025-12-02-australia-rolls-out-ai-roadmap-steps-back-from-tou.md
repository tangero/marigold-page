---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2025-12-02 00:48:50'
description: AustrÃ¡lie zveÅ™ejnila nÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci, kterÃ½ mÃ¡ urychlit
  jejÃ­ adopci v ekonomice, ale mÃ­sto novÃ½ch pÅ™Ã­snÃ½ch pravidel se spolÃ©hÃ¡ na stÃ¡vajÃ­cÃ­
  zÃ¡kony k Å™Ã­zenÃ­ rizik. Tento pÅ™Ã­stup znamenÃ¡ Ãºstup od dÅ™Ã­vÄ›jÅ¡Ã­ch zÃ¡mÄ›rÅ¯ zavÃ©st specifickÃ©
  regulace pro vysorizikovÃ© aplikace AI.
importance: 3
layout: tech_news_article
original_title: Australia rolls out AI roadmap, steps back from tougher rules
publishedAt: '2025-12-02T00:48:50+00:00'
slug: australia-rolls-out-ai-roadmap-steps-back-from-tou
source:
  emoji: ğŸ“°
  id: null
  name: CNA
title: AustrÃ¡lie pÅ™edstavuje roadmapu pro umÄ›lou inteligenci, ustupuje od pÅ™Ã­snÄ›jÅ¡Ã­ch
  regulacÃ­
url: https://www.channelnewsasia.com/business/australia-rolls-out-ai-roadmap-steps-back-tougher-rules-5521451
urlToImage: https://dam.mediacorp.sg/image/upload/s--rO_cRSZS--/c_fill,g_auto,h_676,w_1200/fl_relative,g_south_east,l_mediacorp:cna:watermark:2024-04:reuters_1,w_0.1/f_auto,q_auto/v1/one-cms/core/2025-12-02T004850Z_1_LYNXMPELB101A_RTROPTP_3_AUSTRALIA-DAILYLIFE.JPG?itok=NxUC-930
urlToImageBackup: https://dam.mediacorp.sg/image/upload/s--rO_cRSZS--/c_fill,g_auto,h_676,w_1200/fl_relative,g_south_east,l_mediacorp:cna:watermark:2024-04:reuters_1,w_0.1/f_auto,q_auto/v1/one-cms/core/2025-12-02T004850Z_1_LYNXMPELB101A_RTROPTP_3_AUSTRALIA-DAILYLIFE.JPG?itok=NxUC-930
---

### Souhrn
AustrÃ¡lie 2. prosince 2025 zveÅ™ejnila NÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci (National AI Plan), kterÃ½ se zamÄ›Å™uje na rozÅ¡Ã­Å™enÃ­ adopce AI v celÃ© ekonomice. MÃ­sto zavedenÃ­ novÃ½ch pÅ™Ã­snÃ½ch regulacÃ­ vlÃ¡da potvrdila, Å¾e bude vyuÅ¾Ã­vat existujÃ­cÃ­ prÃ¡vnÃ­ rÃ¡mec k Å™eÅ¡enÃ­ rizik spojenÃ½ch s AI. PlÃ¡n zahrnuje investice do datovÃ½ch center, rozvoj dovednostÃ­ a zÅ™Ã­zenÃ­ Ãšstavu pro bezpeÄnost AI v roce 2026.

### KlÃ­ÄovÃ© body
- Podpora adopce AI prostÅ™ednictvÃ­m investic do pokroÄilÃ½ch datovÃ½ch center a budovÃ¡nÃ­ pracovnÃ­ch dovednostÃ­.
- SpolÃ©hÃ¡nÃ­ na stÃ¡vajÃ­cÃ­ regulace mÃ­sto novÃ½ch specifickÃ½ch zÃ¡konÅ¯ pro AI.
- ZÅ™Ã­zenÃ­ Ãšstavu pro bezpeÄnost AI v roce 2026 k posouzenÃ­ rizik.
- Agence a regulÃ¡toÅ™i budou odpovÄ›dnÃ­ za identifikaci a Å™Ã­zenÃ­ Å¡kod v jejich sektorech.
- Ãšstup od plÃ¡nÅ¯ na dobrovolnÃ© smÄ›rnice z minulÃ©ho roku kvÅ¯li obavÃ¡m z soukromÃ­, bezpeÄnosti a transparentnosti.

### Podrobnosti
AustralskÃ¡ labouristickÃ¡ vlÃ¡da, kterÃ¡ nemÃ¡ Å¾Ã¡dnÃ© specifickÃ© zÃ¡kony tÃ½kajÃ­cÃ­ se umÄ›lÃ© inteligence, v ÃºterÃ½ 2. prosince 2025 pÅ™edstavila NÃ¡rodnÃ­ plÃ¡n pro AI. Tento dokument reaguje na rostoucÃ­ integraci AI do kaÅ¾dodennÃ­ho Å¾ivota a ekonomiky, ale klÃ­ÄovÃ½m bodem je odmÃ­tnutÃ­ pÅ™Ã­snÄ›jÅ¡Ã­ch regulacÃ­. MÃ­sto toho plÃ¡n zdÅ¯razÅˆuje, Å¾e "vlÃ¡dnÃ­ regulaÄnÃ­ pÅ™Ã­stup k AI bude nadÃ¡le stavÄ›t na robustnÃ­m existujÃ­cÃ­m prÃ¡vnÃ­m a regulaÄnÃ­m rÃ¡mci AustrÃ¡lie, pÅ™iÄemÅ¾ stÃ¡vajÃ­cÃ­ zÃ¡kony zÅ¯stanou zÃ¡kladem pro Å™eÅ¡enÃ­ a zmÃ­rnÄ›nÃ­ rizik spojenÃ½ch s AI".

PlÃ¡n se soustÅ™edÃ­ na tÅ™i hlavnÃ­ pilÃ­Å™e: pÅ™ilÃ¡kÃ¡nÃ­ investic do pokroÄilÃ½ch datovÃ½ch center, kterÃ¡ jsou nezbytnÃ¡ pro trÃ©nink a provoz velkÃ½ch AI modelÅ¯ jako jsou LLM (large language models), budovÃ¡nÃ­ dovednostÃ­ pro podporu pracovnÃ­ch mÃ­st a zajiÅ¡tÄ›nÃ­ veÅ™ejnÃ© bezpeÄnosti. DatovÃ¡ centra umoÅ¾ÅˆujÃ­ Å¡kÃ¡lovÃ¡nÃ­ AI aplikacÃ­, napÅ™Ã­klad v oblasti zdravotnictvÃ­ pro diagnostiku zobrazenÃ­ nebo v logistice pro optimalizaci dodavatelskÃ½ch Å™etÄ›zcÅ¯. VlÃ¡da plÃ¡nuje podporovat vzdÄ›lÃ¡vÃ¡nÃ­ v AI, aby pracovnÃ­ sÃ­la mohla efektivnÄ› spolupracovat s tÄ›mito technologiemi a chrÃ¡nit stÃ¡vajÃ­cÃ­ zamÄ›stnanost pÅ™ed automatizacÃ­.

MinulÃ½ rok vlÃ¡da signalizovala zavedenÃ­ dobrovolnÃ½ch smÄ›rnic kvÅ¯li obavÃ¡m z poruÅ¡enÃ­ soukromÃ­, bezpeÄnosti a nedostatku transparentnosti v AI systÃ©mech, jako jsou generativnÃ­ modely schopnÃ© vytvÃ¡Å™et deepfakes nebo rozhodovacÃ­ algoritmy v justici. NynÃ­ vÅ¡ak agendy a regulÃ¡toÅ™i v jednotlivÃ½ch sektorech â€“ napÅ™Ã­klad v telekomunikacÃ­ch nebo finance â€“ pÅ™ebÃ­rajÃ­ odpovÄ›dnost za identifikaci rizik, jako jsou biasy v AI modelech nebo kybernetickÃ© hrozby. VlÃ¡da oznÃ¡mila zÅ™Ã­zenÃ­ Ãšstavu pro bezpeÄnost AI v roce 2026, kterÃ½ bude pomÃ¡hat s hodnocenÃ­m rizik, podobnÄ› jako britskÃ½ AI Safety Institute, kterÃ½ testuje modely na bezpeÄnostnÃ­ slabiny.

Tento pÅ™Ã­stup kontrastuje s Evropskou uniÃ­, kde platÃ­ AI Act s kategorizacÃ­ rizik od minimÃ¡lnÃ­ch po nepÅ™Ã­pustnÃ©, nebo s USA, kde dominuje sektorovÄ› specifickÃ¡ regulace. AustrÃ¡lie tak volÃ­ flexibilnÃ­ model, kterÃ½ mÃ¡ podpoÅ™it inovace bez brzdy byrokraciÃ­.

### ProÄ je to dÅ¯leÅ¾itÃ©
NÃ¡rodnÃ­ plÃ¡n AustrÃ¡lie ukazuje trend v demokratickÃ½ch zemÃ­ch smÄ›rem k lehÄÃ­m regulacÃ­m AI, coÅ¾ umoÅ¾Åˆuje rychlejÅ¡Ã­ adopci v sektorech jako finance, zdravotnictvÃ­ a veÅ™ejnÃ¡ sprÃ¡va. Pro prÅ¯mysl to znamenÃ¡ mÃ©nÄ› administrativnÃ­ zÃ¡tÄ›Å¾e, ale vyÅ¡Å¡Ã­ odpovÄ›dnost firem za compliance se stÃ¡vajÃ­cÃ­mi zÃ¡kony, napÅ™Ã­klad GDPR-analogy v AustrÃ¡lii pro ochranu dat. V Å¡irÅ¡Ã­m kontextu posiluje to globÃ¡lnÃ­ zÃ¡vod v AI, kde zemÄ› jako AustrÃ¡lie, spolÃ©hajÃ­cÃ­ se na investice do infrastruktury, mohou konkurovat ÄŒÃ­nÄ› nebo USA. Riziko spoÄÃ­vÃ¡ v potenciÃ¡lnÃ­m podceÅˆovÃ¡nÃ­ systÃ©movÃ½ch hrozeb, jako jsou autonomnÃ­ zbranÄ› nebo masivnÃ­ dezinformace, pokud nebudou sektoroovÃ© regulÃ¡toÅ™i dostateÄnÄ› vybaveni. Pro uÅ¾ivatele v AustrÃ¡lii to znamenÃ¡ plynulejÅ¡Ã­ integraci AI do kaÅ¾dodennÃ­ch aplikacÃ­, ale s menÅ¡Ã­ jistotou ohlednÄ› dlouhodobÃ© bezpeÄnosti.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.channelnewsasia.com/business/australia-rolls-out-ai-roadmap-steps-back-tougher-rules-5521451)

**Zdroj:** ğŸ“° CNA
