---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2025-12-02 00:48:50'
description: 'Sydney, 2. prosince: AustrÃ¡lie pÅ™edstavila nÃ¡rodnÃ­ plÃ¡n pro rozÅ¡Ã­Å™enÃ­
  adopce umÄ›lÃ© inteligence v ekonomice, pÅ™iÄemÅ¾ se rozhodla spolÃ©hat na stÃ¡vajÃ­cÃ­
  zÃ¡kony pro Å™Ã­zenÃ­ rizik mÃ­sto novÃ½ch pÅ™Ã­snÃ½ch regulacÃ­ pro vysoce rizikovÃ© scÃ©nÃ¡Å™e.'
importance: 3
layout: tech_news_article
original_title: Australia rolls out AI roadmap, steps back from tougher rules
publishedAt: '2025-12-02T00:48:50+00:00'
slug: australia-rolls-out-ai-roadmap-steps-back-from-tou
source:
  emoji: ğŸ“°
  id: null
  name: CNA
title: AustrÃ¡lie pÅ™edstavuje roadmapu pro umÄ›lou inteligenci, ustupuje od pÅ™Ã­snÄ›jÅ¡Ã­ch
  pravidel
url: https://www.channelnewsasia.com/business/australia-rolls-out-ai-roadmap-steps-back-tougher-rules-5521451
urlToImage: https://dam.mediacorp.sg/image/upload/s--rO_cRSZS--/c_fill,g_auto,h_676,w_1200/fl_relative,g_south_east,l_mediacorp:cna:watermark:2024-04:reuters_1,w_0.1/f_auto,q_auto/v1/one-cms/core/2025-12-02T004850Z_1_LYNXMPELB101A_RTROPTP_3_AUSTRALIA-DAILYLIFE.JPG?itok=NxUC-930
urlToImageBackup: https://dam.mediacorp.sg/image/upload/s--rO_cRSZS--/c_fill,g_auto,h_676,w_1200/fl_relative,g_south_east,l_mediacorp:cna:watermark:2024-04:reuters_1,w_0.1/f_auto,q_auto/v1/one-cms/core/2025-12-02T004850Z_1_LYNXMPELB101A_RTROPTP_3_AUSTRALIA-DAILYLIFE.JPG?itok=NxUC-930
---

## Souhrn
AustrÃ¡lie zveÅ™ejnila NÃ¡rodnÃ­ plÃ¡n pro umÄ›lou inteligenci, kterÃ½ mÃ¡ urychlit zavÃ¡dÄ›nÃ­ AI do ekonomiky. VlÃ¡da se rozhodla neuvÃ¡dÄ›t novÃ© specifickÃ© zÃ¡kony pro AI, ale spolÃ©hat se na existujÃ­cÃ­ prÃ¡vnÃ­ rÃ¡mec k Å™eÅ¡enÃ­ rizik. MÃ­sto pÅ™Ã­snÄ›jÅ¡Ã­ch opatÅ™enÃ­ pro vysokorizikovÃ© aplikace plÃ¡nuje investice do datovÃ½ch center a dovednostÃ­.

## KlÃ­ÄovÃ© body
- Å½Ã¡dnÃ© novÃ© specifickÃ© zÃ¡kony pro AI, vyuÅ¾itÃ­ stÃ¡vajÃ­cÃ­ch regulacÃ­.
- ZamÄ›Å™enÃ­ na pÅ™ilÃ¡kÃ¡nÃ­ investic do pokroÄilÃ½ch datovÃ½ch center a rozvoj AI dovednostÃ­ pro ochranu pracovnÃ­ch mÃ­st.
- ZÅ™Ã­zenÃ­ AI Safety Institute v roce 2026 pro posouzenÃ­ rizik.
- Agentury a regulÃ¡toÅ™i budou Å™Ã­dit rizika v rÃ¡mci svÃ½ch sektorÅ¯.
- PÅ™edchozÃ­ plÃ¡ny na dobrovolnÃ© smÄ›rnice z roku 2024 byly opuÅ¡tÄ›ny ve prospÄ›ch flexiblÄ›jÅ¡Ã­ho pÅ™Ã­stupu.

## Podrobnosti
AustralskÃ¡ labouristickÃ¡ vlÃ¡da, kterÃ¡ nemÃ¡ Å¾Ã¡dnÃ© specifickÃ© zÃ¡kony pro umÄ›lou inteligenci, pÅ¯vodnÄ› v loÅˆskÃ©m roce naznaÄovala zavedenÃ­ dobrovolnÃ½ch smÄ›rnic kvÅ¯li obavÃ¡m z ochrany soukromÃ­, bezpeÄnosti a transparentnosti. NÃ¡rodnÃ­ plÃ¡n pro AI, zveÅ™ejnÄ›nÃ½ 2. prosince, vÅ¡ak tento smÄ›r mÄ›nÃ­. Dokument klade dÅ¯raz na ekonomickou integraci AI: pÅ™ilÃ¡kÃ¡nÃ­ investic do datovÃ½ch center pro zpracovÃ¡nÃ­ velkÃ½ch objemÅ¯ dat nutnÃ½ch pro trÃ©nink AI modelÅ¯, rozvoj dovednostÃ­ pracovnÃ­ sÃ­ly, aby AI neohrozila stÃ¡vajÃ­cÃ­ zamÄ›stnanost, a zajiÅ¡tÄ›nÃ­ veÅ™ejnÃ© bezpeÄnosti pÅ™i kaÅ¾dodennÃ­m nasazenÃ­ technologiÃ­ jako jsou velkÃ© jazykovÃ© modely nebo autonomnÃ­ systÃ©my.

PlÃ¡n explicitnÄ› uvÃ¡dÃ­, Å¾e regulaÄnÃ­ pÅ™Ã­stup bude stavÄ›t na robustnÃ­m existujÃ­cÃ­m prÃ¡vnÃ­m rÃ¡mci. To znamenÃ¡, Å¾e rizika jako bias v algoritmech, Ãºniky dat nebo dezinformace budou Å™eÅ¡ena prostÅ™ednictvÃ­m souÄasnÃ½ch zÃ¡konÅ¯ o ochranÄ› dat (napÅ™. Privacy Act), spotÅ™ebitelskÃ© ochranÄ› a sektorovÄ› specifickÃ½ch pÅ™edpisÅ¯. Agentury jako Australian Competition and Consumer Commission nebo Office of the Australian Information Commissioner zÅ¯stanou odpovÄ›dnÃ© za identifikaci a mitigaci Å¡kod v oblastech jako finance, zdravotnictvÃ­ nebo doprava. Tento pÅ™Ã­stup kontrastuje s pÅ™Ã­snÄ›jÅ¡Ã­mi modely jinde: napÅ™Ã­klad EvropskÃ½ AI Act klasifikuje AI podle rizikovosti a zavÃ¡dÃ­ povinnÃ© testovÃ¡nÃ­ pro vysokorizikovÃ© systÃ©my, zatÃ­mco USA spolÃ©hajÃ­ na dobrovolnÃ© rÃ¡mce od spoleÄnostÃ­ jako OpenAI.

DalÅ¡Ã­m krokem je zaloÅ¾enÃ­ AI Safety Institute v roce 2026, kterÃ½ mÃ¡ pomoci s hodnocenÃ­m rizik, testovÃ¡nÃ­m modelÅ¯ a vÃ½vojem standardÅ¯. Institut bude podobnÃ½ britskÃ©mu AI Safety Institute a zamÄ›Å™Ã­ se na bezpeÄnostnÃ­ aspekty, jako je robustnost proti jailbreakÅ¯m nebo predikce spoleÄenskÃ½ch dopadÅ¯. PlÃ¡n takÃ© zdÅ¯razÅˆuje etickÃ© aspekty, ale bez vymahatelnÃ½ch sankcÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento opatrnÃ½ pÅ™Ã­stup AustrÃ¡lie odrÃ¡Å¾Ã­ globÃ¡lnÃ­ dilema mezi inovacÃ­ a regulacÃ­. Pro prÅ¯mysl znamenÃ¡ niÅ¾Å¡Ã­ bariÃ©ry pro nasazenÃ­ AI v oblastech jako zdravotnictvÃ­ (diagnostika pomocÃ­ AI modelÅ¯) nebo zemÄ›dÄ›lstvÃ­ (optimalizace Ãºrody), coÅ¾ mÅ¯Å¾e posÃ­lit ekonomiku v regionu Asie-Pacifik. NicmÃ©nÄ› kritici upozorÅˆujÃ­ na rizika: bez specifickÃ½ch pravidel pro high-risk AI, jako jsou autonomnÃ­ zbranÄ› nebo deepfakes, mohou nastat incidenty podobnÃ© tÄ›m v USA (napÅ™. bias v rekurzÃ­ch). V Å¡irÅ¡Ã­m kontextu posiluje to trend "light-touch" regulace, kterÃ½ sledujÃ­ i VelkÃ¡ BritÃ¡nie a Singapur, oproti restriktivnÃ­mu EU modelu. Pro uÅ¾ivatele v ÄŒesku a EU to znamenÃ¡, Å¾e australskÃ© firmy budou konkurovat s menÅ¡Ã­mi regulaÄnÃ­mi zÃ¡tÄ›Å¾emi, coÅ¾ ovlivnÃ­ globÃ¡lnÃ­ dodavatelskÃ© Å™etÄ›zce AI technologiÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.channelnewsasia.com/business/australia-rolls-out-ai-roadmap-steps-back-tougher-rules-5521451)

**Zdroj:** ğŸ“° CNA
