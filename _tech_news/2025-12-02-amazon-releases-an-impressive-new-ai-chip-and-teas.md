---
author: Marisa Aigen
category: ai
companies:
- Amazon
- Nvidia
date: '2025-12-02 16:01:46'
description: AWS vydal tÅ™etÃ­ generaci svÃ©ho Äipu pro trÃ©nink AI modelÅ¯ Trainium3 s
  vÃ½raznÄ› vyÅ¡Å¡Ã­m vÃ½konem a energetickou ÃºÄinnostÃ­. Na konferenci re:Invent 2025 spoleÄnost
  takÃ© oznÃ¡mila plÃ¡ny na Trainium4, kterÃ½ bude integrovat s Äipy Nvidia.
importance: 3
layout: tech_news_article
original_title: Amazon releases an impressive new AI chip and teases a Nvidia-friendly
  roadmapÂ Â  | TechCrunch
publishedAt: '2025-12-02T16:01:46+00:00'
slug: amazon-releases-an-impressive-new-ai-chip-and-teas
source:
  emoji: ğŸš€
  id: techcrunch
  name: TechCrunch
title: Amazon pÅ™edstavil novÃ½ AI Äip Trainium3 a naznaÄil roadmapu kompatibilnÃ­ s
  Nvidia
url: https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/
urlToImage: https://techcrunch.com/wp-content/uploads/2020/01/GettyImages-1136663877.jpg?resize=1200,800
urlToImageBackup: https://techcrunch.com/wp-content/uploads/2020/01/GettyImages-1136663877.jpg?resize=1200,800
---

### Souhrn
Amazon Web Services (AWS) pÅ™edstavil na konferenci re:Invent 2025 Äip Trainium3, tÅ™etÃ­ generaci svÃ©ho hardwaru pro trÃ©nink a inference AI modelÅ¯. Tento Äip na 3nanometrovÃ©m vÃ½robnÃ­m procesu pÅ™inÃ¡Å¡Ã­ ÄtyÅ™nÃ¡sobnÃ© zrychlenÃ­ oproti druhÃ© generaci Trainium2 a ÄtyÅ™nÃ¡sobnÄ› vyÅ¡Å¡Ã­ kapacitu pamÄ›ti. SpoleÄnost zÃ¡roveÅˆ naznaÄila vÃ½voj Trainium4, kterÃ½ umoÅ¾nÃ­ bezproblÃ©movou spoluprÃ¡ci s Äipy Nvidia.

### KlÃ­ÄovÃ© body
- Trainium3 UltraServer obsahuje 144 ÄipÅ¯ na jeden server a lze je propojit do clusterÅ¯ s aÅ¾ 1 milionem ÄipÅ¯, coÅ¾ je desetinÃ¡sobek pÅ™edchozÃ­ generace.
- ÄŒtyÅ™nÃ¡sobnÃ½ nÃ¡rÅ¯st vÃ½konu a pamÄ›ti platÃ­ jak pro trÃ©nink velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), tak pro inference, tedy nasazenÃ­ modelÅ¯ v produkci.
- 40procentnÃ­ zlepÅ¡enÃ­ energetickÃ© ÃºÄinnosti oproti Trainium2, coÅ¾ sniÅ¾uje spotÅ™ebu energie v datech centrech.
- ZÃ¡kaznÃ­ci jako Anthropic, japonskÃ¡ firma Karakuri specializujÃ­cÃ­ se na LLM, SplashMusic (AI pro hudbu) a Decart jiÅ¾ Äip testovali a snÃ­Å¾ili nÃ¡klady na inference.
- Trainium4 bude "Nvidia-friendly", coÅ¾ umoÅ¾nÃ­ hybridnÃ­ konfigurace hardwaru.

### Podrobnosti
AWS vyvÃ­jÃ­ vlastnÃ­ AI Äipy od roku 2018, kdy uvedl prvnÃ­ Trainium, urÄenÃ½ primÃ¡rnÄ› pro trÃ©nink hlubokÃ½ch neuronovÃ½ch sÃ­tÃ­. Trainium3 stavÃ­ na zkuÅ¡enostech z pÅ™edchozÃ­ch generacÃ­ a integruje pokroÄilou sÃ­Å¥ovou technologii neuronÃ½ch sÃ­tÃ­, kterou AWS vyvinul internÄ›. KaÅ¾dÃ½ UltraServer, systÃ©m postavenÃ½ kolem Trainium3, zvlÃ¡dne 144 ÄipÅ¯, coÅ¾ umoÅ¾Åˆuje Å¡kÃ¡lovÃ¡nÃ­ na obrovskÃ© clustery. NapÅ™Ã­klad propojenÃ­m tisÃ­cÅ¯ serverÅ¯ lze dosÃ¡hnout kapacity 1 milionu ÄipÅ¯, ideÃ¡lnÃ­ pro trÃ©nink modelÅ¯ s biliony parametrÅ¯, jako jsou souÄasnÃ© LLM typu GPT nebo Claude.

VÃ½konovÃ½ skok je podle AWS ÄtyÅ™nÃ¡sobnÃ½ v porovnÃ¡nÃ­ s Trainium2, coÅ¾ znamenÃ¡ rychlejÅ¡Ã­ iterace pÅ™i vÃ½voji AI modelÅ¯ a niÅ¾Å¡Ã­ latenci pÅ™i inference â€“ tedy odpovÄ›dÃ­ch AI aplikacÃ­ v reÃ¡lnÃ©m Äase. PamÄ›Å¥ovÃ¡ kapacita vzrostla podobnÄ›, coÅ¾ umoÅ¾Åˆuje zpracovÃ¡nÃ­ vÄ›tÅ¡Ã­ch datovÃ½ch sad bez nutnosti ÄastÃ©ho pÅ™enÃ¡Å¡enÃ­ dat mezi Äipy. KlÃ­Äovou vÃ½hodou je 40procentnÃ­ snÃ­Å¾enÃ­ spotÅ™eby energie, coÅ¾ je v dobÄ›, kdy data centra pohlcujÃ­ gigawatty elektÅ™iny, zÃ¡sadnÃ­ faktor. AWS to prezentuje jako Ãºsporu pro zÃ¡kaznÃ­ky, kteÅ™Ã­ platÃ­ podle spotÅ™eby.

ZÃ¡kaznÃ­ci jako Anthropic, vÃ½vojÃ¡Å™ modelÅ¯ Claude a investor Amazonu, potvrdili snÃ­Å¾enÃ­ nÃ¡kladÅ¯ na inference. Karakuri vyvÃ­jÃ­ japonskÃ© LLM pro podnikovÃ© aplikace, SplashMusic generuje hudbu pomocÃ­ AI a Decart se zamÄ›Å™uje na optimalizaci AI workflow. Tyto pÅ™Ã­pady ukazujÃ­ praktickÃ© vyuÅ¾itÃ­ v cloudu. Na rozdÃ­l od Nvidia GPU, kterÃ© dominujÃ­ trhu dÃ­ky univerzÃ¡lnosti, jsou Trainium Äipy optimalizovÃ¡ny specificky pro AI trÃ©nink, coÅ¾ vede k vyÅ¡Å¡Ã­ efektivitÄ› v tÃ©to domÃ©nÄ›. OznÃ¡menÃ­ Trainium4 s kompatibilitou k Nvidia naznaÄuje, Å¾e AWS nehodlÃ¡ ignorovat ekosystÃ©m Nvidia CUDA, ale spÃ­Å¡e ho doplnÃ­ hybridnÃ­mi Å™eÅ¡enÃ­mi.

### ProÄ je to dÅ¯leÅ¾itÃ©
V Ã©Å™e explozivnÃ­ho rÅ¯stu AI hardware je Trainium3 dalÅ¡Ã­m krokem v konkurenci custom ÄipÅ¯ (TPU od Google, Inferentia od AWS) proti Nvidia monopolÅ¯m. EnergetickÃ¡ Ãºspora Å™eÅ¡Ã­ klÃ­ÄovÃ½ bottleneck data center â€“ spotÅ™ebu energie, kterÃ¡ brzdÃ­ expanzi. Pro uÅ¾ivatele cloudy znamenÃ¡ niÅ¾Å¡Ã­ ceny trÃ©ninku a inference, coÅ¾ demokratizuje pÅ™Ã­stup k velkÃ½m AI modelÅ¯m. Kompatibilita s Nvidia v Trainium4 umoÅ¾nÃ­ firmÃ¡m mixovat hardware podle potÅ™eb, coÅ¾ zvyÅ¡uje flexibilitu. NicmÃ©nÄ› specifikace pochÃ¡zejÃ­ z AWS, nezÃ¡vislÃ© benchmarky chybÃ­, a dlouhodobÃ½ dopad zÃ¡visÃ­ na adopci zÃ¡kaznÃ­kÅ¯. V Å¡irÅ¡Ã­m kontextu posiluje to zÃ¡vod o suverÃ©nnÃ­ AI infrastrukturu mezi cloudy, kde AWS drÅ¾Ã­ silnou pozici.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/)

**Zdroj:** ğŸš€ TechCrunch
