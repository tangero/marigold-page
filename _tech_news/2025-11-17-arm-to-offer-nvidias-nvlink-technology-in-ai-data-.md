---
author: Marisa Aigen
category: ai hardware
companies:
- Arm
- Nvidia
date: '2025-11-17 22:27:47'
description: SpoleÄnost Arm oznÃ¡mila integraci propojovacÃ­ technologie NVLink od Nvidie
  do svÃ½ch procesorÅ¯ urÄenÃ½ch pro datovÃ¡ centra zamÄ›Å™enÃ¡ na umÄ›lou inteligenci. Tento
  krok mÃ¡ zvÃ½Å¡it vÃ½kon a efektivitu AI Ãºloh dÃ­ky rychlejÅ¡Ã­ komunikaci mezi Äipy.
importance: 4
layout: tech_news_article
original_title: Arm to Offer Nvidiaâ€™s NVLink Technology in AI Data Center Chips
publishedAt: '2025-11-17T22:27:47+00:00'
slug: arm-to-offer-nvidias-nvlink-technology-in-ai-data-
source:
  emoji: ğŸ“°
  id: null
  name: Biztoc.com
title: Arm zaÄne nabÃ­zet technologii NVLink od Nvidie v Äipech pro AI datovÃ¡ centra
url: https://biztoc.com/x/b89c0d49b8f1bf78
urlToImage: https://biztoc.com/cdn/b89c0d49b8f1bf78_s.webp
urlToImageBackup: https://biztoc.com/cdn/b89c0d49b8f1bf78_s.webp
---

## Souhrn
Arm, britskÃ½ nÃ¡vrhÃ¡Å™ procesorovÃ½ch architektur, zaÄne integrovat propojovacÃ­ technologii NVLink od Nvidie do svÃ½ch ÄipÅ¯ urÄenÃ½ch pro datovÃ¡ centra specializovanÃ¡ na AI Ãºlohy. Tento krok umoÅ¾nÃ­ rychlejÅ¡Ã­ a efektivnÄ›jÅ¡Ã­ komunikaci mezi procesory a akcelerÃ¡tory, coÅ¾ je klÃ­ÄovÃ© pro Å¡kÃ¡lovÃ¡nÃ­ nÃ¡roÄnÃ½ch AI modelÅ¯.

## KlÃ­ÄovÃ© body
- Arm bude nabÃ­zet NVLink jako souÄÃ¡st svÃ½ch Å™eÅ¡enÃ­ pro datovÃ¡ centra.
- NVLink umoÅ¾Åˆuje vysokorychlostnÃ­ propojenÃ­ mezi GPU a CPU s niÅ¾Å¡Ã­ latencÃ­ neÅ¾ standardnÃ­ PCIe.
- SpoluprÃ¡ce posiluje ekosystÃ©m AI hardwaru mimo x86 architekturu.
- CÃ­lem je konkurovat Å™eÅ¡enÃ­m od Intelu a AMD v rychle rostoucÃ­m trhu AI infrastruktury.
- Integrace bude dostupnÃ¡ u budoucÃ­ch generacÃ­ Arm procesorÅ¯ pro serverovÃ© aplikace.

## Podrobnosti
NVLink je proprietÃ¡rnÃ­ propojovacÃ­ technologie od Nvidie, kterÃ¡ umoÅ¾Åˆuje pÅ™Ã­mou, vysokorychlostnÃ­ komunikaci mezi GPU a mezi GPU a CPU. Na rozdÃ­l od standardnÃ­ sbÄ›rnice PCIe, kterÃ¡ je univerzÃ¡lnÃ­, ale pomalejÅ¡Ã­ a s vyÅ¡Å¡Ã­ latencÃ­, NVLink nabÃ­zÃ­ Å¡Ã­Å™ku pÃ¡sma aÅ¾ desÃ­tky gigabajtÅ¯ za sekundu a lepÅ¡Ã­ Å¡kÃ¡lovatelnost pro paralelnÃ­ vÃ½poÄty. Arm nynÃ­ tuto technologii zaÄlenÃ­ do svÃ½ch serverovÃ½ch procesorÅ¯, coÅ¾ umoÅ¾nÃ­ vÃ½robcÅ¯m serverÅ¯ (napÅ™. Ampere, AWS nebo Fujitsu) vytvÃ¡Å™et systÃ©my optimalizovanÃ© pro trÃ©novÃ¡nÃ­ a inferenci velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM). Tento krok je logickÃ½m dÅ¯sledkem rostoucÃ­ho vyuÅ¾itÃ­ Arm architektury v datovÃ½ch centrech â€“ napÅ™Ã­klad AWS Graviton Äipy jiÅ¾ nÄ›kolik let konkuruje Intelu a AMD v bÄ›Å¾nÃ½ch cloudovÃ½ch ÃºlohÃ¡ch, nynÃ­ se vÅ¡ak Arm zamÄ›Å™uje i na nÃ¡roÄnÄ›jÅ¡Ã­ AI workloady. Integrace NVLink takÃ© sniÅ¾uje zÃ¡vislost na x86 platformÃ¡ch a posiluje ekosystÃ©m open-source a alternativnÃ­ch architektur.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato spoluprÃ¡ce mezi Armem a NvidiÃ­ mÃ¡ potenciÃ¡l pÅ™evÃ©st trh AI hardwaru smÄ›rem k vÄ›tÅ¡Ã­ diverzifikaci. ZatÃ­mco vÄ›tÅ¡ina AI datovÃ½ch center dnes bÄ›Å¾Ã­ na kombinaci x86 CPU a Nvidia GPU pÅ™es PCIe, novÃ© Arm-NVLink systÃ©my mohou nabÃ­dnout lepÅ¡Ã­ pomÄ›r vÃ½kon/spotÅ™eba a niÅ¾Å¡Ã­ nÃ¡klady na Å¡kÃ¡lovÃ¡nÃ­. Pro vÃ½vojÃ¡Å™e AI to znamenÃ¡ moÅ¾nost vyuÅ¾Ã­vat efektivnÄ›jÅ¡Ã­ infrastrukturu, zejmÃ©na u distribuovanÃ©ho trÃ©novÃ¡nÃ­ modelÅ¯. Z dlouhodobÃ©ho hlediska mÅ¯Å¾e tento trend oslabit postavenÃ­ Intelu a AMD v AI segmentu a urychlit pÅ™echod na specializovanÃ©, energeticky ÃºspornÃ© architektury â€“ coÅ¾ je klÃ­ÄovÃ© v dobÄ›, kdy spotÅ™eba energie AI datovÃ½mi centry rychle roste.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://biztoc.com/x/b89c0d49b8f1bf78)

**Zdroj:** ğŸ“° Biztoc.com
