---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2026-01-09 22:43:44'
description: VelkÃ© jazykovÃ© modely se â€neuÄÃ­â€œ â€“ kopÃ­rujÃ­. To by mohlo zÃ¡sadnÄ› ovlivnit
  technologickÃ½ prÅ¯mysl.
importance: 5
layout: tech_news_article
original_title: AI's Memorization Crisis
publishedAt: '2026-01-09T22:43:44+00:00'
slug: ais-memorization-crisis
source:
  emoji: ğŸ“°
  id: null
  name: The Atlantic
title: Krize memorizace v AI
url: https://www.theatlantic.com/technology/2026/01/ai-memorization-research/685552/
urlToImage: https://cdn.theatlantic.com/thumbor/uoz9_OY2pO-93_0emQxcOSAJICY=/0x32:1498x812/1200x625/media/img/mt/2026/01/2025_12_18_Ai_compress_mpg_landscape/original.gif
urlToImageBackup: https://cdn.theatlantic.com/thumbor/uoz9_OY2pO-93_0emQxcOSAJICY=/0x32:1498x812/1200x625/media/img/mt/2026/01/2025_12_18_Ai_compress_mpg_landscape/original.gif
---

## Souhrn
VÃ½zkumnÃ­ci ze StanfordskÃ© univerzity a Yaleovy univerzity prokÃ¡zali, Å¾e ÄtyÅ™i oblÃ­benÃ© velkÃ© jazykovÃ© modely â€“ OpenAI GPT, Anthropic Claude, Google Gemini a xAI Grok â€“ uklÃ¡dajÃ­ a dokÃ¡Å¾ou reprodukovat dlouhÃ© Ãºryvky z knih, na kterÃ½ch byly trÃ©novÃ¡ny. Model Claude napÅ™Ã­klad poskytl tÃ©mÄ›Å™ kompletnÃ­ text knihy Harry Potter a KÃ¡men mudrcÅ¯ nebo 1984 od George Orwella. Tento jev, oznaÄovanÃ½ jako memorizace, firmy dlouho popÃ­raly, ale studie ho jednoznaÄnÄ› potvrzuje.

## KlÃ­ÄovÃ© body
- TestovÃ¡no 13 knih, vÄetnÄ› Harry Potter a KÃ¡men mudrcÅ¯, VelkÃ½ Gatsby, 1984, Frankenstein, Hry o Å¾ivot a ZachytÃ¡vaÄ v Å¾itÄ›.
- Claude reprodukoval tisÃ­ce slov, jinÃ© modely menÅ¡Ã­ ÄÃ¡sti.
- AI firmy jako OpenAI a Google tvrdily, Å¾e modely neuklÃ¡dajÃ­ kopie trÃ©novacÃ­ch dat.
- Studie je souÄÃ¡stÃ­ Å¡irÅ¡Ã­ho vÃ½zkumu, vÄetnÄ› autorovÃ½ch zjiÅ¡tÄ›nÃ­ o memorizaci v obrazovÃ½ch modelech.
- Å½Ã¡dnÃ¡ z firem neposkytla komentÃ¡Å™ k Å¾Ã¡dostem o rozhovor.

## Podrobnosti
Studie publikovanÃ¡ tento ÃºterÃ½ analyzovala chovÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ pÅ™i specifickÃ½ch promptech navrÅ¾enÃ½ch tak, aby vyvolaly reprodukci trÃ©novacÃ­ch dat. VÃ½zkumnÃ­ci pouÅ¾ili strategie, kterÃ© modelmi donutily vrÃ¡tit dlouhÃ© pasÃ¡Å¾e z knih, kterÃ© byly souÄÃ¡stÃ­ jejich trÃ©novacÃ­ho korpusu. NapÅ™Ã­klad AnthropicÅ¯v Claude, model urÄenÃ½ pro generovÃ¡nÃ­ textu na zÃ¡kladÄ› kontextu, poskytl tÃ©mÄ›Å™ celÃ½ text Harry Potter a KÃ¡men mudrcÅ¯ od J. K. RowlingovÃ©, coÅ¾ pÅ™esahuje 70 tisÃ­c slov. PodobnÄ› se choval u klasik jako VelkÃ½ Gatsby od F. Scotta Fitzgeralda, 1984 od George Orwella nebo Frankenstein od Mary ShelleyovÃ©. OstatnÃ­ modely â€“ OpenAI GPT pro obecnÃ© Ãºlohy jako psanÃ­ textÅ¯ a kÃ³dovÃ¡nÃ­, Google Gemini pro multimodÃ¡lnÃ­ zpracovÃ¡nÃ­ textu a obrÃ¡zkÅ¯ nebo xAI Grok od Elona Muska pro rychlÃ© odpovÄ›di â€“ reprodukovaly rÅ¯znÃ© mnoÅ¾stvÃ­ tÄ›chto textÅ¯, i kdyÅ¾ v menÅ¡Ã­ mÃ­Å™e.

Tento objev pÅ™ichÃ¡zÃ­ v dobÄ›, kdy AI firmy opakovanÄ› popÃ­raly masovou memorizaci. V dopise americkÃ©mu ÃšÅ™adu pro autorskÃ© prÃ¡vo z roku 2023 OpenAI uvedla, Å¾e â€modely neuklÃ¡dajÃ­ kopie informacÃ­, ze kterÃ½ch se uÄÃ­â€œ. Google tvrdil, Å¾e â€v modelu nenÃ­ Å¾Ã¡dnÃ¡ kopie trÃ©novacÃ­ch dat, aÅ¥ uÅ¾ textu, obrÃ¡zkÅ¯ nebo jinÃ½ch formÃ¡tÅ¯â€œ. PodobnÃ¡ prohlÃ¡Å¡enÃ­ vydaly Anthropic, Meta nebo Microsoft. StanfordskÃ¡ studie vÅ¡ak dokazuje opak a navazuje na pÅ™edchozÃ­ vÃ½zkumy, kterÃ© ukazovaly na stejnÃ½ problÃ©m. Autor ÄlÃ¡nku v The Atlantic navÃ­c v vlastnÃ­ch testech zjistil, Å¾e i obrazovÃ© modely, jako ty generujÃ­cÃ­ umÄ›nÃ­ nebo fotografie na zÃ¡kladÄ› trÃ©novacÃ­ch dat, dokÃ¡Å¾ou reprodukovat pÅ¯vodnÃ­ dÃ­la.

Technicky lze memorizaci vysvÄ›tlit tak, Å¾e bÄ›hem trÃ©ninku na miliardÃ¡ch tokenÅ¯ (malÃ½ch textovÃ½ch jednotek) dochÃ¡zÃ­ k pÅ™Ã­liÅ¡nÃ©mu zapamatovÃ¡nÃ­ vzÃ¡cnÃ½ch nebo opakovanÃ½ch sekvencÃ­. Modely jako GPT-4 nebo Claude 3.5 jsou trÃ©novÃ¡ny na obÅ™Ã­ch datech z internetu, vÄetnÄ› chrÃ¡nÄ›nÃ½ch knih, bez souhlasu autorÅ¯. StrategickÃ© prompty, napÅ™Ã­klad opakovÃ¡nÃ­ ÃºryvkÅ¯ nebo kontextovÃ© vodÃ­tka, model pÅ™imÄ›jÃ­ vrÃ¡tit uloÅ¾enÃ© texty doslova.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento objev pÅ™edstavuje obrovskÃ© prÃ¡vnÃ­ riziko pro AI prÅ¯mysl. Pokud soudy uznajÃ­ reprodukci jako poruÅ¡enÃ­ autorskÃ©ho prÃ¡va, firmy ÄekajÃ­ miliardovÃ© odÅ¡kodnÃ© a moÅ¾nÃ© staÅ¾enÃ­ modelÅ¯ z trhu. UÅ¾ nynÃ­ probÃ­hajÃ­ soudy, jako New York Times proti OpenAI, kde se podobnÃ© argumenty objevujÃ­. ZpochybÅˆuje to zÃ¡kladnÃ­ narativ AI firem o â€uÄenÃ­ seâ€œ mÃ­sto kopÃ­rovÃ¡nÃ­, coÅ¾ ovlivÅˆuje regulace a veÅ™ejnÃ© vnÃ­mÃ¡nÃ­. Pro uÅ¾ivatele znamenÃ¡ riziko nechtÄ›nÃ©ho plagiÃ¡torstvÃ­ â€“ texty generovanÃ© AI mohou obsahovat chrÃ¡nÄ›nÃ½ obsah. V Å¡irÅ¡Ã­m kontextu nutÃ­ firmy zlepÅ¡it trÃ©novacÃ­ procesy, napÅ™Ã­klad lepÅ¡Ã­m ÄiÅ¡tÄ›nÃ­m dat nebo technikami jako differential privacy, kterÃ© minimalizujÃ­ memorizaci. Pokud se problÃ©m neÅ™eÅ¡Ã­, mÅ¯Å¾e zpÅ¯sobit zpomalenÃ­ vÃ½voje velkÃ½ch modelÅ¯ kvÅ¯li nedostatku legÃ¡lnÃ­ch dat. Tato studie tak nastavuje precedens pro budoucÃ­ vÃ½zkum bezpeÄnosti AI a etiky trÃ©ninku.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.theatlantic.com/technology/2026/01/ai-memorization-research/685552/)

**Zdroj:** ğŸ“° The Atlantic
