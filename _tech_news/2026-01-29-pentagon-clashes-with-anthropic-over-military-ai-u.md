---
author: Marisa Aigen
category: vojenskÃ© ai
companies:
- Anthropic
date: '2026-01-29 23:46:36'
description: Po tÃ½dnech jednÃ¡nÃ­ v rÃ¡mci smlouvy v hodnotÄ› aÅ¾ 200 milionÅ¯ dolarÅ¯ jsou
  americkÃ© ministerstvo obrany a Anthropic v patovÃ© situaci kvÅ¯li sporu o bezpeÄnostnÃ­
  omezenÃ­ AI.
importance: 4
layout: tech_news_article
original_title: 'Pentagon Clashes With Anthropic Over Military AI Use: Report'
publishedAt: '2026-01-29T23:46:36+00:00'
slug: pentagon-clashes-with-anthropic-over-military-ai-u
source:
  emoji: ğŸ“°
  id: null
  name: HuffPost
title: 'Pentagon se stÅ™etl s Anthropic kvÅ¯li vojenskÃ©mu vyuÅ¾itÃ­ AI: ZprÃ¡va'
url: https://www.huffpost.com/entry/pentagon-anthropic-eliminating-safeguards-artificial-intelligence_n_697bf09ce4b0d9ba36b46e74
urlToImage: https://img.huffingtonpost.com/asset/697bf0e42200007d0a6d8fb4.jpeg?ops=1200_630
urlToImageBackup: https://img.huffingtonpost.com/asset/697bf0e42200007d0a6d8fb4.jpeg?ops=1200_630
---

## Souhrn
AmerickÃ© ministerstvo obrany, znÃ¡mÃ© jako Pentagon, a spoleÄnost Anthropic, vÃ½vojÃ¡Å™ velkÃ½ch jazykovÃ½ch modelÅ¯ jako Claude, se neshodnou na podmÃ­nkÃ¡ch kontraktu za aÅ¾ 200 milionÅ¯ dolarÅ¯. Spor se soustÅ™edÃ­ na odstranÄ›nÃ­ bezpeÄnostnÃ­ch mechanismÅ¯, kterÃ© brÃ¡nÃ­ pouÅ¾itÃ­ AI k autonomnÃ­mu Å™Ã­zenÃ­ zbranÃ­ nebo domÃ¡cÃ­mu sledovÃ¡nÃ­ v USA. JednÃ¡nÃ­ uvÃ­zla v patu po tÃ½dnech diskusÃ­, coÅ¾ pÅ™edstavuje prvnÃ­ vÃ½znamnÃ½ test vlivu Silicon Valley na vojenskÃ© nasazenÃ­ AI.

## KlÃ­ÄovÃ© body
- Pentagon argumentuje, Å¾e komerÄnÃ­ AI lze nasadit bez ohledu na firemnÃ­ omezenÃ­, pokud splÅˆuje americkÃ© zÃ¡kony, podle memoranda z 9. ledna.
- Anthropic odmÃ­tÃ¡ odstranit bezpeÄnostnÃ­ prvky proti autonomnÃ­m zbranÃ­m a sledovÃ¡nÃ­, coÅ¾ zhorÅ¡uje napÄ›tÃ­ s Trumpovou administrativou.
- Kontrakt je souÄÃ¡stÃ­ Å¡irÅ¡Ã­ho zapojenÃ­ AI firem jako Google (Alphabet), xAI Elona Muska a OpenAI.
- Ministerstvo obrany bylo Trumpovou administrativou pÅ™ejmenovÃ¡no na Department of War.
- Anthropic hlÃ¡sÃ­, Å¾e jeho AI je jiÅ¾ Å¡iroce vyuÅ¾Ã­vÃ¡no pro nÃ¡rodnÃ­ bezpeÄnost a jednÃ¡nÃ­ pokraÄujÃ­ produktivnÄ›.

## Podrobnosti
Podle tÅ™Ã­ zdrojÅ¯ obeznÃ¡menÃ½ch se situacÃ­, kterÃ© mluvily pod podmÃ­nkou anonymity, Pentagon tlaÄÃ­ na Anthropic, aby povolil odstranÄ›nÃ­ tzv. bezpeÄnostnÃ­ch kolejÃ­ (safeguards) v jejich AI modelech. Tyto mechanismy zabraÅˆujÃ­ modelÅ¯m generovat instrukce pro autonomnÃ­ cÃ­lenÃ­ zbranÃ­ nebo analÃ½zu dat pro domÃ¡cÃ­ sledovÃ¡nÃ­, coÅ¾ je citlivÃ¡ oblast vzhledem k etickÃ½m a prÃ¡vnÃ­m rizikÅ¯m. Anthropic, zaloÅ¾enÃ½ v roce 2021 bÃ½valÃ½mi vÃ½vojÃ¡Å™i OpenAI, se specializuje na vÃ½voj bezpeÄnÃ½ch AI systÃ©mÅ¯ s dÅ¯razem na prevenci zneuÅ¾itÃ­, coÅ¾ je vidÄ›t v jejich modelu Claude, kterÃ½ slouÅ¾Ã­ k analÃ½ze textu, generovÃ¡nÃ­ kÃ³du a rozhodovacÃ­m procesÅ¯m, ale s vestavÄ›nÃ½mi limity proti Å¡kodlivÃ½m aplikacÃ­m.

Diskuse probÃ­hajÃ­ v kontextu memoranda ministerstva obrany z 9. ledna, kterÃ© definuje strategii pro AI a zdÅ¯razÅˆuje potÅ™ebu flexibility pÅ™i nasazovÃ¡nÃ­ komerÄnÃ­ch technologiÃ­ na bojiÅ¡ti. Pentagon vidÃ­ v AI nÃ¡stroje pro zpracovÃ¡nÃ­ dat ze senzorÅ¯, predikci hrozeb nebo optimalizaci logistiky, ale firemnÃ­ politiky jako ty od Anthropic brÃ¡nÃ­ plnÃ©mu vyuÅ¾itÃ­. Tento kontrakt, udÄ›lenÃ½ loni mezi nÄ›kolika firmami, mÄ›l umoÅ¾nit testovÃ¡nÃ­ AI v nÃ¡rodnÃ­ch bezpeÄnostnÃ­ch misÃ­ch. NapÄ›tÃ­ eskalovalo za Trumpovy administrativy, kterÃ¡ pÅ™ejmenovala ministerstvo na Department of War, signalizujÃ­c tvrdÅ¡Ã­ pÅ™Ã­stup k obranÄ›. Anthropic v prohlÃ¡Å¡enÃ­ potvrdil pokraÄujÃ­cÃ­ spoluprÃ¡ci, ale detaily zÅ¯stÃ¡vajÃ­ neveÅ™ejnÃ©. Tento pÅ™Ã­pad ilustruje Å¡irÅ¡Ã­ trend: po letech napÄ›tÃ­ mezi Silicon Vallejem a Washingtonem teÄ AI firmy dostÃ¡vajÃ­ velkÃ© zakÃ¡zky, ale ÄelÃ­ tlaku na Ãºstupky v bezpeÄnostnÃ­ch standardech. NapÅ™Ã­klad OpenAI uvolnilo omezenÃ­ pro armÃ¡dnÃ­ pouÅ¾itÃ­ v minulÃ©m roce, zatÃ­mco Anthropic zÅ¯stÃ¡vÃ¡ opatrnÄ›jÅ¡Ã­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento spor testuje hranice komerÄnÃ­ho AI v armÃ¡dnÃ­ch aplikacÃ­ch a mÅ¯Å¾e nastavit precedent pro dalÅ¡Ã­ firmy jako Google nebo xAI. Pokud Pentagon uspÄ›je, otevÅ™e to cestu k rychlejÅ¡Ã­mu nasazenÃ­ AI v autonomnÃ­ch systÃ©mech, coÅ¾ zvyÅ¡uje rizika chybnÃ©ho rozhodovÃ¡nÃ­ v boji nebo zneuÅ¾itÃ­ dat. Pro prÅ¯mysl to znamenÃ¡, Å¾e vÃ½vojÃ¡Å™i AI budou muset balancovat mezi etickÃ½mi standardy a vlÃ¡dnÃ­mi kontrakty, coÅ¾ ovlivnÃ­ investice do bezpeÄnostnÃ­ch vrstev. V Å¡irÅ¡Ã­m kontextu posiluje to debatu o regulaci AI zbranÃ­, kde USA soutÄ›Å¾Ã­ s ÄŒÃ­nou, a ukazuje, jak Trumpova administrativa mÄ›nÃ­ dynamiku vztahÅ¯ mezi tech sektorem a stÃ¡tem. DlouhodobÄ› to mÅ¯Å¾e vÃ©st k fragmentaci AI trhu, kde armÃ¡dnÃ­ verze budou mÃ©nÄ› bezpeÄnÃ© neÅ¾ civilnÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.huffpost.com/entry/pentagon-anthropic-eliminating-safeguards-artificial-intelligence_n_697bf09ce4b0d9ba36b46e74)

**Zdroj:** ğŸ“° HuffPost
