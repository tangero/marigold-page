---
author: Marisa Aigen
category: polovodiÄe
companies:
- Nvidia
- Groq
date: '2025-12-30 15:18:05'
description: Tato neakvizice umoÅ¾nÃ­ Nvidia diverzifikovat dodavatelskÃ© Å™etÄ›zce a vstoupit
  do novÃ½ch trhÅ¯, pÅ™iÄemÅ¾ se vyhne antimonopolnÃ­mu dohledu.
importance: 4
layout: tech_news_article
original_title: Nvidia licenses Groqâ€™s inferencing chip tech and hires its leaders
publishedAt: '2025-12-30T15:18:05+00:00'
slug: nvidia-licenses-groqs-inferencing-chip-tech-and-hi
source:
  emoji: ğŸ“°
  id: null
  name: Network World
title: Nvidia licencuje technologii inferenÄnÃ­ch ÄipÅ¯ od Groq a najÃ­mÃ¡ jejÃ­ lÃ­dry
url: https://www.networkworld.com/article/4112131/nvidia-licenses-groqs-inferencing-chip-tech-and-hires-its-leaders.html
urlToImage: https://www.networkworld.com/wp-content/uploads/2025/12/4112131-0-24168400-1767107688-Groq.jpg?quality=50&strip=all&w=1024
urlToImageBackup: https://www.networkworld.com/wp-content/uploads/2025/12/4112131-0-24168400-1767107688-Groq.jpg?quality=50&strip=all&w=1024
---

## Souhrn
Nvidia zÃ­skala neexkluzivnÃ­ licenci na duÅ¡evnÃ­ vlastnictvÃ­ (IP) spoleÄnosti Groq pro technologii inferenÄnÃ­ch ÄipÅ¯ a najala si nÄ›kolik jejÃ­ch klÃ­ÄovÃ½ch lÃ­drÅ¯, vÄetnÄ› zakladatele Jonathana Rosse a prezidenta Sunnyho Madry. Tento krok nenÃ­ plnohodnotnou akvizicÃ­, ale mÃ¡ pomoci Nvidia posÃ­lit svou pozici v oblasti AI inferencingu. Deal mÅ¯Å¾e mÃ­t hodnotu aÅ¾ 20 miliard USD.

## KlÃ­ÄovÃ© body
- Nvidia licencovala IP pro LPUs (language processing units), Äipy optimalizovanÃ© pro AI inferencing.
- PÅ™echod vrcholovÃ½ch manaÅ¾erÅ¯ z Groq do Nvidia pro dalÅ¡Ã­ rozvoj technologie.
- Groq provozuje sluÅ¾bu GroqCloud pro inferencing jako sluÅ¾bu.
- Å˜eÅ¡enÃ­ napÄ›tÃ­ v dodavatelskÃ©m Å™etÄ›zci, zejmÃ©na nedostatku vysokopÃ¡smovÃ© pamÄ›ti (HBM).
- VyhnutÃ­ se antimonopolnÃ­mu dohledu dÃ­ky formÄ› licencovÃ¡nÃ­ mÃ­sto akvizice.

## Podrobnosti
SpoleÄnost Groq se specializuje na nÃ¡vrh a vÃ½robu ÄipÅ¯ urÄenÃ½ch pÅ™edevÅ¡Ã­m pro fÃ¡zi inferencingu v umÄ›lÃ© inteligenci, tedy pro spouÅ¡tÄ›nÃ­ hotovÃ½ch AI modelÅ¯ v produkÄnÃ­m prostÅ™edÃ­. Na rozdÃ­l od grafickÃ½ch procesorÅ¯ (GPU) od Nvidia, kterÃ© jsou primÃ¡rnÄ› urÄeny pro trÃ©nink modelÅ¯ a vyÅ¾adujÃ­ vysokÃ½ vÃ½kon i spotÅ™ebu energie, jsou LPUs od Groq mÃ©nÄ› nÃ¡roÄnÃ© na energii a levnÄ›jÅ¡Ã­. Tyto Äipy umoÅ¾ÅˆujÃ­ rychlÃ© zpracovÃ¡nÃ­ jazykovÃ½ch Ãºloh, jako je generovÃ¡nÃ­ textu v modelech typu large language models (LLM), coÅ¾ je klÃ­ÄovÃ© pro aplikace jako chatboti nebo real-time AI sluÅ¾by.

Nvidia potvrdila, Å¾e licencovala tuto technologii neexkluzivnÄ› a integrovala do svÃ©ho tÃ½mu inÅ¾enÃ½ry z Groq. Podle mluvÄÃ­ho Nvidia jde o posÃ­lenÃ­ mise v oblasti akcelerovanÃ©ho vÃ½poÄtu. Groq sama oznÃ¡mila dohodu 24. prosince, kde zdÅ¯raznila, Å¾e licence zahrnuje jejich inferenÄnÃ­ technologii a pÅ™echod klÃ­ÄovÃ½ch osobnostÃ­ pro Å¡kÃ¡lovÃ¡nÃ­. Tento krok pÅ™ichÃ¡zÃ­ v dobÄ›, kdy Nvidia ÄelÃ­ tlaku v dodavatelskÃ©m Å™etÄ›zci: jejÃ­ CFO v poslednÃ­ kvartÃ¡lnÃ­ zprÃ¡vÄ› uvedl, Å¾e mnoho ÄipÅ¯ je vyprodanÃ½ch kvÅ¯li nedostatku vysokopÃ¡smovÃ© pamÄ›ti (HBM), kterÃ¡ je nezbytnÃ¡ pro AI aplikace. Analytici poukazujÃ­, Å¾e LPUs od Groq by mohly pomoci snÃ­Å¾it zÃ¡vislost na tÃ©to pamÄ›ti tÃ­m, Å¾e optimalizujÃ­ architekturu pro inferencing.

Groq navÃ­c nabÃ­zÃ­ svÃ© Äipy prostÅ™ednictvÃ­m GroqCloud, platformy pro inferencing jako sluÅ¾bu, kde uÅ¾ivatelÃ© platÃ­ za pouÅ¾itÃ­ bez nutnosti vlastnÃ­ho hardwaru. To rozÅ¡iÅ™uje trh za hranice velkÃ½ch datovÃ½ch center. Nvidia tak zÃ­skÃ¡vÃ¡ pÅ™Ã­stup k tÃ©to technologii bez plnÃ©ho vlastnictvÃ­, coÅ¾ minimalizuje rizika spojenÃ¡ s regulaÄnÃ­mi orgÃ¡ny, jako je FTC v USA, kterÃ© intenzivnÄ› dohlÃ­Å¾ejÃ­ na akvizice v AI sektoru.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento deal signalizuje posun v AI hardwaru od dominance GPU v trÃ©ninku k rostoucÃ­mu dÅ¯razu na inferencing, kterÃ½ tvoÅ™Ã­ vÄ›tÅ¡inu budoucÃ­ho objemu AI vÃ½poÄtÅ¯. Pro Nvidia pÅ™edstavuje diverzifikaci: s rostoucÃ­m tlakem na supply chain a konkurencÃ­ od firem jako AMD nebo custom ÄipÅ¯ od Google (TPU) a Amazonu (Trainium) potÅ™ebuje alternativy k HBM. Pro prÅ¯mysl znamenÃ¡ levnÄ›jÅ¡Ã­ inferencing niÅ¾Å¡Ã­ nÃ¡klady na nasazenÃ­ AI modelÅ¯, coÅ¾ urychlÃ­ adopci v edge computingu nebo menÅ¡Ã­ch firmÃ¡ch. NavÃ­c hiring lÃ­drÅ¯ z Groq posiluje Nvidia inÅ¾enÃ½rskÃ½ tÃ½m, coÅ¾ mÅ¯Å¾e vÃ©st k hybridnÃ­m Å™eÅ¡enÃ­m GPU+LPU. V Å¡irÅ¡Ã­m kontextu to ukazuje, jak giganti jako Nvidia kupujÃ­ inovace bez akvizic, aby se vyhnuli antitrustovÃ½m bariÃ©rÃ¡m, coÅ¾ ovlivnÃ­ konsolidaci v polovodiÄovÃ©m sektoru. CelkovÄ› posiluje Nvidia svou hegemonii v AI, zatÃ­mco Groq zÃ­skÃ¡vÃ¡ kapitÃ¡l pro dalÅ¡Ã­ rÅ¯st.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.networkworld.com/article/4112131/nvidia-licenses-groqs-inferencing-chip-tech-and-hires-its-leaders.html)

**Zdroj:** ğŸ“° Network World
