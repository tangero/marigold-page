---
author: Marisa Aigen
category: kyberbezpeÄnost
date: '2025-11-18 06:05:40'
description: VyuÅ¾itÃ­ AI chatbotÅ¯ vyvolÃ¡vÃ¡ prÃ¡vnÃ­ rizika spojenÃ¡ s federÃ¡lnÃ­mi i stÃ¡tnÃ­mi
  zÃ¡kony proti odposlechu, coÅ¾ vede k novÃ½m Å¾alobÃ¡m a nejistotÄ› ohlednÄ› pojiÅ¡tÄ›nÃ­.
importance: 3
layout: tech_news_article
original_title: What security pros should know about insurance coverage for AI chatbot
  wiretapping claims
publishedAt: '2025-11-18T06:05:40+00:00'
slug: what-security-pros-should-know-about-insurance-cov
source:
  emoji: ğŸ“°
  id: null
  name: Help Net Security
title: Co by mÄ›li bezpeÄnostnÃ­ odbornÃ­ci vÄ›dÄ›t o pojiÅ¡tÄ›nÃ­ proti nÃ¡rokÅ¯m za odposlech
  prostÅ™ednictvÃ­m AI chatbotÅ¯
url: https://www.helpnetsecurity.com/2025/11/18/stephanie-gee-reed-smith-ai-chatbot-legal-risks/
urlToImage: https://img.helpnetsecurity.com/wp-content/uploads/2025/11/17175956/stephanie_gee-2-reed_smith.webp
urlToImageBackup: https://img.helpnetsecurity.com/wp-content/uploads/2025/11/17175956/stephanie_gee-2-reed_smith.webp
---

## Souhrn
VyuÅ¾Ã­vÃ¡nÃ­ AI chatbotÅ¯ v podnikÃ¡nÃ­ pÅ™inÃ¡Å¡Ã­ novÃ¡ prÃ¡vnÃ­ rizika spojenÃ¡ s federÃ¡lnÃ­mi a stÃ¡tnÃ­mi zÃ¡kony proti odposlechu a tajnÃ©mu zaznamenÃ¡vÃ¡nÃ­ komunikace. NedÃ¡vnÃ© Å¾aloby testujÃ­, zda tyto technologie poruÅ¡ujÃ­ soukromÃ­ uÅ¾ivatelÅ¯, a zÃ¡roveÅˆ vznikÃ¡ nejistota, zda existujÃ­cÃ­ pojiÅ¡tÄ›nÃ­ kryje nÃ¡roky vzniklÃ© z takovÃ©ho pouÅ¾itÃ­.

## KlÃ­ÄovÃ© body
- AI chatboty mohou zaznamenÃ¡vat obsahovÄ› bohatÃ© konverzace, coÅ¾ je prÃ¡vnÄ› citlivÄ›jÅ¡Ã­ neÅ¾ sbÄ›r anonymnÃ­ch dat (napÅ™. cookies).
- Soudy posuzujÃ­, zda zÃ¡znam konverzacÃ­ bez vÃ½slovnÃ©ho souhlasu poruÅ¡uje zÃ¡kony proti odposlechu.
- TradiÄnÃ­ pojiÅ¡tÄ›nÃ­ kybernetickÃ©ho rizika nemusÃ­ pokrÃ½vat nÃ¡roky vzniklÃ© z pouÅ¾itÃ­ AI chatbotÅ¯.
- PrÃ¡vnÃ­ rÃ¡mec se liÅ¡Ã­ podle stÃ¡tu â€“ nÄ›kterÃ© jurisdikce vyÅ¾adujÃ­ souhlas vÅ¡ech stran zapojenÃ½ch do komunikace.
- BezpeÄnostnÃ­ profesionÃ¡lovÃ© by mÄ›li pÅ™ezkoumat pojistnÃ© smlouvy a zvÃ¡Å¾it specializovanÃ© krytÃ­.

## Podrobnosti
AI chatboty, kterÃ© komunikujÃ­ s uÅ¾ivateli v reÃ¡lnÃ©m Äase, Äasto uklÃ¡dajÃ­ celÃ© konverzace pro ÃºÄely trÃ©novÃ¡nÃ­ modelÅ¯ nebo analÃ½zy. Na rozdÃ­l od technologiÃ­ jako session replay (kterÃ© zaznamenÃ¡vajÃ­ pouze pohyby myÅ¡Ã­ a kliknutÃ­), chatboty zachycujÃ­ skuteÄnÃ½ obsah komunikace â€“ coÅ¾ mÅ¯Å¾e podle nÄ›kterÃ½ch zÃ¡konÅ¯ (napÅ™. California Invasion of Privacy Act) vyÅ¾adovat vÃ½slovnÃ½ souhlas vÅ¡ech ÃºÄastnÃ­kÅ¯. V poslednÃ­ch mÄ›sÃ­cÃ­ch se objevily Å¾aloby proti spoleÄnostem, kterÃ© nasazujÃ­ chatboty bez dostateÄnÃ©ho informovÃ¡nÃ­ uÅ¾ivatelÅ¯ o zÃ¡znamu. Stephanie Gee z advokÃ¡tnÃ­ kancelÃ¡Å™e Reed Smith upozorÅˆuje, Å¾e pojistnÃ© smlouvy Äasto obsahujÃ­ vÃ½jimky pro poruÅ¡enÃ­ soukromÃ­ nebo zÃ¡mÄ›rnÃ¡ poruÅ¡enÃ­ zÃ¡konÅ¯, coÅ¾ mÅ¯Å¾e vÃ©st k odmÃ­tnutÃ­ krytÃ­ nÃ¡rokÅ¯. BezpeÄnostnÃ­ tÃ½my by proto mÄ›ly spolupracovat s prÃ¡vnÃ­ky a pojistnÃ½mi maklÃ©Å™i na pÅ™esnÃ© definici rizik spojenÃ½ch s AI a na ÃºpravÄ› pojistnÃ½ch podmÃ­nek.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento trend ukazuje, Å¾e nasazenÃ­ AI nenÃ­ jen technologickou, ale i prÃ¡vnÃ­ a pojiÅ¡Å¥ovacÃ­ vÃ½zvou. SpoleÄnosti, kterÃ© chatboty pouÅ¾Ã­vajÃ­ pro zÃ¡kaznickou podporu nebo internÃ­ komunikaci, mohou Äelit vysokÃ½m nÃ¡kladÅ¯m na obranu i nÃ¡hradÃ¡m Å¡kod. ZÃ¡roveÅˆ se formuje novÃ¡ kategorie rizik, kterou tradiÄnÃ­ kyberpojiÅ¡tÄ›nÃ­ neÅ™eÅ¡Ã­ dostateÄnÄ›. Vzhledem k rostoucÃ­mu vyuÅ¾itÃ­ LLM (large language models) v podnikovÃ©m prostÅ™edÃ­ je nutnÃ© tyto aspekty Å™eÅ¡it preventivnÄ› â€“ ne aÅ¾ po podÃ¡nÃ­ Å¾aloby.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.helpnetsecurity.com/2025/11/18/stephanie-gee-reed-smith-ai-chatbot-legal-risks/)

**Zdroj:** ğŸ“° Help Net Security
