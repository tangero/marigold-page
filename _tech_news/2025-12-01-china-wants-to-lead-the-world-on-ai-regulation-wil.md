---
author: Marisa Aigen
category: regulace ai
date: '2025-12-01 00:00:00'
description: ÄŒÃ­na, kterÃ¡ umÄ›lou inteligenci umÃ­stila do centra svÃ© ekonomickÃ© strategie,
  vede snahy o vytvoÅ™enÃ­ mezinÃ¡rodnÃ­ho systÃ©mu pro Å™Ã­zenÃ­ pouÅ¾itÃ­ tÃ©to technologie.
importance: 3
layout: tech_news_article
original_title: China wants to lead the world on AI regulation â€” will the plan work?
publishedAt: '2025-12-01T00:00:00+00:00'
slug: china-wants-to-lead-the-world-on-ai-regulation-wil
source:
  emoji: ğŸ“°
  id: null
  name: Nature.com
title: ÄŒÃ­na chce vÃ©st svÄ›t v regulaci umÄ›lÃ© inteligence â€“ uspÄ›je tento plÃ¡n?
url: https://www.nature.com/articles/d41586-025-03902-y
urlToImage: https://media.nature.com/lw1200/magazine-assets/d41586-025-03902-y/d41586-025-03902-y_51767196.jpg
urlToImageBackup: https://media.nature.com/lw1200/magazine-assets/d41586-025-03902-y/d41586-025-03902-y_51767196.jpg
---

## Souhrn
ÄŒÃ­na aktivnÄ› prosazuje globÃ¡lnÃ­ regulaci umÄ›lÃ© inteligence prostÅ™ednictvÃ­m nÃ¡vrhu na zaloÅ¾enÃ­ SvÄ›tovÃ© organizace pro spoluprÃ¡ci v oblasti umÄ›lÃ© inteligence (WAICO). Tento krok prezentoval prezident Si Å¤in-pching na zasedÃ¡nÃ­ fÃ³ra Asijsko-tichomoÅ™skÃ© hospodÃ¡Å™skÃ© spoluprÃ¡ce (APEC) v Å™Ã­jnu. NÃ¡vrh kontrastuje s pÅ™Ã­stupem USA zamÄ›Å™enÃ½m na deregulaci a odrÃ¡Å¾Ã­ ÄÃ­nskou touhu ovlÃ¡dnout mezinÃ¡rodnÃ­ normy pro AI.

## KlÃ­ÄovÃ© body
- ÄŒÃ­na navrhuje WAICO jako platformu pro mezinÃ¡rodnÃ­ spoluprÃ¡ci na globÃ¡lnÃ­ governance AI.
- ÄŒÃ­nskÃ© firmy vydÃ¡vajÃ­ AI modely jako open weight, coÅ¾ umoÅ¾Åˆuje jejich staÅ¾enÃ­ a dalÅ¡Ã­ vÃ½voj.
- Na rozdÃ­l od ZÃ¡padu se ÄŒÃ­na mÃ©nÄ› zamÄ›Å™uje na umÄ›lou obecnÃ© inteligence (AGI) a vÃ­ce na praktickÃ© aplikace AI.
- Expertka Wendy Hall z University of Southampton oznaÄila ÄŒÃ­nu za â€dobrÃ©ho chlapa" v oblasti transparentnosti AI politiky.
- CÃ­lem je vytvoÅ™it zÃ¡vaznÃ© mezinÃ¡rodnÃ­ dohody podobnÃ© tÄ›m pro jadernou energii nebo letectvÃ­.

## Podrobnosti
ÄŒlÃ¡nek popisuje situaci, kdy svÄ›t stÃ¡le postrÃ¡dÃ¡ jednotnou regulaci umÄ›lÃ© inteligence, pÅ™estoÅ¾e rizika zahrnujÃ­ prohlubovÃ¡nÃ­ nerovnostÃ­ aÅ¾ po existenciÃ¡lnÃ­ hrozby. ExistujÃ­ nÃ¡rodnÃ­ a regionÃ¡lnÃ­ pÅ™edpisy, ale globÃ¡lnÃ­ rÃ¡mec chybÃ­. Na zasedÃ¡nÃ­ APEC v jiÅ¾nÃ­ Koreji v Å™Ã­jnu Si Å¤in-pching znovu navrhl WAICO, kterÃ¡ by slouÅ¾ila jako krok k vytvoÅ™enÃ­ systÃ©mu globÃ¡lnÃ­ho Å™Ã­zenÃ­ AI. Tento nÃ¡vrh je souÄÃ¡stÃ­ Å¡irÅ¡Ã­ ÄÃ­nskÃ© strategie sebeosamostatnÄ›nÃ­ vÄ›dy v pÄ›tiletÃ©m plÃ¡nu a snahy vÃ©st regulaci AI, na rozdÃ­l od USA, kde pÅ™evaÅ¾uje deregulace.

ÄŒÃ­nskÃ½ ekosystÃ©m AI se liÅ¡Ã­ od zÃ¡padnÃ­ho. Podporou vlÃ¡dy ÄÃ­nskÃ© firmy vydÃ¡vajÃ­ modely jako open weight â€“ tedy s veÅ™ejnÄ› dostupnÃ½mi vÃ¡hami, kterÃ© lze stÃ¡hnout a dÃ¡le upravovat pro specifickÃ© aplikace, jako je zpracovÃ¡nÃ­ obrazu nebo pÅ™eklady. To umoÅ¾Åˆuje rychlejÅ¡Ã­ Å¡Ã­Å™enÃ­ a adaptaci modelÅ¯ v prÅ¯myslu. Na rozdÃ­l od USA nebo Evropy, kde je priorita vÃ½voj AGI â€“ systÃ©mu schopnÃ©ho pÅ™ekonat lidskou inteligenci ve vÅ¡ech oblastech â€“, se ÄŒÃ­na soustÅ™edÃ­ na komerÄnÃ­ vyuÅ¾itÃ­ AI v oblastech jako logistika, zdravotnictvÃ­ nebo surveillance. NapÅ™Ã­klad modely od firem jako Baidu nebo Alibaba jsou optimalizovÃ¡ny pro masovÃ© nasazenÃ­ v ÄÃ­nskÃ© ekonomice.

PÅ™ekÃ¡Å¾ky pro zaloÅ¾enÃ­ WAICO jsou vÃ½znamnÃ©: geopolitickÃ© napÄ›tÃ­ mezi USA a ÄŒÃ­nou, rozdÃ­lnÃ© priority (ZÃ¡pad zdÅ¯razÅˆuje etiku a bezpeÄnost AGI, ÄŒÃ­na efektivitu) a absence konsenzu. PÅ™esto nÄ›kteÅ™Ã­ experti, jako Wendy Hall, chvÃ¡lÃ­ ÄÃ­nskou transparentnost v politice AI. SrovnÃ¡vajÃ­ to s ÃºspÄ›Å¡nÃ½mi dohodami pro jadernou energii (napÅ™. NPT) nebo letectvÃ­ (ICAO), kde rizikovÃ© technologie zÃ­skaly globÃ¡lnÃ­ normy. ÄŒÃ­na tak vyuÅ¾Ã­vÃ¡ svou ekonomickou vÃ¡hu â€“ je nejvÄ›tÅ¡Ã­m trhem pro AI hardware â€“ k prosazovÃ¡nÃ­ svÃ½ch standardÅ¯, coÅ¾ by mohlo ovlivnit vÃ½voj modelÅ¯ po celÃ©m svÄ›tÄ›.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento ÄÃ­nskÃ½ tah mÅ¯Å¾e formovat globÃ¡lnÃ­ normy pro AI, coÅ¾ ovlivnÃ­ vÃ½vojÃ¡Å™e, firmy i stÃ¡ty. Pokud WAICO vznikne, mohla by standardizovat bezpeÄnostnÃ­ testy modelÅ¯, sdÃ­lenÃ­ dat nebo etickÃ© smÄ›rnice, coÅ¾ by zpomalilo neÅ™Ã­zenÃ½ rÅ¯st AI v USA. Pro evropskÃ© uÅ¾ivatele by to znamenalo harmonizaci s EU AI Act, ale riziko je v ÄÃ­nskÃ©m vlivu na surveillance nÃ¡stroje. V Å¡irÅ¡Ã­m kontextu posiluje to soutÄ›Å¾ mezi supervelmocemi o kontrolu nad AI, coÅ¾ by mohlo vÃ©st k fragmentaci technologie mÃ­sto spoluprÃ¡ce. DlouhodobÄ› by ÃºspÄ›Å¡nÃ¡ regulace snÃ­Å¾ila rizika, jako je zneuÅ¾itÃ­ deepfake nebo bias v modelech, ale selhÃ¡nÃ­ by prohloubilo globÃ¡lnÃ­ rozdÃ­ly v pÅ™Ã­stupu k AI.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.nature.com/articles/d41586-025-03902-y)

**Zdroj:** ğŸ“° Nature.com
