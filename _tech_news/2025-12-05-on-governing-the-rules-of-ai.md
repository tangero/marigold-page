---
author: Marisa Aigen
category: regulace ai
date: '2025-12-05 19:19:13'
description: V tÃ©to epizodÄ› diskutujÃ­ experti o geopolitickÃ½ch dopadech transformaÄnÃ­ch
  technologiÃ­ jako umÄ›lÃ¡ inteligence (AI), vÄetnÄ› navigace Å™Ã­zenÃ­m, vyvaÅ¾ovÃ¡nÃ­ inovacÃ­
  s riziky a Å™eÅ¡enÃ­ otÃ¡zek rovnosti a odpovÄ›dnosti.
importance: 3
layout: tech_news_article
original_title: On Governing the Rules of AI
publishedAt: '2025-12-05T19:19:13+00:00'
slug: on-governing-the-rules-of-ai
source:
  emoji: ğŸ“°
  id: null
  name: Podbean.com
title: O Å™Ã­zenÃ­ pravidel umÄ›lÃ© inteligence
url: https://cfrontherecord.podbean.com/e/on-the-rules-of-ai/
urlToImage: https://d2bwo9zemjwxh5.cloudfront.net/image-logo/21286471/CFR-Events-Audio_1200x628.jpg?s=9c40a9b8875599ce2c49ac0507112cdf&e=jpeg
urlToImageBackup: https://d2bwo9zemjwxh5.cloudfront.net/image-logo/21286471/CFR-Events-Audio_1200x628.jpg?s=9c40a9b8875599ce2c49ac0507112cdf&e=jpeg
---

## Souhrn
V epizodÄ› podcastu od Council on Foreign Relations experti rozebÃ­rajÃ­ geopolitickÃ© aspekty umÄ›lÃ© inteligence (AI), zamÄ›Å™ujÃ­ se na vÃ½zvy Å™Ã­zenÃ­, rovnovÃ¡hu mezi inovacemi a riziky a otÃ¡zky spravedlnosti. Diskuse zahrnuje hosty jako profesorku Lauru DeNardisovou, Vinh Nguyena a Miriam Vogelovou, kteÅ™Ã­ analyzujÃ­, jak stÃ¡ty a firmy Å™eÅ¡Ã­ tyto problÃ©my.

## KlÃ­ÄovÃ© body
- GeopolitickÃ© dopady AI: Jak transformaÄnÃ­ technologie ovlivÅˆujÃ­ mezinÃ¡rodnÃ­ vztahy a nÃ¡rodnÃ­ bezpeÄnost.
- Å˜Ã­zenÃ­ AI: Strategie rozhodovatelÅ¯ pro nastavenÃ­ pravidel, kterÃ© chrÃ¡nÃ­ pÅ™ed riziky bez brzdenÃ­ pokroku.
- Rovnost a odpovÄ›dnost: Diskuse o tom, jak zajistit spravedlivÃ½ pÅ™Ã­stup k AI a odpovÄ›dnost za jejÃ­ chyby.
- DoporuÄenÃ© ÄtenÃ­: ÄŒlÃ¡nky o pÅ™Ã­spÄ›vku AI k ekonomickÃ©mu rÅ¯stu USA a ochranÄ› AI systÃ©mÅ¯ v demokraciÃ­ch.

## Podrobnosti
Epizoda s nÃ¡zvem â€On Governing the Rules of AIâ€œ moderovanÃ¡ Maryam Mujicovou, hlavnÃ­ Å™editelkou pro veÅ™ejnou politiku ve firmÄ› General Catalyst, se konala pÅ™ed dvÄ›ma dny a je dostupnÃ¡ na YouTube kanÃ¡lu Council on Foreign Relations. General Catalyst je venture kapitÃ¡lovÃ¡ spoleÄnost zamÄ›Å™enÃ¡ na investice do technologickÃ½ch startupÅ¯, vÄetnÄ› tÄ›ch v oblasti AI. MujicovÃ¡ vede debatu s tÅ™emi experty: Laurou DeNardisovou, profesorkou a Å™editelkou Centra pro digitÃ¡lnÃ­ etiku na Georgetown University, kterÃ¡ se specializuje na etiku technologiÃ­ a spoleÄenskÃ© dopady; Vinh Nguyenem, senior fellowem pro AI v Council on Foreign Relations, think-tanku zabÃ½vajÃ­cÃ­m se zahraniÄnÃ­ politikou USA; a Miriam Vogelovou, autorkou knihy â€Governing the Machine: How to Navigate the Risks of AI and Unlock Its True Potentialâ€œ, kterÃ¡ je prezidentkou a vÃ½konnou Å™editelkou EqualAI, organizace vÄ›novanÃ© etickÃ©mu nasazenÃ­ AI.

Diskuse se soustÅ™edÃ­ na to, jak AI mÄ›nÃ­ geopolitickou mapu svÄ›ta. Experti zdÅ¯razÅˆujÃ­, Å¾e AI nenÃ­ jen technologickÃ½ nÃ¡stroj, ale strategickÃ½ prvek, kterÃ½ ovlivÅˆuje hospodÃ¡Å™skou konkurenceschopnost, vojenskÃ© schopnosti a globÃ¡lnÃ­ mocenskÃ© pomÄ›ry. NapÅ™Ã­klad USA a ÄŒÃ­na soutÄ›Å¾Ã­ o vedenÃ­ v AI, coÅ¾ zvyÅ¡uje potÅ™ebu regulacÃ­, kterÃ© brÃ¡nÃ­ zneuÅ¾itÃ­, jako je Å¡Ã­Å™enÃ­ dezinformacÃ­ nebo autonomnÃ­ zbranÄ›. DeNardisovÃ¡ poukazuje na nutnost zachovat dÅ¯vÄ›ru v instituce tÃ­m, Å¾e se demokratickÃ© zemÄ› zamÄ›Å™Ã­ na transparentnÃ­ standardy pro AI systÃ©my, zatÃ­mco autoritÃ¡Å™skÃ© reÅ¾imy mohou AI vyuÅ¾Ã­t k dohledu nad obÄany.

Nguyen analyzuje, zda investice do AI pÅ™ispÃ­vajÃ­ k ekonomickÃ©mu rÅ¯stu USA â€“ odkazuje na doprovodnÃ½ ÄlÃ¡nek, kterÃ½ hodnotÃ­, Å¾e zatÃ­m pÅ™Ã­nos nenÃ­ tak vÃ½znamnÃ½, jak se oÄekÃ¡valo, kvÅ¯li vysokÃ½m nÃ¡kladÅ¯m na trÃ©nink modelÅ¯ jako GPT nebo Gemini. VogelovÃ¡, s ohledem na svou knihu, navrhuje rÃ¡mce pro navigaci rizik: od auditu AI algoritmÅ¯ pro bias aÅ¾ po odpovÄ›dnost firem za Å¡kody zpÅ¯sobenÃ© chybnÃ½mi rozhodnutÃ­mi AI, napÅ™Ã­klad v oblasti nÃ¡boru zamÄ›stnancÅ¯ nebo soudnÃ­ch rozhodnutÃ­. Epizoda doporuÄuje odbÄ›r Daily News Brief newsletteru CFR a sledovÃ¡nÃ­ jejich udÃ¡lostÃ­ na cfr.org/event. CelkovÄ› jde o praktickou diskusi bez konkrÃ©tnÃ­ch legislativnÃ­ch nÃ¡vrhÅ¯, ale s dÅ¯razem na to, Å¾e absence regulacÃ­ vede k fragmentaci standardÅ¯ mezi stÃ¡ty.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato debata podtrhuje, Å¾e regulace AI nenÃ­ jen teoretickÃ¡ zÃ¡leÅ¾itost, ale klÃ­ÄovÃ½ faktor pro udrÅ¾enÃ­ technologickÃ© pÅ™evahy ZÃ¡padu. V Å¡irÅ¡Ã­m kontextu, kde AI modely jako large language models (LLM) umoÅ¾ÅˆujÃ­ rychlÃ© Å¡kÃ¡lovÃ¡nÃ­ aplikacÃ­ od automatizace k prediktivnÃ­ analÃ½ze, absence koordinovanÃ©ho Å™Ã­zenÃ­ hrozÃ­ eskalacÃ­ rizik, jako kybernetickÃ© Ãºtoky nebo sociÃ¡lnÃ­ nerovnosti. Pro prÅ¯mysl to znamenÃ¡ potÅ™ebu standardÅ¯, kterÃ© usnadnÃ­ compliance bez zvyÅ¡ovÃ¡nÃ­ nÃ¡kladÅ¯ na vÃ½voj â€“ napÅ™Ã­klad open-source rÃ¡mce pro etickÃ© testovÃ¡nÃ­. Pro uÅ¾ivatele to pÅ™inÃ¡Å¡Ã­ lepÅ¡Ã­ ochranu pÅ™ed diskriminacÃ­ v AI systÃ©mech, jako jsou chatboti nebo doporuÄovacÃ­ algoritmy. V dobÄ›, kdy EU pÅ™ijÃ­mÃ¡ AI Act a USA zvaÅ¾ujÃ­ vÃ½konnÃ¡ opatÅ™enÃ­, takovÃ© diskuze pomÃ¡hajÃ­ formovat politiku, kterÃ¡ chrÃ¡nÃ­ inovace pÅ™ed pÅ™Ã­liÅ¡nou byrokraciÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://cfrontherecord.podbean.com/e/on-the-rules-of-ai/)

**Zdroj:** ğŸ“° Podbean.com
