---
author: Marisa Aigen
category: polovodiÄe
companies:
- SK hynix
date: '2025-12-29 08:15:06'
description: Podle ZDNet Korea SK hynix posuzuje vÃ½stavbu prvnÃ­ masovÃ© vÃ½robnÃ­ linky
  pro 2.5D pokroÄilÃ© balenÃ­ v USA, coÅ¾ by prohloubilo roli tohoto jihokorejskÃ©ho vÃ½robce
  pamÄ›tÃ­ v dodÃ¡vkÃ¡ch pro systÃ©my umÄ›lÃ© inteligence. PlÃ¡novanÃ¡ tovÃ¡rna v IndianÄ› by
  se stala strategickÃ½m centrem pro pokroÄilÃ© AI pamÄ›ti.
importance: 4
layout: tech_news_article
original_title: SK Hynix weighs US expansion for advanced chip packaging
publishedAt: '2025-12-29T08:15:06+00:00'
slug: sk-hynix-weighs-us-expansion-for-advanced-chip-pac
source:
  emoji: ğŸ“°
  id: null
  name: Digitimes
title: SK hynix zvaÅ¾uje rozÅ¡Ã­Å™enÃ­ v USA pro pokroÄilÃ© balenÃ­ ÄipÅ¯
url: https://www.digitimes.com/news/a20251229PD230/packaging-technology-expansion-production-manufacturing.html
urlToImage: https://img.digitimes.com/newsshow/20251229pd230_files/1_r.jpg
urlToImageBackup: https://img.digitimes.com/newsshow/20251229pd230_files/1_r.jpg
---

## Souhrn
SK hynix, pÅ™ednÃ­ svÄ›tovÃ½ vÃ½robce high-bandwidth memory (HBM), zvaÅ¾uje instalaci prvnÃ­ masovÃ© vÃ½robnÃ­ linky pro 2.5D pokroÄilÃ© balenÃ­ v plÃ¡novanÃ© tovÃ¡rnÄ› v West Lafayette v IndianÄ› v USA. Tento krok by umoÅ¾nil firmÄ› pÅ™evzÃ­t sloÅ¾itÄ›jÅ¡Ã­ integraci pamÄ›tÃ­ s procesory pÅ™Ã­mo v domÃ¡cÃ­ vÃ½robÄ›, mÃ­sto spolÃ©hÃ¡nÃ­ na externÃ­ partnery jako TSMC. Projekt s investicÃ­ 3,87 miliardy USD by mÄ›l zahÃ¡jit masovou vÃ½robu v druhÃ© polovinÄ› roku 2028 a posÃ­lÃ­ dodÃ¡vky pro AI akcelerÃ¡tory.

## KlÃ­ÄovÃ© body
- SK hynix plÃ¡nuje prvnÃ­ tovÃ¡rnu v USA s pÅ¯vodnÃ­m zamÄ›Å™enÃ­m na HBM, nynÃ­ rozÅ¡Ã­Å™enou o 2.5D balenÃ­.
- 2.5D technologie pouÅ¾Ã­vÃ¡ silikonovÃ½ interposer k propojenÃ­ HBM s GPU nebo CPU pro vyÅ¡Å¡Ã­ rychlost dat a energetickou ÃºÄinnost.
- Firma vede globÃ¡lnÃ­ trh s HBM pro AI, ale balenÃ­ ovlÃ¡dÃ¡ TSMC; internÃ­ kapacity zlepÅ¡Ã­ spolehlivost vÃ½roby.
- Podpora federÃ¡lnÃ­ch incentiv a CHIPS Act pro posÃ­lenÃ­ americkÃ©ho Å™etÄ›zce dodÃ¡vek polovodiÄÅ¯.
- CÃ­l: masovÃ¡ vÃ½roba v roce 2028, zamÄ›Å™eno na AI produkty jako pamÄ›ti pro Nvidia akcelerÃ¡tory.

## Podrobnosti
SK hynix, jihokorejskÃ½ gigant v oblasti pamÄ›tÃ­ DRAM a NAND flash, je klÃ­ÄovÃ½m dodavatelem HBM pro modernÃ­ AI hardware. HBM slouÅ¾Ã­ k rychlÃ©mu pÅ™enosu obrovskÃ½ch objemÅ¯ dat v trÃ©novacÃ­ch clusterech AI, kde je spojovÃ¡na s vÃ½konnÃ½mi grafickÃ½mi procesory (GPU) nebo centrÃ¡lnÃ­mi procesory (CPU). PÅ¯vodnÃ­ plÃ¡n tovÃ¡rny v IndianÄ› byl zamÄ›Å™en na vÃ½robu tÄ›chto pamÄ›tÃ­, ale novÃ© zprÃ¡vy z ZDNet Korea naznaÄujÃ­ pÅ™idÃ¡nÃ­ linky pro 2.5D advanced packaging. Tato technologie integruje vÃ­ce ÄipÅ¯ na jednÃ© desce pomocÃ­ silikonovÃ©ho interposeru â€“ ten funguje jako pokroÄilÃ½ most mezi HBM a logickÃ½mi Äipy, coÅ¾ umoÅ¾Åˆuje pÅ™enos dat rychlostmi pÅ™esahujÃ­cÃ­mi 1 TB/s pÅ™i niÅ¾Å¡Ã­ spotÅ™ebÄ› energie oproti starÅ¡Ã­m metodÃ¡m.

Doposud SK hynix outsourcovala balenÃ­ na Taiwan k TSMC, kterÃ© dominuje v pokroÄilÃ½ch uzlech jako 3 nm nebo CoWoS (Chip on Wafer on Substrate). VlastnÃ­ 2.5D linka by firmÄ› umoÅ¾nila kontrolovat celÃ½ proces od vÃ½roby HBM po finÃ¡lnÃ­ integraci, coÅ¾ je klÃ­ÄovÃ© pro pÅ™Ã­Å¡tÃ­ generace jako HBM3E nebo HBM4. TovÃ¡rna v IndianÄ›, podporovanÃ¡ miliardovÃ½mi federÃ¡lnÃ­mi dotacemi podle CHIPS and Science Act, mÃ¡ slouÅ¾it jako hub pro americkou vÃ½robu AI komponent. SK hynix jiÅ¾ dodÃ¡vÃ¡ HBM pro Nvidia H100 a H200 GPU, kterÃ© pohÃ¡nÄ›jÃ­ modely jako GPT-4 nebo Llama, a internÃ­ balenÃ­ by zkrÃ¡tilo dodacÃ­ lhÅ¯ty a snÃ­Å¾ilo rizika v dodavatelskÃ©m Å™etÄ›zci. Tento posun pÅ™ichÃ¡zÃ­ v dobÄ›, kdy poptÃ¡vka po AI hardware exploduje, ale vÃ½robnÃ­ kapacity zaostÃ¡vajÃ­ â€“ napÅ™Ã­klad nedostatek HBM zpÅ¯sobil zpoÅ¾dÄ›nÃ­ v deployi AI trÃ©ninkÅ¯.

## ProÄ je to dÅ¯leÅ¾itÃ©
RozÅ¡Ã­Å™enÃ­ SK hynix v USA pÅ™edstavuje krok k vertikÃ¡lnÃ­ integraci v polovodiÄovÃ©m prÅ¯myslu, coÅ¾ je nezbytnÃ© pro Å¡kÃ¡lovatelnost AI. ExternÃ­ zÃ¡vislost na TSMC vytvÃ¡Å™Ã­ rizika â€“ geopolitickÃ© napÄ›tÃ­ v Tchaj-wanu by mohlo naruÅ¡it dodÃ¡vky pro celÃ½ AI ekosystÃ©m, vÄetnÄ› trÃ©ninku velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM). VlastnÃ­ 2.5D kapacity umoÅ¾nÃ­ rychlejÅ¡Ã­ vÃ½voj a vÃ½robu pokroÄilÃ½ch AI akcelerÃ¡torÅ¯, coÅ¾ pÅ™Ã­mo ovlivnÃ­ dostupnost vÃ½poÄetnÃ­ho vÃ½konu pro firmy jako OpenAI nebo Google. Pro americkÃ½ prÅ¯mysl to znamenÃ¡ posÃ­lenÃ­ domÃ¡cÃ­ho Å™etÄ›zce podle nÃ¡rodnÃ­ch bezpeÄnostnÃ­ch priorit, s potenciÃ¡lem snÃ­Å¾it ceny HBM dlouhodobÄ›. Jako expert na AI hardware vidÃ­m zde klÃ­ÄovÃ½ impuls pro pÅ™echod k efektivnÄ›jÅ¡Ã­m AI systÃ©mÅ¯m, kde pamÄ›Å¥ovÃ½ bottleneck brzdÃ­ pokrok v AGI smÄ›ru â€“ bez dostupnÃ©ho HBM nebude moÅ¾nÃ© trÃ©novat modely s biliony parametrÅ¯.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.digitimes.com/news/a20251229PD230/packaging-technology-expansion-production-manufacturing.html)

**Zdroj:** ğŸ“° Digitimes
