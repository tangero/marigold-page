---
author: Marisa Aigen
category: bezpeÄnost ai
companies:
- OpenAI
date: '2026-02-21 23:06:12'
description: KanadskÃ½ ministr pro umÄ›lou inteligenci zvyÅ¡uje obavy u OpenAI a dalÅ¡Ã­ch
  platforem ohlednÄ› bezpeÄnostnÃ­ch protokolÅ¯ potÃ©, co spoleÄnost potvrdila ÃºÄet teenagera
  odpovÄ›dnÃ©ho za masovou stÅ™elbu v Tumbler Ridge v BritskÃ© Kolumbii.
importance: 4
layout: tech_news_article
original_title: Federal AI minister raises concerns over OpenAI safety protocols after
  Tumbler Ridge mass shooting
publishedAt: '2026-02-21T23:06:12+00:00'
slug: federal-ai-minister-raises-concerns-over-openai-sa
source:
  emoji: ğŸ“°
  id: cbc-news
  name: CBC News
title: KanadskÃ½ ministr pro umÄ›lou inteligenci upozorÅˆuje na bezpeÄnostnÃ­ protokoly
  OpenAI po masovÃ© stÅ™elbÄ› v Tumbler Ridge
url: https://www.cbc.ca/news/canada/british-columbia/federal-ai-minister-raises-concerns-over-openai-tumbler-ridge-shooting-9.7101279
urlToImage: https://i.cbc.ca/ais/06625b6e-4f06-4066-a12f-d152a6f71b67,1771713106276/full/max/0/default.jpg?im=Crop%2Crect%3D%280%2C68%2C1280%2C720%29%3BResize%3D620
urlToImageBackup: https://i.cbc.ca/ais/06625b6e-4f06-4066-a12f-d152a6f71b67,1771713106276/full/max/0/default.jpg?im=Crop%2Crect%3D%280%2C68%2C1280%2C720%29%3BResize%3D620
---

## Souhrn
KanadskÃ½ federÃ¡lnÃ­ ministr pro umÄ›lou inteligenci ISED Dominic LeBlanc vyjÃ¡dÅ™il obavy ohlednÄ› bezpeÄnostnÃ­ch mechanismÅ¯ OpenAI po potvrzenÃ­, Å¾e teenager odpovÄ›dnÃ½ za masovou stÅ™elbu v Tumbler Ridge mÄ›l aktivnÃ­ ÃºÄet u tÃ©to spoleÄnosti. Incident zvyÅ¡uje debatu o odpovÄ›dnosti AI platforem za obsah generovanÃ½ jejich modely, jako je ChatGPT. Ministr plÃ¡nuje pÅ™Ã­mÃ½ dialog s OpenAI a dalÅ¡Ã­mi firmami.

## KlÃ­ÄovÃ© body
- KanadskÃ½ ministr Dominic LeBlanc zvyÅ¡uje obavy u OpenAI kvÅ¯li bezpeÄnostnÃ­m protokolÅ¯m po masovÃ© stÅ™elbÄ› v Tumbler Ridge, B.C.
- OpenAI potvrdilo, Å¾e stÅ™elec, teenager, mÄ›l ÃºÄet na jejich platformÄ›, coÅ¾ naznaÄuje moÅ¾nou interakci s AI modely.
- Diskuse se tÃ½kÃ¡ moderovÃ¡nÃ­ obsahu, detekce rizikovÃ©ho chovÃ¡nÃ­ a spoluprÃ¡ce s ÃºÅ™ady.
- Kanada posiluje regulace AI prostÅ™ednictvÃ­m Artificial Intelligence and Data Act (AIDA).
- Incident podtrhuje globÃ¡lnÃ­ tlaky na bezpeÄnost velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).

## Podrobnosti
MasovÃ¡ stÅ™elba v Tumbler Ridge, malÃ© komunitÄ› v BritskÃ© Kolumbii, si vyÅ¾Ã¡dala nÄ›kolik obÄ›tÃ­ a byla provedena teenagerem, jehoÅ¾ ÃºÄet u OpenAI byl potvrzen spoleÄnostÃ­. AÄkoli detaily o tom, jak pÅ™esnÄ› teenager AI vyuÅ¾il â€“ napÅ™Ã­klad k generovÃ¡nÃ­ plÃ¡nÅ¯, manifestÅ¯ nebo rad â€“ nebyly plnÄ› zveÅ™ejnÄ›ny, incident vyvolal otÃ¡zky ohlednÄ› schopnosti OpenAI detekovat a brÃ¡nit rizikovÃ©mu pouÅ¾itÃ­ jejich modelÅ¯. OpenAI, kterÃ½ vyvinul ChatGPT a GPT sÃ©rie modelÅ¯ pro generovÃ¡nÃ­ textu, kÃ³du a analÃ½z, mÃ¡ implementovanÃ© bezpeÄnostnÃ­ vrstvy jako content moderation filtry a red teaming testy, ale tyto se ukazujÃ­ nedostateÄnÃ© v extrÃ©mnÃ­ch pÅ™Ã­padech.

KanadskÃ½ ministr Dominic LeBlanc z Innovation, Science and Economic Development Canada (ISED) oznÃ¡mil, Å¾e bude jednat pÅ™Ã­mo s OpenAI a podobnÃ½mi platformami, jako Anthropic nebo Google DeepMind. Kanada pracuje na Artificial Intelligence and Data Act (AIDA), kterÃ½ zavÃ¡dÃ­ povinnosti pro vysokorizikovÃ© AI systÃ©my, vÄetnÄ› povinnÃ©ho reportingu incidentÅ¯ a auditÅ¯. Tento pÅ™Ã­stup kontrastuje s americkÃ½m, kde regulace zÅ¯stÃ¡vajÃ­ dobrovolnÃ©, a evropskÃ½m AI Act, kterÃ½ klasifikuje systÃ©my podle rizika.

V kontextu pÅ™edchozÃ­ch incidentÅ¯, jako kdyÅ¾ AI modely poskytly rady k sebevraÅ¾dÃ¡m nebo plÃ¡novÃ¡nÃ­ nÃ¡silÃ­, OpenAI aktualizovalo svÃ© modely o lepÅ¡Ã­ alignment â€“ techniku, kterÃ¡ zarovnÃ¡vÃ¡ vÃ½stupy s etickÃ½mi standardy pomocÃ­ RLHF (Reinforcement Learning from Human Feedback). PÅ™esto teenager mohl obejÃ­t filtry jailbreaking technikami, kterÃ© jsou bÄ›Å¾nÃ© v komunitÃ¡ch jako Reddit nebo 4chan. Pro uÅ¾ivatele to znamenÃ¡ riziko, Å¾e AI mÅ¯Å¾e zesÃ­lit radikalizaci, zejmÃ©na u mladÃ½ch, kteÅ™Ã­ tvoÅ™Ã­ vÃ½znamnou ÄÃ¡st uÅ¾ivatelÅ¯ ChatGPT. PrÅ¯mysl ÄekÃ¡ na data z forenznÃ­ analÃ½zy ÃºÄtu, kterÃ¡ by odhalila, zda doÅ¡lo k opakovanÃ½m interakcÃ­m s tÃ©maty nÃ¡silÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento incident zdÅ¯razÅˆuje slabiny souÄasnÃ½ch bezpeÄnostnÃ­ch protokolÅ¯ u velkÃ½ch AI firem a urychluje globÃ¡lnÃ­ regulaÄnÃ­ debatu. Pro Kanadu to posiluje pozici v AI governance, kde AIDA mÅ¯Å¾e slouÅ¾it jako model pro povinnÃ© bezpeÄnostnÃ­ audity a sdÃ­lenÃ­ dat s policiÃ­. V Å¡irÅ¡Ã­m ekosystÃ©mu to tlaÄÃ­ OpenAI k investicÃ­m do proaktivnÃ­ detekce, jako anomaly detection v uÅ¾ivatelskÃ½ch vzorcÃ­ch, coÅ¾ by mohlo zvÃ½Å¡it nÃ¡klady na provoz o desÃ­tky procent. UÅ¾ivatelÃ© a spoleÄnost ÄelÃ­ riziku, Å¾e bez lepÅ¡Ã­ho oversightu se AI stane nÃ¡strojem pro extremisty, coÅ¾ podtrhuje nutnost vyvÃ¡Å¾enÃ©ho pÅ™Ã­stupu mezi inovacÃ­ a bezpeÄnostÃ­. Pokud OpenAI nereaguje rychle, hrozÃ­ mezinÃ¡rodnÃ­ sankce nebo omezenÃ­ pÅ™Ã­stupu v regulovanÃ½ch trzÃ­ch.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.cbc.ca/news/canada/british-columbia/federal-ai-minister-raises-concerns-over-openai-tumbler-ridge-shooting-9.7101279)

**Zdroj:** ğŸ“° CBC News
