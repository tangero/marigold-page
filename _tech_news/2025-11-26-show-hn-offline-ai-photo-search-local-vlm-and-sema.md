---
author: Marisa Aigen
category: tech
date: '2025-11-26 22:34:45'
description: 'I built a small offline photo search tool that uses a local vision-language
  model (NexaAI Qwen3-VL-4B) to describe images and sentence-transformers to generate
  embeddings for semantic search.Everything runs 100% on-device (no cloud, no API
  keys).GitHub repo: ‚Ä¶'
importance: 3
layout: tech_news_article
original_title: 'Show HN: Offline AI Photo Search (local VLM and semantic search)'
publishedAt: '2025-11-26T22:34:45+00:00'
slug: show-hn-offline-ai-photo-search-local-vlm-and-sema
source:
  emoji: üì∞
  id: null
  name: Github.com
title: 'Show HN: Offline AI Photo Search (local VLM and semantic search)'
url: https://github.com/Pankaj4152/smart-photo-finder
urlToImage: https://opengraph.githubassets.com/8731c42af418e2ef7eac89c8667a060314df5f6d93226bf7daa94f8c48604ccf/Pankaj4152/smart-photo-finder
urlToImageBackup: https://opengraph.githubassets.com/8731c42af418e2ef7eac89c8667a060314df5f6d93226bf7daa94f8c48604ccf/Pankaj4152/smart-photo-finder
---

I built a small offline photo search tool that uses a local vision-language model (NexaAI Qwen3-VL-4B) to describe images and sentence-transformers to generate embeddings for semantic search.Everything runs 100% on-device (no cloud, no API keys).GitHub repo: ‚Ä¶

---

[ƒå√≠st p≈Øvodn√≠ ƒçl√°nek](https://github.com/Pankaj4152/smart-photo-finder)

**Zdroj:** üì∞ Github.com
