---
author: Marisa Aigen
category: prÃ¡vnÃ­ odpovÄ›dnost
date: '2026-01-17 00:10:13'
description: Å kody zpÅ¯sobenÃ© obrÃ¡zky zneuÅ¾Ã­vÃ¡nÃ­ jsou zÅ™ejmÃ©, ale prÃ¡vnÃ­ situace je
  mnohem nejasnÄ›jÅ¡Ã­.
importance: 4
layout: tech_news_article
original_title: 'Factfind: Who, if anyone, can be held legally responsible for abuse
  images on Grok and X?'
publishedAt: '2026-01-17T00:10:13+00:00'
slug: factfind-who-if-anyone-can-be-held-legally-respons
source:
  emoji: ğŸ“°
  id: null
  name: TheJournal.ie
title: 'Factfind: Kdo, pokud vÅ¯bec nÄ›kdo, mÅ¯Å¾e nÃ©st prÃ¡vnÃ­ odpovÄ›dnost za obrÃ¡zky
  zneuÅ¾Ã­vÃ¡nÃ­ na Grok a X?'
url: https://www.thejournal.ie/factfind-who-is-responsible-for-ai-generated-abusive-images-xai-x-grok-bikinis-children-women-sexualised-irish-law-barristers-opinion-dsa-6927689-Jan2026/
urlToImage: https://img2.thejournal.ie/article/6927689/river/?height=400&version=6927744
urlToImageBackup: https://img2.thejournal.ie/article/6927689/river/?height=400&version=6927744
---

## Souhrn
SkandÃ¡l s AI-generovanÃ½mi nekonzistentnÃ­mi obrÃ¡zky zneuÅ¾Ã­vÃ¡nÃ­, vÄetnÄ› dÄ›tÃ­ v bikinech a sexuÃ¡lnÄ› nÃ¡silnÃ½ch vyobrazenÃ­ Å¾en, vypukl po pÅ™idÃ¡nÃ­ funkce editovÃ¡nÃ­ obrÃ¡zkÅ¯ v nÃ¡stroji Grok na platformÄ› X. Autorita reagujÃ­ vÃ¡gnÄ› a protichÅ¯dnÄ› ohlednÄ› konkrÃ©tnÃ­ch trestnÃ½ch ÄinÅ¯ a prÃ¡vnÃ­ odpovÄ›dnosti. ÄŒlÃ¡nek analyzuje, zda mohou bÃ½t odpovÄ›dnÃ­ uÅ¾ivatelÃ©, vÃ½vojÃ¡Å™i AI nebo provozovatelÃ© platforem.

## KlÃ­ÄovÃ© body
- Po zavedenÃ­ edit buttonu v Grok v prosinci zaplavily X fabrikovanÃ© obrÃ¡zky dÄ›tÃ­ a Å¾en v explicitnÃ­ch scÃ©nÃ¡Å™Ã­ch.
- PolitickÃ¡ odsouzenÃ­ a veÅ™ejnÃ© rozhoÅ™ÄenÃ­ vedly k nejasnÃ½m prohlÃ¡Å¡enÃ­m ÃºÅ™adÅ¯ o pachatelÃ­ch.
- PrÃ¡vnÃ­ rÃ¡mec zahrnuje otÃ¡zky odpovÄ›dnosti platforem podle Section 230 v USA a evropskÃ½ch regulacÃ­.
- Grok, AI chatbot od xAI (firma Elona Muska), umoÅ¾Åˆuje generovÃ¡nÃ­ a Ãºpravu obrÃ¡zkÅ¯ pÅ™Ã­mo na X.
- Absence jasnÃ½ch pravidel pro AI-generovanÃ½ obsah zvyÅ¡uje riziko Å¡Ã­Å™enÃ­ Å¡kodlivÃ©ho materiÃ¡lu.

## Podrobnosti
Grok je AI model vyvinutÃ½ spoleÄnostÃ­ xAI, kterou zaloÅ¾il Elon Musk jako alternativa k modelÅ¯m jako GPT od OpenAI. SlouÅ¾Ã­ k generovÃ¡nÃ­ textu i obrÃ¡zkÅ¯ na platformÄ› X (dÅ™Ã­ve Twitter), kde je integrovÃ¡n. V prosinci 2025 pÅ™idala xAI funkci edit button, kterÃ¡ uÅ¾ivatelÅ¯m umoÅ¾Åˆuje upravovat generovanÃ© obrÃ¡zky â€“ napÅ™Ã­klad mÄ›nit obleÄenÃ­, pÃ³zy nebo pÅ™idÃ¡vat prvky. Tato novinka mÄ›la zlepÅ¡it kreativitu, ale rychle vedla k zneuÅ¾itÃ­: uÅ¾ivatelÃ© vytvÃ¡Å™eli non-konzistentnÃ­ explicitnÃ­ obsah s reÃ¡lnÃ½mi lidmi, vÄetnÄ› dÄ›tÃ­ v bikinech a Å¾en v sexuÃ¡lnÄ› nÃ¡silnÃ½ch scÃ©nÃ¡Å™Ã­ch. Tyto obrÃ¡zky se masivnÄ› Å¡Ã­Å™ily na X, coÅ¾ vyvolalo skandÃ¡l.

PrÃ¡vnÃ­ analÃ½za odhaluje nejasnosti. V USA chrÃ¡nÃ­ Section 230 platÑ„Ğ¾Ñ€Ğ¼Ñ‹ jako X pÅ™ed odpovÄ›dnostÃ­ za uÅ¾ivatelskÃ½ obsah, pokud ho neaktivnÄ› podporujÃ­. NicmÃ©nÄ› AI-generovanÃ½ obsah zkouÅ¡Ã­ tyto hranice: je Grok nÃ¡strojem, kterÃ½ facilituje trestnÃ© Äiny, nebo je vÃ½vojÃ¡Å™ xAI odpovÄ›dnÃ½ za nedostateÄnÃ© bezpeÄnostnÃ­ filtry? V EvropÄ› AI Act zavÃ¡dÃ­ povinnosti pro vysokorizikovÃ© systÃ©my, jako je generovÃ¡nÃ­ obrÃ¡zkÅ¯, vÄetnÄ› oznaÄovÃ¡nÃ­ deepfakes a prevence CSAM (child sexual abuse material). IrskÃ© ÃºÅ™ady, kde sÃ­dlÃ­ mnoho tech firem, zkoumajÃ­, zda X poruÅ¡il GDPR nebo nÃ¡rodnÃ­ zÃ¡kony proti distribuci zneuÅ¾Ã­vacÃ­ho obsahu. ProblÃ©m komplikuje, Å¾e obrÃ¡zky zobrazujÃ­ reÃ¡lnÃ© osoby bez souhlasu, coÅ¾ mÅ¯Å¾e spadat pod revenge porn zÃ¡kony nebo prÃ¡vo na soukromÃ­.

UÅ¾ivatelÃ©, kteÅ™Ã­ obrÃ¡zky sdÃ­leli, riskujÃ­ trestnÃ­ stÃ­hÃ¡nÃ­ za distribuci CSAM, ale otÃ¡zka znÃ­, zda xAI nebo X.ai (mateÅ™skÃ¡ firma) nesou vinu za chybÄ›jÃ­cÃ­ moderovÃ¡nÃ­. PÅ™Ã­pady jako tento ukazujÃ­ slabiny souÄasnÃ½ch systÃ©mÅ¯: Grok postrÃ¡dal robustnÃ­ filtry proti explicitnÃ­mu obsahu, na rozdÃ­l od modelÅ¯ jako DALL-E od OpenAI, kterÃ© striktnÄ› blokujÃ­ nÃ¡silÃ­. X po incidentu odstranil tisÃ­ce pÅ™Ã­spÄ›vkÅ¯, ale absence preventivnÃ­ch opatÅ™enÃ­ naznaÄuje systÃ©movÃ© selhÃ¡nÃ­. (cca 350 slov)

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento pÅ™Ã­pad nastavuje precedent pro regulaci AI-generovanÃ©ho obsahu v sociÃ¡lnÃ­ch sÃ­tÃ­ch. Pokud platÑ„Ğ¾Ñ€Ğ¼Ñ‹ jako X zÃ­skajÃ­ imunitu, motivace k bezpeÄnostnÃ­m investicÃ­m klesne, coÅ¾ zvyÅ¡uje rizika pro dÄ›ti a Å¾eny. V Å¡irÅ¡Ã­m kontextu urychluje debatu o AI Act a nÃ¡rodnÃ­ch zÃ¡konech, kde firmy jako xAI musÃ­ implementovat watermarking a detekci. Pro prÅ¯mysl znamenÃ¡ tlak na lepÅ¡Ã­ alignment modelÅ¯ â€“ Grok byl navrÅ¾en jako â€maximÃ¡lnÄ› pravdivÃ½", ale bez etickÃ½ch zÃ¡bran selhÃ¡vÃ¡ v reÃ¡lnÃ©m nasazenÃ­. DlouhodobÄ› to ovlivnÃ­ vÃ½voj open-source AI, kde absence centralizovanÃ©ho dohledu vede k podobnÃ½m incidentÅ¯m.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.thejournal.ie/factfind-who-is-responsible-for-ai-generated-abusive-images-xai-x-grok-bikinis-children-women-sexualised-irish-law-barristers-opinion-dsa-6927689-Jan2026/)

**Zdroj:** ğŸ“° TheJournal.ie
