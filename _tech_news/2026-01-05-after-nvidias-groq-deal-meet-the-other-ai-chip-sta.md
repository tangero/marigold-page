---
author: Marisa Aigen
category: ai Äipy
companies:
- Nvidia
- Groq
date: '2026-01-05 19:26:34'
description: Nvidia oznÃ¡mila na Å tÄ›drÃ½ veÄer dohodu v hodnotÄ› 20 miliard dolarÅ¯ na
  licencovÃ¡nÃ­ technologie AI ÄipÅ¯ startupu Groq a pÅ™evzetÃ­ vÄ›tÅ¡iny jeho tÃ½mu vÄetnÄ›
  CEO Jonathana Rossa. Tento krok naznaÄuje, Å¾e Nvidia pÅ™iznÃ¡vÃ¡ rostoucÃ­ konkurenci
  v oblasti AI hardwaru mimo svÃ© GPU.
importance: 5
layout: tech_news_article
original_title: After Nvidiaâ€™s Groq deal, meet the other AI chip startups that may
  be in playâ€”and one looking to disrupt them all
people:
- Jonathan Ross
publishedAt: '2026-01-05T19:26:34+00:00'
slug: after-nvidias-groq-deal-meet-the-other-ai-chip-sta
source:
  emoji: ğŸ“°
  id: null
  name: Biztoc.com
title: 'Po dohodÄ› Nvidia s Groq: DalÅ¡Ã­ startupy na AI Äipy v hÅ™e â€“ a jeden, kterÃ½
  je ohroÅ¾uje vÅ¡echny'
url: https://biztoc.com/x/9dc49bc1cffe1ec2
urlToImage: https://biztoc.com/cdn/9dc49bc1cffe1ec2_s.webp
urlToImageBackup: https://biztoc.com/cdn/9dc49bc1cffe1ec2_s.webp
---

## Souhrn
Nvidia pÅ™ekvapivÄ› uzavÅ™ela dohodu v hodnotÄ› 20 miliard dolarÅ¯ na licencovÃ¡nÃ­ technologie startupu Groq, kterÃ½ vyvÃ­jÃ­ specializovanÃ© Äipy pro zpracovÃ¡nÃ­ AI modelÅ¯. SpoleÄnost pÅ™ebÃ­rÃ¡ vÄ›tÅ¡inu tÃ½mu Groq vÄetnÄ› spoluzakladatele a CEO Jonathana Rossa. Tento krok signalizuje, Å¾e Nvidia uÅ¾ nepovaÅ¾uje svÃ© grafickÃ© procesory (GPU) za jedinÃ© Å™eÅ¡enÃ­ pro AI Ãºlohy.

## KlÃ­ÄovÃ© body
- Nvidia licencuje technologii Groq za 20 miliard dolarÅ¯ a pÅ™ebÃ­rÃ¡ klÃ­ÄovÃ© zamÄ›stnance.
- Groq se specializuje na Language Processing Units (LPU), Äipy optimalizovanÃ© pro rychlou inferenci velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
- Dohoda naznaÄuje posun v strategii Nvidia smÄ›rem k integraci konkurenÄnÃ­ch architektur.
- ÄŒlÃ¡nek zmiÅˆuje dalÅ¡Ã­ startupy jako potenciÃ¡lnÃ­ cÃ­le akvizic: Cerebras, SambaNova nebo Tenstorrent.
- Jeden disruptor, napÅ™Ã­klad Etched, cÃ­lÃ­ na transformaci AI ÄipÅ¯ pomocÃ­ specifickÃ½ch architektur pro attention mechanismy.

## Podrobnosti
Nvidia, dlouholetÃ½ dominant v trhu AI ÄipÅ¯ dÃ­ky svÃ½m GPU jako H100 nebo nadchÃ¡zejÃ­cÃ­ Blackwell sÃ©rii, oznÃ¡mila tuto dohodu 24. prosince 2025. Groq, zaloÅ¾enÃ½ v roce 2016 bÃ½valÃ½mi zamÄ›stnanci Google, vyvinul unikÃ¡tnÃ­ architekturu LPU, kterÃ¡ je navrÅ¾ena pÅ™edevÅ¡Ã­m pro inferenci â€“ fÃ¡zi, kdy AI modely jako GPT nebo Llama generujÃ­ odpovÄ›di na poÅ¾adavky uÅ¾ivatelÅ¯. Na rozdÃ­l od GPU, kterÃ© jsou univerzÃ¡lnÃ­ a excelujÃ­ v trÃ©ninku modelÅ¯, LPU od Groq dosahujÃ­ vyÅ¡Å¡Ã­ propustnosti pÅ™i niÅ¾Å¡Ã­ latenci dÃ­ky tensor streaming processorÅ¯m (TSP), coÅ¾ umoÅ¾Åˆuje zpracovÃ¡vat aÅ¾ 500 tokenÅ¯ za sekundu na Äip oproti desÃ­tkÃ¡m u standardnÃ­ch GPU.

Tento krok pÅ™ichÃ¡zÃ­ v dobÄ›, kdy poptÃ¡vka po AI hardwaru exploduje, ale dodÃ¡vky Nvidia ÄipÅ¯ zaostÃ¡vajÃ­ kvÅ¯li vÃ½robnÃ­m limitÅ¯m TSMC. Groq jiÅ¾ nasadil svÃ© systÃ©my v cloudovÃ½ch sluÅ¾bÃ¡ch pro firmy jako Anthropic nebo Perplexity AI, kde demonstroval aÅ¾ 10nÃ¡sobnou rychlost oproti Nvidia A100. PÅ™evzetÃ­m tÃ½mu Rossa, kterÃ½ mÃ¡ zkuÅ¡enosti z Google TPU projektu, Nvidia zÃ­skÃ¡vÃ¡ know-how pro hybridnÃ­ Å™eÅ¡enÃ­: kombinaci GPU pro trÃ©nink a LPU pro inferenci.

ÄŒlÃ¡nek Fortune rovnÄ›Å¾ poukazuje na dalÅ¡Ã­ startupy v hledÃ¡Äku. Cerebras vyvÃ­jÃ­ obrovskÃ© Wafer-Scale Engine Äipy, kterÃ© integrujÃ­ miliardy tranzistorÅ¯ na jedinÃ©m krystalu pro paralelnÃ­ zpracovÃ¡nÃ­. SambaNova nabÃ­zÃ­ kompletnÃ­ AI platformy s reconfigurable dataflow units (RDU), kterÃ© dynamicky pÅ™izpÅ¯sobujÃ­ architekturu Ãºlohe. Tenstorrent od Jima Kellherona (ex-AMD) se zamÄ›Å™uje na skalovatelnÃ© Äipy s n-gram processing pro efektivnÃ­ LLM. Tyto firmy jiÅ¾ zÃ­skaly funding v Å™Ã¡dech stovek milionÅ¯ a lÃ¡kajÃ­ investory jako Saudi Aramco nebo AMD.

Jako disruptor je zmÃ­nÄ›n Etched, kterÃ½ stavÃ­ Äipy plnÄ› optimalizovanÃ© pro attention vrstvy v transformerech â€“ jÃ¡dro modernÃ­ch LLM. Jejich architektura Sohu slibuje aÅ¾ 100nÃ¡sobnou Ãºsporu energie oproti GPU tÃ­m, Å¾e nahrazuje univerzÃ¡lnÃ­ vÃ½poÄty specializovanÃ½mi logickÃ½mi obvody. To by mohlo dramaticky snÃ­Å¾it nÃ¡klady na inferenci v datech centrech.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato dohoda potvrzuje, Å¾e Ã©ra dominance Nvidia GPU konÄÃ­. Inferenci tvoÅ™Ã­ 90 % provozu AI cloudÅ¯, kde univerzÃ¡lnost GPU vede k plÃ½tvÃ¡nÃ­ energiÃ­ â€“ aÅ¾ 10x vyÅ¡Å¡Ã­ spotÅ™ebÄ› neÅ¾ specializovanÃ© Äipy. Pro prÅ¯mysl znamenÃ¡ akceleraci vÃ½voje hybridnÃ­ch systÃ©mÅ¯, coÅ¾ snÃ­Å¾Ã­ zÃ¡vislost na Nvidia a urychlÃ­ nasazenÃ­ AI v edge zaÅ™Ã­zenÃ­ch nebo autonomnÃ­ch vozidlech. UÅ¾ivatelÃ© pocÃ­tÃ­ niÅ¾Å¡Ã­ ceny API volÃ¡nÃ­ (napÅ™. od OpenAI) dÃ­ky levnÄ›jÅ¡Ã­ inferenci. V Å¡irÅ¡Ã­m kontextu to posiluje konkurenci, coÅ¾ brÃ¡nÃ­ monopolnÃ­mu chovÃ¡nÃ­ Nvidia a stimuluje inovace v smÄ›ru udrÅ¾itelnÄ›jÅ¡Ã­ho AI hardwaru. Pokud Nvidia integruje LPU, mohla by posÃ­lit svou pozici, ale riskuje kanibalizaci vlastnÃ­ch prodejÅ¯ GPU.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://biztoc.com/x/9dc49bc1cffe1ec2)

**Zdroj:** ğŸ“° Biztoc.com
