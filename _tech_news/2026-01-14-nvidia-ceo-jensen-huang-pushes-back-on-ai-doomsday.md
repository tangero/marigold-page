---
author: Marisa Aigen
category: ai
companies:
- Nvidia
date: '2026-01-14 11:47:42'
description: Å Ã©f Nvidia Jensen Huang kritizoval doomerskÃ© narativy, kterÃ© vykreslujÃ­
  umÄ›lou inteligenci jako konec svÄ›ta, a argumentoval, Å¾e takovÃ© sci-fi rÃ¡movÃ¡nÃ­ zkresluje
  veÅ™ejnÃ© chÃ¡pÃ¡nÃ­ a regulace. V podcastu No Priors varoval, Å¾e to Å¡kodÃ­ prÅ¯myslu i
  vlÃ¡dÃ¡m.
importance: 4
layout: tech_news_article
original_title: 'Nvidia CEO Jensen Huang pushes back on AI doomsday talk: Says, â€˜we
  grew up enjoying science fiction, but itâ€™s not helpfulâ€™'
people:
- Jensen Huang
publishedAt: '2026-01-14T11:47:42+00:00'
slug: nvidia-ceo-jensen-huang-pushes-back-on-ai-doomsday
source:
  emoji: ğŸ“°
  id: the-times-of-india
  name: The Times of India
title: 'Å Ã©f Nvidia Jensen Huang odmÃ­tÃ¡ apokalyptickÃ© spekulace o AI: Sci-fi nenÃ­ uÅ¾iteÄnÃ©'
url: https://economictimes.indiatimes.com/magazines/panache/nvidia-ceo-jensen-huang-pushes-back-on-ai-doomsday-talk-says-we-grew-up-enjoying-science-fiction-but-its-not-helpful/articleshow/126525908.cms
urlToImage: https://img.etimg.com/thumb/msid-126526024,width-1200,height-630,imgsize-463453,overlay-etpanache/articleshow.jpg
urlToImageBackup: https://img.etimg.com/thumb/msid-126526024,width-1200,height-630,imgsize-463453,overlay-etpanache/articleshow.jpg
---

## Souhrn
Å Ã©f spoleÄnosti Nvidia Jensen Huang v podcastu No Priors kritizoval pÅ™ehnanÃ© apokalyptickÃ© pÅ™edpovÄ›di o umÄ›lÃ© inteligenci, oznaÄenÃ© jako doomerskÃ© narativy. TvrdÃ­, Å¾e takovÃ© sci-fi inspirace zkreslujÃ­ veÅ™ejnÃ© vnÃ­mÃ¡nÃ­, regulace a brzdÃ­ inovace. MÃ­sto strachu z konce svÄ›ta by se mÄ›lo zamÄ›Å™it na souÄasnÃ© limity AI, jako je nedostateÄnÃ¡ spolehlivost.

## KlÃ­ÄovÃ© body
- Huang kritizoval vlivnÃ© osobnosti za Å¡Ã­Å™enÃ­ doomerskÃ½ch narativÅ¯ inspirovanÃ½ch sci-fi, kterÃ© podle nÄ›j Å¡kodÃ­ spoleÄnosti, prÅ¯myslu i vlÃ¡dÃ¡m.
- Varoval, Å¾e alarmistickÃ© scÃ©nÃ¡Å™e ovlivÅˆujÃ­ regulace, coÅ¾ mÅ¯Å¾e zpÅ¯sobit restrikce brzdÃ­cÃ­ inovace a favorizujÃ­cÃ­ velkÃ© firmy.
- NaznaÄil, Å¾e nÄ›kteÅ™Ã­ kritici AI rizik majÃ­ konkurenÄnÃ­ komerÄnÃ­ zÃ¡jmy a snaÅ¾Ã­ se ovlivnit regulace ve svÅ¯j prospÄ›ch (regulatory capture).
- ZdÅ¯raznil, Å¾e AI je stÃ¡le nÃ¡stroj s problÃ©my v zÃ¡kladnÃ­ spolehlivosti, nikoli neÃºprosnÃ¡ sÃ­la niÄÃ­cÃ­ lidstvo.
- Podcast No Priors, reportovÃ¡n TechSpotem, znovu otevÅ™el debatu o tom, jak hovoÅ™it o rychle rostoucÃ­ technologii AI.

## Podrobnosti
Jensen Huang, generÃ¡lnÃ­ Å™editel Nvidia â€“ spoleÄnosti dominantnÃ­ v produkci grafickÃ½ch procesorÅ¯ (GPU) nezbytnÃ½ch pro trÃ©nink velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) jako GPT nebo Llama â€“ se v nedÃ¡vnÃ©m epizodu podcastu No Priors, vedenÃ©m Elad Gil a Sarah Guo, jasnÄ› postavil proti pÅ™ehnanÃ©mu strachu z umÄ›lÃ© inteligence. Nvidia dodÃ¡vÃ¡ hardware, kterÃ½ pohÃ¡nÃ­ vÄ›tÅ¡inu souÄasnÃ½ch AI aplikacÃ­, od generovÃ¡nÃ­ textu po obrazovÃ© modely, a Huang tak mluvÃ­ z pozice klÃ­ÄovÃ©ho hrÃ¡Äe v ekosystÃ©mu.

â€UdÄ›lali jsme hodnÄ› Å¡kody velmi respektovanÃ½mi lidmi, kteÅ™Ã­ namalovali doomerskÃ½ narativ, konec-svÄ›ta narativ, sci-fi narativ,â€œ Å™ekl Huang. â€VyrÅ¯stali jsme na sci-fi, ale to nenÃ­ uÅ¾iteÄnÃ©. NenÃ­ to uÅ¾iteÄnÃ© pro lidi, prÅ¯mysl, spoleÄnost ani vlÃ¡dy.â€œ Podle nÄ›j takovÃ© rÃ¡movÃ¡nÃ­ pÅ™ehlÃ­Å¾Ã­ realitu: AI stÃ¡le bojuje s zÃ¡kladnÃ­mi problÃ©my, jako je halucinace v LLM (vymÃ½Å¡lenÃ­ faktÅ¯) nebo nestabilita v autonomnÃ­ch systÃ©mech. NapÅ™Ã­klad modely jako GPT-4o nebo Claude 3.5 stÃ¡le selhÃ¡vajÃ­ v jednoduchÃ½ch Ãºkolech spolehlivosti, coÅ¾ vyÅ¾aduje lidskÃ½ dohled.

Huang takÃ© upozornil na rizika regulacÃ­ ovlivnÄ›nÃ½ch strachem. AlarmistickÃ© scÃ©nÃ¡Å™e, popularizovanÃ© osobnostmi jako Geoffrey Hinton (bÃ½valÃ½ vÃ½zkumnÃ­k Google) nebo Eliezer Yudkowsky (z OpenAI/MIRI), mohou vÃ©st k pÅ™Ã­snÃ½m pravidlÅ¯m, kterÃ© zpomalÃ­ vÃ½voj a dÃ¡le posÃ­lÃ­ dominance velkÃ½ch firem jako Nvidia, OpenAI Äi Google. Bez pojmenovÃ¡nÃ­ konkrÃ©tnÃ­ch osob naznaÄil, Å¾e nÄ›kteÅ™Ã­ varovnÃ­ci majÃ­ â€skrytÃ© motivyâ€œ spojenÃ© s komerÄnÃ­ rivalitou. PÅ™Ã­kladem regulatory capture je, jak etablovanÃ© entity lobbyujÃ­ za pravidla zvyÅ¡ujÃ­cÃ­ vstupnÃ­ bariÃ©ry pro startupy â€“ napÅ™Ã­klad poÅ¾adavky na obrovskÃ© vÃ½poÄetnÃ­ zdroje, kterÃ© jen giganti jako Nvidia dokÃ¡Å¾ou dodat.

Tato debata pÅ™ichÃ¡zÃ­ v dobÄ›, kdy AI regulace nabÃ­rajÃ­ na obrÃ¡tkÃ¡ch: EU AI Act zavÃ¡dÃ­ kategorie rizik pro AI systÃ©my, USA diskutujÃ­ o vÃ½konnostnÃ­ch limitech modelÅ¯ a ÄŒÃ­na omezuje export ÄipÅ¯. Huangovo stanovisko kontrastuje s vÃ½roky Elona Muska (xAI/Tesla), kterÃ½ varuje pÅ™ed existenciÃ¡lnÃ­mi riziky, nebo Sama Altmana (OpenAI), kterÃ½ volÃ¡ po globÃ¡lnÃ­ koordinaci.

## ProÄ je to dÅ¯leÅ¾itÃ©
Huangovo vystoupenÃ­ ovlivÅˆuje Å¡irÅ¡Ã­ debatu o AI governance, kde se stÅ™etÃ¡vajÃ­ zÃ¡jmy inovÃ¡torÅ¯ a skeptikÅ¯. Nvidia, s trÅ¾nÃ­ kapitalizacÃ­ pÅ™es 3 biliony dolarÅ¯ dÃ­ky AI boomu, mÃ¡ obrovskÃ½ vliv na policy â€“ jejich GPU Äipy jako H100 nebo nadchÃ¡zejÃ­cÃ­ Blackwell sÃ©rie jsou klÃ­Äem pro Å¡kÃ¡lovÃ¡nÃ­ modelÅ¯. Pokud doomerskÃ© narativy pÅ™evaÅ¾ujÃ­, mohou vÃ©st k regulacÃ­m brzdÃ­cÃ­m pokrok v oblastech jako autonomnÃ­ vozidla (Tesla FSD) nebo robotika (Figure AI), kde spolehlivost roste postupnÄ›. Naopak, racionÃ¡lnÃ­ diskuse by podpoÅ™ila vyvÃ¡Å¾enÃ½ pÅ™Ã­stup zamÄ›Å™enÃ½ na skuteÄnÃ¡ rizika, jako bias v datech nebo kybernetickÃ¡ zranitelnost API rozhranÃ­ AI sluÅ¾eb. Pro uÅ¾ivatele to znamenÃ¡ rychlejÅ¡Ã­ pÅ™Ã­stup k uÅ¾iteÄnÃ½m nÃ¡strojÅ¯m, jako jsou AI asistenti v kaÅ¾dodennÃ­m softwaru, bez zbyteÄnÃ½ch omezenÃ­. Tato pozice posiluje optimismus v prÅ¯myslu, ale kritici namÃ­tajÃ­, Å¾e bagatelizace rizik ignoruje dlouhodobÃ© scÃ©nÃ¡Å™e superinteligence.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://economictimes.indiatimes.com/magazines/panache/nvidia-ceo-jensen-huang-pushes-back-on-ai-doomsday-talk-says-we-grew-up-enjoying-science-fiction-but-its-not-helpful/articleshow/126525908.cms)

**Zdroj:** ğŸ“° The Times of India
