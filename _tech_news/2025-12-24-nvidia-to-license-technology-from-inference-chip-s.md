---
author: Marisa Aigen
category: ai Äipy
companies:
- Nvidia
- Groq
date: '2025-12-24 23:27:04'
description: SpoleÄnost Groq Inc. oznÃ¡mila, Å¾e Nvidia Corp. licencuje jejÃ­ technologii
  na neexkluzivnÃ­m zÃ¡kladÄ›. Deal zahrnuje takÃ© najmutÃ­ nÄ›kolika klÃ­ÄovÃ½ch zamÄ›stnancÅ¯
  Groq, vÄetnÄ› zaklÃ¡dajÃ­cÃ­ho generÃ¡lnÃ­ho Å™editele Jonathana Rosse a prezidenta Sunnyho
  Madry.
importance: 5
layout: tech_news_article
original_title: Nvidia to license technology from inference chip startup Groq in reported
  $20B deal
publishedAt: '2025-12-24T23:27:04+00:00'
slug: nvidia-to-license-technology-from-inference-chip-s
source:
  emoji: ğŸ“°
  id: null
  name: SiliconANGLE News
title: Nvidia licencuje technologii od startupu na inference Äipy Groq v ÃºdajnÃ­m dealu
  za 20 miliard dolarÅ¯
url: https://siliconangle.com/2025/12/24/nvidia-license-technology-inference-chip-startup-groq-reported-20b-deal/
urlToImage: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2025/12/Groq.png
urlToImageBackup: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2025/12/Groq.png
---

### Souhrn
SpoleÄnost Nvidia oznÃ¡mila licenci na technologii inference ÄipÅ¯ od startupu Groq za ÃºdajnÃ½ch 20 miliard dolarÅ¯. Tento deal typu reverse acquihire zahrnuje pÅ™evzetÃ­ klÃ­ÄovÃ½ch zamÄ›stnancÅ¯ Groq bez plnÃ© akvizice firmy. Transakce umoÅ¾Åˆuje Nvidii integrovat efektivnÃ­ inference technologii LPU do svÃ©ho portfolia.

### KlÃ­ÄovÃ© body
- Nvidia licencuje Groqovu technologii inference za 20 miliard dolarÅ¯, coÅ¾ pÅ™edstavuje prÃ©mii 13,1 miliardy oproti valuaci Groq z zÃ¡Å™Ã­.
- PÅ™evzetÃ­ zamÄ›stnancÅ¯ vÄetnÄ› CEO Jonathana Rosse a prezidenta Sunnyho Madry.
- GroqÅ¯v Äip LPU spotÅ™ebovÃ¡vÃ¡ desetkrÃ¡t mÃ©nÄ› energie neÅ¾ grafickÃ© karty dÃ­ky deterministickÃ©mu designu a on-chip SRAM pamÄ›ti.
- Deal obchÃ¡zÃ­ antitrustovou kontrolu spojenou s plnÃ½mi akvizicemi.
- Nvidia posiluje pozici v oblasti AI inference, kde roste poptÃ¡vka po efektivnÃ­ch Å™eÅ¡enÃ­ch.

### Podrobnosti
Startup Groq Inc., specializujÃ­cÃ­ se na vÃ½voj ÄipÅ¯ pro inference v umÄ›lÃ© inteligenci, dnes potvrdil licenci svÃ© klÃ­ÄovÃ© technologie pro Nvidia. Podle Alexa Davise, CEO investora Disruptive Technology Advisers, dosahuje hodnota transakce 20 miliard dolarÅ¯. Tento typ dohody, znÃ¡mÃ½ jako reverse acquihire, umoÅ¾Åˆuje velkÃ½m firmÃ¡m zÃ­skat technologie a talenty bez nutnosti plnÃ©ho pÅ™evzetÃ­ spoleÄnosti, coÅ¾ minimalizuje rizika antitrustovÃ½ch Å¡etÅ™enÃ­. PodobnÃ© struktury vyuÅ¾ily v poslednÃ­ch tÅ™ech letech Microsoft a Meta pro posÃ­lenÃ­ svÃ½ch AI strategiÃ­.

Technologie Groq se zamÄ›Å™uje na inference Äipy typu LPU (Language Processing Unit), navrÅ¾enÃ© pro zpracovÃ¡nÃ­ AI modelÅ¯ po jejich trÃ©ninku. Inference je fÃ¡ze, kdy nasazenÃ© modely jako velkÃ© jazykovÃ© modely (LLM) generujÃ­ odpovÄ›di v reÃ¡lnÃ©m Äase. LPU vynikÃ¡ deterministickÃ½m designem, kterÃ½ pÅ™esnÄ› kontroluje ÄasovÃ¡nÃ­ vÃ½poÄtÅ¯ a eliminuje neoÄekÃ¡vanÃ© zpoÅ¾dÄ›nÃ­ typickÃ¡ pro standardnÃ­ nedeterministickÃ© Äipy, jako jsou GPU. DÃ¡le obsahuje stovky megabajtÅ¯ on-chip SRAM pamÄ›ti, coÅ¾ je nejrychlejÅ¡Ã­ typ pamÄ›ti na trhu, efektivnÄ›jÅ¡Ã­ a ÃºspornÄ›jÅ¡Ã­ neÅ¾ HBM pamÄ›Å¥ pouÅ¾Ã­vanÃ¡ v grafickÃ½ch kartÃ¡ch Nvidia. Groq spojuje servery s LPU do clusterÅ¯ pro Å¡kÃ¡lovatelnÃ© inference workloady.

Nvidia, dominantnÃ­ hrÃ¡Ä na trhu AI ÄipÅ¯ s podÃ­lem pÅ™es 80 procent, tak zÃ­skÃ¡vÃ¡ konkurenÄnÃ­ vÃ½hodu v oblasti energetickÃ© efektivity. Groq tvrdÃ­, Å¾e LPU dosahuje desetinÃ¡sobnÃ© Ãºspory energie oproti GPU pro stejnÃ© inference Ãºlohy. Tento deal pÅ™ichÃ¡zÃ­ v dobÄ›, kdy datovÃ¡ centra spotÅ™ebovÃ¡vajÃ­ obrovskÃ© mnoÅ¾stvÃ­ energie kvÅ¯li explozivnÃ­mu rÅ¯stu AI aplikacÃ­. LicencovÃ¡nÃ­ je neexkluzivnÃ­, takÅ¾e Groq si zachovÃ¡vÃ¡ schopnost spolupracovat s jinÃ½mi partnery.

### ProÄ je to dÅ¯leÅ¾itÃ©
Tento deal za 20 miliard dolarÅ¯ markuje nejvÄ›tÅ¡Ã­ licenci v historii AI hardware a signalizuje posun v soutÄ›Å¾i o inference trh, kterÃ½ pÅ™edstavuje aÅ¾ 70 procent celkovÃ½ch AI vÃ½poÄetnÃ­ch nÃ¡kladÅ¯. Nvidia, kterÃ¡ ÄelÃ­ tlaku od custom ÄipÅ¯ jako Amazon Trainium nebo Google TPU, tÃ­m integrovat specializovanou technologii pro snÃ­Å¾enÃ­ spotÅ™eby energie v datovÃ½ch centrech. Pro prÅ¯mysl to znamenÃ¡ potenciÃ¡lnÄ› levnÄ›jÅ¡Ã­ a udrÅ¾itelnÄ›jÅ¡Ã­ AI nasazenÃ­, coÅ¾ ovlivnÃ­ cloud providery i koncovÃ© uÅ¾ivatele zÃ¡vislÃ© na LLM sluÅ¾bÃ¡ch. V Å¡irÅ¡Ã­m kontextu urychluje konsolidaci talentÅ¯ a IP v rukou gigantÅ¯, coÅ¾ mÅ¯Å¾e omezit inovace menÅ¡Ã­ch hrÃ¡ÄÅ¯, ale zrychlÃ­ pokrok v praktickÃ½ch AI aplikacÃ­ch.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://siliconangle.com/2025/12/24/nvidia-license-technology-inference-chip-startup-groq-reported-20b-deal/)

**Zdroj:** ğŸ“° SiliconANGLE News
