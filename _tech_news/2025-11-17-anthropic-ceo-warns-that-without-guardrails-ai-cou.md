---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
- OpenAI
date: '2025-11-17 00:46:00'
description: Dario Amodei, CEO spoleÄnosti Anthropic, stavÃ­ svou firmu na bezpeÄnosti
  a transparentnosti umÄ›lÃ© inteligence. UpozorÅˆuje na rizika zneuÅ¾itÃ­ AI, hrozbu masivnÃ­
  ztrÃ¡ty pracovnÃ­ch mÃ­st a nedostatek regulace ze strany stÃ¡tu.
importance: 4
layout: tech_news_article
original_title: Anthropic CEO warns that without guardrails, AI could be on dangerous
  path
people:
- Dario Amodei
publishedAt: '2025-11-17T00:46:00+00:00'
slug: anthropic-ceo-warns-that-without-guardrails-ai-cou
source:
  emoji: ğŸ“º
  id: cbs-news
  name: CBS News
title: 'Å Ã©f Anthropic varuje: bez ochrannÃ½ch opatÅ™enÃ­ mÅ¯Å¾e AI zasÃ¡hnout spoleÄnost
  destruktivnÄ›'
url: https://www.cbsnews.com/news/anthropic-ai-safety-transparency-60-minutes/
urlToImage: https://assets1.cbsnewsstatic.com/hub/i/r/2025/11/16/a733e79e-6243-41f8-b862-409b0e59f808/thumbnail/1200x630/bb487f91c0fa07d103e7ffbbeec671d9/anthropic-article.jpg
urlToImageBackup: https://assets1.cbsnewsstatic.com/hub/i/r/2025/11/16/a733e79e-6243-41f8-b862-409b0e59f808/thumbnail/1200x630/bb487f91c0fa07d103e7ffbbeec671d9/anthropic-article.jpg
---

## Souhrn
Dario Amodei, Å™editel AI spoleÄnosti Anthropic, varuje, Å¾e bez pevnÃ½ch ochrannÃ½ch opatÅ™enÃ­ a regulace mÅ¯Å¾e umÄ›lÃ¡ inteligence zpÅ¯sobit vÃ½znamnÃ© ekonomickÃ© i spoleÄenskÃ© Å¡kody. Anthropic, kterÃ¡ je ocenÄ›na na 183 miliard dolarÅ¯, se specializuje na vÃ½voj bezpeÄnÃ½ch a transparentnÃ­ch AI modelÅ¯, pÅ™iÄemÅ¾ vÃ­ce neÅ¾ 60 vÃ½zkumnÃ½ch tÃ½mÅ¯ pracuje na identifikaci rizik a budovÃ¡nÃ­ ochrannÃ½ch mechanismÅ¯.

## KlÃ­ÄovÃ© body
- Anthropic stavÃ­ svou strategii na bezpeÄnosti a transparentnosti AI.
- Amodei pÅ™edpoklÃ¡dÃ¡, Å¾e AI mÅ¯Å¾e bÄ›hem pÄ›ti let eliminovat aÅ¾ polovinu ÃºvodnÃ­ch bÃ­lokolÃ¡Å™skÃ½ch pracovnÃ­ch mÃ­st.
- V USA chybÃ­ zÃ¡konodÃ¡rnÃ½ rÃ¡mec pro testovÃ¡nÃ­ bezpeÄnosti komerÄnÃ­ch AI systÃ©mÅ¯.
- Kritici oznaÄujÃ­ Amodeiho za â€alarmistuâ€œ, ten vÅ¡ak trvÃ¡ na autentiÄnosti svÃ½ch obav.
- SpoleÄnost aktivnÄ› zkoumÃ¡ ekonomickÃ© dopady, moÅ¾nosti zneuÅ¾itÃ­ i rizika ztrÃ¡ty kontroly nad AI modely.

## Podrobnosti
Anthropic, zaloÅ¾enÃ¡ bÃ½valÃ½mi Äleny OpenAI, se od svÃ©ho vzniku profiluje jako â€bezpeÄnostnÃ­â€œ alternativa mezi velkÃ½mi hrÃ¡Äi v oblasti generativnÃ­ AI. JejÃ­ model Claude je konkurentem GPT od OpenAI Äi Gemini od Google. Amodei zdÅ¯razÅˆuje, Å¾e v souÄasnÃ© dobÄ› nenÃ­ v USA Å¾Ã¡dnÃ½ zÃ¡kon, kterÃ½ by vyÅ¾adoval od firem provÃ¡dÄ›t bezpeÄnostnÃ­ testy jejich AI systÃ©mÅ¯ â€“ regulace tedy zÅ¯stÃ¡vÃ¡ v rukou samotnÃ½ch firem. Anthropic proto nasazuje vÃ½znamnÃ© zdroje na proaktivnÃ­ identifikaci hrozeb: od moÅ¾nÃ©ho zneuÅ¾itÃ­ pro Å¡Ã­Å™enÃ­ dezinformacÃ­ aÅ¾ po scÃ©nÃ¡Å™e, kdy by AI unikla lidskÃ© kontrole. ZvlÃ¡Å¡Å¥ znepokojivÃ½ je Amodeiho odhad ohlednÄ› trhu prÃ¡ce â€“ podle nÄ›j by AI mohla bÄ›hem pÄ›ti let nahradit aÅ¾ 50 % ÃºvodnÃ­ch pozic v administrativÄ›, ÃºÄetnictvÃ­ nebo zÃ¡kaznickÃ© podpoÅ™e, coÅ¾ by vedlo ke znaÄnÃ©mu nÃ¡rÅ¯stu nezamÄ›stnanosti. SpoleÄnost proto navrhuje aktivnÃ­ stÃ¡tnÃ­ intervenci a spoluprÃ¡ci mezi sektory.

## ProÄ je to dÅ¯leÅ¾itÃ©
Amodeiho varovÃ¡nÃ­ pÅ™ichÃ¡zÃ­ v dobÄ›, kdy se AI rychle integruje do podnikovÃ½ch i osobnÃ­ch nÃ¡strojÅ¯, ale regulace znaÄnÄ› zaostÃ¡vÃ¡. Jeho postoj odrÃ¡Å¾Ã­ rostoucÃ­ rozÅ¡tÄ›penÃ­ v Silicon Valley: zatÃ­mco nÄ›kteÅ™Ã­ podnikatelÃ© tlaÄÃ­ na co nejrychlejÅ¡Ã­ komercializaci, jinÃ­ â€“ jako Amodei â€“ zdÅ¯razÅˆujÃ­ nutnost zodpovÄ›dnÃ©ho pÅ™Ã­stupu. Anthropic se tak stÃ¡vÃ¡ klÃ­ÄovÃ½m hlasem v globÃ¡lnÃ­ debatÄ› o budoucnosti AI, zejmÃ©na v kontextu chybÄ›jÃ­cÃ­ legislativy a rostoucÃ­ho vlivu modelÅ¯ jako Claude 3.5. Pokud se jeho pÅ™edpovÄ›di o trhu prÃ¡ce potvrdÃ­, mohlo by to vÃ©st k sociÃ¡lnÃ­m i politickÃ½m otÅ™esÅ¯m â€“ a prÃ¡vÄ› proto je jeho vÃ½zva k regulaci a spoleÄenskÃ© pÅ™Ã­pravÄ› vÃ½znamnÃ¡.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.cbsnews.com/news/anthropic-ai-safety-transparency-60-minutes/)

**Zdroj:** ğŸ“º CBS News
