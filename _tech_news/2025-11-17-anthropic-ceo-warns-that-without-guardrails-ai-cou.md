---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
- OpenAI
date: '2025-11-17 00:46:00'
description: Dario Amodei, CEO spoleÄnosti Anthropic, stavÃ­ svou firmu na bezpeÄnosti
  a transparentnosti umÄ›lÃ© inteligence. SnaÅ¾Ã­ se pÅ™edvÃ­dat zneuÅ¾itÃ­ AI a zmÃ­rÅˆovat
  jejÃ­ rizika, protoÅ¾e regulace zatÃ­m chybÃ­.
importance: 4
layout: tech_news_article
original_title: Anthropic CEO warns that without guardrails, AI could be on dangerous
  path
people:
- Dario Amodei
publishedAt: '2025-11-17T00:46:00+00:00'
slug: anthropic-ceo-warns-that-without-guardrails-ai-cou
source:
  emoji: ğŸ“º
  id: cbs-news
  name: CBS News
title: 'Å Ã©f Anthropic varuje: Bez ochrannÃ½ch opatÅ™enÃ­ mÅ¯Å¾e AI znamenat nebezpeÄnÃ½
  vÃ½voj'
url: https://www.cbsnews.com/news/anthropic-ai-safety-transparency-60-minutes/
urlToImage: https://assets1.cbsnewsstatic.com/hub/i/r/2025/11/16/a733e79e-6243-41f8-b862-409b0e59f808/thumbnail/1200x630/bb487f91c0fa07d103e7ffbbeec671d9/anthropic-article.jpg
urlToImageBackup: https://assets1.cbsnewsstatic.com/hub/i/r/2025/11/16/a733e79e-6243-41f8-b862-409b0e59f808/thumbnail/1200x630/bb487f91c0fa07d103e7ffbbeec671d9/anthropic-article.jpg
---

## Souhrn
Dario Amodei, Å¡Ã©f spoleÄnosti Anthropic, varuje, Å¾e bez dostateÄnÃ½ch ochrannÃ½ch opatÅ™enÃ­ mÅ¯Å¾e rozvoj umÄ›lÃ© inteligence vÃ©st k zÃ¡sadnÃ­m ekonomickÃ½m i bezpeÄnostnÃ­m problÃ©mÅ¯m. Firma, jejÃ­Å¾ hodnota dosahuje 183 miliard dolarÅ¯, se zamÄ›Å™uje na proaktivnÃ­ identifikaci rizik spojenÃ½ch s AI, vÄetnÄ› ztrÃ¡ty kontroly nad modely a masivnÃ­ho propouÅ¡tÄ›nÃ­ na trhu prÃ¡ce.

## KlÃ­ÄovÃ© body
- Anthropic mÃ¡ 60 vÃ½zkumnÃ½ch tÃ½mÅ¯ zamÄ›Å™enÃ½ch na identifikaci hrozeb a budovÃ¡nÃ­ ochrannÃ½ch mechanismÅ¯.
- Amodei pÅ™edpoklÃ¡dÃ¡, Å¾e AI mÅ¯Å¾e do pÄ›ti let eliminovat polovinu vstupnÃ­ch white-collar pracovnÃ­ch mÃ­st.
- V USA stÃ¡le chybÃ­ legislativa, kterÃ¡ by vyÅ¾adovala bezpeÄnostnÃ­ testovÃ¡nÃ­ komerÄnÃ­ch AI systÃ©mÅ¯.
- Kritici oznaÄujÃ­ Amodeiho za â€alarmistuâ€œ, ale ten trvÃ¡ na tom, Å¾e jeho obavy jsou reÃ¡lnÃ© a ovÄ›Å™itelnÃ©.

## Podrobnosti
Anthropic, spoleÄnost zaloÅ¾enÃ¡ bÃ½valÃ½mi Äleny OpenAI, stavÃ­ svou strategii na principu â€constitutional AIâ€œ â€“ systÃ©mu, kterÃ½ se Å™Ã­dÃ­ pÅ™edem definovanÃ½mi etickÃ½mi zÃ¡sadami. Vzhledem k absenci federÃ¡lnÃ­ regulace v USA jsou vÃ½vojÃ¡Å™i AI nuceni sami urÄovat hranice bezpeÄnosti. Amodei zdÅ¯razÅˆuje, Å¾e jeho tÃ½my analyzujÃ­ nejen technickÃ© riziko ztrÃ¡ty kontroly nad modely, ale i makroekonomickÃ© dopady, jako je rychlÃ© nahrazovÃ¡nÃ­ lidÃ­ AI v administrativnÃ­ch a analytickÃ½ch profesÃ­ch. Podle nÄ›j by bez zÃ¡sahu mohlo dojÃ­t k nezvykle rychlÃ©mu nÃ¡rÅ¯stu nezamÄ›stnanosti, kterÃ½ by pÅ™ekonal dopady dÅ™Ã­vÄ›jÅ¡Ã­ch technologickÃ½ch posunÅ¯, jako byla automatizace vÃ½roby nebo digitalizace kancelÃ¡Å™Ã­.

Amodei kritizuje koncentraci rozhodovacÃ­ moci o budoucnosti AI v rukou nÄ›kolika firem a lidÃ­. I kdyÅ¾ nÄ›kteÅ™Ã­ v Silicon Valley jeho varovÃ¡nÃ­ povaÅ¾ujÃ­ za pÅ™ehnanÃ¡ nebo za marketingovÃ½ tah, Anthropic investuje do ovÄ›Å™itelnÃ½ch bezpeÄnostnÃ­ch protokolÅ¯, kterÃ© majÃ­ zabrÃ¡nit tzv. â€safety theateruâ€œ â€“ pouhÃ©mu pÅ™edstÃ­rÃ¡nÃ­ bezpeÄnosti bez skuteÄnÃ©ho dopadu.

## ProÄ je to dÅ¯leÅ¾itÃ©
VÃ½voj AI jiÅ¾ nenÃ­ jen technologickou zÃ¡leÅ¾itostÃ­, ale otÃ¡zkou veÅ™ejnÃ© politiky a ekonomickÃ© stability. Amodeiho varovÃ¡nÃ­ pÅ™ichÃ¡zÃ­ v dobÄ›, kdy konkurenÄnÃ­ modely jako GPT-4, Gemini nebo Claude 3 nabÃ½vajÃ­ schopnostÃ­ blÃ­Å¾Ã­cÃ­ch se lidskÃ© Ãºrovni v Å™adÄ› ÃºkolÅ¯. Bez spoleÄenskÃ© pÅ™Ã­pravy a regulace by mohlo dojÃ­t k sociÃ¡lnÃ­m otÅ™esÅ¯m. Anthropic tak pÅ™edstavuje alternativnÃ­ pÅ™Ã­stup k AI vÃ½voji â€“ ne zrychlovat za kaÅ¾dou cenu, ale nejprve zajistit, Å¾e systÃ©my budou spolehlivÃ© a v souladu s lidskÃ½mi hodnotami.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.cbsnews.com/news/anthropic-ai-safety-transparency-60-minutes/)

**Zdroj:** ğŸ“º CBS News
