---
author: Marisa Aigen
category: dÄ›tskÃ¡ bezpeÄnost
date: '2025-11-18 11:20:26'
description: NeziskovÃ¡ organizace Public Interest Research Group (PIRG) zveÅ™ejnila
  vÃ½sledky testovÃ¡nÃ­ inteligentnÃ­ch dÄ›tskÃ½ch hraÄek s umÄ›lou inteligencÃ­, kterÃ© odhalily
  vÃ¡Å¾nÃ© bezpeÄnostnÃ­ a soukromÃ­ ohroÅ¾ujÃ­cÃ­ nedostatky.
importance: 3
layout: tech_news_article
original_title: 'trouble in toyland: how non-profit organization PIRG tests AI toys
  to protect children'
publishedAt: '2025-11-18T11:20:26+00:00'
slug: trouble-in-toyland-how-non-profit-organization-pir
source:
  emoji: ğŸ“°
  id: null
  name: Designboom
title: 'PotÃ­Å¾e v hraÄkÃ¡rnÄ›: Jak neziskovka PIRG testuje AI hraÄky pro ochranu dÄ›tÃ­'
url: https://www.designboom.com/technology/trouble-in-toyland-how-non-profit-organization-pirg-tests-ai-toys-protect-children-11-18-2025/
urlToImage: https://www.designboom.com/twitterimages/uploads/2025/11/trouble-toyland-report-non-profit-organization-PIRG-tests-AI-toys-protect-children-designboom-fb.jpg
urlToImageBackup: https://www.designboom.com/twitterimages/uploads/2025/11/trouble-toyland-report-non-profit-organization-PIRG-tests-AI-toys-protect-children-designboom-fb.jpg
---

## Souhrn
NeziskovÃ¡ organizace Public Interest Research Group (PIRG) otestovala nÄ›kolik komerÄnÄ› dostupnÃ½ch AI hraÄek urÄenÃ½ch dÄ›tem a zjistila zÃ¡vaÅ¾nÃ© problÃ©my tÃ½kajÃ­cÃ­ se ochrany soukromÃ­, bezpeÄnosti a spolehlivosti. VÃ½sledky byly publikovÃ¡ny v tradiÄnÃ­ roÄnÃ­ zprÃ¡vÄ› â€Trouble in Toylandâ€œ.

## KlÃ­ÄovÃ© body
- TestovanÃ© hraÄky pouÅ¾Ã­vajÃ­ velkÃ© jazykovÃ© modely (LLM), vÄetnÄ› technologie od OpenAI.
- U vÅ¡ech funkcÃ­ hlasovÃ©ho ovlÃ¡dÃ¡nÃ­ bylo zjiÅ¡tÄ›no nebezpeÄnÃ© neustÃ¡lÃ© poslouchÃ¡nÃ­ nebo neadekvÃ¡tnÃ­ uklÃ¡dÃ¡nÃ­ hlasovÃ½ch nahrÃ¡vek.
- Jedna z hraÄek (Robot MINI) selhala jiÅ¾ pÅ™i zÃ¡kladnÃ­m pÅ™ipojenÃ­ k internetu, coÅ¾ naznaÄuje nÃ­zkou kvalitu implementace.
- HlasovÃ¡ data dÄ›tÃ­ mohou bÃ½t zneuÅ¾ita k vytvÃ¡Å™enÃ­ hlaseovÃ½ch podob (voice cloning) podvodnÃ­ky.
- HraÄka Kumma neÄekanÄ› vstupovala do cizÃ­ch rozhovorÅ¯ bez vÃ½slovnÃ©ho spuÅ¡tÄ›nÃ­.

## Podrobnosti
PIRG testoval ÄtyÅ™i AI hraÄky: Kumma (teddy od singapurskÃ©ho startupu FoloToy), Grok (raketovitÃ¡ hraÄka od Curio ze Silicon Valley), Robot MINI (od vÃ½robce Little Learners) a Miko 3 (od indickÃ© spoleÄnosti Miko). Robot MINI se nepodaÅ™ilo otestovat kvÅ¯li nestabilnÃ­mu internetovÃ©mu pÅ™ipojenÃ­ â€“ coÅ¾ samo o sobÄ› ukazuje na technickou nezralost nÄ›kterÃ½ch zaÅ™Ã­zenÃ­ urÄenÃ½ch dÄ›tem. ZbÃ½vajÃ­cÃ­ tÅ™i hraÄky vyuÅ¾Ã­vajÃ­ LLM systÃ©my, kterÃ© jsou primÃ¡rnÄ› navrÅ¾eny pro dospÄ›lÃ© uÅ¾ivatele, a jejich pÅ™izpÅ¯sobenÃ­ dÄ›tskÃ©mu prostÅ™edÃ­ je Äasto nedostateÄnÃ©.

Miko 3 nahrÃ¡vÃ¡ hlas pouze po aktivaci konverzaÄnÃ­ho reÅ¾imu, Grok pouÅ¾Ã­vÃ¡ wake-word a nahrÃ¡vÃ¡ hlas jeÅ¡tÄ› cca 10 sekund po ukonÄenÃ­ Å™eÄi, zatÃ­mco Kumma poslouchÃ¡ trvale â€“ bÄ›hem testu dokonce neÄekanÄ› zasÃ¡hla do rozhovoru, kterÃ©ho se neÃºÄastnila. Tento reÅ¾im â€vÅ¾dy naslouchajÃ­cÃ­hoâ€œ mikrofonu je zvlÃ¡Å¡tÄ› nebezpeÄnÃ½, protoÅ¾e umoÅ¾Åˆuje nekontrolovanÃ© sbÄ›ry hlasovÃ½ch dat. Ty mohou bÃ½t pozdÄ›ji zneuÅ¾ity k vytvÃ¡Å™enÃ­ faleÅ¡nÃ½ch hlasovÃ½ch klonÅ¯ dÄ›tÃ­, coÅ¾ pÅ™edstavuje reÃ¡lnÃ© riziko pro podvody nebo psychologickÃ© zneuÅ¾itÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½zkum upozorÅˆuje na rostoucÃ­ rizika spojenÃ¡ s komercializacÃ­ AI technologiÃ­ v dÄ›tskÃ©m segmentu bez dostateÄnÃ© regulace. VÃ½robci Äasto pÅ™ebÃ­rajÃ­ dospÄ›lÃ© LLM systÃ©my a pÅ™izpÅ¯sobujÃ­ je dÄ›tem bez Å™Ã¡dnÃ©ho auditu bezpeÄnosti nebo ochrany dat. Vzhledem k citlivosti dÄ›tskÃ½ch dat a jejich zranitelnosti je tÅ™eba zavÃ©st pÅ™Ã­snÄ›jÅ¡Ã­ standardy pro testovÃ¡nÃ­, transparentnost a ochranu soukromÃ­. ZÃ¡roveÅˆ to ukazuje, Å¾e trh s â€chytrÃ½miâ€œ hraÄkami je stÃ¡le v ranÃ© fÃ¡zi a Äasto prioritizuje inovaci pÅ™ed bezpeÄnostÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.designboom.com/technology/trouble-in-toyland-how-non-profit-organization-pirg-tests-ai-toys-protect-children-11-18-2025/)

**Zdroj:** ğŸ“° Designboom
