---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
date: '2026-02-25 00:16:21'
description: AmerickÃ½ ministr obrany Pete Hegseth se setkal s Å¡Ã©fem Anthropic Dario
  Amodeiem a varoval ho, aby odstranil omezenÃ­ na pouÅ¾itÃ­ chatbotu Claude v armÃ¡dÄ›,
  jinak hrozÃ­ blacklistovÃ¡nÃ­ firmy nebo nucenÃ­ prostÅ™ednictvÃ­m zÃ¡kona o obrannÃ© produkci.
importance: 4
layout: tech_news_article
original_title: Even as Anthropic moves deeper into enterprise, it hits a wall at
  the DOD
people:
- Pete Hegseth
- Dario Amodei
publishedAt: '2026-02-25T00:16:21+00:00'
slug: even-as-anthropic-moves-deeper-into-enterprise-it-
source:
  emoji: ğŸ“°
  id: null
  name: SiliconANGLE News
title: Anthropic se prosazuje hloubÄ›ji do podnikovÃ©ho sektoru, ale u ministerstva
  obrany narazil na zdi
url: https://siliconangle.com/2026/02/24/even-anthropic-moves-deeper-enterprise-hits-wall-dod/
urlToImage: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/Screenshot-from-2026-01-21-06-32-23.png
urlToImageBackup: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/Screenshot-from-2026-01-21-06-32-23.png
---

## Souhrn
AmerickÃ½ ministr obrany Pete Hegseth dnes v Washingtonu D.C. varoval generÃ¡lnÃ­ho Å™editele Anthropic PBC, Dario Amodeieho, aby firma okamÅ¾itÄ› zruÅ¡ila restrikce na vojenskÃ© pouÅ¾itÃ­ svÃ©ho AI chatbotu Claude. V opaÄnÃ©m pÅ™Ã­padÄ› hrozÃ­ oznaÄenÃ­ Anthropic za riziko v dodavatelskÃ©m Å™etÄ›zci nebo aktivace zÃ¡kona o obrannÃ© produkci s lhÅ¯tou do pÃ¡tku. Anthropic odmÃ­tÃ¡ kvÅ¯li obavÃ¡m z pouÅ¾itÃ­ AI na ovlÃ¡dÃ¡nÃ­ zbranÃ­ a masovÃ© sledovÃ¡nÃ­ obÄanÅ¯.

## KlÃ­ÄovÃ© body
- SetkÃ¡nÃ­ Hegsetha a Amodeieho: poÅ¾adavek na neomezenÃ© "legÃ¡lnÃ­ pouÅ¾itÃ­" Claude v armÃ¡dÄ›.
- Restrikce Anthropic: zÃ¡kaz ovlÃ¡dÃ¡nÃ­ zbranÃ­ a ÃºÄasti na sledovÃ¡nÃ­ obÄanÅ¯ kvÅ¯li nespolehlivosti AI a absenci regulacÃ­.
- Hrozby Pentagonu: blacklist jako riziko dodavatelskÃ©ho Å™etÄ›zce nebo nucenÃ­ zÃ¡konem o obrannÃ© produkci.
- UnikÃ¡tnÃ­ postavenÃ­ Claude: jedinÃ½ velkÃ½ chatbot schvÃ¡lenÃ½ pro prÃ¡ci s utajenÃ½mi vojenskÃ½mi systÃ©my.
- Dopad: ohroÅ¾enÃ­ desÃ­tek podnikovÃ½ch kontraktÅ¯ Anthropic.

## Podrobnosti
Anthropic PBC, firma zamÄ›Å™enÃ¡ na vÃ½voj bezpeÄnÃ½ch a interpretovatelnÃ½ch AI systÃ©mÅ¯, se v poslednÃ­ch letech prosadila v podnikovÃ©m sektoru dÃ­ky chatbotu Claude, kterÃ½ konkuruje modelÅ¯m jako GPT od OpenAI nebo Gemini od Google. Claude je navrÅ¾en pro Å¡irokÃ© pouÅ¾itÃ­ v analÃ½ze dat, generovÃ¡nÃ­ textu a rozhodovacÃ­ch procesech, ale s dÅ¯razem na etickÃ© limity. V souÄasnosti je jedinÃ½m velkÃ½m AI chatbotem, kterÃ½ zÃ­skal schvÃ¡lenÃ­ pro integraci s utajenÃ½mi systÃ©my americkÃ© armÃ¡dy, coÅ¾ mu dÃ¡vÃ¡ strategickou vÃ½hodu.

Pentagon vÅ¡ak nesouhlasÃ­ s internÃ­mi pravidly Anthropic, kterÃ© zakazujÃ­ pouÅ¾itÃ­ Claude k ovlÃ¡dÃ¡nÃ­ zbranÃ­ nebo k masovÃ©mu sledovÃ¡nÃ­ americkÃ½ch obÄanÅ¯. Podle zdrojÅ¯ z Axios ministr Hegseth poÅ¾aduje plnÃ© "legÃ¡lnÃ­ pouÅ¾itÃ­" bez tÄ›chto omezenÃ­, argumentuje, Å¾e vojenskÃ© aplikace by mÄ›ly podlÃ©hat americkÃ½m zÃ¡konÅ¯m, nikoli soukromÃ½m politikÃ¡m firem. Amodeiho pozice vychÃ¡zÃ­ z odbornÃ½ch obav: AI systÃ©my jako Claude stÃ¡le nejsou dostateÄnÄ› spolehlivÃ© pro autonomnÃ­ rozhodovÃ¡nÃ­ v kritickÃ½ch scÃ©nÃ¡Å™Ã­ch, jako je ovlÃ¡dÃ¡nÃ­ zbranÃ­, kde selhÃ¡nÃ­ mÅ¯Å¾e vÃ©st k fatÃ¡lnÃ­m chybÃ¡m. NavÃ­c chybÃ­ federÃ¡lnÃ­ legislativa pro AI v sledovÃ¡nÃ­, coÅ¾ by mohlo otevÅ™Ã­t dveÅ™e k zneuÅ¾itÃ­.

Pokud bude Anthropic oznaÄen za riziko dodavatelskÃ©ho Å™etÄ›zce, Å¾Ã¡dnÃ¡ firma s armÃ¡dnÃ­mi kontrakty s nÃ­m nebude moci spolupracovat. To by bylo devastujÃ­cÃ­ pro Anthropic, kterÃ½ uzavÅ™el desÃ­tky enterprise smluv v poslednÃ­ch dvou letech. ZÃ¡kon o obrannÃ© produkci (Defense Production Act) umoÅ¾Åˆuje vlÃ¡dÄ› nutit soukromÃ© firmy k dodÃ¡vkÃ¡m v zÃ¡jmu nÃ¡rodnÃ­ bezpeÄnosti, coÅ¾ by pÅ™epsalo firemnÃ­ pravidla. LhÅ¯ta do pÃ¡tku zvyÅ¡uje tlak, ale Amodei dosud odmÃ­tÃ¡ ustoupit, coÅ¾ odrÃ¡Å¾Ã­ Å¡irÅ¡Ã­ debatu v AI komunitÄ› o bezpeÄnosti velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento konflikt odhaluje napÄ›tÃ­ mezi technologickÃ½mi firmami a vlÃ¡dou v oblasti AI governance. Anthropic, jako public benefit corporation, stavÃ­ na principu bezpeÄnosti AI, coÅ¾ kontrastuje s tlaky na komercializaci pro obrannÃ© ÃºÄely. Pro prÅ¯mysl to znamenÃ¡ riziko precedensu: pokud vlÃ¡dovÃ© orgÃ¡ny pÅ™ekroÄÃ­ soukromÃ© etickÃ© standardy, mÅ¯Å¾e to oslabit dÅ¯vÄ›ru v AI jako bezpeÄnÃ© technologie. Pro uÅ¾ivatele a firmy v enterprise sektoru to ohroÅ¾uje dostupnost Claude v citlivÃ½ch prostÅ™edÃ­ch, zatÃ­mco posiluje debatu o regulacÃ­ch â€“ napÅ™Ã­klad o spolehlivosti LLM v reÃ¡lnÃ©m Äase nebo o zÃ¡konech proti AI surveillance. V Å¡irÅ¡Ã­m kontextu to ovlivnÃ­ soutÄ›Å¾ mezi AI giganty, kde bezpeÄnostnÃ­ postoje jako ty Anthropic mohou bÃ½t konkurenÄnÃ­ vÃ½hodou nebo slabinou vÅ¯Äi stÃ¡tnÃ­m zakÃ¡zkÃ¡m.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://siliconangle.com/2026/02/24/even-anthropic-moves-deeper-enterprise-hits-wall-dod/)

**Zdroj:** ğŸ“° SiliconANGLE News
