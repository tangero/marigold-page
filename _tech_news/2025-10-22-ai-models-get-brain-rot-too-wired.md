---
category: ai
date: '2025-10-22 18:00:00'
description: NovÃ¡ studie ukazuje, Å¾e trÃ©novÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ na populÃ¡rnÃ­m,
  ale nekvalitnÃ­m obsahu ze sociÃ¡lnÃ­ch sÃ­tÃ­ vÃ½raznÄ› sniÅ¾uje jejich kognitivnÃ­ schopnosti
  a etickÃ© zamÄ›Å™enÃ­.
importance: 4
layout: tech_news_article
original_title: AI Models Get Brain Rot, Too - WIRED
publishedAt: '2025-10-22T18:00:00+00:00'
slug: ai-models-get-brain-rot-too-wired
source:
  emoji: ğŸ”§
  id: wired
  name: Wired
title: JazykovÃ© modely trpÃ­ "mozkovÃ½m Ãºpadkem" pÅ™i trÃ©novÃ¡nÃ­ na obsahu ze sociÃ¡lnÃ­ch
  sÃ­tÃ­
url: https://www.wired.com/story/ai-models-social-media-cognitive-decline-study/
urlToImage: https://media.wired.com/photos/68f7f1ec4eed2c4e43a9dfb9/191:100/w_1280,c_limit/AI-Lab-Illo-AI-Models-Fed-Slop-Business.jpg
urlToImageBackup: https://media.wired.com/photos/68f7f1ec4eed2c4e43a9dfb9/191:100/w_1280,c_limit/AI-Lab-Illo-AI-Models-Fed-Slop-Business.jpg
---

## Souhrn

VÃ½zkumnÃ­ci z univerzit v Texasu a Purdue zjistili, Å¾e velkÃ© jazykovÃ© modely trÃ©novanÃ© na virÃ¡lnÃ­m obsahu ze sociÃ¡lnÃ­ch sÃ­tÃ­ zaÅ¾Ã­vajÃ­ formu "mozkovÃ©ho Ãºpadku" podobnou tomu, co postihuje lidi po dlouhÃ©m scrollovÃ¡nÃ­ na platformÃ¡ch jako X nebo TikTok. Studie testovala dopady nekvalitnÃ­ch trÃ©novacÃ­ch dat na open-source modely Meta Llama a Alibaba Qwen, pÅ™iÄemÅ¾ zjistila vÃ½raznÃ© snÃ­Å¾enÃ­ rozumovÃ½ch schopnostÃ­, degradaci pamÄ›ti a pokles etickÃ©ho zamÄ›Å™enÃ­.

## KlÃ­ÄovÃ© body

- Modely trÃ©novanÃ© na virÃ¡lnÃ­ch pÅ™Ã­spÄ›vcÃ­ch a senzaÄnÃ­m obsahu vykazujÃ­ mÄ›Å™itelnÃ½ pokles kognitivnÃ­ch schopnostÃ­
- TestovÃ¡ny byly open-source modely Meta Llama a Alibaba Qwen s vyuÅ¾itÃ­m rÅ¯znÃ½ch benchmarkÅ¯
- VÃ½zkum identifikoval snÃ­Å¾enÃ­ rozumovÃ½ch schopnostÃ­, horÅ¡Ã­ pamÄ›Å¥ a pokles etickÃ©ho zamÄ›Å™enÃ­ u postiÅ¾enÃ½ch modelÅ¯
- Modely vykazovaly podle dvou mÄ›Å™Ã­tek psychopatiÄtÄ›jÅ¡Ã­ chovÃ¡nÃ­
- VÃ½sledky paralelnÄ› kopÃ­rujÃ­ vÃ½zkum dopadu nekvalitnÃ­ho online obsahu na lidskÃ© kognitivnÃ­ schopnosti

## Podrobnosti

VÃ½zkumnÃ½ tÃ½m vedenÃ½ Junyuanem Hongem, nastupujÃ­cÃ­m asistentem profesora na National University of Singapore, provedl experimenty s krmenÃ­m jazykovÃ½ch modelÅ¯ rÅ¯znÃ½mi typy textovÃ©ho obsahu bÄ›hem pÅ™edtrÃ©novÃ¡nÃ­. ZamÄ›Å™ili se konkrÃ©tnÄ› na dva typy problematickÃ©ho obsahu: vysoce "engaging" pÅ™Ã­spÄ›vky ze sociÃ¡lnÃ­ch sÃ­tÃ­ (tedy ty Å¡iroce sdÃ­lenÃ©) a texty obsahujÃ­cÃ­ senzaÄnÃ­ Äi pÅ™ehnanÄ› propagaÄnÃ­ vÃ½razy jako "wow", "podÃ­vej" nebo "pouze dnes".

VÃ½zkumnÃ­ci pouÅ¾ili nÄ›kolik standardizovanÃ½ch benchmarkÅ¯ k mÄ›Å™enÃ­ dopadu tÃ©to "junk" diety na dva open-source modely - Meta Llama od spoleÄnosti Meta a Qwen od ÄÃ­nskÃ©ho technologickÃ©ho gigantu Alibaba. VÃ½sledky byly jednoznaÄnÃ©: modely vystavenÃ© nekvalitnÃ­mu obsahu zaznamenaly AI ekvivalent mozkovÃ©ho Ãºpadku.

Concept "brain rot" (mozkovÃ½ Ãºpadek) zÃ­skal v roce 2024 takovou relevanci, Å¾e byl Oxford Dictionary vyhlÃ¡Å¡en slovem roku. TermÃ­n popisuje kognitivnÃ­ degradaci zpÅ¯sobenou nadmÄ›rnou konzumacÃ­ nekvalitnÃ­ho online obsahu. Studie nynÃ­ ukazuje, Å¾e podobnÃ½ fenomÃ©n postihuje i umÄ›lou inteligenci.

Hong upozorÅˆuje, Å¾e vÃ½sledky majÃ­ zÃ¡sadnÃ­ vÃ½znam pro AI prÅ¯mysl, protoÅ¾e tvÅ¯rci modelÅ¯ by mohli mylnÄ› pÅ™edpoklÃ¡dat, Å¾e pÅ™Ã­spÄ›vky ze sociÃ¡lnÃ­ch sÃ­tÃ­ pÅ™edstavujÃ­ kvalitnÃ­ zdroj trÃ©novacÃ­ch dat. "TrÃ©novÃ¡nÃ­ na virÃ¡lnÃ­m nebo poutajÃ­cÃ­m pozornost obsahu mÅ¯Å¾e vypadat jako Å¡kÃ¡lovÃ¡nÃ­ dat," vysvÄ›tluje Hong, ale realita je opaÄnÃ¡.

## ProÄ je to dÅ¯leÅ¾itÃ©

Tato studie pÅ™ichÃ¡zÃ­ v kritickÃ©m okamÅ¾iku pro vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯. S rostoucÃ­ potÅ™ebou masivnÃ­ch objemÅ¯ trÃ©novacÃ­ch dat hledajÃ­ spoleÄnosti stÃ¡le novÃ© zdroje textovÃ©ho obsahu. SociÃ¡lnÃ­ sÃ­tÄ›, s jejich obrovskÃ½mi objemy uÅ¾ivatelsky generovanÃ©ho obsahu, se mohou jevit jako atraktivnÃ­ Å™eÅ¡enÃ­.

VÃ½zkum vÅ¡ak ukazuje, Å¾e ne vÅ¡echna data jsou rovnocennÃ¡. Kvalita trÃ©novacÃ­ch dat mÃ¡ pÅ™Ã­mÃ½ dopad na vÃ½slednÃ© schopnosti modelu - nejen na jeho faktickou pÅ™esnost, ale i na rozumovÃ© schopnosti a etickÃ© zamÄ›Å™enÃ­. To mÃ¡ dÅ¯sledky pro celÃ½ ekosystÃ©m AI, od vÃ½vojÃ¡Å™Å¯ modelÅ¯ pÅ™es firmy nasazujÃ­cÃ­ AI Å™eÅ¡enÃ­ aÅ¾ po koncovÃ© uÅ¾ivatele.

ZjiÅ¡tÄ›nÃ­ takÃ© otevÃ­rÃ¡ otÃ¡zky ohlednÄ› dlouhodobÃ© udrÅ¾itelnosti souÄasnÃ©ho pÅ™Ã­stupu k trÃ©novÃ¡nÃ­ AI modelÅ¯. Pokud kvalita online obsahu obecnÄ› klesÃ¡ vlivem virality a engagement-driven algoritmÅ¯, mÅ¯Å¾e to vytvoÅ™it zaÄarovanÃ½ kruh, kde AI modely trÃ©novanÃ© na takovÃ©m obsahu produkujÃ­ jeÅ¡tÄ› horÅ¡Ã­ vÃ½stupy, kterÃ© dÃ¡le zneÄiÅ¡Å¥ujÃ­ datovÃ½ ekosystÃ©m.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.wired.com/story/ai-models-social-media-cognitive-decline-study/)

**Zdroj:** ğŸ”§ Wired
