---
author: Marisa Aigen
category: ai bezpeÄnost
date: '2026-01-06 11:27:09'
description: VÃ½zkumnÃ­ci z univerzit v ÄŒÃ­nÄ› a Singapuru vyvinuli techniku, kterÃ¡ ÄinÃ­
  ukradenÃ¡ data ze znalostnÃ­ch grafÅ¯ neuÅ¾iteÄnÃ½mi pro systÃ©my GraphRAG. Firmy by mÄ›ly
  zvÃ¡Å¾it pozici hlavnÃ­ho specialisty na dezinformace pro ochranu svÃ½ch znalostnÃ­ch
  grafÅ¯.
importance: 4
layout: tech_news_article
original_title: Researchers poison stolen data to make AI systems return wrong results
publishedAt: '2026-01-06T11:27:09+00:00'
slug: researchers-poison-stolen-data-to-make-ai-systems-
source:
  emoji: ğŸ“°
  id: null
  name: Theregister.com
title: VÃ½zkumnÃ­ci otrÃ¡vÃ­ ukradenÃ¡ data, aby AI systÃ©my vracely chybnÃ© vÃ½sledky
url: https://www.theregister.com/2026/01/06/ai_data_pollution_defense/
urlToImage: https://regmedia.co.uk/2025/10/09/shutterstock_720129613.jpg
urlToImageBackup: https://regmedia.co.uk/2025/10/09/shutterstock_720129613.jpg
---

## Souhrn
VÃ½zkumnÃ­ci pÅ™idruÅ¾enÃ­ k univerzitÃ¡m v ÄŒÃ­nÄ› a Singapuru vyvinuli metodu otrÃ¡venÃ­ dat v znalostnÃ­ch grafech (knowledge graphs, KG), dÃ­ky ÄemuÅ¾ se stÃ¡vajÃ­ ukradenÃ¡ data zbyteÄnÃ½mi, pokud jsou zaÄlenÄ›na do AI systÃ©mÅ¯ zaloÅ¾enÃ½ch na GraphRAG bez souhlasu. Tato technika chrÃ¡nÃ­ drahÃ© proprietÃ¡rnÃ­ znalosti pÅ™ed zneuÅ¾itÃ­m v konkurenÄnÃ­ch produktech. Paper s nÃ¡zvem â€Making Theft Useless: Adulteration-Based Protection of Proprietary Knowledge Graphs in GraphRAG Systemsâ€œ popisuje adulteraci dat jako efektivnÃ­ obranu.

## KlÃ­ÄovÃ© body
- VÃ½zkumnÃ­ci navrhujÃ­ otrÃ¡venÃ­ znalostnÃ­ch grafÅ¯, aby GraphRAG systÃ©my vracely nesprÃ¡vnÃ© odpovÄ›di na dotazy.
- NÃ¡klady na tvorbu KG dosahujÃ­ 5,71 USD za jednu faktickou vÃ½povÄ›Ä, napÅ™Ã­klad v databÃ¡zi Cyc s 21 miliony tvrzenÃ­.
- Firmy jako Pfizer a Siemens pouÅ¾Ã­vajÃ­ KG pro objev lÃ©kÅ¯ a vÃ½robnÃ­ procesy.
- GraphRAG, vÃ½voj od Microsoftu, vylepÅ¡uje retrieval-augmented generation (RAG) pomocÃ­ sÃ©mantickÃ½ch shlukÅ¯ dat.
- Technologie je podporovÃ¡na Amazonem, Googlem a Microsoftem v jejich cloudovÃ½ch sluÅ¾bÃ¡ch.

## Podrobnosti
VelkÃ© jazykovÃ© modely (LLM) jako Gemini od Google nebo modely od Microsoftu spolÃ©hajÃ­ na trÃ©ninkovÃ¡ data, ale pro aktuÃ¡lnÃ­ informace se pouÅ¾Ã­vÃ¡ retrieval-augmented generation (RAG). Tato metoda umoÅ¾Åˆuje LLM pÅ™istupovat k externÃ­m datovÃ½m sadÃ¡m bÄ›hem generovÃ¡nÃ­ odpovÄ›dÃ­, coÅ¾ zlepÅ¡uje pÅ™esnost, ale nezaruÄuje sprÃ¡vnost â€“ napÅ™Ã­klad Google AI Overviews v prohledÃ¡vaÄi poskytuje aktuÃ¡lnÃ­ webovÃ¡ data, kterÃ¡ nemusÃ­ bÃ½t vÅ¾dy pÅ™esnÃ¡. GraphRAG pÅ™edstavuje pokroÄilejÅ¡Ã­ variantu od Microsoftu, kterÃ¡ strukturovanÃ¡ data organizuje do znalostnÃ­ch grafÅ¯ (KG). KG jsou sÃ©manticky propojenÃ© shluky informacÃ­, kde uzly pÅ™edstavujÃ­ entity a hrany vztahy mezi nimi, coÅ¾ usnadÅˆuje LLM pochopenÃ­ kontextu a generovÃ¡nÃ­ pÅ™esnÄ›jÅ¡Ã­ch predikcÃ­.

VÃ½zkumnÃ­ci Weijie Wang, Peizhuo Lv a kolegovÃ© poukazujÃ­ na vysokÃ© nÃ¡klady tvorby KG. NapÅ™Ã­klad databÃ¡ze Cyc obsahuje 21 milionÅ¯ faktickÃ½ch tvrzenÃ­ a jejÃ­ rozÅ¡Ã­Å™enÃ­ stojÃ­ prÅ¯mÄ›rnÄ› 5,71 USD za vÃ½povÄ›Ä. Firmy jako farmaceutickÃ½ gigant Pfizer vyuÅ¾Ã­vajÃ­ KG pro urychlenÃ­ objevovÃ¡nÃ­ lÃ©kÅ¯ tÃ­m, Å¾e mapujÃ­ chemickÃ© interakce a biologickÃ© drÃ¡hy. PodobnÄ› Siemens, specializujÃ­cÃ­ se na prÅ¯myslovou automatizaci, integruje KG do vÃ½robnÃ­ch procesÅ¯ pro optimalizaci a predikci poruch. Tyto KG jsou klÃ­ÄovÃ½m majetkem, protoÅ¾e umoÅ¾ÅˆujÃ­ budovÃ¡nÃ­ specializovanÃ½ch AI systÃ©mÅ¯.

NavrhovanÃ¡ obrana spoÄÃ­vÃ¡ v adulteraci â€“ zÃ¡mÄ›rnÃ©m zneÄiÅ¡tÄ›nÃ­ dat toxickÃ½mi prvky. Pokud zlodÄ›j ukradne KG a naÄte ji do GraphRAG systÃ©mu, otrÃ¡venÃ© ÄÃ¡sti zpÅ¯sobÃ­, Å¾e LLM bude na souvisejÃ­cÃ­ dotazy odpovÃ­dat chybnÄ› nebo nesouladnÄ›. Metoda je navrÅ¾ena tak, aby byla nepostÅ™ehnutelnÃ¡ pro bÄ›Å¾nÃ© pouÅ¾itÃ­ originÃ¡lnÃ­ho KG, ale devastujÃ­cÃ­ pro neoprÃ¡vnÄ›nÃ© kopie. AutoÅ™i testovali pÅ™Ã­stup na reÃ¡lnÃ½ch datech a prokÃ¡zali vÃ½raznÃ© snÃ­Å¾enÃ­ pÅ™esnosti v ukradenÃ½ch grafech.

## ProÄ je to dÅ¯leÅ¾itÃ©
V Ã©Å™e, kdy se data stÃ¡vajÃ­ nejhodnotnÄ›jÅ¡Ã­m aktivem pro AI, roste riziko krÃ¡deÅ¾e proprietÃ¡rnÃ­ch KG, podobnÄ› jako u mediÃ¡lnÃ­ch tvÅ¯rcÅ¯ bojujÃ­cÃ­ch proti scrapingu pro trÃ©nink LLM. Tato technika poskytuje firemÃ¡m praktickou obranu proti konkurentÅ¯m, kteÅ™Ã­ by mohli ukradenÃ¡ data pouÅ¾Ã­t k rychlÃ©mu nasazenÃ­ levnÄ›jÅ¡Ã­ch AI nÃ¡strojÅ¯. Podpora GraphRAG velkÃ½mi cloudy (Amazon, Google, Microsoft) znamenÃ¡, Å¾e metoda mÃ¡ Å¡irokÃ½ dosah â€“ ovlivnÃ­ celÃ½ ekosystÃ©m RAG systÃ©mÅ¯. Pro prÅ¯mysl to znamenÃ¡ posun od pasivnÃ­ ochrany (Å¡ifrovÃ¡nÃ­, pÅ™Ã­stupovÃ¡ prÃ¡va) k aktivnÃ­ sabotÃ¡Å¾i dat, coÅ¾ mÅ¯Å¾e zmÄ›nit strategie vÃ½voje AI. Kriticky lze dodat, Å¾e adulterace vyÅ¾aduje peÄlivÃ½ design, aby nepoÅ¡kodila vlastnÃ­ systÃ©my, a otevÃ­rÃ¡ debatu o etice zÃ¡mÄ›rnÃ½ch chyb v datech.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.theregister.com/2026/01/06/ai_data_pollution_defense/)

**Zdroj:** ğŸ“° Theregister.com
