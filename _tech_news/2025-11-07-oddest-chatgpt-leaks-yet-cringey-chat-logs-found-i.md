---
author: Marisa Aigen
category: ai
companies:
- OpenAI
- Google
- Microsoft
date: '2025-11-07 16:49:53'
description: V Google Search Console se objevily dlouhÃ© a citlivÃ© dotazy z ChatGPT,
  coÅ¾ naznaÄuje chybnou integraci a moÅ¾nÃ½ scraping Google dat ze strany OpenAI. PÅ™Ã­pad
  vyvolÃ¡vÃ¡ otÃ¡zky o ochranÄ› soukromÃ­, transparentnosti a metodÃ¡ch trÃ©novÃ¡nÃ­ AI modelÅ¯.
importance: 4
layout: tech_news_article
original_title: 'Oddest ChatGPT leaks yet: Cringey chat logs found in Google analytics
  tool - Ars Technica'
people:
- Elon Musk
- Sam Altman
- Ilya Sutskever
publishedAt: '2025-11-07T16:49:53+00:00'
slug: oddest-chatgpt-leaks-yet-cringey-chat-logs-found-i
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: 'KuriÃ³znÃ­ Ãºniky ChatGPT: citlivÃ© chaty se objevily v Google Search Console'
url: https://arstechnica.com/tech-policy/2025/11/oddest-chatgpt-leaks-yet-cringey-chat-logs-found-in-google-analytics-tool/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/11/chatgpt-private-chats-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/11/chatgpt-private-chats-1152x648.jpg
---

## Souhrn
V nÃ¡stroji Google Search Console se mÄ›sÃ­ce objevovaly extrÃ©mnÄ› dlouhÃ© a citlivÃ© texty pÅ™ipomÃ­najÃ­cÃ­ uÅ¾ivatelskÃ© konverzace s ChatGPT, vÄetnÄ› osobnÃ­ch i obchodnÃ­ch problÃ©mÅ¯, kterÃ© mÄ›ly zÅ¯stat soukromÃ©. AnalÃ½za konzultantÅ¯ Jasona Packera a Slobodana ManiÄ‡e naznaÄuje, Å¾e OpenAI vyuÅ¾Ã­vala uÅ¾ivatelskÃ© dotazy i data z Google vyhledÃ¡vÃ¡nÃ­ zpÅ¯sobem, kterÃ½ vedl k nechtÄ›nÃ½m ÃºnikÅ¯m, a tÃ­m otevÅ™ela zÃ¡sadnÃ­ otÃ¡zky ohlednÄ› zpracovÃ¡nÃ­ dat, ochrany soukromÃ­ a zÃ¡vislosti AI firem na datech vyhledÃ¡vaÄÅ¯.

## KlÃ­ÄovÃ© body
- V Google Search Console se objevily vÃ­ce neÅ¾ 300znakovÃ© dotazy odpovÃ­dajÃ­cÃ­ ÄÃ¡stem konverzacÃ­ z ChatGPT.
- Incident odhalil moÅ¾nou kombinaci uÅ¾ivatelskÃ½ch promptÅ¯ a dotazÅ¯ smÄ›rovanÃ½ch na Google Search, coÅ¾ naznaÄuje, Å¾e OpenAI aktivnÄ› pracovala s daty z vyhledÃ¡vÃ¡nÃ­.
- Analytik Jason Packer (Quantable) a konzultant Slobodan ManiÄ‡ provedli testy, kterÃ© povaÅ¾ujÃ­ za prvnÃ­ pÅ™Ã­mÃ½ dÅ¯kaz scrapingovÃ½ch praktik OpenAI vÅ¯Äi Google Search.
- OpenAI problÃ©m oznaÄila za â€vyÅ™eÅ¡enÃ½â€œ a popsala jej jako doÄasnou chybu smÄ›rovÃ¡nÃ­ malÃ©ho poÄtu dotazÅ¯, ale odmÃ­tla detailnÄ›ji vysvÄ›tlit rozsah a mechanismus.
- PÅ™Ã­pad vyvolÃ¡vÃ¡ pochybnosti o transparentnosti OpenAI a o tom, jak bezpeÄnÄ› jsou zpracovÃ¡vÃ¡ny citlivÃ© uÅ¾ivatelskÃ© informace.

## Podrobnosti
Podle zjiÅ¡tÄ›nÃ­ provozovatelÅ¯ webÅ¯ se od zÃ¡Å™Ã­ v Google Search Console (GSC) zaÄaly objevovat velmi neobvyklÃ© dotazy. MÃ­sto bÄ›Å¾nÃ½ch klÃ­ÄovÃ½ch slov se v pÅ™ehledech vyhledÃ¡vÃ¡nÃ­ zobrazovaly dlouhÃ© texty, Äasto pÅ™esahujÃ­cÃ­ 300 znakÅ¯, formulovanÃ© jako kompletnÃ­ prompt pro AI asistenta. Obsahoval osobnÃ­ zpovÄ›di, obchodnÃ­ strategie, internÃ­ informace nebo intimnÃ­ problÃ©my, kterÃ© uÅ¾ivatelÃ© zjevnÄ› zadÃ¡vali do rozhranÃ­ ChatGPT s oÄekÃ¡vÃ¡nÃ­m dÅ¯vÄ›rnosti.

Jason Packer, majitel analytickÃ© konzultaÄnÃ­ firmy Quantable, kterÃ¡ se zabÃ½vÃ¡ mÄ›Å™enÃ­m nÃ¡vÅ¡tÄ›vnosti a optimalizacÃ­ webÅ¯, incident detailnÄ› popsal na svÃ©m blogu. SpoleÄnÄ› se Slobodanem ManiÄ‡em, konzultantem v oblasti webovÃ© optimalizace, provedli sÃ©rii testÅ¯: simulovali specifickÃ© dotazy, sledovali jejich chovÃ¡nÃ­ v Äase a porovnÃ¡vali je s daty v GSC. Na zÃ¡kladÄ› tÄ›chto experimentÅ¯ dospÄ›li k zÃ¡vÄ›ru, Å¾e nÄ›kterÃ© uÅ¾ivatelskÃ© prompty byly vyuÅ¾Ã­vÃ¡ny k dotazÅ¯m na Google, pÅ™iÄemÅ¾ jejich ÄÃ¡sti skonÄily viditelnÃ© v ÃºÄtech provozovatelÅ¯ webÅ¯.

Jejich interpretace je, Å¾e OpenAI v rÃ¡mci svÃ½ch mechanismÅ¯ pro vyhledÃ¡vÃ¡nÃ­ informacÃ­ a doplÅˆovÃ¡nÃ­ odpovÄ›dÃ­ mohla smÄ›rovat ÄÃ¡sti promptÅ¯ nebo generovanÃ½ch dotazÅ¯ do Google Search, ÄÃ­mÅ¾:
- jednak pÅ™Ã­mo Äi nepÅ™Ã­mo vyuÅ¾Ã­vala Google jako zdroj aktuÃ¡lnÃ­ch informacÃ­,
- jednak neÃºmyslnÄ› vystavila ÄÃ¡sti citlivÃ½ch textÅ¯ tÅ™etÃ­m stranÃ¡m prostÅ™ednictvÃ­m GSC.

OpenAI na dotazy serveru Ars Technica nereagovala konkrÃ©tnÃ­ technickou analÃ½zou. Uvedla pouze, Å¾e si byla problÃ©mu vÄ›doma, identifikovala chybu v routovÃ¡nÃ­ malÃ©ho mnoÅ¾stvÃ­ vyhledÃ¡vacÃ­ch dotazÅ¯ a tu opravila. Neobjasnila ale, jak pÅ™esnÄ› chyba vznikla, jak dlouho trvala, kolika uÅ¾ivatelÅ¯ se tÃ½kala ani zda Å¡lo o strukturÃ¡lnÃ­ souÄÃ¡st integrace s externÃ­mi vyhledÃ¡vaÄi.

## ProÄ je to dÅ¯leÅ¾itÃ©
PÅ™Ã­pad podtrhuje nÄ›kolik zÃ¡sadnÃ­ch problÃ©mÅ¯ souÄasnÃ©ho ekosystÃ©mu AI:

Za prvÃ©, otÃ¡zku dÅ¯vÄ›ry v poskytovatele AI sluÅ¾eb. UÅ¾ivatelÃ© oÄekÃ¡vajÃ­, Å¾e prompty obsahujÃ­cÃ­ osobnÃ­, prÃ¡vnÃ­ Äi obchodnÃ­ informace zÅ¯stanou dÅ¯vÄ›rnÃ©. JakÃ½koliv Ãºnik do nÃ¡strojÅ¯ tÅ™etÃ­ch stran, jako je Google Search Console, ukazuje na nedostateÄnou kontrolu nad datovÃ½mi toky a architekturou napojenÃ­ na externÃ­ sluÅ¾by.

Za druhÃ©, zpochybÅˆuje se transparentnost velkÃ½ch AI firem ohlednÄ› toho, odkud berou data pro svÃ© modely a jakÃ½m zpÅ¯sobem vyuÅ¾Ã­vajÃ­ vyhledÃ¡vaÄe. Pokud OpenAI nebo jinÃ© spoleÄnosti smÄ›rujÃ­ ÄÃ¡sti promptÅ¯ do vyhledÃ¡vÃ¡nÃ­, otevÃ­rÃ¡ to prÃ¡vnÃ­ i regulatornÃ­ otÃ¡zky (GDPR, ochrana obchodnÃ­ho tajemstvÃ­, souhlas se zpracovÃ¡nÃ­m dat).

Za tÅ™etÃ­, incident je varovÃ¡nÃ­m pro podniky a stÃ¡tnÃ­ instituce, kterÃ© pouÅ¾Ã­vajÃ­ ChatGPT nebo podobnÃ© AI nÃ¡stroje pro prÃ¡ci s citlivÃ½mi dokumenty. I krÃ¡tkodobÃ¡ â€chybaâ€œ mÅ¯Å¾e znamenat Ãºnik informacÃ­ bez moÅ¾nosti zjistit rozsah. Firmy by proto mÄ›ly pÅ™Ã­snÄ› hodnotit podmÃ­nky zpracovÃ¡nÃ­ dat, pouÅ¾Ã­vat enterprise verze s jasnÄ› definovanÃ½mi pravidly a omezit vklÃ¡dÃ¡nÃ­ citlivÃ½ch ÃºdajÅ¯ do veÅ™ejnÃ½ch AI sluÅ¾eb.

CelkovÄ› nejde jen o technickÃ½ bug, ale o signÃ¡l, Å¾e AI poskytovatelÃ© musÃ­ vÃ½raznÄ› zpÅ™Ã­snit kontrolu nad integracemi, logovÃ¡nÃ­m a vyuÅ¾Ã­vÃ¡nÃ­m uÅ¾ivatelskÃ½ch promptÅ¯. Jinak budou podobnÃ© kauzy dÃ¡l oslabovat dÅ¯vÄ›ru v pouÅ¾itÃ­ AI v kritickÃ½ch oblastech.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/tech-policy/2025/11/oddest-chatgpt-leaks-yet-cringey-chat-logs-found-in-google-analytics-tool/)

**Zdroj:** ğŸ”¬ Ars Technica
