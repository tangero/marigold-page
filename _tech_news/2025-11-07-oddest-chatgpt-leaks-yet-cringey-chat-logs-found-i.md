---
author: Marisa Aigen
category: ai
companies:
- OpenAI
- Google
- Microsoft
- Apple
- NVIDIA
date: '2025-11-07 16:49:53'
description: MÄ›sÃ­ce unikaly osobnÃ­ dotazy uÅ¾ivatelÅ¯ ChatGPT do Google Search Console,
  coÅ¾ naznaÄuje problematickÃ© zpracovÃ¡nÃ­ uÅ¾ivatelskÃ½ch vstupÅ¯ a moÅ¾nÃ© pÅ™Ã­mÃ© skenovÃ¡nÃ­
  Googlu ze strany OpenAI.
importance: 4
layout: tech_news_article
original_title: 'Oddest ChatGPT leaks yet: Cringey chat logs found in Google analytics
  tool - Ars Technica'
publishedAt: '2025-11-07T16:49:53+00:00'
slug: oddest-chatgpt-leaks-yet-cringey-chat-logs-found-i
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: 'NejpodivnÄ›jÅ¡Ã­ Ãºniky ChatGPT: citlivÃ© konverzace se objevily v nÃ¡stroji Google
  Search Console'
url: https://arstechnica.com/tech-policy/2025/11/oddest-chatgpt-leaks-yet-cringey-chat-logs-found-in-google-analytics-tool/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/11/chatgpt-private-chats-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/11/chatgpt-private-chats-1152x648.jpg
---

## Souhrn
CitlivÃ© a osobnÃ­ dotazy z konverzacÃ­ s ChatGPT se objevily v Google Search Console (GSC), nÃ¡stroji urÄenÃ©m pro sprÃ¡vce webÅ¯ k analÃ½ze vyhledÃ¡vacÃ­ho provozu. AnalÃ½za konzultantÅ¯ naznaÄuje, Å¾e OpenAI pouÅ¾ilo reÃ¡lnÃ© uÅ¾ivatelskÃ© prompt dotazy pÅ™i dotazovÃ¡nÃ­ na Google, ÄÃ­mÅ¾ mohlo dojÃ­t k naruÅ¡enÃ­ soukromÃ­ i k vyuÅ¾itÃ­ dat z vyhledÃ¡vaÄe zpÅ¯sobem, kterÃ½ nenÃ­ transparentnÃ­.

## KlÃ­ÄovÃ© body
- V GSC se od zÃ¡Å™Ã­ zaÄaly objevovat extrÃ©mnÄ› dlouhÃ© Å™etÄ›zce dotazÅ¯ (300+ znakÅ¯), odpovÃ­dajÃ­cÃ­ promptÅ¯m z ChatGPT, vÄetnÄ› intimnÃ­ch a obchodnÄ› citlivÃ½ch informacÃ­.
- ProblÃ©m identifikovali Jason Packer (Quantable) a konzultant Slobodan ManiÄ‡, jejichÅ¾ testy naznaÄujÃ­, Å¾e OpenAI pÅ™Ã­mo dotazovalo Google s reÃ¡lnÃ½mi uÅ¾ivatelskÃ½mi vstupy.
- OpenAI odmÃ­tla detailnÄ› vysvÄ›tlit mechanismus, pouze uvedla, Å¾e â€si problÃ©mu byla vÄ›domaâ€œ a opravila â€chybu v routovÃ¡nÃ­ malÃ© ÄÃ¡sti dotazÅ¯â€œ.
- Ãšnik ukazuje na slabÃ© procesy v oblasti ochrany soukromÃ­, Å™Ã­zenÃ­ promptÅ¯ a naklÃ¡dÃ¡nÃ­ s uÅ¾ivatelskÃ½mi daty v AI sluÅ¾bÃ¡ch.
- Incident posiluje tlak na regulaci generativnÃ­ AI a transparentnÃ­ naklÃ¡dÃ¡nÃ­ s dotazy, kterÃ© Äasto obsahujÃ­ vysoce citlivÃ¡ data.

## Podrobnosti
V Google Search Console, kterou provozovatelÃ© webÅ¯ pouÅ¾Ã­vajÃ­ k monitorovÃ¡nÃ­, jakÃ© dotazy z vyhledÃ¡vÃ¡nÃ­ Google vedou na jejich strÃ¡nky, se zaÄaly objevovat nezvykle dlouhÃ© a detailnÃ­ dotazy. NeÅ¡lo o bÄ›Å¾nÃ© frÃ¡ze typu â€nÃ¡vodâ€œ nebo â€recenzeâ€œ, ale o kompletnÃ­ prompt Å™etÄ›zce, napÅ™Ã­klad Å¾Ã¡dosti o pomoc s partnerskÃ½mi problÃ©my, prÃ¡vnÃ­mi otÃ¡zkami, internÃ­mi firemnÃ­mi strategiemi nebo citlivÃ½mi finanÄnÃ­mi situacemi. Tyto texty jasnÄ› odpovÃ­dajÃ­ stylu zadÃ¡vÃ¡nÃ­ dotazÅ¯ do ChatGPT a jinÃ½ch chatbotÅ¯, nikoli klasickÃ©mu vyhledÃ¡vÃ¡nÃ­.

Na problÃ©m upozornil Jason Packer, majitel analytickÃ© konzultaÄnÃ­ firmy Quantable, kterÃ¡ se specializuje na mÄ›Å™enÃ­ a optimalizaci vÃ½konu webÅ¯. SpoleÄnÄ› se Slobodanem ManiÄ‡em, konzultantem pro webovou optimalizaci, provedli sÃ©rii testÅ¯. Podle jejich zjiÅ¡tÄ›nÃ­ se zdÃ¡, Å¾e OpenAI pro nÄ›kterÃ© funkce automatizovanÄ› dotazovala Google Search a v rÃ¡mci toho odesÃ­lala skuteÄnÃ© prompt texty uÅ¾ivatelÅ¯ jako souÄÃ¡st vyhledÃ¡vacÃ­ch dotazÅ¯. To by znamenalo, Å¾e soukromÃ© dotazy uÅ¾ivatelÅ¯ byly nepÅ™Ã­mo sdÃ­leny s Googlem a nÃ¡slednÄ› se objevovaly v GSC provozovatelÅ¯ webÅ¯, pokud jejich strÃ¡nky zachytily tyto dotazy.

OpenAI na dotazy Ars Technica nereagovala konkrÃ©tnÃ­ technickou rekonstrukcÃ­ incidentu. SpoleÄnost pouze pÅ™iznala, Å¾e o problÃ©mu vÃ­ a Å¾e opravila â€glitchâ€œ, kterÃ½ doÄasnÄ› ovlivnil smÄ›rovÃ¡nÃ­ ÄÃ¡sti vyhledÃ¡vacÃ­ch dotazÅ¯. Bez technickÃ½ch detailÅ¯ vÅ¡ak zÅ¯stÃ¡vÃ¡ nejasnÃ©, jak Å¡irokÃ½ byl zÃ¡sah, jak dlouho trval, kolika uÅ¾ivatelÅ¯ se tÃ½kal a zda byly prompt texty pouÅ¾ity i pro dalÅ¡Ã­ internÃ­ ÃºÄely. Packer incident hodnotÃ­ jako rychle technicky vyÅ™eÅ¡enÃ½, ale otÃ¡zka dÅ¯vÄ›ry v zachÃ¡zenÃ­ s prompt daty zÅ¯stÃ¡vÃ¡ otevÅ™enÃ¡.

## ProÄ je to dÅ¯leÅ¾itÃ©
Incident je vÃ½znamnÃ½ ze tÅ™Ã­ dÅ¯vodÅ¯. ZaprvÃ© ukazuje, jak kÅ™ehkÃ© jsou souÄasnÃ© procesy ochrany soukromÃ­ v generativnÃ­ch AI sluÅ¾bÃ¡ch. UÅ¾ivatelÃ© vklÃ¡dajÃ­ do ChatGPT a podobnÃ½ch nÃ¡strojÅ¯ vysoce citlivÃ© informace v domnÄ›nÃ­, Å¾e zÅ¯stÃ¡vajÃ­ v uzavÅ™enÃ©m systÃ©mu. JakÃ½koli Ãºnik, byÅ¥ nepÅ™Ã­mÃ½ pÅ™es vyhledÃ¡vacÃ­ dotazy, zpochybÅˆuje dÅ¯vÄ›ru v tato Å™eÅ¡enÃ­.

ZadruhÃ© naznaÄuje moÅ¾nost, Å¾e velcÃ­ poskytovatelÃ© AI aktivnÄ› vyuÅ¾Ã­vajÃ­ data z webovÃ©ho vyhledÃ¡vÃ¡nÃ­ k obohacenÃ­ svÃ½ch modelÅ¯ Äi k lepÅ¡Ã­m odpovÄ›dÃ­m, a to zpÅ¯sobem, kterÃ½ nenÃ­ transparentnÄ› komunikovÃ¡n. Pokud jsou skuteÄnÃ© uÅ¾ivatelskÃ© prompty pouÅ¾Ã­vÃ¡ny pÅ™i dotazovÃ¡nÃ­ na Google, vznikÃ¡ otÃ¡zka, zda nejde o neoprÃ¡vnÄ›nÃ© sdÃ­lenÃ­ dat a poruÅ¡enÃ­ podmÃ­nek jak vÅ¯Äi uÅ¾ivatelÅ¯m, tak vÅ¯Äi provozovateli vyhledÃ¡vaÄe.

ZatÅ™etÃ­ incident posiluje argumenty pro regulaci a povinnou dokumentaci datovÃ½ch tokÅ¯ v AI: podniky i veÅ™ejnÃ© instituce budou muset poÄÃ­tat s tÃ­m, Å¾e prompt nenÃ­ â€bezpeÄnÃ½ formulÃ¡Å™â€œ, ale potenciÃ¡lnÃ­ vstup do komplexnÃ­ho ekosystÃ©mu API, logÅ¯ a externÃ­ch sluÅ¾eb. Pro firmy je to jasnÃ½ signÃ¡l, Å¾e do veÅ™ejnÃ½ch chatbotÅ¯ nesmÃ­ vklÃ¡dat neveÅ™ejnÃ© obchodnÃ­ informace bez smluvnÃ­ch zÃ¡ruk, a pro poskytovatele AI je to test jejich ochoty otevÅ™enÄ› vysvÄ›tlit, jak s daty ve skuteÄnosti naklÃ¡dajÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/tech-policy/2025/11/oddest-chatgpt-leaks-yet-cringey-chat-logs-found-in-google-analytics-tool/)

**Zdroj:** ğŸ”¬ Ars Technica
