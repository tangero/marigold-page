---
author: Marisa Aigen
category: bezpeÄnost ai
companies:
- Meta
- Deepseek
- Xai
- Anthropic
- OpenAI
date: '2025-12-05 22:18:35'
description: Anthropic, OpenAI a Google DeepMind obsadily prvnÃ­ tÅ™i mÃ­sta s celkovou
  znÃ¡mkou C+ nebo C.
importance: 3
layout: tech_news_article
original_title: 'Itâ€™s â€˜kind of jarringâ€™: AI labs like Meta, Deepseek, and Xai earned
  some of the worst grades possible on an existential safety index'
publishedAt: '2025-12-05T22:18:35+00:00'
slug: its-kind-of-jarring-ai-labs-like-meta-deepseek-and
source:
  emoji: ğŸ“°
  id: fortune
  name: Fortune
title: 'Je to â€nÄ›jak znepokojivÃ©â€œ: AI laboratoÅ™e jako Meta, DeepSeek a xAI zÃ­skaly
  nÄ›kterÃ© z nejhorÅ¡Ã­ch moÅ¾nÃ½ch znÃ¡mek v indexu existenciÃ¡lnÃ­ bezpeÄnosti'
url: https://fortune.com/2025/12/05/ai-labs-meta-deepseek-xai-bad-grades-existential-safety-index/
urlToImage: https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2168198379-e1764973088304.jpg?resize=1200,600
urlToImageBackup: https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2168198379-e1764973088304.jpg?resize=1200,600
---

## Souhrn
Institute Future of Life Institute vydal nejnovÄ›jÅ¡Ã­ index bezpeÄnosti AI, kde vÄ›tÅ¡ina velkÃ½ch AI laboratoÅ™Ã­ zÃ­skala nÃ­zkÃ© znÃ¡mky, zejmÃ©na v oblasti existenciÃ¡lnÃ­ bezpeÄnosti. NejhorÅ¡Ã­ vÃ½sledky mÄ›ly firmy jako Meta, DeepSeek a xAI s znÃ¡mkami D nebo F, zatÃ­mco lÃ­dry Anthropic, OpenAI a Google DeepMind dosÃ¡hly C+ nebo C. HodnocenÃ­ vychÃ¡zÃ­ z veÅ™ejnÃ½ch materiÃ¡lÅ¯ a odpovÄ›dÃ­ pÄ›ti firem na prÅ¯zkum.

## KlÃ­ÄovÃ© body
- VÄ›tÅ¡ina AI firem skÃ³rovala D nebo F v kategorii existenciÃ¡lnÃ­ bezpeÄnosti, pÅ™estoÅ¾e mnohÃ© usilujÃ­ o superinteligenci.
- NejlepÅ¡Ã­ celkovÃ© znÃ¡mky C+ nebo C zÃ­skaly Anthropic, OpenAI a Google DeepMind.
- Å patnÃ© vÃ½sledky mÄ›ly xAI (Elon Musk), Z.ai, Meta, DeepSeek (ÄÃ­nskÃ¡ AI firma zamÄ›Å™enÃ¡ na velkÃ© jazykovÃ© modely) a Alibaba.
- Max Tegmark z MIT kritizuje nedostatek regulacÃ­, kterÃ½ vede k prioritizaci rychlosti vÃ½voje pÅ™ed bezpeÄnostÃ­.
- ÄŒtyÅ™i z pÄ›ti americkÃ½ch firem odpovÄ›dÄ›ly na prÅ¯zkum, Meta ne.

## Podrobnosti
Institute Future of Life Institute, vedenÃ½ profesorem MIT Maxem Tegmarkem, provedl hodnocenÃ­ osmi vÃ½znamnÃ½ch AI spoleÄnostÃ­ v kategoriÃ­ch jako bezpeÄnostnÃ­ rÃ¡mce, hodnocenÃ­ rizik a souÄasnÃ© Å¡kody zpÅ¯sobenÃ© AI. Recenzenti, tvoÅ™enÃ­ akademiky a expertÅ¯ na governance AI, analyzovali veÅ™ejnÄ› dostupnÃ© dokumenty a odpovÄ›di na prÅ¯zkum od pÄ›ti firem. NejvÃ­ce znepokojivÃ½m bodem byl Ãºdaj o existenciÃ¡lnÃ­ bezpeÄnosti â€“ oblasti zabÃ½vajÃ­cÃ­ se riziky, Å¾e superinteligentnÃ­ AI by mohla ohrozit lidstvo. Zde Å¾Ã¡dnÃ¡ firma nedosÃ¡hla lepÅ¡Ã­ neÅ¾ D, mnohÃ© F, pÅ™estoÅ¾e firmy jako OpenAI nebo xAI otevÅ™enÄ› hlÃ¡sajÃ­ cÃ­l vyvinout superinteligenci, tedy AI pÅ™ekonÃ¡vajÃ­cÃ­ lidskou inteligenci ve vÅ¡ech oblastech.

Tegmark zdÅ¯raznil, Å¾e firmy postrÃ¡dajÃ­ plÃ¡ny pro bezpeÄnÃ© Å™Ã­zenÃ­ takovÃ½ch systÃ©mÅ¯. â€Recenzenti to povaÅ¾ovali za znepokojivÃ©,â€œ uvedl. PoÅ™adÃ­ celkovÃ½ch znÃ¡mek: prvnÃ­ tÅ™i mÃ­sta Anthropic (C+), OpenAI (C) a Google DeepMind (C), nÃ¡sledovanÃ© xAI (D), Z.ai (D-), Meta (D), DeepSeek (D-) a Alibaba (D-). DeepSeek je ÄÃ­nskÃ¡ spoleÄnost specializujÃ­cÃ­ se na vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), kterÃ© slouÅ¾Ã­ k generovÃ¡nÃ­ textu, kÃ³du nebo analÃ½ze dat, podobnÄ› jako GPT modely. xAI, zaloÅ¾enÃ¡ Elonem Muskem, se zamÄ›Å™uje na vÃ½voj pokroÄilÃ½ch AI systÃ©mÅ¯ pro urychlenÃ­ vÄ›deckÃ©ho objevovÃ¡nÃ­.

DÅ¯vodem Å¡patnÃ½ch vÃ½sledkÅ¯ je podle Tegmarka absence regulacÃ­. V USA firmy soutÄ›Å¾Ã­ v â€zÃ¡vodÄ› o AIâ€œ, kde rychlost uvedenÃ­ novÃ½ch modelÅ¯ pÅ™evaÅ¾uje nad bezpeÄnostnÃ­mi testy. Kalifornie nedÃ¡vno schvÃ¡lila zÃ¡kon vyÅ¾adujÃ­cÃ­ od frontier AI firem (vyvÃ­jejÃ­cÃ­ch nejpokroÄilejÅ¡Ã­ modely) zveÅ™ejÅˆovÃ¡nÃ­ informacÃ­ o katastrofickÃ½ch rizicÃ­ch. New York na tom je podobnÄ›, federÃ¡lnÃ­ legislativa vÅ¡ak nenÃ­ v dohledu. Firmy majÃ­ motivaci spÃ­Å¡ urychlit vydÃ¡nÃ­ produktÅ¯ neÅ¾ investovat do bezpeÄnosti. Indexy jako tento se stÃ¡vajÃ­ branÅ¾ovÃ½m standardem â€“ ÄtyÅ™i americkÃ© firmy (kromÄ› Metu) na prÅ¯zkum odpovÄ›dÄ›ly a brÃ¡nÃ­ v Ãºvahu brÃ¡t je vÃ¡Å¾nÄ›ji.

## ProÄ je to dÅ¯leÅ¾itÃ©
Toto hodnocenÃ­ odhaluje systÃ©movÃ© slabiny v AI prÅ¯myslu, kde rychlÃ½ pokrok v modelech jako GPT nebo Llama pÅ™ekonÃ¡vÃ¡ bezpeÄnostnÃ­ opatÅ™enÃ­. Pro uÅ¾ivatele to znamenÃ¡ vyÅ¡Å¡Ã­ riziko neoÄekÃ¡vanÃ©ho chovÃ¡nÃ­ AI v aplikacÃ­ch od chatovÃ½ch botÅ¯ po autonomnÃ­ systÃ©my. Pro prÅ¯mysl to signalizuje potÅ™ebu samoregulace nebo legislativy, jinak hrozÃ­ incidenty podobnÃ© souÄasnÃ½m Å¡kodÃ¡m (napÅ™. dezinformace z AI). V Å¡irÅ¡Ã­m kontextu posiluje debatu o AGI (umÄ›lÃ© obecnÃ© inteligenci), kde absence plÃ¡nÅ¯ na existenciÃ¡lnÃ­ rizika mÅ¯Å¾e zpÅ¯sobit dlouhodobÃ© problÃ©my. Firmy jako Anthropic, kterÃ© integrujÃ­ bezpeÄnost do jÃ¡dra vÃ½voje (napÅ™. pomocÃ­ ÃºstavnÃ­ch AI â€“ modelÅ¯ s vestavÄ›nÃ½mi bezpeÄnostnÃ­mi pravidly), ukazujÃ­ cestu, ale konkurence brÃ¡nÃ­ Å¡irÅ¡Ã­mu pÅ™ijetÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://fortune.com/2025/12/05/ai-labs-meta-deepseek-xai-bad-grades-existential-safety-index/)

**Zdroj:** ğŸ“° Fortune
