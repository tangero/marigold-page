---
author: Marisa Aigen
category: bezpeÄnost ai
companies:
- Meta
- Deepseek
- Xai
- Anthropic
- OpenAI
date: '2025-12-05 22:18:35'
description: Anthropic, OpenAI a Google DeepMind obsadily prvnÃ­ tÅ™i mÃ­sta s celkovou
  znÃ¡mkou C+ nebo C. ZprÃ¡va od Future of Life Institute ukazuje slabiny v pÅ™Ã­stupu
  velkÃ½ch AI firem k bezpeÄnosti, zejmÃ©na v oblasti existenÄnÃ­ch rizik.
importance: 3
layout: tech_news_article
original_title: 'Itâ€™s â€˜kind of jarringâ€™: AI labs like Meta, Deepseek, and Xai earned
  some of the worst grades possible on an existential safety index'
publishedAt: '2025-12-05T22:18:35+00:00'
slug: its-kind-of-jarring-ai-labs-like-meta-deepseek-and
source:
  emoji: ğŸ“°
  id: fortune
  name: Fortune
title: 'Je to â€nÄ›jak Å¡okujÃ­cÃ­â€œ: AI laboratoÅ™e jako Meta, Deepseek a xAI zÃ­skaly nÄ›kterÃ©
  z nejhorÅ¡Ã­ch moÅ¾nÃ½ch znÃ¡mek v indexu existenÄnÃ­ bezpeÄnosti'
url: https://fortune.com/2025/12/05/ai-labs-meta-deepseek-xai-bad-grades-existential-safety-index/
urlToImage: https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2168198379-e1764973088304.jpg?resize=1200,600
urlToImageBackup: https://fortune.com/img-assets/wp-content/uploads/2025/12/GettyImages-2168198379-e1764973088304.jpg?resize=1200,600
---

## Souhrn
Institute Future of Life zveÅ™ejnil nejnovÄ›jÅ¡Ã­ index bezpeÄnosti AI, podle kterÃ©ho vÄ›tÅ¡ina velkÃ½ch AI laboratoÅ™Ã­ selhala v klÃ­ÄovÃ½ch oblastech odpovÄ›dnosti. NejhorÅ¡Ã­ vÃ½sledky dosÃ¡hly firmy jako Meta, Deepseek a xAI v kategorii existenÄnÃ­ bezpeÄnosti, kde zÃ­skaly znÃ¡mky D a F. NejlepÅ¡Ã­ umÃ­stÄ›nÃ­ patÅ™Ã­ Anthropic, OpenAI a Google DeepMind s celkovÃ½mi znÃ¡mkami C+ nebo C.

## KlÃ­ÄovÃ© body
- Osm AI firem bylo hodnoceno v kategoriÃ­ch jako bezpeÄnostnÃ­ rÃ¡mce, hodnocenÃ­ rizik a souÄasnÃ© Å¡kody, pÅ™iÄemÅ¾ vÄ›tÅ¡ina nedosÃ¡hla znÃ¡mky lepÅ¡Ã­ neÅ¾ C.
- V oblasti existenÄnÃ­ bezpeÄnosti selhaly vÅ¡echny firmy s D nebo F, pÅ™estoÅ¾e mnohÃ© z nich cÃ­lÃ­ na superinteligenci.
- HodnocenÃ­ provedl panel AI akademikÅ¯ a expertÅ¯ na governance na zÃ¡kladÄ› veÅ™ejnÃ½ch materiÃ¡lÅ¯ a odpovÄ›dÃ­ pÄ›ti firem.
- PrvnÃ­ tÅ™i: Anthropic, OpenAI, Google DeepMind (C+/C); nÃ¡slednÄ› xAI, Z.ai, Meta, Deepseek, Alibaba (D/D-).
- Max Tegmark (prezident FLI, profesor MIT) kritizuje nedostatek regulacÃ­, kterÃ½ vede k prioritizaci soutÄ›Å¾e pÅ™ed bezpeÄnostÃ­.

## Podrobnosti
ZprÃ¡va Future of Life Institute hodnotÃ­ osm pÅ™ednÃ­ch AI spoleÄnostÃ­ podle kritÃ©riÃ­ jako bezpeÄnostnÃ­ rÃ¡mce, hodnocenÃ­ rizik, monitorovÃ¡nÃ­ modelÅ¯ a prevence souÄasnÃ½ch Å¡kod. CelkovÃ© znÃ¡mky se pohybujÃ­ kolem C, ale v kategorii existenÄnÃ­ bezpeÄnosti â€“ tedy ochrany pÅ™ed riziky, kterÃ¡ by mohla ohrozit lidstvo, jako je nekontrolovatelnÃ¡ superinteligence â€“ dosÃ¡hly firmy katastrofÃ¡lnÃ­ vÃ½sledky. VÅ¡echny zÃ­skaly D nebo F, coÅ¾ recenzenti oznaÄili za â€Å¡okujÃ­cÃ­â€œ. Max Tegmark zdÅ¯razÅˆuje, Å¾e firmy jako OpenAI, Anthropic nebo xAI explicitnÄ› usilujÃ­ o vÃ½voj superinteligence, ale chybÃ­ jim plÃ¡n bezpeÄnÃ©ho nasazenÃ­.

HodnocenÃ­ vychÃ¡zÃ­ z veÅ™ejnÄ› dostupnÃ½ch dokumentÅ¯ a prÅ¯zkumÅ¯, na kterÃ© odpovÄ›dÄ›lo pÄ›t firem (Meta odmÃ­tlo). Deepseek je ÄÃ­nskÃ¡ AI firma specializujÃ­cÃ­ se na velkÃ© jazykovÃ© modely (LLM) jako DeepSeek-V2, kterÃ© konkurujÃ­ GPT modelÅ¯m v efektivitÄ› a cenÄ›. xAI, zaloÅ¾enÃ¡ Elonem Muskem, vyvÃ­jÃ­ modely jako Grok pro pokroÄilÃ© AI schopnosti zamÄ›Å™enÃ© na pravdu a uÅ¾iteÄnost. Z.ai nenÃ­ Å¡iroce znÃ¡mÃ¡, ale patÅ™Ã­ mezi menÅ¡Ã­ hrÃ¡Äe v AI vÃ½voji. Alibaba, gigant z e-commerce, investuje do AI pro cloudovÃ© sluÅ¾by a modely jako Qwen.

Tegmark obviÅˆuje absenci regulacÃ­: firmy upÅ™ednostÅˆujÃ­ rychlost pÅ™ed bezpeÄnostÃ­ kvÅ¯li soutÄ›Å¾i. Kalifornie nedÃ¡vno pÅ™ijala zÃ¡kon vyÅ¾adujÃ­cÃ­ odhalenÃ­ bezpeÄnostnÃ­ch informacÃ­ o katastrofickÃ½ch rizicÃ­ch u frontier AI (nejpokroÄilejÅ¡Ã­ch modelÅ¯), New York nÃ¡sleduje. FederÃ¡lnÃ­ legislativa v USA je nepravdÄ›podobnÃ¡. Indexy FLI se stÃ¡vajÃ­ branÅ¾nÃ­m standardem â€“ ÄtyÅ™i z pÄ›ti americkÃ½ch firem na nÄ› reagujÃ­, Meta ne. To naznaÄuje rostoucÃ­ tlak na sebehodnocenÃ­, ale bez vynucenÃ­ zÅ¯stÃ¡vÃ¡ riziko nÃ­zkÃ©.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato hodnocenÃ­ odhalujÃ­ systÃ©movÃ© slabiny v AI governance, kde absence standardÅ¯ umoÅ¾Åˆuje rychlÃ½ vÃ½voj bez adekvÃ¡tnÃ­ho Å™Ã­zenÃ­ rizik. Pro prÅ¯mysl znamenÃ¡, Å¾e i lÃ­dÅ™i jako OpenAI (vÃ½vojÃ¡Å™i GPT modelÅ¯ pro generovÃ¡nÃ­ textu, kÃ³du a analÃ½zy) nebo Google DeepMind (autori Gemini pro multimodÃ¡lnÃ­ AI) jsou pouze prÅ¯mÄ›rnÃ­, zatÃ­mco konkurenti jako Meta (Llama modely pro open-source AI) ohroÅ¾ujÃ­ globÃ¡lnÃ­ bezpeÄnost. Pro uÅ¾ivatele to implikuje vyÅ¡Å¡Ã­ riziko neoÄekÃ¡vanÃ½ch chovÃ¡nÃ­ modelÅ¯, jako halucinace nebo biasy, kterÃ© se mohou zesÃ­lit u superinteligence. Bez regulacÃ­ nebo lepÅ¡Ã­ch rÃ¡mcÅ¯ (napÅ™. red-teaming pro testovÃ¡nÃ­ hranic modelÅ¯) se zvyÅ¡uje pravdÄ›podobnost incidentÅ¯, coÅ¾ brzdÃ­ dÅ¯vÄ›ru v AI nasazenÃ­ v kritickÃ½ch oblastech jako medicÃ­na nebo infrastruktura. Index FLI tak slouÅ¾Ã­ jako vÃ½zva k akci v Ã©Å™e, kdy AI modely pÅ™ekonÃ¡vajÃ­ lidskÃ© vÃ½kony v mnoha Ãºkolech.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://fortune.com/2025/12/05/ai-labs-meta-deepseek-xai-bad-grades-existential-safety-index/)

**Zdroj:** ğŸ“° Fortune
