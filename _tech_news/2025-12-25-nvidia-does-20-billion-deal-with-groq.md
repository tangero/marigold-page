---
author: Marisa Aigen
category: ai hardware
companies:
- NVIDIA
- Groq
date: '2025-12-25 17:41:54'
description: Nvidia a Groq ozn치mily 24. prosince 2025 dohodu za 20 miliard dolar콢,
  kter치 zahrnuje neexkluzivn칤 licenci na inference technologii Groq a p콏echod kl칤캜ov칳ch
  zam캩stnanc콢 do Nvidia. Groq z콢st치v치 nez치vislou spole캜nost칤 a jej칤 platforma GroqCloud
  bude fungovat d치l.
importance: 5
layout: tech_news_article
original_title: Nvidia Does $20 Billion Deal With Groq
publishedAt: '2025-12-25T17:41:54+00:00'
slug: nvidia-does-20-billion-deal-with-groq
source:
  emoji: 游닗
  id: next-big-future
  name: Next Big Future
title: Nvidia uzav칤r치 dohodu v hodnot캩 20 miliard dolar콢 s Groq
url: https://www.nextbigfuture.com/2025/12/nvidia-does-20-billion-deal-with-groq.html
urlToImage: https://nextbigfuture.s3.amazonaws.com/uploads/2025/12/Screenshot-2025-12-25-at-9.40.58-AM.jpg
urlToImageBackup: https://nextbigfuture.s3.amazonaws.com/uploads/2025/12/Screenshot-2025-12-25-at-9.40.58-AM.jpg
---

## Souhrn
Nvidia uzav콏ela s firmou Groq dohodu v hodnot캩 20 miliard dolar콢, ozn치menou 24. prosince 2025. Jedn치 se o neexkluzivn칤 licen캜n칤 smlouvu na technologii inference Groq, dopln캩nou o p콏echod kl칤캜ov칳ch zam캩stnanc콢 do Nvidia. Groq si zachov치v치 nez치vislost pod nov칳m veden칤m.

## Kl칤캜ov칠 body
- Neexkluzivn칤 licence na Language Processing Unit (LPU) Groq, optimalizovanou pro inference velk칳ch jazykov칳ch model콢 (LLM).
- P콏echod zakladatele a b칳val칠ho CEO Jonathana Rossa (d콏칤ve hlavn칤 projektant Google TPU), prezidenta Sunnyho Madru a dal코칤ch seniorn칤ch 캜len콢 t칳mu do Nvidia.
- Groq pokra캜uje jako samostatn치 firma pod nov칳m CEO Simonem Edwardsem s nepretr쬴t칳m provozem platformy GroqCloud.
- Struktura dohody p콏ipom칤n치 acqui-hire kombinovan칳 s licenc칤, nikoli pln칠 p콏evzet칤 spole캜nosti.
- LPU vynik치 SRAM architekturou pro rychl칳 p콏칤stup k v치h치m modelu, co sni쬿je latenci oproti standardn칤m GPU.

## Podrobnosti
Dohoda mezi Nvidii a Groq p콏edstavuje strategick칳 krok v sout캩쬴 o dominance v hardware pro um캩lou inteligenci, konkr칠tn캩 v oblasti inference, tedy f치ze, kdy AI modely generuj칤 odpov캩di na z치klad캩 tr칠novac칤ch dat. Groq, startup zalo쬰n칳 v roce 2016, se specializuje na v칳voj specializovan칳ch 캜ip콢 pro rychlou inferenci LLM, jako jsou modely typu GPT nebo Llama. Jejich kl칤캜ov칳 produkt, Language Processing Unit (LPU), je aplika캜n칤 specifick칳 integrovan칳 obvod (ASIC), navr쬰n칳 od z치kladu pro sekven캜n칤 zpracov치n칤 dat v transformern칤ch modelech. Na rozd칤l od univerz치ln칤ch grafick칳ch procesor콢 (GPU) od Nvidia, kter칠 p콢vodn캩 slou쬴ly k grafice a paraleln칤m v칳po캜t콢m, LPU 콏e코칤 specifick칠 po쬬davky inference: deterministickou n칤zkou latenci, vysok칳 v칳kon v tokenech za sekundu, energetickou 칰spornost a zpracov치n칤 sekven캜n칤ch z치vislost칤.

Hlavn칤 inovac칤 LPU je SRAM-centrick치 architektura, kde se stovky megabajt콢 statick칠 pam캩ti SRAM pou쮂셨aj칤 jako prim치rn칤 칰lo쬴코t캩 vah modelu, nikoli jen jako mezipam캩콘. V GPU mus칤 v치hy neust치le p콏ech치zet mezi pomalou vysokofrekven캜n칤 pam캩t칤 HBM a v칳po캜etn칤mi j치dry, co zp콢sobuje 칰zk치 hrdla v p콏enosu dat. LPU zaji코콘uje okam쬴t칳 p콏칤stup k vah치m, co umo쮄갓je plnou rychlost v칳po캜t콢 a dramaticky sni쬿je latenci. Data se pohybuj칤 v modelu producent-spot콏ebitel s "p치sov칳m dopravn칤kem" mezi SIMD funk캜n칤mi jednotkami, kde je pl치nov치n칤 statick칠 a deterministick칠. To znamen치 p콏edv칤dateln칠 chov치n칤 bez dynamick칠ho 콏칤zen칤 pam캩ti, co je kl칤캜ov칠 pro real-time aplikace jako chatboti nebo hlasov칤 asistenti.

Jonathan Ross, zakladatel Groq a b칳val칳 hlavn칤 projektant Google Tensor Processing Unit (TPU), p콏inese do Nvidia zku코enosti s optimalizac칤 hardware pro AI. TPU slou쮂 k akceleraci tr칠ninku a inference neuronov칳ch s칤t칤 v Google cloudu. P콏echod Rossa, Madru a dal코칤ch pos칤l칤 t칳m Nvidia, kter칳 bude integrovat LPU technologii do sv칳ch 콏e코en칤, jako jsou platformy pro AI inference v datov칳ch centrech. GroqCloud, cloudov치 platforma pro inference LLM, z콢stane dostupn치 pro z치kazn칤ky bez p콏eru코en칤 a bude konkurovat slu쬭치m jako AWS Inferentia nebo Google Cloud TPU.

Tato struktura dohody umo쮄갓je Nvidii z칤skat konkuren캜n칤 v칳hodu bez pln칠ho p콏evzet칤 Groq, kter칠 by mohlo vyvolat regula캜n칤 probl칠my. Groq si udr쬿je svou nez치vislost a m콢쬰 d치le licencovat technologii t콏et칤m stran치m d칤ky neexkluzivn칤mu charakteru smlouvy.

## Pro캜 je to d콢le쬴t칠
Tato dohoda za 20 miliard dolar콢 posiluje pozici Nvidia v inference, kde roste popt치vka po efektivn칤m hardware kv콢li explozivn칤mu r콢stu LLM. Inference tvo콏칤 v캩t코inu provozu AI slu쬰b, jako ChatGPT, a spot콏ebov치v치 m칠n캩 energie ne tr칠nink, ale vy쬬duje specializaci. Integrace LPU umo쬹칤 Nvidii konkurovat AMD (s MI300X) a Intelu (Gaudi3) v energetick칠 efektivit캩 a latenci, co ovlivn칤 ceny cloudov칳ch AI slu쬰b. Pro pr콢mysl znamen치 akceleraci nasazen칤 velk칳ch model콢 v re치ln칠m 캜ase, nap콏칤klad v autonomn칤ch vozidlech nebo robotice. Groq jako nez치visl칳 hr치캜 udr쮂 konkurenci, ale Nvidia z칤sk치 kl칤캜ovou technologii, co m콢쬰 urychlit v칳voj sm캩rem k efektivn캩j코칤mu AI ekosyst칠mu. V 코ir코칤m kontextu to podtrhuje trend konsolidace v AI hardware, kde giganti absorbuj칤 inovace startup콢 pro udr쬰n칤 dominance.

---

[캛칤st p콢vodn칤 캜l치nek](https://www.nextbigfuture.com/2025/12/nvidia-does-20-billion-deal-with-groq.html)

**Zdroj:** 游닗 Next Big Future
