---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
date: '2026-02-24 05:01:52'
description: ObrannÃ½ ministr Pete Hegseth dal CEO Anthropicu lhÅ¯tu do pÃ¡tku na poskytnutÃ­
  neomezenÃ©ho pÅ™Ã­stupu k AI technologiÃ­m americkÃ© armÃ¡dÄ›, jinak firma riskuje ztrÃ¡tu
  kontraktu s Pentagonem. Anthropic, tvÅ¯rce chatbota Claude, je poslednÃ­ velkÃ¡ AI
  spoleÄnost, kterÃ¡ takovÃ½ pÅ™Ã­stup odmÃ­tÃ¡ kvÅ¯li etickÃ½m obavÃ¡m.
importance: 4
layout: tech_news_article
original_title: Hegseth pressures Anthropic to give military broader access to its
  AI tech, AP source says
people:
- Pete Hegseth
publishedAt: '2026-02-24T05:01:52+00:00'
slug: hegseth-pressures-anthropic-to-give-military-broad
source:
  emoji: ğŸ“°
  id: associated-press
  name: Associated Press
title: Hegseth tlaÄÃ­ na Anthropic, aby armÃ¡dÄ› umoÅ¾nil Å¡irÅ¡Ã­ pÅ™Ã­stup k AI technologiÃ­m,
  tvrdÃ­ zdroj AP
url: https://apnews.com/article/anthropic-hegseth-ai-pentagon-military-3d86c9296fe953ec0591fcde6a613aba
urlToImage: https://dims.apnews.com/dims4/default/b6b956b/2147483647/strip/true/crop/7140x4758+0+1/resize/980x653!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F47%2F5a%2F349dbe7a1af4cbd637bfc3d3d413%2F1e82b5de757e411abcdb85a499d8170a
urlToImageBackup: https://dims.apnews.com/dims4/default/b6b956b/2147483647/strip/true/crop/7140x4758+0+1/resize/980x653!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F47%2F5a%2F349dbe7a1af4cbd637bfc3d3d413%2F1e82b5de757e411abcdb85a499d8170a
---

### Souhrn
ObrannÃ½ ministr USA Pete Hegseth v utorok setrval na setkÃ¡nÃ­ s CEO Anthropicu Dariem Amodeiem a dal mu lhÅ¯tu do pÃ¡tku na otevÅ™enÃ­ AI technologiÃ­ firmy pro neomezenÃ© pouÅ¾itÃ­ armÃ¡dou. Anthropic, kterÃ½ vyvinul chatbot Claude urÄenÃ½ k bezpeÄnÃ© interakci s uÅ¾ivateli na Ãºrovni velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), je poslednÃ­ z hlavnÃ­ch AI firem, jeÅ¾ neposkytuje svÃ© nÃ¡stroje novÃ© vnitÅ™nÃ­ sÃ­ti Pentagonu. V pÅ™Ã­padÄ› odmÃ­tnutÃ­ hrozÃ­ ztrÃ¡ta vlÃ¡dnÃ­ho kontraktu a dalÅ¡Ã­ sankce.

### KlÃ­ÄovÃ© body
- Hegsethova lhÅ¯ta do pÃ¡tku pro neomezenÃ½ vojenskÃ½ pÅ™Ã­stup k AI Anthropicu.
- EtickÃ© obavy CEO Amodeie z autonomnÃ­ch ozbrojenÃ½ch dronÅ¯ a AI-pomocnÃ©ho hromadnÃ©ho sledovÃ¡nÃ­.
- Pentagon zvaÅ¾uje oznaÄenÃ­ Anthropicu za riziko v dodavatelskÃ©m Å™etÄ›zci nebo aktivaci Defense Production Act pro nucenÃ© pouÅ¾itÃ­ technologiÃ­.
- Anthropic dosud neposkytl pÅ™Ã­stup, na rozdÃ­l od konkurentÅ¯ jako OpenAI nebo Google.
- ZprÃ¡va pochÃ¡zÃ­ od anonymnÃ­ho zdroje obeznÃ¡menÃ©ho se setkÃ¡nÃ­m a vysokÃ©ho pÅ™edstavitele Pentagonu.

### Podrobnosti
Pete Hegseth, souÄasnÃ½ obrannÃ½ ministr USA, se setkal v ÃºterÃ½ s Dariem Amodeiem, spoluzakladatelem a CEO Anthropicu, firmy specializujÃ­cÃ­ se na vÃ½voj bezpeÄnÃ½ch a interpretovatelnÃ½ch systÃ©mÅ¯ umÄ›lÃ© inteligence. Anthropic je znÃ¡mÃ½ pÅ™edevÅ¡Ã­m chatbotem Claude, kterÃ½ slouÅ¾Ã­ k generovÃ¡nÃ­ textu, analÃ½ze dat a Å™eÅ¡enÃ­ sloÅ¾itÃ½ch ÃºkolÅ¯ podobnÄ› jako GPT modely od OpenAI, ale s dÅ¯razem na bezpeÄnostnÃ­ mechanismy proti zneuÅ¾itÃ­. Firma je poslednÃ­ z pÄ›ti hlavnÃ­ch AI hrÃ¡ÄÅ¯ (vÄetnÄ› OpenAI, Google DeepMind, xAI a Meta AI), kterÃ¡ odmÃ­tÃ¡ integrovat svÃ© technologie do novÃ© vnitÅ™nÃ­ sÃ­tÄ› americkÃ© armÃ¡dy urÄenÃ© pro rychlÃ© nasazenÃ­ AI v operaÄnÃ­ch scÃ©nÃ¡Å™Ã­ch.

Amodei dlouhodobÄ› upozorÅˆuje na rizika neomezenÃ©ho vojenskÃ©ho vyuÅ¾itÃ­ AI. KonkrÃ©tnÄ› se obÃ¡vÃ¡ plnÄ› autonomnÃ­ch ozbrojenÃ½ch dronÅ¯, kterÃ© by bez lidskÃ©ho zÃ¡sahu rozhodovaly o ÃºtocÃ­ch, a AI systÃ©mÅ¯ pro hromadnÃ© sledovÃ¡nÃ­, schopnÃ½ch identifikovat a trackovat disidenty na zÃ¡kladÄ› dat z kamer, sociÃ¡lnÃ­ch sÃ­tÃ­ Äi mobilnÃ­ch zaÅ™Ã­zenÃ­. Tyto obavy rezonujÃ­ s Å¡irÅ¡Ã­ debatou v AI komunitÄ›, kde organizace jako Future of Life Institute volajÃ­ po moratoriu na vÃ½voj smrtÃ­cÃ­ch autonomnÃ­ch zbranÃ­.

Pentagon naopak argumentuje potÅ™ebou rychlÃ©ho pÅ™Ã­stupu k Å¡piÄkovÃ½m AI pro udrÅ¾enÃ­ technologickÃ© pÅ™evahy vÅ¯Äi ÄŒÃ­nÄ› a Rusku. Podle zdrojÅ¯ by armÃ¡da chtÄ›la pouÅ¾Ã­vat Claude pro analÃ½zu zpravodajskÃ½ch dat, plÃ¡novÃ¡nÃ­ operacÃ­ nebo simulace bojovÃ½ch scÃ©nÃ¡Å™Å¯. V pÅ™Ã­padÄ› nesplnÄ›nÃ­ poÅ¾adavkÅ¯ hrozÃ­ oznaÄenÃ­ Anthropicu za "riziko v dodavatelskÃ©m Å™etÄ›zci", coÅ¾ by vedlo k vylouÄenÃ­ z federÃ¡lnÃ­ch zakÃ¡zek, nebo aktivace Defense Production Act z roku 1950. Tento zÃ¡kon umoÅ¾Åˆuje vlÃ¡dÄ› nucit soukromÃ© firmy k produkci materiÃ¡lu pro nÃ¡rodnÃ­ bezpeÄnost, vÄetnÄ› software, bez souhlasu vlastnÃ­ka.

Tato situace nÃ¡sleduje po sÃ©rii podobnÃ½ch sporÅ¯. OpenAI napÅ™Ã­klad v roce 2024 uvolnil omezenÃ­ na vojenskÃ© pouÅ¾itÃ­ svÃ½ch modelÅ¯ pro ne-smrtÃ­cÃ­ aplikace, zatÃ­mco Google se po protestech zamÄ›stnancÅ¯ vzdal projektu Maven pro analÃ½zu dronovÃ½ch videÃ­. Anthropic, financovanÃ½ Amazonem a Googlem, mÃ¡ roÄnÃ­ vÃ½daje na vÃ½poÄetnÃ­ vÃ½kon pÅ™es 1 miliardu dolarÅ¯ a dosahuje trÅ¾eb stovek milionÅ¯, coÅ¾ ho ÄinÃ­ atraktivnÃ­m pro vlÃ¡dnÃ­ zakÃ¡zky.

### ProÄ je to dÅ¯leÅ¾itÃ©
Tento konflikt odhaluje napÄ›tÃ­ mezi komerÄnÃ­mi AI firmami a stÃ¡tnÃ­mi zÃ¡jmy v oblasti nÃ¡rodnÃ­ bezpeÄnosti. Pro prÅ¯mysl znamenÃ¡ potenciÃ¡lnÃ­ precedent: vlÃ¡da mÅ¯Å¾e donutit k otevÅ™enÃ­ proprietÃ¡rnÃ­ch modelÅ¯, coÅ¾ oslabÃ­ konkurenÄnÃ­ vÃ½hody a donutÃ­ investovat do bezpeÄnostnÃ­ch opatÅ™enÃ­ proti ÃºnikÅ¯m. Pro uÅ¾ivatele to pÅ™inÃ¡Å¡Ã­ rizika eskalace v zÃ¡vodech o AI zbranÄ›, kde autonomnÃ­ systÃ©my jiÅ¾ testuje ÄŒÃ­na (napÅ™. v JihoÄÃ­nskÃ©m moÅ™i). Jako expert na AI vidÃ­m zde klÃ­ÄovÃ½ test hranic etiky â€“ AnthropicÅ¯v postoj chrÃ¡nÃ­ pÅ™ed zneuÅ¾itÃ­m, ale mÅ¯Å¾e ho izolovat od miliardovÃ½ch kontraktÅ¯. DlouhodobÄ› to urychlÃ­ vÃ½voj specializovanÃ½ch vojenskÃ½ch AI, coÅ¾ zvyÅ¡uje globÃ¡lnÃ­ rizika eskalace konfliktÅ¯.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://apnews.com/article/anthropic-hegseth-ai-pentagon-military-3d86c9296fe953ec0591fcde6a613aba)

**Zdroj:** ğŸ“° Associated Press
