---
author: Marisa Aigen
category: ai hardware
companies:
- Amazon
- Nvidia
date: '2025-12-02 16:00:15'
description: Na konferenci Re:Invent Amazon ozn√°mil, ≈æe Trainium4 akceler√°tory pou≈æij√≠
  NVLink od Nvidia pro 6n√°sobn√Ω v√Ωkon. Z√°rove≈à debutuje Trainium3 s mo≈ænost√≠ milionov√Ωch
  cluster≈Ø pro tr√©nink AI model≈Ø.
importance: 3
layout: tech_news_article
original_title: Amazon primed to fuse Nvidia's NVLink into 4th-gen Trainium accelerators
publishedAt: '2025-12-02T16:00:15+00:00'
slug: amazon-primed-to-fuse-nvidias-nvlink-into-4th-gen-
source:
  emoji: üì∞
  id: null
  name: Theregister.com
title: Amazon integruje Nvidia NVLink do akceler√°tor≈Ø Trainium ƒçtvrt√© generace
url: https://www.theregister.com/2025/12/02/amazon_nvidia_trainium/
urlToImage: https://regmedia.co.uk/2025/07/03/trainium2_chip.jpg
urlToImageBackup: https://regmedia.co.uk/2025/07/03/trainium2_chip.jpg
---

## Souhrn
Amazon Web Services (AWS) na konferenci Re:Invent v Las Vegas p≈ôedstavil akceler√°tory Trainium3, kter√© umo≈æn√≠ clustery s miliony ƒçip≈Ø pro tr√©nink AI. Dal≈°√≠ generace Trainium4 integruje NVLink od Nvidia, co≈æ m√° p≈ôin√©st 6n√°sobn√Ω v√Ωkon oproti p≈ôedchoz√≠m verz√≠m d√≠ky lep≈°√≠ propojitosti ƒçip≈Ø.

## Kl√≠ƒçov√© body
- Trainium4 pou≈æije NVLink Fusion pro komunikaci mezi akceler√°tory Trainium, procesory Graviton a s√≠≈•ovou technologi√≠ EFA.
- Oƒçek√°van√© zlep≈°en√≠: 3n√°sobn√Ω v√Ωkon v FP8, 6n√°sobn√Ω v FP4 a 4n√°sobn√° ≈°√≠≈ôka p√°sma pamƒõti.
- Trainium3 slibuje clustery s a≈æ milionem ƒçip≈Ø pro tr√©nink velk√Ωch AI model≈Ø.
- NVLink 5. generace nab√≠z√≠ 1,8 TB/s ≈°√≠≈ôky p√°sma na GPU, p≈ô√≠≈°t√≠ rok a≈æ 3,6 TB/s.
- Integrace prob√≠h√° v rackech Nvidia MGX.

## Podrobnosti
AWS na sv√© konferenci Re:Invent 2. prosince 2025 ozn√°mil pokroky ve vlastn√≠m hardware pro AI. Trainium je ≈ôada akceler√°tor≈Ø urƒçen√Ωch prim√°rnƒõ pro tr√©nink velk√Ωch jazykov√Ωch model≈Ø a jin√Ωch AI syst√©m≈Ø, kter√© AWS vyv√≠j√≠, aby sn√≠≈æil z√°vislost na extern√≠ch dodavatel√≠ch jako Nvidia. Trainium3, kter√Ω pr√°vƒõ debutuje, je navr≈æen pro ≈°k√°lov√°n√≠ do cluster≈Ø s a≈æ milionem ƒçip≈Ø, co≈æ umo≈æn√≠ tr√©nink extr√©mnƒõ velk√Ωch model≈Ø na √∫rovni miliard parametr≈Ø efektivnƒõji ne≈æ u souƒçasn√Ωch syst√©m≈Ø.

Kl√≠ƒçovou novinkou je Trainium4, kter√Ω poprv√© p≈ôijme NVLink Fusion ‚Äì vysokorychlostn√≠ propojovac√≠ technologii od Nvidia. NVLink umo≈æ≈àuje propojit v√≠ce GPU nebo akceler√°tor≈Ø nap≈ô√≠ƒç syst√©my tak, aby fungovaly jako jeden celek, s minim√°ln√≠mi ztr√°tami p≈ôi komunikaci. D≈ô√≠ve byla tato technologie omezena na Nvidia hardware, ale v kvƒõtnu 2025 Nvidia otev≈ôela NVLink Fusion t≈ôet√≠m stran√°m na Computexu. AWS tak m≈Ø≈æe integrovat sv√© Trainium4, procesory Graviton (ARM-based CPU pro cloud) a s√≠≈•ovou technologii Elastic Fabric Adapter (EFA, vysokorychlostn√≠ s√≠≈• pro HPC) p≈ô√≠mo do rack≈Ø Nvidia MGX. Aktu√°ln√≠ p√°t√° generace NVLink dosahuje 1,8 TB/s ≈°√≠≈ôky p√°sma na GPU (900 GB/s obƒõma smƒõry), p≈ôiƒçem≈æ Nvidia pl√°nuje zdvojn√°soben√≠ na 3,6 TB/s v roce 2026.

AWS neup≈ôesnil, zda zlep≈°en√≠ v√Ωkonu (3x FLOPS v FP8 pro tr√©nink, 6x v FP4 pro inference, 4x ≈°√≠≈ôka p√°sma pamƒõti) plat√≠ pro jednotliv√© ƒçipy nebo pro rackov√© syst√©my UltraServer. P≈ôi p≈ôedpokladu rack≈Ø, jako u Trainium3, by UltraServer Trainium4 mohl dos√°hnout p≈ôes 2 exaFLOPS v FP4 a 2,8 PB/s ≈°√≠≈ôky p√°sma pamƒõti. To je v√Ωhoda pro inference √∫lohy omezen√© ≈°√≠≈ôkou p√°sma. Jmenov√°n√≠ je matouc√≠ ‚Äì Trainium slou≈æ√≠ AWS internƒõ i externƒõ pro z√°kazn√≠ky p≈ôes slu≈æby jako SageMaker.

## Proƒç je to d≈Øle≈æit√©
Tato integrace posiluje konkurenci v AI hardware, kde Nvidia dominuje s 80-90 % trhu GPU. AWS, kter√Ω investoval miliardy do vlastn√≠ch ƒçip≈Ø (Trainium pro tr√©nink, Inferentia pro inference), nyn√≠ spolupracuje s Nvidia m√≠sto konfrontace, co≈æ urychl√≠ ≈°k√°lov√°n√≠ cluster≈Ø pro z√°kazn√≠ky. Pro pr≈Ømysl znamen√° lep≈°√≠ cenovou efektivitu tr√©ninku velk√Ωch model≈Ø, proto≈æe NVLink sni≈æuje latenci komunikace v clusterech. U≈æivatel√© AWS z√≠skaj√≠ p≈ô√≠stup k v√Ωkonnƒõj≈°√≠m instanc√≠m bez nutnosti migrace na Nvidia-only ekosyst√©m. V ≈°ir≈°√≠m kontextu to ukazuje konsolidaci: i velc√≠ hr√°ƒçi jako Amazon pot≈ôebuj√≠ otev≈ôen√© standardy pro hypersk√°lov√°n√≠ AI, co≈æ m≈Ø≈æe sn√≠≈æit ceny cloudov√Ωch AI slu≈æeb o 20-40 % dlouhodobƒõ.

---

[ƒå√≠st p≈Øvodn√≠ ƒçl√°nek](https://www.theregister.com/2025/12/02/amazon_nvidia_trainium/)

**Zdroj:** üì∞ Theregister.com
