---
author: Marisa Aigen
category: ai
companies:
- Nvidia
date: '2025-12-06 13:00:00'
description: Å Ã©f Nvidia Jensen Huang v nedÃ¡vnÃ©m podcastu Joea Rogana prohlÃ¡sil, Å¾e
  vynÃ¡lezci deep learningu spustili prvnÃ­ sÃ­Å¥ strojovÃ©ho uÄenÃ­ na dvojici GTX 580
  v SLI v roce 2012. VÃ½zkumnÃ­ci z University of Toronto tak poloÅ¾ili zÃ¡klady souÄasnÃ©
  Ã©ry umÄ›lÃ© inteligence.
importance: 3
layout: tech_news_article
original_title: Two GTX 580s in SLI are responsible for the AI we have today â€” Nvidia's
  Huang revealed that the invention of deep learning began with two flagship Fermi
  GPUs in 2012
people:
- Jensen Huang
publishedAt: '2025-12-06T13:00:00+00:00'
slug: two-gtx-580s-in-sli-are-responsible-for-the-ai-we-
source:
  emoji: ğŸ“°
  id: null
  name: Tom's Hardware UK
title: Dva GTX 580 v SLI jsou zodpovÄ›dnÃ© za dneÅ¡nÃ­ AI â€“ Nvidia Å¡Ã©f Huang odhalil,
  Å¾e vynÃ¡lez deep learningu zaÄal na dvou vlajkovÃ½ch Fermi GPU v roce 2012
url: https://www.tomshardware.com/tech-industry/artificial-intelligence/two-gtx-580s-in-sli-are-responsible-for-the-ai-we-have-today-nvidias-huang-revealed-that-the-invention-of-deep-learning-began-with-two-flagship-fermi-gpus-in-2012
urlToImage: https://cdn.mos.cms.futurecdn.net/SeFR7XjGGqt3DeeARQcBRb-2560-80.jpg
urlToImageBackup: https://cdn.mos.cms.futurecdn.net/SeFR7XjGGqt3DeeARQcBRb-2560-80.jpg
---

### Souhrn
Å Ã©f Nvidia Jensen Huang v podcastu Joea Rogana (#2422) odhalil, Å¾e deep learning, zÃ¡klad souÄasnÃ© AI, vznikl na dvou grafickÃ½ch kartÃ¡ch GTX 580 v konfiguraci SLI v roce 2012. Tyto karty, pÅ¯vodnÄ› urÄenÃ© pro hranÃ­ her, pouÅ¾ili vÃ½zkumnÃ­ci Alex Krizhevsky, Ilya Sutskever a Geoffrey Hinton z University of Toronto k trÃ©novÃ¡nÃ­ sÃ­tÄ› AlexNet. Tento model dramaticky zlepÅ¡il rozpoznÃ¡vÃ¡nÃ­ obrÃ¡zkÅ¯ a stal se prÅ¯lomem v poÄÃ­taÄovÃ©m vidÄ›nÃ­.

### KlÃ­ÄovÃ© body
- GTX 580 (Fermi architektura, 3 GB GDDR5 pamÄ›ti) byly prvnÃ­ grafickÃ½mi kartami, kterÃ© spustily deep learning sÃ­Å¥.
- AlexNet mÄ›la 8 vrstev a pÅ™ibliÅ¾nÄ› 60 milionÅ¯ parametrÅ¯, kombinovala konvoluÄnÃ­ vrstvy s hlubokÃ½mi neuronovÃ½mi sÃ­tÄ›mi.
- SÃ­Å¥ byla optimalizovÃ¡na pro dvÄ› GPU v SLI, data se vymÄ›Åˆovala jen nutnÄ›, coÅ¾ zkrÃ¡tilo trÃ©nink.
- V roce 2012 pÅ™ekonala AlexNet pÅ™edchozÃ­ algoritmy o vÃ­ce neÅ¾ 70 % v ÃºspÄ›Å¡nosti rozpoznÃ¡vÃ¡nÃ­ obrÃ¡zkÅ¯ na soutÄ›Å¾i ImageNet.
- Nvidia tehdy investovala pÅ™evÃ¡Å¾nÄ› do 3D grafiky a her, ne do AI.

### Podrobnosti
V roce 2011 vÃ½zkumnÃ­ci z University of Toronto â€“ Geoffrey Hinton, znÃ¡mÃ½ jako otec deep learningu, jeho student Ilya Sutskever (pozdÄ›ji spoluzakladatel OpenAI) a Alex Krizhevsky â€“ hledali lepÅ¡Ã­ metody pro rozpoznÃ¡vÃ¡nÃ­ obrÃ¡zkÅ¯ v poÄÃ­taÄovÃ©m vidÄ›nÃ­. TehdejÅ¡Ã­ pÅ™Ã­stupy spolÃ©hali na ruÄnÄ› navrÅ¾enÃ© algoritmy detekujÃ­cÃ­ hrany, rohy a textury, coÅ¾ bylo pracnÃ© a neefektivnÃ­. MÃ­sto toho vytvoÅ™ili AlexNet, architekturu hlubokÃ© neuronovÃ© sÃ­tÄ› s osmi vrstvami, kterÃ¡ se uÄÃ­ sama z dat pomocÃ­ konvoluÄnÃ­ch vrstev (convolutional layers), kterÃ© extrahujÃ­ vlastnosti jako tvary a objekty, a plnÄ› propojenÃ½ch vrstev pro finÃ¡lnÃ­ klasifikaci.

TrÃ©novÃ¡nÃ­ probÃ­halo na dvou GTX 580, grafickÃ½ch kartÃ¡ch z Å™ady Fermi vydanÃ½ch v roce 2010. KaÅ¾dÃ¡ mÄ›la 512 CUDA jader, 3 GB GDDR5 pamÄ›ti a podporu SLI pro paralelnÃ­ zpracovÃ¡nÃ­. CUDA, programovacÃ­ platforma Nvidia pro paralelnÃ­ vÃ½poÄty na GPU, umoÅ¾nila pÅ™evÃ©st sloÅ¾itÃ© vÃ½poÄty neuronovÃ½ch sÃ­tÃ­ na grafickÃ½ hardware. SÃ­Å¥ byla rozdÄ›lena mezi dvÄ› karty, pÅ™iÄemÅ¾ data se synchronizovala jen minimÃ¡lnÄ›, coÅ¾ snÃ­Å¾ilo latenci a umoÅ¾nilo trÃ©novat na datasetu ImageNet s 1,2 milionu obrÃ¡zkÅ¯ za rozumnÃ½ Äas â€“ nÄ›kolik dnÃ­ mÃ­sto tÃ½dnÅ¯ na CPU.

Na konferenci ImageNet Large Scale Visual Recognition Challenge v roce 2012 dosÃ¡hla AlexNet chybovosti 15,3 %, oproti 26,2 % u druhÃ©ho mÃ­sta. Tento skok â€“ relativnÃ­ zlepÅ¡enÃ­ pÅ™es 70 % â€“ upoutal pozornost akademikÅ¯ i prÅ¯myslu. Bez GPU by deep learning zÅ¯stal neproveditelnÃ½ kvÅ¯li vÃ½poÄetnÃ­ nÃ¡roÄnosti; CPU nestaÄily na miliony parametrÅ¯ a velkÃ© datasety. Nvidia tehdy CUDA propagovala hlavnÄ› pro fyzikÃ¡lnÃ­ simulace a rendering, ne AI, pÅ™esto tento experiment ukÃ¡zal potenciÃ¡l konzumernÃ­ho hardware.

### ProÄ je to dÅ¯leÅ¾itÃ©
Toto odhalenÃ­ podtrhuje, jak neÃºmyslnÃ© pouÅ¾itÃ­ hernÃ­ch GPU katalyzovalo revoluci v AI. GTX 580 nebyly navrÅ¾eny pro machine learning, ale dÃ­ky paralelizaci CUDA umoÅ¾nily Å¡kÃ¡lovat trÃ©nink neuronovÃ½ch sÃ­tÃ­, coÅ¾ vedlo k dominanci Nvidia na trhu AI hardware dnes (napÅ™. H100, Blackwell). Pro prÅ¯mysl znamenÃ¡, Å¾e deep learning nenÃ­ jen o sofistikovanejÅ¡Ã­ch modelech jako GPT-4, ale o hardwarovÃ© podpoÅ™e â€“ bez nÃ­ by souÄasnÃ© velkÃ© jazykovÃ© modely (LLM) nebo autonomnÃ­ systÃ©my neexistovaly. Kriticky: pÅ™estoÅ¾e AlexNet byl prÅ¯lom, dne se ukazuje, Å¾e Å¡kÃ¡lovÃ¡nÃ­ na tisÃ­ce GPU vede k Ãºbytku efektivity (scaling laws se zpomalujÃ­), coÅ¾ klade otÃ¡zky na budoucnost bez novÃ½ch architektur. Pro uÅ¾ivatele to znamenÃ¡, Å¾e AI nÃ¡stroje jako image generÃ¡tory (Stable Diffusion) nebo rozpoznÃ¡vaÄe tvÃ¡Å™Ã­ vychÃ¡zejÃ­ z tohoto zÃ¡kladu, ale zÃ¡visÃ­ na dostupnosti vÃ½poÄetnÃ­ho vÃ½konu.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.tomshardware.com/tech-industry/artificial-intelligence/two-gtx-580s-in-sli-are-responsible-for-the-ai-we-have-today-nvidias-huang-revealed-that-the-invention-of-deep-learning-began-with-two-flagship-fermi-gpus-in-2012)

**Zdroj:** ğŸ“° Tom's Hardware UK
