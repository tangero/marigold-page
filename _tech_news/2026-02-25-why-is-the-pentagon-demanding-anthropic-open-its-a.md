---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
companies:
- Anthropic
date: '2026-02-25 00:14:51'
description: NapÄ›tÃ­ mezi pÅ™Ã­stupem a bezpeÄnostnÃ­mi opatÅ™enÃ­mi. Mezi pÅ™edstaviteli
  americkÃ©ho ministerstva obrany a spoleÄnostÃ­ Anthropic, tvÅ¯rcem modelu Claude, doÅ¡lo
  k patovÃ© situaci ohlednÄ› pouÅ¾itÃ­ technologie v armÃ¡dnÃ­ch provozech.
importance: 4
layout: tech_news_article
original_title: 'Why is the Pentagon demanding Anthropic open its AI model? #world'
publishedAt: '2026-02-25T00:14:51+00:00'
slug: why-is-the-pentagon-demanding-anthropic-open-its-a
source:
  emoji: ğŸ“°
  id: null
  name: Alltoc.com
title: ProÄ Pentagon poÅ¾aduje od Anthropic otevÅ™enÃ­ svÃ©ho AI modelu?
url: https://alltoc.com/world/why-is-the-pentagon-demanding-anthropic-open-its-ai-model
urlToImage: https://alltoc.com/cdn/1046/og.png
urlToImageBackup: https://alltoc.com/cdn/1046/og.png
---

## Souhrn
AmerickÃ© ministerstvo obrany (Pentagon) tlaÄÃ­ na spoleÄnost Anthropic, aby otevÅ™ela svÅ¯j AI model Claude pro Å¡irÅ¡Ã­ vojenskÃ© vyuÅ¾itÃ­ bez stÃ¡vajÃ­cÃ­ch bezpeÄnostnÃ­ch omezenÃ­. Anthropic, kterÃ¡ se profiluje jako firma zamÄ›Å™enÃ¡ na bezpeÄnost umÄ›lÃ© inteligence, odmÃ­tÃ¡ kvÅ¯li rizikÅ¯m zneuÅ¾itÃ­. Spor eskaloval k ultimÃ¡tu s hrozbou sankcÃ­.

## KlÃ­ÄovÃ© body
- Pentagon poÅ¾aduje pÅ™Ã­stup k modelu Claude pro integraci do tajnÃ½ch systÃ©mÅ¯, logistiky a plÃ¡novÃ¡nÃ­ operacÃ­.
- Anthropic implementovala guardrails â€“ bezpeÄnostnÃ­ bariÃ©ry â€“ do svÃ½ch modelÅ¯, aby minimalizovala rizika zneuÅ¾itÃ­.
- Ministerstvo obrany hrozÃ­ sankcemi, jako oznaÄenÃ­ za riziko v dodavatelskÃ©m Å™etÄ›zci, coÅ¾ by omezilo spoluprÃ¡ci s vlÃ¡dou.
- KlÃ­ÄovÃ© postavy: ministr obrany Pete Hegseth a dalÅ¡Ã­ pÅ™edstavitelÃ©.
- Dopady: zpomalenÃ­ adopce AI v armÃ¡dÄ› versus ochrana pÅ™ed Å¡kodami.

## Podrobnosti
SpoleÄnost Anthropic, zaloÅ¾enÃ¡ bÃ½valÃ½mi vÃ½zkumnÃ­ky OpenAI a specializujÃ­cÃ­ se na vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯ jako Claude, se odliÅ¡uje od konkurence dÅ¯razem na bezpeÄnost. JejÃ­ modely obsahujÃ­ vestavÄ›nÃ© guardrails â€“ omezenÃ­, kterÃ¡ brÃ¡nÃ­ generovÃ¡nÃ­ Å¡kodlivÃ©ho obsahu, napÅ™Ã­klad nÃ¡vodÅ¯ na vÃ½robu zbranÃ­ nebo plÃ¡nÅ¯ ÃºtokÅ¯. Tyto mechanismy slouÅ¾Ã­ k prevenci downstream harms, tedy Å¡kod zpÅ¯sobenÃ½ch uÅ¾ivateli po nasazenÃ­ modelu, a umoÅ¾ÅˆujÃ­ bezpeÄnÄ›jÅ¡Ã­ integraci do aplikacÃ­ jako chatboti nebo analytickÃ© nÃ¡stroje.

Pentagon naopak argumentuje, Å¾e takovÃ¡ omezenÃ­ brÃ¡nÃ­ efektivnÃ­mu nasazenÃ­ v klasifikovanÃ½ch prostÅ™edÃ­ch. ArmÃ¡da chce vyuÅ¾Ã­t Claude pro logistiku (optimalizace zÃ¡sobovÃ¡nÃ­), analÃ½zu zpravodajstvÃ­ (rychlÃ© zpracovÃ¡nÃ­ dat z druÅ¾ic a senzorÅ¯) a podporu rozhodovÃ¡nÃ­ (simulace scÃ©nÃ¡Å™Å¯). Bez plnÃ©ho pÅ™Ã­stupu nelze tyto schopnosti integrovat do bezpeÄnostnÃ­ch systÃ©mÅ¯, kde by guardrails mohly blokovat citlivÃ© dotazy. Ministr obrany Pete Hegseth a dalÅ¡Ã­ pÅ™edstavitelÃ© firmu nalÃ©hali na Ãºstupky, ale Anthropic trvÃ¡ na svÃ© pozici.

Spor dospÄ›l k eskalaci: ministerstvo naznaÄilo, Å¾e odmÃ­tnutÃ­ by vedlo k oznaÄenÃ­ Anthropic za riziko v dodavatelskÃ©m Å™etÄ›zci. To by znamenalo omezenÃ­ vlÃ¡dnÃ­ch zakÃ¡zek, coÅ¾ je pro AI firmy klÃ­ÄovÃ½ zdroj pÅ™Ã­jmÅ¯ â€“ vlÃ¡da USA utratila v poslednÃ­ch letech miliardy za AI technologie. Tento tlak odrÃ¡Å¾Ã­ Å¡irÅ¡Ã­ trend, kdy soukromÃ© firmy ÄelÃ­ poÅ¾adavkÅ¯m na pÅ™izpÅ¯sobenÃ­ produktÅ¯ stÃ¡tnÃ­m potÅ™ebÃ¡m, Äasto na Ãºkor etickÃ½ch standardÅ¯. NapÅ™Ã­klad podobnÃ© debaty probÃ­haly u OpenAI, kterÃ¡ pÅ¯vodnÄ› slibovala nepouÅ¾itÃ­ v zbranÃ­ch, ale pozdÄ›ji udÄ›lala vÃ½jimky.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento konflikt odhaluje napÄ›tÃ­ mezi nÃ¡rodnÃ­ bezpeÄnostÃ­ a bezpeÄnostÃ­ umÄ›lÃ© inteligence. Pro armÃ¡du by omezenÃ½ pÅ™Ã­stup zpomalil pokrok v autonomnÃ­ch systÃ©mech, kde AI jako Claude mÅ¯Å¾e zpracovÃ¡vat petabajty dat rychleji neÅ¾ ÄlovÄ›k, coÅ¾ je klÃ­ÄovÃ© pro modernÃ­ vÃ¡lky. Na druhÃ© stranÄ›, odstranÄ›nÃ­ guardrails zvyÅ¡uje rizika: modely by mohly bÃ½t zneuÅ¾ity pro kybernetickÃ© Ãºtoky nebo dezinformace, coÅ¾ ohroÅ¾uje nejen USA, ale globÃ¡lnÃ­ stabilitu.

Pro prÅ¯mysl nastavuje precedent â€“ firmy jako xAI nebo Google DeepMind budou muset zvÃ¡Å¾it, zda priorizovat vlÃ¡dnÃ­ zakÃ¡zky pÅ™ed bezpeÄnostÃ­. Pokud Anthropic ustoupÃ­, oslabÃ­ to jejÃ­ reputaci mezi etickÃ½mi investory; sankce by naopak ukÃ¡zaly, jak vlÃ¡da ovlivÅˆuje inovace. Sledujte, zda dojde k tajnÃ© dohodÄ› nebo Å¡irÅ¡Ã­m regulacÃ­m, kterÃ© by ovlivnily vÃ½voj AI modelÅ¯. V Å¡irÅ¡Ã­m ekosystÃ©mu to podtrhuje, Å¾e bezpeÄnostnÃ­ design nenÃ­ volitelnÃ½ luxus, ale nutnost, zvlÃ¡Å¡tÄ› kdyÅ¾ se technologie stÃ¡vajÃ­ strategickÃ½mi aktivy. (Celkem 512 slov)

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://alltoc.com/world/why-is-the-pentagon-demanding-anthropic-open-its-ai-model)

**Zdroj:** ğŸ“° Alltoc.com
