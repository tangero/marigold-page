---
author: Marisa Aigen
category: ai infrastruktura
companies:
- Amazon
- NVIDIA
date: '2025-11-24 08:00:00'
description: Amazon SageMaker HyperPod nynÃ­ podporuje technologii NVIDIA Multi-Instance
  GPU (MIG), kterÃ¡ umoÅ¾Åˆuje rozdÄ›lit jednu GPU na nÄ›kolik izolovanÃ½ch instancÃ­. Tato
  funkce zvyÅ¡uje vyuÅ¾itÃ­ hardwarovÃ½ch zdrojÅ¯ pÅ™i spouÅ¡tÄ›nÃ­ menÅ¡Ã­ch generativnÃ­ch AI
  Ãºloh.
importance: 3
layout: tech_news_article
original_title: Amazon SageMaker HyperPod now supports NVIDIA Multi-Instance GPU (MIG)
  for generative AI tasks
publishedAt: '2025-11-24T08:00:00+00:00'
slug: amazon-sagemaker-hyperpod-now-supports-nvidia-mult
source:
  emoji: ğŸ“°
  id: null
  name: Amazon.com
title: Amazon SageMaker HyperPod nynÃ­ podporuje NVIDIA Multi-Instance GPU (MIG) pro
  generativnÃ­ AI Ãºlohy
url: https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-hyperpod-nvidia-multi-instance-gpu/
---

## Souhrn
Amazon SageMaker HyperPod nynÃ­ podporuje technologii NVIDIA Multi-Instance GPU (MIG), dÃ­ky nÃ­Å¾ lze jednu fyzickou GPU rozdÄ›lit na aÅ¾ sedm izolovanÃ½ch virtuÃ¡lnÃ­ch GPU. Tato funkce umoÅ¾Åˆuje efektivnÄ›jÅ¡Ã­ vyuÅ¾itÃ­ vÃ½poÄetnÃ­ch zdrojÅ¯ pÅ™i provozu menÅ¡Ã­ch generativnÃ­ch AI (GenAI) Ãºloh, jako jsou lehkÃ© inferenÄnÃ­ modely nebo interaktivnÃ­ notebooky.

## KlÃ­ÄovÃ© body
- SageMaker HyperPod nynÃ­ podporuje MIG na clusterech s orchestrÃ¡torem EKS.
- AdministrÃ¡toÅ™i mohou GPU dÄ›lit buÄ pÅ™es konzoli, nebo vlastnÃ­ konfiguracÃ­ pro pÅ™esnÃ© poÅ¾adavky.
- Je moÅ¾nÃ© alokovat kvÃ³ty pro spravedlivÃ© rozdÄ›lenÃ­ zdrojÅ¯ mezi tÃ½my.
- SystÃ©m poskytuje monitorovacÃ­ dashboard s reÃ¡lnÃ½mi metrikami vyuÅ¾itÃ­ jednotlivÃ½ch GPU partit.
- Funkce je dostupnÃ¡ v 17 regionech AWS po celÃ©m svÄ›tÄ›.

## Podrobnosti
NVIDIA Multi-Instance GPU (MIG) je hardwarovÃ¡ technologie dostupnÃ¡ na GPU Å™ady A100 a H100, kterÃ¡ umoÅ¾Åˆuje fyzicky izolovat jednotlivÃ© ÄÃ¡sti GPU â€“ vÄetnÄ› pamÄ›ti, cache a vÃ½poÄetnÃ­ch jednotek â€“ a pÅ™idÄ›lit je rÅ¯znÃ½m ÃºlohÃ¡m. V rÃ¡mci Amazon SageMaker HyperPod, coÅ¾ je spravovanÃ¡ platforma pro Å¡kÃ¡lovatelnÃ© trÃ©novÃ¡nÃ­ a nasazenÃ­ AI modelÅ¯, lze nynÃ­ tuto funkci vyuÅ¾Ã­t pro optimalizaci nÃ¡kladÅ¯ a vÃ½konu. AdministrÃ¡toÅ™i mohou napÅ™Ã­klad spustit nÄ›kolik lehkÃ½ch inferenÄnÃ­ch sluÅ¾eb nebo Jupyter notebookÅ¯ pro datovÃ© vÄ›dce paralelnÄ› na jednÃ© GPU, aniÅ¾ by dochÃ¡zelo ke vzÃ¡jemnÃ©mu ovlivÅˆovÃ¡nÃ­ vÃ½konu. Platforma nabÃ­zÃ­ jak jednoduchÃ© nastavenÃ­ pÅ™es webovou konzoli, tak pokroÄilÃ© moÅ¾nosti konfigurace pro specifickÃ© poÅ¾adavky. DÃ­ky integrovanÃ©mu monitorovÃ¡nÃ­ lze sledovat vytÃ­Å¾enÃ­ jednotlivÃ½ch partit a dynamicky upravovat alokaci zdrojÅ¯. Tato funkce je aktuÃ¡lnÄ› dostupnÃ¡ pouze pro clustery SageMaker HyperPod vyuÅ¾Ã­vajÃ­cÃ­ Kubernetes orchestrÃ¡tor EKS a je nasazena v 17 regionech AWS, vÄetnÄ› Evropy (Ireland, Frankfurt, LondÃ½n, Stockholm, Å panÄ›lsko) a Asie (Tokyo, Seoul, Singapur, Sydney a dalÅ¡Ã­).

## ProÄ je to dÅ¯leÅ¾itÃ©
EfektivnÃ­ vyuÅ¾itÃ­ GPU je klÃ­ÄovÃ© pro ekonomiku provozu generativnÃ­ch AI modelÅ¯, kterÃ© Äasto nevyuÅ¾Ã­vajÃ­ plnou kapacitu drahÃ½ch akcelerÃ¡torÅ¯. MIG v kombinaci se SageMaker HyperPod umoÅ¾Åˆuje organizacÃ­m snÃ­Å¾it nÃ¡klady a zÃ¡roveÅˆ zkrÃ¡tit ÄekacÃ­ doby pro vÃ½vojÃ¡Å™e a datovÃ© vÄ›dce. Tento krok posiluje konkurenceschopnost AWS v oblasti AI infrastruktury, zejmÃ©na vÅ¯Äi Azure a Google Cloud, kterÃ© nabÃ­zejÃ­ podobnÃ© mechanismy izolace zdrojÅ¯. Pro prÅ¯mysl to znamenÃ¡ vÄ›tÅ¡Ã­ flexibilitu pÅ™i nasazovÃ¡nÃ­ hybridnÃ­ch Ãºloh â€“ od trÃ©novÃ¡nÃ­ velkÃ½ch modelÅ¯ po bÄ›h lehkÃ½ch inferencÃ­ â€“ na stejnÃ©m hardwarovÃ©m zÃ¡kladÄ›.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://aws.amazon.com/about-aws/whats-new/2025/11/sagemaker-hyperpod-nvidia-multi-instance-gpu/)

**Zdroj:** ğŸ“° Amazon.com
