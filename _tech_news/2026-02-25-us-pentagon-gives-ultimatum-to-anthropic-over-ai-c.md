---
author: Marisa Aigen
category: ai
companies:
- Anthropic
date: '2026-02-25 04:57:00'
description: AmerickÃ½ ministr obrany Pete Hegseth ÃºdajnÄ› stanovil spoleÄnosti Anthropic
  lhÅ¯tu do pÃ¡tku na souhlas s neomezenÃ½m vojenskÃ½m pouÅ¾itÃ­m jejich AI technologiÃ­.
  Jinak hrozÃ­ oznaÄenÃ­ za riziko v dodavatelskÃ©m Å™etÄ›zci nebo nucenÃ­ podle zÃ¡kona
  o obrannÃ© produkci.
importance: 4
layout: tech_news_article
original_title: 'US: Pentagon gives ultimatum to Anthropic over AI curbs â€” report'
people:
- Pete Hegseth
publishedAt: '2026-02-25T04:57:00+00:00'
slug: us-pentagon-gives-ultimatum-to-anthropic-over-ai-c
source:
  emoji: ğŸ“°
  id: null
  name: DW (English)
title: 'USA: Pentagon dal Anthropic ultimÃ¡tum kvÅ¯li omezenÃ­m AI â€” zprÃ¡va'
url: https://www.dw.com/en/us-pentagon-gives-ultimatum-to-anthropic-over-ai-curbs-report/a-76111915
urlToImage: https://static.dw.com/image/76110827_6.jpg
urlToImageBackup: https://static.dw.com/image/76110827_6.jpg
---

## Souhrn
AmerickÃ© ministerstvo obrany (Pentagon) dalo spoleÄnosti Anthropic, vÃ½vojÃ¡Å™i modelÅ¯ umÄ›lÃ© inteligence Claude, ultimÃ¡tum: do pÃ¡tku 5:00 poledne mÃ­stnÃ­ho Äasu musÃ­ uvolnit omezenÃ­ na vojenskÃ© pouÅ¾itÃ­ svÃ½ch technologiÃ­, jinak ÄelÃ­ tvrdÃ½m opatÅ™enÃ­m. Konflikt vzeÅ¡el z etickÃ½ch obav Anthropic ohlednÄ› domÃ¡cÃ­ surveillance a plnÄ› autonomnÃ­ch zbraÅˆovÃ½ch systÃ©mÅ¯. JednÃ¡nÃ­ mezi ministrem obrany Petem Hegsethem a generÃ¡lnÃ­m Å™editelem Anthropic Dariem Amodeiem probÄ›hla v dobrosousedskÃ©m duchu, ale bez kompromisu.

## KlÃ­ÄovÃ© body
- Pentagon stanovil lhÅ¯tu do pÃ¡tku 17:00 ET (23:00 CET) na uvolnÄ›nÃ­ omezenÃ­ pro vojenskÃ© aplikace.
- Anthropic odmÃ­tÃ¡ pouÅ¾itÃ­ Claude modelÅ¯ pro masovou domÃ¡cÃ­ sledovacÃ­ Äinnost a autonomnÃ­ cÃ­lenÃ­ v bojovÃ½ch operacÃ­ch.
- Hrozby zahrnujÃ­ oznaÄenÃ­ za riziko v dodavatelskÃ©m Å™etÄ›zci nebo aktivaci Defense Production Act pro nucenÃ­ soukromÃ½ch firem.
- Firma Anthropic zdÅ¯razÅˆuje pokraÄujÃ­cÃ­ dialog v souladu s jejich zÃ¡sadami bezpeÄnÃ©ho pouÅ¾itÃ­ AI.
- Konflikt trvÃ¡ mÄ›sÃ­ce a souvisÃ­ s nÃ¡rodnÃ­ bezpeÄnostÃ­ USA.

## Podrobnosti
SpoleÄnost Anthropic, kterÃ¡ se specializuje na vÃ½voj velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) jako je Å™ada Claude, dlouhodobÄ› prosazuje striktnÃ­ zÃ¡sady pouÅ¾itÃ­. Tyto modely slouÅ¾Ã­ k zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka, generovÃ¡nÃ­ textu, analÃ½ze dat a Å™eÅ¡enÃ­ sloÅ¾itÃ½ch ÃºkolÅ¯, ale firma je omezuje pro citlivÃ© aplikace, aby minimalizovala rizika zneuÅ¾itÃ­. OdmÃ­tnutÃ­ spoluprÃ¡ce s Pentagonem zaÄalo kvÅ¯li dvÄ›ma klÃ­ÄovÃ½m oblastem: masovÃ© sledovÃ¡nÃ­ americkÃ½ch obÄanÅ¯ na domÃ¡cÃ­ pÅ¯dÄ› a nasazenÃ­ v plnÄ› autonomnÃ­ch zbraÅˆovÃ½ch systÃ©mech, kde AI rozhoduje o cÃ­lech bez lidskÃ©ho zÃ¡sahu.

Podle zdrojÅ¯ citovanÃ½ch agenturou AP probÄ›hlo v ÃºterÃ½ setkÃ¡nÃ­ mezi Petem Hegsethem, novÃ½m ministrem obrany, a Dariem Amodeiem. Rozhovory byly zdvoÅ™ilÃ©, ale Anthropic na svÃ½ch pozicÃ­ch trvÃ¡. Firma vydala prohlÃ¡Å¡enÃ­, Å¾e pokraÄuje v "dobrÃ© vÃ­Å™e rozhovorech o svÃ© politice pouÅ¾itÃ­, aby mohla nadÃ¡le podporovat nÃ¡rodnÃ­ bezpeÄnost v souladu s tÃ­m, co jejich modely spolehlivÄ› a zodpovÄ›dnÄ› zvlÃ¡dnou". PozdÄ›jÅ¡Ã­ zprÃ¡vy vÅ¡ak hovoÅ™Ã­ o ultimÃ¡tu: do pÃ¡tku musÃ­ Anthropic uvolnit omezenÃ­, jinak Pentagon aktivuje mechanismy jako oznaÄenÃ­ za bezpeÄnostnÃ­ riziko v dodavatelskÃ©m Å™etÄ›zci nebo Defense Production Act. Tento zÃ¡kon z roku 1950 umoÅ¾Åˆuje federÃ¡lnÃ­ vlÃ¡dÄ› pÅ™ikazovat soukromÃ½m firmÃ¡m prioritu pro nÃ¡rodnÃ­ bezpeÄnost, vÄetnÄ› nucenÃ© produkce nebo sdÃ­lenÃ­ technologiÃ­.

Tento spor nenÃ­ ojedinÄ›lÃ½. Anthropic, zaloÅ¾enÃ½ bÃ½valÃ½mi vÃ½zkumnÃ­ky OpenAI s dÅ¯razem na AI alignment (zarovnÃ¡nÃ­ AI s lidskÃ½mi hodnotami), se profiluje jako eticky odpovÄ›dnÃ¡ alternativa. NapÅ™Ã­klad jejich modely Claude 3.5 Sonnet pÅ™ekonÃ¡vajÃ­ GPT-4o v benchmarkÃ¡ch jako MMLU (masivnÃ­ vÃ­cesmÄ›rovÃ© porozumÄ›nÃ­ jazyku), ale s vestavÄ›nÃ½mi bezpeÄnostnÃ­mi vrstvami proti Å¡kodlivÃ©mu obsahu. Pentagon naopak tlaÄÃ­ na pÅ™Ã­stup k Å¡piÄkovÃ½m AI pro vÃ½hodu v soutÄ›Å¾i s ÄŒÃ­nou, kde firmy jako Baidu nebo Huawei jiÅ¾ vojensky spolupracujÃ­. Kritici varujÃ­, Å¾e nucenÃ­ by mohlo oslabit dÅ¯vÄ›ru v americkÃ© AI firmy a urychlit globÃ¡lnÃ­ zÃ¡vod v autonomnÃ­ch zbranÃ­ch, znÃ¡mÃ½ch jako lethal autonomous weapons systems (LAWS).

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento konflikt odhaluje napÄ›tÃ­ mezi nÃ¡rodnÃ­ bezpeÄnostÃ­ a etickÃ½mi standardy v AI prÅ¯myslu. Pro uÅ¾ivatele znamenÃ¡ potenciÃ¡lnÃ­ posun v dostupnosti Claude modelÅ¯ â€“ pokud Pentagon uspÄ›je, mohou se objevit vojensky optimalizovanÃ© verze, ale s rizikem Ãºniku dat nebo zneuÅ¾itÃ­ v civilnÃ­ch aplikacÃ­ch. Pro prÅ¯mysl to nastavuje precedent: vlÃ¡dy mohou donutit soukromÃ© firmy k militarizaci AI, coÅ¾ ohroÅ¾uje snahy o globÃ¡lnÃ­ regulace jako EU AI Act. V Å¡irÅ¡Ã­m kontextu posiluje to debatu o AI bezpeÄnosti â€“ autonomnÃ­ zbranÄ› by mohly eskalovat konflikty bez lidskÃ©ho rozhodnutÃ­, zatÃ­mco surveillance by naruÅ¡ila soukromÃ­. AnthropicÅ¯v odpor podtrhuje, Å¾e etika nenÃ­ jen marketing, ale jÃ¡dro konkurenÄnÃ­ vÃ½hody v Ã©Å™e, kdy AI ovlivÅˆuje geopolitiku.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.dw.com/en/us-pentagon-gives-ultimatum-to-anthropic-over-ai-curbs-report/a-76111915)

**Zdroj:** ğŸ“° DW (English)
