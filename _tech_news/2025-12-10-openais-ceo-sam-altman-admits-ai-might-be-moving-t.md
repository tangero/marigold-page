---
author: Marisa Aigen
category: ai
companies:
- OpenAI
date: '2025-12-10 12:04:00'
description: Å Ã©f OpenAI Sam Altman v rozhovoru zdÅ¯raznil rizika rychlÃ©ho vÃ½voje ChatGPT
  a umÄ›lÃ© inteligence, vÄetnÄ› environmentÃ¡lnÃ­ch nÃ¡kladÅ¯ a zÃ¡vislosti uÅ¾ivatelÅ¯. PÅ™iznal,
  Å¾e tempo zmÄ›n mÅ¯Å¾e vÃ©st k chybÃ¡m s dlouhodobÃ½mi dÅ¯sledky.
importance: 4
layout: tech_news_article
original_title: OpenAI's CEO Sam Altman admits AI might be moving too fast as the
  three-year-old technology keeps rapidly evolving â€” "You could imagine getting it
  wrong"
people:
- Sam Altman
publishedAt: '2025-12-10T12:04:00+00:00'
slug: openais-ceo-sam-altman-admits-ai-might-be-moving-t
source:
  emoji: ğŸ“°
  id: null
  name: Windows Central
title: Å Ã©f OpenAI Sam Altman pÅ™iznÃ¡vÃ¡, Å¾e umÄ›lÃ¡ inteligence se vyvÃ­jÃ­ pÅ™Ã­liÅ¡ rychle,
  tÅ™Ã­letÃ¡ technologie se rychle mÄ›nÃ­ â€“ 'Lze si pÅ™edstavit, Å¾e to pokazÃ­me'
url: https://www.windowscentral.com/artificial-intelligence/sam-altman-admits-ai-might-be-moving-too-fast
urlToImage: https://cdn.mos.cms.futurecdn.net/TreeSnwGP95H44UXLwncTT-2560-80.jpg
urlToImageBackup: https://cdn.mos.cms.futurecdn.net/TreeSnwGP95H44UXLwncTT-2560-80.jpg
---

### Souhrn
Å Ã©f OpenAI Sam Altman v rozhovoru v poÅ™adu The Tonight Show s Jimmy Fallonem pÅ™iznal, Å¾e vÃ½voj umÄ›lÃ© inteligence postupuje pÅ™Ã­liÅ¡ rychle a existuje riziko, Å¾e se to pokazÃ­. ZdÅ¯raznil negativnÃ­ aspekty Å¡irokÃ©ho pÅ™ijetÃ­ ChatGPT, jako jsou vysokÃ© environmentÃ¡lnÃ­ nÃ¡klady na chlazenÃ­ a elektÅ™inu, zÃ¡vislost uÅ¾ivatelÅ¯ a potenciÃ¡l pro zneuÅ¾itÃ­. Tyto vÃ½roky pÅ™ichÃ¡zejÃ­ v kontextu rychlÃ©ho pokroku generativnÃ­ AI od jejÃ­ho spuÅ¡tÄ›nÃ­ pÅ™ed tÅ™emi lety.

### KlÃ­ÄovÃ© body
- Rychlost vÃ½voje AI: Altman varuje, Å¾e tempo zmÄ›n pÅ™ekonÃ¡vÃ¡ naÅ¡i schopnost Å™Ã­zenÃ­ rizik.
- EnvironmentÃ¡lnÃ­ dopady: TrÃ©nink a provoz modelÅ¯ jako ChatGPT spotÅ™ebovÃ¡vÃ¡ obrovskÃ© mnoÅ¾stvÃ­ energie a vyÅ¾aduje intenzivnÃ­ chlazenÃ­.
- ZÃ¡vislost uÅ¾ivatelÅ¯: NÃ¡rÅ¯st pÅ™Ã­padÅ¯, kdy lidÃ© pÅ™Ã­liÅ¡ spolÃ©hajÃ­ na AI nÃ¡stroje, s extrÃ©mnÃ­mi dÅ¯sledky vÄetnÄ› zmÃ­nek o sebevraÅ¾dÃ¡ch souvisejÃ­cÃ­ch s touto zÃ¡vislostÃ­.
- PotenciÃ¡l pro dobro i zlo: AI mÅ¯Å¾e pomoci v medicÃ­nÄ›, napÅ™Ã­klad pÅ™i vÃ½voji lÃ©kÅ¯ na rakovinu, ale zÃ¡roveÅˆ umoÅ¾nit teroristÅ¯m zpÅ¯sobit Å¡kody.
- Reakce na kritiku GPT-5: Altman vysvÄ›tlil stÃ­Å¾nosti uÅ¾ivatelÅ¯ jako projev jejich zÃ¡vislosti na pÅ™edchozÃ­ch verzÃ­ch.

### Podrobnosti
Sam Altman, generÃ¡lnÃ­ Å™editel OpenAI, firmy stojÃ­cÃ­ za ChatGPT, se v nedÃ¡vnÃ©m rozhovoru na The Tonight Show s Jimmy Fallonem otevÅ™enÄ› vyjÃ¡dÅ™il k rizikÅ¯m rychlÃ©ho pokroku v oblasti generativnÃ­ umÄ›lÃ© inteligence. ChatGPT, spuÅ¡tÄ›nÃ½ v listopadu 2022, se bÄ›hem tÅ™Ã­ let stal symbolem revoluce v AI, kdy jednoduchÃ© chatboti schopnÃ© generovat texty a obrÃ¡zky na zÃ¡kladÄ› zadÃ¡nÃ­ pÅ™eÅ¡ly na sofistikovanÃ© nÃ¡stroje ovlivÅˆujÃ­cÃ­ medicÃ­nu, vzdÄ›lÃ¡vÃ¡nÃ­ a vÃ½poÄetnÃ­ techniky. Altman zmÃ­nil, Å¾e tato technologie pÅ™inÃ¡Å¡Ã­ reÃ¡lnÃ½ dopad na spoleÄnost, ale za cenu vysokÃ½ch nÃ¡kladÅ¯. TrÃ©nink velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) jako GPT-4o vyÅ¾aduje datovÃ¡ centra s tisÃ­ci GPU, coÅ¾ vede k obrovskÃ© spotÅ™ebÄ› elektÅ™iny â€“ odhady hovoÅ™Ã­ o desÃ­tkÃ¡ch terawatthodin roÄnÄ› pro celÃ½ sektor AI, srovnatelnÃ© s energetickou spotÅ™ebou malÃ½ch zemÃ­. ChlazenÃ­ tÄ›chto systÃ©mÅ¯ navÃ­c zvyÅ¡uje emise CO2.

DalÅ¡Ã­m problÃ©mem je rostoucÃ­ zÃ¡vislost uÅ¾ivatelÅ¯. Altman naznaÄil, Å¾e stÃ­Å¾nosti na zhorÅ¡enÃ­ uÅ¾ivatelskÃ©ho zÃ¡Å¾itku po vydÃ¡nÃ­ GPT-5 pramenÃ­ z toho, Å¾e lidÃ© si zvyĞºĞ»Ğ¸ na pÃ©Äi, kterou jim poskytovala pÅ™edchozÃ­ verze GPT-4o â€“ ChatGPT funguje jako virtuÃ¡lnÃ­ asistent pro psanÃ­ textÅ¯, analÃ½zu dat nebo generovÃ¡nÃ­ kÃ³du. ÄŒlÃ¡nek spekuluje o nÃ¡rÅ¯stu sebevraÅ¾d spojenÃ½ch s pÅ™Ã­liÅ¡nou dÅ¯vÄ›rou v AI, coÅ¾ vÅ¡ak postrÃ¡dÃ¡ ovÄ›Å™enÃ© statistiky a spÃ­Å¡e slouÅ¾Ã­ k senzacechtivosti. Altman rovnÄ›Å¾ upozornil na duÃ¡lnÃ­ povahu AI: zatÃ­mco mÅ¯Å¾e urychlit objev lÃ©kÅ¯ na rakovinu analÃ½zou molekulÃ¡rnÃ­ch dat, Å¡patnÃ­ aktÃ©Å™i by ji mohli pouÅ¾Ã­t k tvorbÄ› biologickÃ½ch zbranÃ­ nebo kybernetickÃ½ch ÃºtokÅ¯. Tento rozhovor navazuje na Altmanovy pÅ™edchozÃ­ vÃ½roky, kde oznaÄil technologii za nejvÄ›tÅ¡Ã­ vyrovnÃ¡vaÄ ve spoleÄnosti, ale nynÃ­ pÅ™iznÃ¡vÃ¡ rizika neÅ™Ã­zenÃ©ho tempa.

### ProÄ je to dÅ¯leÅ¾itÃ©
VÃ½roky Altmana podtrhujÃ­ napÄ›tÃ­ v AI prÅ¯myslu, kde miliardovÃ© investice do modelÅ¯ jako GPT, Claude nebo Gemini tlaÄÃ­ na rychlejÅ¡Ã­ vydÃ¡vÃ¡nÃ­ verzÃ­ bez dostateÄnÃ©ho testovÃ¡nÃ­ bezpeÄnosti. Pro uÅ¾ivatele to znamenÃ¡ riziko Å¡Ã­Å™enÃ­ dezinformacÃ­ nebo etickÃ½ch problÃ©mÅ¯, jako je halucinace modelÅ¯ â€“ nesprÃ¡vnÃ© odpovÄ›di prezentovanÃ© jako fakta. Pro prÅ¯mysl to signalizuje potÅ™ebu lepÅ¡Ã­ regulace, podobnÄ› jako u evropskÃ©ho AI Actu, kterÃ½ klasifikuje systÃ©my podle rizik. V Å¡irÅ¡Ã­m kontextu posiluje to debatu o alignementu AI, tj. sladÄ›nÃ­ chovÃ¡nÃ­ modelÅ¯ s lidskÃ½mi hodnotami, coÅ¾ je klÃ­ÄovÃ© pro pÅ™echod k AGI. Pokud se tempo nevzpomalÃ­, mohou nastat systÃ©movÃ© selhÃ¡nÃ­, ovlivÅˆujÃ­cÃ­ ekonomiku i bezpeÄnost.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.windowscentral.com/artificial-intelligence/sam-altman-admits-ai-might-be-moving-too-fast)

**Zdroj:** ğŸ“° Windows Central
