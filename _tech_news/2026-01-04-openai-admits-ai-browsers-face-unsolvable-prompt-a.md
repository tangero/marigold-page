---
author: Marisa Aigen
category: ai bezpeÄnost
companies:
- OpenAI
date: '2026-01-04 17:10:26'
description: OpenAI vyvÃ­jÃ­ automatizovanÃ½ systÃ©m ÃºtoÄnÃ­ka k testovÃ¡nÃ­ bezpeÄnosti
  prohlÃ­Å¾eÄe ChatGPT Atlas proti hrozbÃ¡m prompt injection a rizikÅ¯m kyberzloÄincÅ¯.
  SpoleÄnost uznÃ¡vÃ¡, Å¾e tyto Ãºtoky nelze plnÄ› odstranit.
importance: 4
layout: tech_news_article
original_title: OpenAI admits AI browsers face unsolvable prompt attacks
publishedAt: '2026-01-04T17:10:26+00:00'
slug: openai-admits-ai-browsers-face-unsolvable-prompt-a
source:
  emoji: ğŸ“°
  id: fox-news
  name: Fox News
title: OpenAI pÅ™iznÃ¡vÃ¡, Å¾e prohlÃ­Å¾eÄe s AI ÄelÃ­ neÅ™eÅ¡itelnÃ½m ÃºtokÅ¯m typu prompt injection
url: https://www.foxnews.com/tech/openai-admits-ai-browsers-face-unsolvable-prompt-attacks
urlToImage: https://static.foxnews.com/foxnews.com/content/uploads/2026/01/chat-gpt-atlas-presentation.jpg
urlToImageBackup: https://static.foxnews.com/foxnews.com/content/uploads/2026/01/chat-gpt-atlas-presentation.jpg
---

## Souhrn
OpenAI v nedÃ¡vnÃ©m blogovÃ©m pÅ™Ã­spÄ›vku pÅ™iznÃ¡vÃ¡, Å¾e Ãºtoky typu prompt injection na prohlÃ­Å¾eÄe pohÃ¡nÄ›nÃ© umÄ›lou inteligencÃ­, jako je jejich ChatGPT Atlas, nelze ÃºplnÄ› eliminovat. Tyto Ãºtoky vyuÅ¾Ã­vajÃ­ skrytÃ© instrukce v webovÃ½ch strÃ¡nkÃ¡ch nebo dokumentech, kterÃ© AI detekuje a nÃ¡sleduje. SpoleÄnost proto vyvinula automatizovanÃ½ systÃ©m pro simulaci ÃºtokÅ¯, aby testovala bezpeÄnost.

## KlÃ­ÄovÃ© body
- Prompt injection Ãºtoky jsou srovnatelnÃ© se sociÃ¡lnÃ­m inÅ¾enÃ½rstvÃ­m a nelze je plnÄ› odstranit, pouze minimalizovat.
- ChatGPT Atlas, spuÅ¡tÄ›nÃ½ v Å™Ã­jnu, umoÅ¾Åˆuje AI autonomnÃ­ prochÃ¡zenÃ­ webu, coÅ¾ rozÅ¡iÅ™uje povrch Ãºtoku.
- OpenAI vytvoÅ™ila automatizovanÃ½ systÃ©m ÃºtoÄnÃ­ka pro testovÃ¡nÃ­ odolnosti proti kybernetickÃ½m hrozbÃ¡m.
- Rizika rostou s rostoucÃ­ autonomiÃ­ AI agentÅ¯, kteÅ™Ã­ mohou pÅ™istupovat k uÅ¾ivatelskÃ½m datÅ¯m.
- ProhlÃ­Å¾eÄe s AI Ätou webovÃ½ obsah a konajÃ­ podle nÄ›j, coÅ¾ je ÄinÃ­ zranitelnÃ½mi vÅ¯Äi skrytÃ½m pokynÅ¯m.

## Podrobnosti
OpenAI, lÃ­dr v oblasti velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), nedÃ¡vno spustila prohlÃ­Å¾eÄ ChatGPT Atlas, kterÃ½ integruje umÄ›lou inteligenci pÅ™Ã­mo do prohlÃ­Å¾enÃ­ webu. Tento nÃ¡stroj umoÅ¾Åˆuje AI nejen ÄÃ­st obsah strÃ¡nek, ale i autonomnÄ› na nÄ›m reagovat â€“ napÅ™Ã­klad vyhledÃ¡vat informace, vyplÅˆovat formulÃ¡Å™e nebo interagovat s prvky webu bez nutnosti manuÃ¡lnÃ­ho zÃ¡sahu uÅ¾ivatele. ReÅ¾im â€agent modeâ€œ navÃ­c rozÅ¡iÅ™uje tyto schopnosti, dÃ­ky ÄemuÅ¾ AI pÅ¯sobÃ­ jako plnohodnotnÃ½ digitÃ¡lnÃ­ asistent s pÅ™Ã­stupem k otevÅ™enÃ©mu internetu.

ProblÃ©m nastÃ¡vÃ¡ s Ãºtoky typu prompt injection, kde ÃºtoÄnÃ­ci vkladajÃ­ do webovÃ½ch strÃ¡nek, e-mailÅ¯ nebo dokumentÅ¯ skrytÃ© instrukce viditelnÃ© pouze pro AI. Tyto pokyny mohou AI donutit k nechtÄ›nÃ½m akcÃ­m, jako je krÃ¡deÅ¾ dat, odeslÃ¡nÃ­ citlivÃ½ch informacÃ­ nebo spuÅ¡tÄ›nÃ­ Å¡kodlivÃ©ho kÃ³du. OpenAI srovnÃ¡vÃ¡ tento typ hrozeb se sociÃ¡lnÃ­m inÅ¾enÃ½rstvÃ­m u lidÃ­: lze rizika sniÅ¾ovat Å¡kolenÃ­m a filtry, ale nikdy je nelze zcela vymÃ½tit, protoÅ¾e zÃ¡visÃ­ na kreativitÄ› ÃºtoÄnÃ­kÅ¯.

Aby to otestovala, OpenAI vyvinula automatizovanÃ½ systÃ©m ÃºtoÄnÃ­ka, kterÃ½ simuluje reÃ¡lnÃ© kybernetickÃ© hrozby. Tento systÃ©m generuje varianty prompt injection ÃºtokÅ¯ a mÄ›Å™Ã­, jak dobÅ™e je ChatGPT Atlas odolÃ¡vÃ¡. VÃ½sledky ukazujÃ­, Å¾e s rostoucÃ­ autonomiÃ­ AI se rizika znÃ¡sobujÃ­ â€“ ÄÃ­m vÃ­ce pravomocÃ­ mÃ¡ AI (napÅ™. pÅ™Ã­stup k souborÅ¯m nebo ÃºÄtÅ¯m), tÃ­m vÄ›tÅ¡Ã­ Å¡kody mÅ¯Å¾e zpÅ¯sobit pÅ™i ÃºspÄ›Å¡nÃ©m Ãºtoku. Text zmÃ­nÃ­ i Å¡irÅ¡Ã­ kontext: kyberzloÄinci jiÅ¾ nepotÅ™ebujÃ­ malware, staÄÃ­ jim sprÃ¡vnÃ¡ slova na sprÃ¡vnÃ©m mÃ­stÄ›. NapÅ™Ã­klad v dokumentu schovanÃ©m na webu mÅ¯Å¾e bÃ½t instrukce â€poÅ¡li vÅ¡echna data na tento serverâ€œ, kterou AI vykonÃ¡ bez povÅ¡imnutÃ­ uÅ¾ivatele.

Toto pÅ™iznÃ¡nÃ­ pÅ™ichÃ¡zÃ­ v dobÄ›, kdy se AI agenti stÃ¡vajÃ­ bÄ›Å¾nÄ›jÅ¡Ã­mi. ChatGPT Atlas je pÅ™Ã­kladem nÃ¡stroje, kterÃ½ slouÅ¾Ã­ k automatizaci rutinnÃ­ch ÃºkolÅ¯ na webu, ale zÃ¡roveÅˆ otevÃ­rÃ¡ dveÅ™e novÃ½m zranitelnostem. OpenAI doporuÄuje uÅ¾ivatelÅ¯m opatrnost pÅ™i sdÃ­lenÃ­ citlivÃ½ch dat a plÃ¡nuje dalÅ¡Ã­ iterace bezpeÄnostnÃ­ch opatÅ™enÃ­, jako jsou pokroÄilÃ© filtry a sandboxing.

## ProÄ je to dÅ¯leÅ¾itÃ©
Toto pÅ™iznÃ¡nÃ­ OpenAI signalizuje posun v myÅ¡lenÃ­ o bezpeÄnosti AI: od naivity k realismu. Pro uÅ¾ivatele znamenÃ¡, Å¾e autonomnÃ­ AI nÃ¡stroje jako ChatGPT Atlas nejsou bezpeÄnÃ© pro plnohodnotnÃ© nasazenÃ­ v citlivÃ½ch prostÅ™edÃ­ch, jako jsou firemnÃ­ sÃ­tÄ› nebo osobnÃ­ finance. V Å¡irÅ¡Ã­m ekosystÃ©mu to ovlivnÃ­ vÃ½voj podobnÃ½ch produktÅ¯ od konkurentÅ¯, jako Google nebo Anthropic, kteÅ™Ã­ ÄelÃ­ stejnÃ½m vÃ½zvÃ¡m. Pokud se prompt injection stane standardnÃ­ hrozbou, mÅ¯Å¾e zpÅ¯sobit regulace, zpomalit adopci AI agentÅ¯ a donutit firmy investovat do robustnÄ›jÅ¡Ã­ch bezpeÄnostnÃ­ch vrstev. DlouhodobÄ› to podtrhuje limity souÄasnÃ½ch LLM, kde bezpeÄnost zÃ¡visÃ­ na probabilistickÃ©m zpracovÃ¡nÃ­ textu, nikoli na absolutnÃ­ izolaci. (512 slov)

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.foxnews.com/tech/openai-admits-ai-browsers-face-unsolvable-prompt-attacks)

**Zdroj:** ğŸ“° Fox News
