---
author: Marisa Aigen
category: tech
companies:
- Google
date: '2026-02-13 00:00:48'
description: NovÃ¡ zprÃ¡va Google Threat Intelligence Group upozorÅˆuje, Å¾e kyberzloÄinci
  pÅ™ekraÄujÃ­ fÃ¡zi experimentÃ¡lnÃ­ho zneuÅ¾Ã­vÃ¡nÃ­ umÄ›lÃ© inteligence a zaÄÃ­najÃ­ ji integrovat
  pÅ™Ã­mo do svÃ½ch operaÄnÃ­ch postupÅ¯ pÅ™i ÃºtocÃ­ch. ZprÃ¡va se zamÄ›Å™uje na zneuÅ¾itÃ­ modelÅ¯
  Gemini, vÄetnÄ› dynamickÃ©ho generovÃ¡nÃ­ kÃ³du malware a pokusÅ¯ o extrakci modelÅ¯.
importance: 5
layout: tech_news_article
original_title: Google warns attackers are wiring AI directly into live cyberattacks
publishedAt: '2026-02-13T00:00:48+00:00'
slug: google-warns-attackers-are-wiring-ai-directly-into
source:
  emoji: ğŸ“°
  id: null
  name: SiliconANGLE News
title: 'Google varuje: ÃštoÄnÃ­ci pÅ™ipojujÃ­ AI pÅ™Ã­mo k probÃ­hajÃ­cÃ­m kyberÃºtokÅ¯m'
url: https://siliconangle.com/2026/02/12/google-warns-attackers-wiring-ai-directly-live-cyberattacks/
urlToImage: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/aihacking.png
urlToImageBackup: https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2026/02/aihacking.png
---

## Souhrn
Google Threat Intelligence Group v novÃ© zprÃ¡vÄ› varuje, Å¾e kyberzloÄinci pÅ™estÃ¡vajÃ­ s povrchnÃ­m testovÃ¡nÃ­m umÄ›lÃ© inteligence a zaÄleÅˆujÃ­ ji pÅ™Ã­mo do aktivnÃ­ch ÃºtokÅ¯. PozorovÃ¡no bylo zneuÅ¾itÃ­ modelÅ¯ Gemini, kde malware bÄ›hem provÃ¡dÄ›nÃ­ volatÃ­ API pro generovÃ¡nÃ­ kÃ³du, coÅ¾ komplikuje tradiÄnÃ­ detekÄnÃ­ mechanismy. Google zÃ¡roveÅˆ odhalil pokusy o extrakci vnitÅ™nÃ­ logiky tÄ›chto modelÅ¯.

## KlÃ­ÄovÃ© body
- Malware rodiny, jako HONESTCUE, dynamicky Å¾Ã¡dajÃ­ o generovÃ¡nÃ­ C# kÃ³du z modelu Gemini prostÅ™ednictvÃ­m API volÃ¡nÃ­ bÄ›hem Ãºtoku.
- ÃštoÄnÃ­ci provÃ¡dÄ›jÃ­ model extraction (distillation attacks) velkÃ½m objemem strukturovanÃ½ch dotazÅ¯, aby napodobily proprietÃ¡rnÃ­ modely bez vlastnÃ­ho vÃ½voje.
- Google identifikoval a zablokoval kampanÄ› s vysokou aktivitou promptÅ¯ zamÄ›Å™enou na extrakci znalostÃ­ z Gemini.
- Tato taktika posouvÃ¡ logiku Ãºtoku mimo statickÃ½ binÃ¡rnÃ­ kÃ³d, coÅ¾ ztÄ›Å¾uje detekci na zÃ¡kladÄ› signatur nebo chovÃ¡nÃ­.
- ZprÃ¡va zdÅ¯razÅˆuje testovÃ¡nÃ­ a zneuÅ¾Ã­vÃ¡nÃ­ generativnÃ­ch AI systÃ©mÅ¯ v reÃ¡lnÃ½ch ÃºtocÃ­ch.

## Podrobnosti
ZprÃ¡va Google Threat Intelligence Group, aktualizovanÃ¡ 12. Ãºnora 2026, popisuje pÅ™echod kyberzloÄincÅ¯ od sporadickÃ©ho experimentovÃ¡nÃ­ s AI k jejÃ­mu plnohodnotnÃ©mu nasazenÃ­ v ÃºtoÄnÃ½ch Å™etÄ›zcÃ­ch. KonkrÃ©tnÄ› se zamÄ›Å™uje na zneuÅ¾itÃ­ Google svÃ½ch vlastnÃ­ch modelÅ¯ Gemini, kterÃ© slouÅ¾Ã­ k generovÃ¡nÃ­ textu, kÃ³du a dalÅ¡Ã­ch vÃ½stupÅ¯ na zÃ¡kladÄ› pÅ™irozenÃ©ho jazyka. VÃ½zkumnÃ­ci Google pozorovali malware, kterÃ½ bÄ›hem svÃ©ho provÃ¡dÄ›nÃ­ pÅ™Ã­mo volatÃ­ API Gemini pro zÃ­skÃ¡nÃ­ zdrojovÃ©ho kÃ³du potÅ™ebnÃ©ho k dokonÄenÃ­ Ãºkolu. NapÅ™Ã­klad rodina malware HONESTCUE pouÅ¾Ã­vÃ¡ peÄlivÄ› navrÅ¾enÃ© prompty k vygenerovÃ¡nÃ­ C# kÃ³du, kterÃ½ se nÃ¡slednÄ› spustÃ­ jako souÄÃ¡st Ãºtoku. Tento pÅ™Ã­stup umoÅ¾Åˆuje ÃºtoÄnÃ­kÅ¯m udrÅ¾ovat malware binÃ¡rnÃ­ soubor minimÃ¡lnÃ­ a flexibilnÃ­ â€“ logika Ãºtoku nenÃ­ pevnÄ› zakÃ³dovÃ¡na, ale generovÃ¡na na poÅ¾Ã¡dÃ¡nÃ­, coÅ¾ vÃ½raznÄ› ztÄ›Å¾uje detekci na zÃ¡kladÄ› statickÃ½ch signatur nebo pÅ™edem definovanÃ½ch chovÃ¡nÃ­.

DalÅ¡Ã­m vÃ½znamnÃ½m prvkem jsou distillation attacks, znÃ¡mÃ© takÃ© jako model extraction. ÃštoÄnÃ­ci vysÃ­lajÃ­ modelÅ¯m jako Gemini tisÃ­ce strukturovanÃ½ch dotazÅ¯, aby na zÃ¡kladÄ› odpovÄ›dÃ­ odvodili vnitÅ™nÃ­ chovÃ¡nÃ­, vzorce reakcÃ­ a logiku. CÃ­lem je vytvoÅ™it levnÄ›jÅ¡Ã­ napodobeniny proprietÃ¡rnÃ­ch modelÅ¯ bez nutnosti investovat do trÃ©ninku od nuly, coÅ¾ by vyÅ¾adovalo obrovskÃ© vÃ½poÄetnÃ­ zdroje a data. Google tyto pokusy detekoval dÃ­ky vysokÃ©mu objemu API poÅ¾adavkÅ¯ a nÃ¡slednÄ› kampanÄ› disruptoval blokovÃ¡nÃ­m pÅ™Ã­stupu. Tato taktika nenÃ­ novÃ¡ teoreticky, ale jejÃ­ aplikace na Å¾ivÃ© modely jako Gemini ukazuje na zralost ÃºtoÄnÃ­kÅ¯ v manipulaci s generativnÃ­ AI. ZprÃ¡va takÃ© naznaÄuje pozorovÃ¡nÃ­ stÃ¡tnÃ­ch aktÃ©rÅ¯, i kdyÅ¾ detaily nejsou plnÄ› specifikovÃ¡ny.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½voj oznaÄuje zÃ¡sadnÃ­ posun v kyberbezpeÄnosti: tradiÄnÃ­ antivirovÃ© systÃ©my zaloÅ¾enÃ© na signaturÃ¡ch selÅ¾ou proti dynamicky generovanÃ©mu kÃ³du, coÅ¾ nutÃ­ prÅ¯mysl k adopci pokroÄilejÅ¡Ã­ch metod, jako je behaviorÃ¡lnÃ­ analÃ½za v runtime nebo monitorovÃ¡nÃ­ API volÃ¡nÃ­. Pro uÅ¾ivatele to znamenÃ¡ vyÅ¡Å¡Ã­ riziko sofistikovanÄ›jÅ¡Ã­ch ÃºtokÅ¯, kde AI urychluje exploitaci zranitelnostÃ­ nebo generovÃ¡nÃ­ phishingu. V Å¡irÅ¡Ã­m kontextu AI ekosystÃ©mu to podtrhuje nutnost robustnÃ­ch ochran u cloudovÃ½ch modelÅ¯ â€“ rate limiting, watermarking vÃ½stupÅ¯ a detekce anomÃ¡lnÃ­ch promptÅ¯. Google svÃ½m reportem nejen upozorÅˆuje, ale i demonstruje svÃ© schopnosti v detekci, coÅ¾ posiluje dÅ¯vÄ›ru v jejich modely, avÅ¡ak zÃ¡roveÅˆ odhaluje, jak rychle se hrozby adaptujÃ­ na novÃ© technologie. Pokud se toto rozÅ¡Ã­Å™Ã­, mÅ¯Å¾e to vÃ©st k eskalaci zÃ¡vodÅ¯ ve vÃ½zbroji mezi obrÃ¡nci a ÃºtoÄnÃ­ky, kde AI bude klÃ­ÄovÃ½m faktorem na obou stranÃ¡ch.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://siliconangle.com/2026/02/12/google-warns-attackers-wiring-ai-directly-live-cyberattacks/)

**Zdroj:** ğŸ“° SiliconANGLE News
