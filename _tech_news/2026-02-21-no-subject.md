---
author: Marisa Aigen
category: kyberbezpeÄnost
companies:
- ACM
date: '2026-02-21 00:20:03'
description: VydÃ¡nÃ­ Risks Digest 34.88 z Ãºnora 2026 shrnuje Å™adu aktuÃ¡lnÃ­ch incidentÅ¯
  v kyberbezpeÄnosti, umÄ›lÃ© inteligenci a IT rizicÃ­ch, vÄetnÄ› velkÃ½ch ÃºtokÅ¯, zranitelnostÃ­
  a varovÃ¡nÃ­ pÅ™ed AI nebezpeÄÃ­mi. Obsahuje odkazy na klÃ­ÄovÃ© ÄlÃ¡nky o selhÃ¡nÃ­ch softwaru
  v autech, kyberÃºtocÃ­ch na nemocnice a rychlÃ½ch hackech AI modelÅ¯.
importance: 5
layout: tech_news_article
original_title: (no subject)
publishedAt: '2026-02-21T00:20:03+00:00'
slug: no-subject
source:
  emoji: ğŸ“°
  id: null
  name: Seclists.org
title: 'Risks Digest 34.88: PÅ™ehled rizik v poÄÃ­taÄovÃ½ch a souvisejÃ­cÃ­ch systÃ©mech'
url: https://seclists.org/risks/2026/q1/7
urlToImage: https://seclists.org/images/risks-img.png
urlToImageBackup: https://seclists.org/images/risks-img.png
---

## Souhrn
Toto vydÃ¡nÃ­ Risks Digest 34.88, vydanÃ© 20. Ãºnora 2026 moderÃ¡torem Peterem G. Neumannem, shrnuje Å¡irokou Å¡kÃ¡lu rizik spojenÃ½ch s poÄÃ­taÄovÃ½mi systÃ©my. ZamÄ›Å™uje se na selhÃ¡nÃ­ podpory softwaru v automobilech, novÃ© CVE zranitelnosti, kyberÃºtoky na zdravotnickÃ¡ zaÅ™Ã­zenÃ­, botovÃ½ traffic, spory o bezpeÄnost AI, hacky velkÃ½ch jazykovÃ½ch modelÅ¯ a regulace AI v EU. Tyto incidenty odhalujÃ­ systÃ©movÃ© slabiny v kritickÃ© infrastruktuÅ™e.

## KlÃ­ÄovÃ© body
- KyberÃºtok na University of Mississippi Medical Center vedl k uzavÅ™enÃ­ vÅ¡ech klinik a zruÅ¡enÃ­ sluÅ¾eb.
- NovÃ¡ CVE-2025-21858 oznaÄenÃ¡ jako "Bad News" z Bruce Schneierova CryptoGramu pÅ™edstavuje vÃ¡Å¾nou zranitelnost.
- Hack ChatGPT a Google AI trval pouze 20 minut, coÅ¾ ukazuje na snadnou manipulovatelnost LLM.
- EU Parlament zablokoval AI nÃ¡stroje kvÅ¯li rizikÅ¯m kyberbezpeÄnosti a soukromÃ­.
- Geoffrey Hinton varuje, Å¾e AI musÃ­ podporovat 'mateÅ™skÃ© instinkty', jinak hrozÃ­ vyhynutÃ­ lidstva.

## Podrobnosti
Risks Digest je dlouholetÃ© fÃ³rum ACM (Association for Computing Machinery) zamÄ›Å™enÃ© na rizika veÅ™ejnosti z poÄÃ­taÄÅ¯ a souvisejÃ­cÃ­ch systÃ©mÅ¯, archivovanÃ© na risks.org. Toto vydÃ¡nÃ­ pokrÃ½vÃ¡ incidenty z Ãºnora 2026, kterÃ© ilustrujÃ­ akutnÃ­ problÃ©my. NapÅ™Ã­klad ÄlÃ¡nek Ars Technica popisuje, co se stane s automobilem, kdyÅ¾ firma za jeho software zanikne: softwarovÃ© aktualizace pÅ™estanou, coÅ¾ ohrozÃ­ bezpeÄnostnÃ­ funkce jako autonomnÃ­ brzdÄ›nÃ­ nebo aktualizace map. To je kritickÃ© pro vozidla zÃ¡vislÃ¡ na cloudovÃ©m softwaru, kde absence podpory vede k nepouÅ¾itelnosti.

DalÅ¡Ã­ poloÅ¾ka je CVE-2025-21858, oznaÄenÃ¡ Bruce Schneierem jako "Bad News" v jeho CryptoGramu. Tato zranitelnost, pravdÄ›podobnÄ› zero-day exploit, umoÅ¾Åˆuje ÃºtoÄnÃ­kÅ¯m kritickÃ© Ãºtoky na Å¡irokou Å¡kÃ¡lu systÃ©mÅ¯, coÅ¾ vyÅ¾aduje okamÅ¾itÃ© patchy. PodobnÄ› University of Mississippi Medical Center utrpÄ›la kyberÃºtok, kterÃ½ paralyzoval provoz: vÅ¡echny kliniky zavÅ™eny, sluÅ¾by zruÅ¡eny, pacienti odkÃ¡zÃ¡ni na jinÃ© zaÅ™Ã­zenÃ­. Ãštok pravdÄ›podobnÄ› ransomware, typickÃ½ pro zdravotnictvÃ­ kvÅ¯li citlivÃ½m datÅ¯m.

V oblasti AI vynikÃ¡ ÄlÃ¡nek BBC o hacku ChatGPT (od OpenAI) a Google AI, kterÃ½ trval 20 minut: ÃºtoÄnÃ­k obeÅ¡el bezpeÄnostnÃ­ filtry prompt injection technikami, coÅ¾ umoÅ¾nilo generovÃ¡nÃ­ Å¡kodlivÃ©ho obsahu. To ukazuje, jak LLM jako GPT nebo Gemini lze rychle zkompromitovat bez pokroÄilÃ½ch nÃ¡strojÅ¯. EU Parlament mezitÃ­m zablokoval nasazenÃ­ AI nÃ¡strojÅ¯ kvÅ¯li rizikÅ¯m kyberÃºtokÅ¯ a ÃºnikÅ¯m dat, coÅ¾ ovlivnÃ­ evropskÃ© firmy. Wired hlÃ¡sÃ­ vlnu nevysvÄ›tlenÃ©ho botovÃ©ho trafficu na webu, kterÃ½ pÅ™etÄ›Å¾uje servery a zkresluje metriky.

Spor mezi US Department of Defense a Anthropic (firma za AI modelem Claude) se tÃ½kÃ¡ bezpeÄnostnÃ­ch testÅ¯ AI, kde DoD poÅ¾aduje pÅ™Ã­stup k modelÅ¯m pro red-teaming. Geoffrey Hinton, otec modernÃ­ neuronovÃ© sÃ­tÄ›, varuje v CBC, Å¾e AI arms race riskuje vyhynutÃ­, pokud nebude podporovat 'mateÅ™skÃ© instinkty' â€“ tedy etickÃ© mechanismy brÃ¡nÃ­cÃ­ agrese. DalÅ¡Ã­ pÅ™Ã­klady zahrnujÃ­ AI-generovanÃ© komentÃ¡Å™e, kterÃ© ovlivnily kalifornskou regulaci zneÄiÅ¡tÄ›nÃ­ (LA Times), nebo TikTok pixel sbÃ­rajÃ­cÃ­ data o zdravÃ­ (Disconnect).

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato vydÃ¡nÃ­ Risks Digest zdÅ¯razÅˆujÃ­ systÃ©movÃ¡ rizika v kyberbezpeÄnosti a AI, kde selhÃ¡nÃ­ jednÃ© firmy ovlivnÃ­ miliony uÅ¾ivatelÅ¯ â€“ od nemocniÄnÃ­ch pacientÅ¯ po Å™idiÄe autonomnÃ­ch aut. Pro prÅ¯mysl znamenÃ¡ to nutnost diverzifikace dodavatelÅ¯ softwaru a posÃ­lenÃ­ open-source alternativ, aby se zabrÃ¡nilo single-point-of-failure. V AI kontextu ukazujÃ­ hacky na nedostateÄnÃ© jailbreak ochrany v modelech jako ChatGPT, coÅ¾ urychluje regulace jako EU AI Act. BezpeÄnostnÃ­ krize jako CVE nebo ransomware Ãºtoky na kritickou infrastrukturu (zdravotnictvÃ­) vedou k hospodÃ¡Å™skÃ½m ztrÃ¡tÃ¡m v miliardÃ¡ch a ztrÃ¡tÄ› dÅ¯vÄ›ry. V Å¡irÅ¡Ã­m ekosystÃ©mu to nutÃ­ firmy jako OpenAI, Google a Anthropic investovat do robustnÃ­ch bezpeÄnostnÃ­ch protokolÅ¯, zatÃ­mco stÃ¡ty jako USA a EU zesilujÃ­ dohled. IgnorovÃ¡nÃ­ tÄ›chto rizik mÅ¯Å¾e vÃ©st k eskalaci, jak varuje Hinton, s potenciÃ¡lem existenciÃ¡lnÃ­ch hrozeb z AI arms race.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://seclists.org/risks/2026/q1/7)

**Zdroj:** ğŸ“° Seclists.org
