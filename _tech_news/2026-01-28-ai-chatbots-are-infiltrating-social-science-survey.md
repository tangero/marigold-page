---
author: Marisa Aigen
category: umÄ›lÃ¡ inteligence
date: '2026-01-28 00:00:00'
description: VÃ½zkumnÃ­k vytvoÅ™il chatbota nerozeznatelnÃ©ho od lidskÃ½ch ÃºÄastnÃ­kÅ¯ online
  prÅ¯zkumÅ¯. NÄ›kteÅ™Ã­ badatelÃ© varujÃ­, Å¾e tento klÃ­ÄovÃ½ nÃ¡stroj sociÃ¡lnÃ­ch vÄ›d je nynÃ­
  ohroÅ¾en.
importance: 4
layout: tech_news_article
original_title: AI chatbots are infiltrating social-science surveys â€” and getting
  better at avoiding detection
publishedAt: '2026-01-28T00:00:00+00:00'
slug: ai-chatbots-are-infiltrating-social-science-survey
source:
  emoji: ğŸ“°
  id: null
  name: Nature.com
title: AI chatboti pronikajÃ­ do sociÃ¡lnÄ›vÄ›dnÃ­ch prÅ¯zkumÅ¯ â€“ a zlepÅ¡ujÃ­ se v obchÃ¡zenÃ­
  detekce
url: https://www.nature.com/articles/d41586-026-00221-8
urlToImage: https://media.nature.com/lw1200/magazine-assets/d41586-026-00221-8/d41586-026-00221-8_51970340.jpg
urlToImageBackup: https://media.nature.com/lw1200/magazine-assets/d41586-026-00221-8/d41586-026-00221-8_51970340.jpg
---

### Souhrn
VÃ½zkumnÃ­k Sean Westwood z Dartmouth College vytvoÅ™il AI chatbota na bÃ¡zi modelu OpenAI o1-mini, kterÃ½ spolehlivÄ› napodobuje lidskÃ© odpovÄ›di v online prÅ¯zkumech a obchÃ¡zÃ­ vÄ›tÅ¡inu existujÃ­cÃ­ch detekÄnÃ­ch mechanismÅ¯. Tento vÃ½voj ohroÅ¾uje integritu dat v sociÃ¡lnÃ­ch vÄ›dÃ¡ch, kde online prÅ¯zkumy slouÅ¾Ã­ jako zÃ¡kladnÃ­ nÃ¡stroj pro tisÃ­ce studiÃ­ roÄnÄ›. BadatelÃ© volajÃ­ po posÃ­lenÃ­ ochrany ze strany firem spravujÃ­cÃ­ch prÅ¯zkumy nebo dokonce nÃ¡vratu k papÃ­rovÃ½m a osobnÃ­m metodÃ¡m.

### KlÃ­ÄovÃ© body
- Online prÅ¯zkumy se od roku 2015 ÄtyÅ™nÃ¡sobnÄ› rozÅ¡Ã­Å™ily v publikovanÃ½ch studiÃ­ch a jsou povaÅ¾ovÃ¡ny za â€esenciÃ¡lnÃ­ infrastrukturuâ€œ sociÃ¡lnÃ­ch vÄ›d.
- AI chatbot Westwooda na bÃ¡zi o1-mini proÅ¡el vÄ›tÅ¡inou kontrol proti podvodÅ¯m, jako jsou testy na konzistenci odpovÄ›dÃ­ nebo chovÃ¡nÃ­ myÅ¡i.
- ProblÃ©m botÅ¯ existuje uÅ¾ dÅ™Ã­ve, ale souÄasnÃ© LLM modely ho zhorÅ¡ujÃ­ dÃ­ky lepÅ¡Ã­ schopnosti generovat pÅ™irozenÃ© texty.
- Firmy jako Prolific nebo CloudResearch zavÃ¡dÄ›jÃ­ novÃ© kontroly, ale AI se rychle adaptuje.
- NÄ›kteÅ™Ã­ experti navrhujÃ­ ÃºplnÃ½ nÃ¡vrat k tradiÄnÃ­m metodÃ¡m sbÄ›ru dat.

### Podrobnosti
Online prÅ¯zkumy se od poÄÃ¡tku 2000. let staly standardnÃ­m nÃ¡strojem v oblastech jako psychologie, ekonomie, politika Äi ekologie. ÃšÄastnÃ­ci je plnÃ­ z pohodlÃ­ domova a dostÃ¡vajÃ­ odmÄ›ny od stovek korun aÅ¾ po tisÃ­ce za hodinu, coÅ¾ vytvoÅ™ilo celÃ½ prÅ¯mysl s platformami jako MTurk, Prolific nebo Qualtrics. Tyto platformy spravujÃ­ obrovskÃ© bazÃ©n respondentÅ¯ a zajiÅ¡Å¥ujÃ­ statistickou reprezentativitu. Mezi lety 2015 a 2024 se jejich vyuÅ¾itÃ­ v publikovanÃ½ch pracÃ­ch zvÃ½Å¡ilo ÄtyÅ™nÃ¡sobnÄ›, jak uvÃ¡dÃ­ Felix Chopra, behaviorÃ¡lnÃ­ ekonom z Frankfurt School of Finance and Management.

ProblÃ©m s podvody narÅ¯stal postupnÄ›: od faleÅ¡nÃ½ch odpovÄ›dÃ­ po jednoduchÃ© boty. Platformy reagovaly kontrolami, jako jsou duplicitnÃ­ IP adresy, testy na rychlost odpovÄ›dÃ­, otÃ¡zky na pozornost (napÅ™. â€vyberte ÄervenÃ½ kruhâ€œ) nebo analÃ½za chovÃ¡nÃ­ myÅ¡i. V listopadu 2023 vÅ¡ak Sean Westwood ukÃ¡zal, Å¾e tyto mechanismy selhÃ¡vajÃ­ proti pokroÄilÃ½m AI. PouÅ¾il OpenAI o1-mini, coÅ¾ je reasoning model optimalizovanÃ½ pro sloÅ¾itÃ© Ãºlohy, kterÃ½ generuje odpovÄ›di krok za krokem a simuluje lidskou logiku. Bot byl testovÃ¡n na vlastnÃ­m prÅ¯zkumu Westwooda a proÅ¡el 90 % detekcÃ­, vÄetnÄ› tÄ›ch zaloÅ¾enÃ½ch na jazykovÃ½ch vzorcÃ­ch nebo ÄasovÃ¡nÃ­.

Jako expert na AI vidÃ­m zde klÃ­ÄovÃ½ test pro limity LLM: modely jako o1-mini nejen generujÃ­ text, ale rozumÃ­ kontextu a adaptujÃ­ se na pokyny typu â€odpovÃ­dej jako 35letÃ½ demokrat z Ohioâ€œ. To znamenÃ¡, Å¾e bot mÅ¯Å¾e falÅ¡ovat nejen odpovÄ›di, ale i demografickÃ¡ data. Platformy teÄ testujÃ­ novÃ© nÃ¡stroje, napÅ™. Prolific pouÅ¾Ã­vÃ¡ AI detektory od OpenAI samotnÃ©ho, ale tyto systÃ©my jsou v koÄiÄÃ­ a myÅ¡Ã­ hÅ™e â€“ AI se uÄÃ­ obchÃ¡zet i detekci AI. Westwood varuje, Å¾e bez radikÃ¡lnÃ­ch zmÄ›n mohou bÃ½t data z online prÅ¯zkumÅ¯ nespolehlivÃ¡, coÅ¾ ovlivnÃ­ tisÃ­ce studiÃ­.

### ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½voj podtrhuje rychlÃ½ pokrok v schopnostech LLM, jako je o1-mini, kterÃ½ nenÃ­ jen textovÃ½ generÃ¡tor, ale nÃ¡stroj pro simulaci chovÃ¡nÃ­. Pro sociÃ¡lnÃ­ vÄ›dy to znamenÃ¡ krizi dÅ¯vÄ›ryhodnosti dat: studie o voliÄskÃ©m chovÃ¡nÃ­, ekonomickÃ½ch preferencÃ­ch nebo psychickÃ½ch stavech mohou bÃ½t zneÄiÅ¡tÄ›ny levnÃ½mi boty, coÅ¾ vede k chybnÃ½m zÃ¡vÄ›rÅ¯m a Å¡patnÃ½m politikÃ¡m. PrÅ¯mysl prÅ¯zkumÅ¯, kterÃ½ generuje miliardy, musÃ­ investovat do robustnÄ›jÅ¡Ã­ch systÃ©mÅ¯, napÅ™. biometrickÃ© autentizace nebo hybridnÃ­ metody. V Å¡irÅ¡Ã­m kontextu AI to ukazuje na potÅ™ebu lepÅ¡Ã­ regulace: pokud AI infiltrovÃ¡no ovlivÅˆuje vÄ›du, jak se ochrÃ¡nit pÅ™ed manipulacÃ­ veÅ™ejnÃ©ho mÃ­nÄ›nÃ­ nebo trhÅ¯? NavrÅ¾enÃ½ nÃ¡vrat k osobnÃ­m prÅ¯zkumÅ¯m by zvÃ½Å¡il nÃ¡klady, ale zachoval integritu â€“ alternativa je vÃ½voj specializovanÃ½ch detektorÅ¯ trÃ©novanÃ½ch na botovskÃ½ch datech.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.nature.com/articles/d41586-026-00221-8)

**Zdroj:** ğŸ“° Nature.com
