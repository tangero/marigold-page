---
author: Marisa Aigen
category: polovodiÄe
companies:
- Nvidia
- Groq
date: '2026-01-01 07:45:40'
description: NejvÄ›tÅ¡Ã­ novinkou v rozvoji AI ÄipÅ¯ je neexkluzivnÃ­ licenÄnÃ­ dohoda Nvidia
  s Groq. Nvidia investovala 20 miliard USD do zÃ­skÃ¡nÃ­ licence na technologii Groq
  a pÅ™evzala jejÃ­ jÃ¡dro inÅ¾enÃ½rskÃ©ho tÃ½mu.
importance: 5
layout: tech_news_article
original_title: 'Commentary: Nvidia''s Groq deal reshapes semiconductor industry in
  3 key ways'
publishedAt: '2026-01-01T07:45:40+00:00'
slug: commentary-nvidias-groq-deal-reshapes-semiconducto
source:
  emoji: ğŸ“°
  id: null
  name: Digitimes
title: 'KomentÃ¡Å™: Dohoda Nvidia s Groq mÄ›nÃ­ polovodiÄovou branÅ¾i tÅ™emi klÃ­ÄovÃ½mi zpÅ¯soby'
url: https://www.digitimes.com/news/a20251231PD230/nvidia-groq-ai-chip-technology-development.html
urlToImage: https://img.digitimes.com/newsshow/20251231pd230_files/2_b.jpg
urlToImageBackup: https://img.digitimes.com/newsshow/20251231pd230_files/2_b.jpg
---

## Souhrn
Nvidia uzavÅ™ela neexkluzivnÃ­ licenÄnÃ­ dohodu se startupem Groq, investovala 20 miliard USD do licence na jeho technologii a pÅ™evzala klÃ­ÄovÃ½ inÅ¾enÃ½rskÃ½ tÃ½m. Tato dohoda ovlivÅˆuje vÃ½voj AI ÄipÅ¯, zejmÃ©na v oblasti inference, a signalizuje posun v polovodiÄovÃ© branÅ¾i. Podle komentÃ¡Å™e mÄ›nÃ­ trh tÅ™emi zpÅ¯soby: zmÄ›nou v architektuÅ™e AI pamÄ›ti, posunem k specializovanÃ½m ÄipÅ¯m pro inferenci a posÃ­lenÃ­m dominance Nvidia.

## KlÃ­ÄovÃ© body
- Nvidia zaplatila 20 miliard USD za neexkluzivnÃ­ licenci na technologii Groq a pÅ™evzala jeho inÅ¾enÃ½ry.
- Groq se specializuje na Language Processing Units (LPU), Äipy optimalizovanÃ© pro rychlou inferenci velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM).
- Dohoda signalizuje zmÄ›nu v AI pamÄ›ti, posun k specializovanÃ½m inference ÄipÅ¯m a obranu Nvidia pÅ™ed konkurencÃ­ v inference.
- SouvisÃ­ s rostoucÃ­mi nÃ¡roky na Å¡kÃ¡lovÃ¡nÃ­ AI workloadÅ¯, kde inference pÅ™edstavuje vÄ›tÅ¡inu provoznÃ­ch nÃ¡kladÅ¯.
- Datum dohody: 1. ledna 2026, publikovÃ¡no DIGITIMES Asia.

## Podrobnosti
SpoleÄnost Groq, americkÃ½ startup zaloÅ¾enÃ½ v roce 2016, vyvinul unikÃ¡tnÃ­ architekturu LPU, kterÃ¡ je navrÅ¾ena pÅ™Ã­mo pro inferenci AI modelÅ¯. Na rozdÃ­l od univerzÃ¡lnÃ­ch GPU od Nvidia, kterÃ© excelujÃ­ v trÃ©ninku modelÅ¯ dÃ­ky paralelnÃ­mu zpracovÃ¡nÃ­, LPU Groq vyuÅ¾Ã­vajÃ­ compiler-optimalizovanou architekturu s vestavÄ›nou SRAM pamÄ›tÃ­ a tensor streaming processor. To umoÅ¾Åˆuje aÅ¾ 10nÃ¡sobnÄ› vyÅ¡Å¡Ã­ rychlost inference pro LLM jako Llama nebo Mixtral oproti standardnÃ­m GPU, pÅ™i niÅ¾Å¡Ã­ spotÅ™ebÄ› energie. Groq jiÅ¾ nabÃ­zÃ­ cloudovou sluÅ¾bu GroqCloud, kde uÅ¾ivatelÃ© spouÅ¡tÄ›jÃ­ modely s latencÃ­ pod 100 ms.

Nvidia, dominantnÃ­ hrÃ¡Ä s 80% podÃ­lem na trhu AI ÄipÅ¯, ÄelÃ­ tlaku v oblasti inference, kde roste poptÃ¡vka po efektivnÃ­ch Å™eÅ¡enÃ­ch pro nasazenÃ­ modelÅ¯ v produkci. Investice 20 miliard USD do neexkluzivnÃ­ licence znamenÃ¡, Å¾e Nvidia zÃ­skÃ¡vÃ¡ pÅ™Ã­stup k patentÅ¯m Groq na LPU architektuÅ™e, vÄetnÄ› pokroÄilÃ©ho packagingu a SRAM integrace, bez plnÃ©ho vlastnictvÃ­. PÅ™evzetÃ­ inÅ¾enÃ½rskÃ©ho tÃ½mu, vÄetnÄ› zakladatele Jonathana Rossa (ex-Google TPU), posiluje internÃ­ kapacity Nvidia pro vÃ½voj ÄipÅ¯ jako Blackwell nebo Rubin, kde by se technologie Groq mohla integrovat pro hybridnÃ­ GPU-LPU designy.

Tato dohoda nenÃ­ plnou akvizicÃ­, coÅ¾ umoÅ¾Åˆuje Groq pokraÄovat samostatnÄ›, ale Nvidia si zajiÅ¡Å¥uje konkurenÄnÃ­ vÃ½hodu. Related zprÃ¡vy z DIGITIMES zmiÅˆujÃ­ dopady na AI pamÄ›Å¥ovÃ½ trh, kde HBM (High Bandwidth Memory) ÄelÃ­ vÃ½zvÃ¡m kvÅ¯li vysokÃ© cenÄ› a spotÅ™ebÄ›; LPU Groq s on-chip SRAM sniÅ¾uje zÃ¡vislost na externÃ­ HBM. DÃ¡le signalizuje posun od univerzÃ¡lnÃ­ch GPU k specializovanÃ½m ÄipÅ¯m, podobnÄ› jako TPUs od Google nebo IPU od Graphcore. Nvidia tak brÃ¡nÃ­ svÅ¯j trh s inference, kde konkurenti jako AMD (MI300X) nebo Intel (Gaudi3) rostou.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato dohoda pÅ™edstavuje prÅ¯lom v polovodiÄovÃ© branÅ¾i, protoÅ¾e 20miliardovÃ¡ investice do technologie a talentu urychlÃ­ vÃ½voj efektivnÃ­ch AI ÄipÅ¯ pro inference, kterÃ¡ tvoÅ™Ã­ 70-80% provoznÃ­ch nÃ¡kladÅ¯ datacenter. Pro prÅ¯mysl znamenÃ¡ snÃ­Å¾enÃ­ latency a energiÃ­ pro nasazenÃ­ LLM v aplikacÃ­ch jako chatboti, autonomnÃ­ systÃ©my nebo real-time analÃ½zy, coÅ¾ umoÅ¾nÃ­ Å¡kÃ¡lovÃ¡nÃ­ AI bez explodujÃ­cÃ­ch nÃ¡kladÅ¯. Nvidia si udrÅ¾uje vedenÃ­ pÅ™ed ÄÃ­nskÃ½mi hrÃ¡Äi jako Huawei Ascend nebo Baidu Kunlunxin (kterÃ½ prÃ¡vÄ› podal na IPO v Hong Kongu).

Å irÅ¡Ã­ kontext: S rostoucÃ­mi AI workloady (oÄekÃ¡vanÃ½ trh inference ÄipÅ¯ nad 100 miliard USD do 2030) tato dohoda mÄ›nÃ­ dynamiku â€“ od HBM-zÃ¡vislÃ½ch GPU k SRAM-optimalizovanÃ½m LPU. Pro uÅ¾ivatele znamenÃ¡ rychlejÅ¡Ã­ a levnÄ›jÅ¡Ã­ AI sluÅ¾by, napÅ™. v cloudu nebo edge zaÅ™Ã­zenÃ­ch. Kriticky: Neexkluzivita umoÅ¾nÃ­ Groq spolupracovat s jinÃ½mi, coÅ¾ mÅ¯Å¾e fragmentovat trh, ale Nvidia zÃ­skÃ¡vÃ¡ prvnÃ­ pÅ™Ã­stup. CelkovÄ› posiluje AGI pokrok tÃ­m, Å¾e Å™eÅ¡Ã­ bottleneck inference, klÃ­ÄovÃ½ pro praktickÃ© nasazenÃ­ pokroÄilÃ½ch modelÅ¯.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.digitimes.com/news/a20251231PD230/nvidia-groq-ai-chip-technology-development.html)

**Zdroj:** ğŸ“° Digitimes
