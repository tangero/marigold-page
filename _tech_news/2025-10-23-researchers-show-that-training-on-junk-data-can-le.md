---
category: umƒõl√° inteligence
date: '2025-10-23 21:20:48'
description: Studie z americk√Ωch univerzit ukazuje, ≈æe jazykov√© modely tr√©novan√© na
  kr√°tk√Ωch, popul√°rn√≠ch a povrchn√≠ch tweetech vykazuj√≠ hor≈°√≠ v√Ωsledky v testech a
  ztr√°cej√≠ kognitivn√≠ schopnosti.
importance: 4
layout: tech_news_article
original_title: Researchers show that training on ‚Äújunk data‚Äù can lead to LLM ‚Äúbrain
  rot‚Äù - Ars Technica
publishedAt: '2025-10-23T21:20:48+00:00'
slug: researchers-show-that-training-on-junk-data-can-le
source:
  emoji: üî¨
  id: ars-technica
  name: Ars Technica
title: V√Ωzkumn√≠ci prok√°zali, ≈æe tr√©nink na "nekvalitn√≠ch datech" vede k degradaci
  jazykov√Ωch model≈Ø
url: https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg
---

## Souhrn

V√Ωzkumn√≠ci z Texas A&M, University of Texas a Purdue University publikovali studii, kter√° kvantifikuje dopady tr√©ninku velk√Ωch jazykov√Ωch model≈Ø na nekvalitn√≠ch datech. Jejich v√Ωzkum ukazuje, ≈æe kontinu√°ln√≠ tr√©nink na "junk" obsahu z webu vede k trval√©mu poklesu v√Ωkonu model≈Ø, co≈æ auto≈ôi p≈ôirovn√°vaj√≠ k lidsk√©mu "brain rot" - degradaci kognitivn√≠ch schopnost√≠ zp≈Øsoben√© konzumac√≠ trivi√°ln√≠ho online obsahu.

## Kl√≠ƒçov√© body

- V√Ωzkumn√≠ci definovali "LLM brain rot hypot√©zu" - kontinu√°ln√≠ p≈ôedtr√©nink na nekvalitn√≠ch webov√Ωch textech zp≈Øsobuje trval√Ω kognitivn√≠ √∫padek jazykov√Ωch model≈Ø
- Pro testov√°n√≠ pou≈æili dataset 100 milion≈Ø tweet≈Ø z HuggingFace, kter√© rozdƒõlili na "junk" a kontroln√≠ skupinu
- Jako "junk" data identifikovali tweety s vysokou m√≠rou engagement (lajky, retweety), ale kr√°tkou d√©lkou a povrchn√≠m obsahem
- Druh√° metrika hodnocen√≠ vyu≈æ√≠vala GPT-4o k identifikaci tweet≈Ø se "s√©mantickou nekvalitou" - konspiraƒçn√≠ teorie, p≈ôehnan√© tvrzen√≠, nepodlo≈æen√° prohl√°≈°en√≠
- Modely tr√©novan√© na tƒõchto datech vykazovaly hor≈°√≠ v√Ωsledky v benchmarkov√Ωch testech

## Podrobnosti

V√Ωzkum vych√°z√≠ z existuj√≠c√≠ch studi√≠ o dopadu nekvalitn√≠ho online obsahu na lidsk√Ω mozek. Podobnƒõ jako lid√©, kte≈ô√≠ konzumuj√≠ velk√© objemy trivi√°ln√≠ho a intelektu√°lnƒõ nen√°roƒçn√©ho obsahu, mohou trpƒõt probl√©my s pozornost√≠, pamƒõt√≠ a soci√°ln√≠m pozn√°v√°n√≠m, i jazykov√© modely vykazuj√≠ podobn√© symptomy degradace p≈ôi tr√©ninku na obdobn√Ωch datech.

Kl√≠ƒçovou v√Ωzvou v√Ωzkumu bylo objektivn√≠ definov√°n√≠ toho, co p≈ôedstavuje "nekvalitn√≠" obsah. V√Ωzkumn√≠ci zvolili dva p≈ô√≠stupy. Prvn√≠ vych√°zel z p≈ôedpokladu, ≈æe "brain rot" u lid√≠ je d≈Øsledkem internetov√© z√°vislosti, proto jako junk data oznaƒçili tweety maximalizuj√≠c√≠ engagement trivi√°ln√≠m zp≈Øsobem - konkr√©tnƒõ popul√°rn√≠ tweety s vysok√Ωm poƒçtem interakc√≠, ale kr√°tkou d√©lkou. Hypot√©za byla, ≈æe popul√°rnƒõj≈°√≠, ale krat≈°√≠ tweety bud—É—Ç pova≈æov√°ny za nekvalitn√≠ data.

Druh√Ω p≈ô√≠stup vyu≈æ√≠val marketingov√Ω v√Ωzkum k definici "s√©mantick√© kvality" samotn√Ωch tweet≈Ø. Pomoc√≠ komplexn√≠ho promptu pro GPT-4o v√Ωzkumn√≠ci identifikovali tweety zamƒõ≈ôen√© na povrchn√≠ t√©mata jako konspiraƒçn√≠ teorie, p≈ôehnan√© n√°roky, nepodlo≈æen√° tvrzen√≠ nebo povrchn√≠ lifestyle obsah.

V√Ωsledky studie maj√≠ z√°sadn√≠ dopady na souƒçasn√Ω v√Ωvoj AI, kdy se firmy pot√Ωkaj√≠ s nedostatkem kvalitn√≠ch tr√©novac√≠ch dat a ƒçasto sahaj√≠ k syntetick√Ωm dat≈Øm nebo m√©nƒõ kvalitn√≠m zdroj≈Øm.

## Proƒç je to d≈Øle≈æit√©

Tato studie p≈ôich√°z√≠ v kritick√©m okam≈æiku pro v√Ωvoj velk√Ωch jazykov√Ωch model≈Ø. S vyƒçerp√°v√°n√≠m kvalitn√≠ch ve≈ôejnƒõ dostupn√Ωch dat se firmy st√°le ƒçastƒõji obracej√≠ k alternativn√≠m zdroj≈Øm, vƒçetnƒõ soci√°ln√≠ch s√≠t√≠ a synteticky generovan√©ho obsahu. V√Ωzkum poskytuje prvn√≠ kvantitativn√≠ d≈Økazy o tom, jak z√°sadn√≠ dopad m√° kvalita tr√©novac√≠ch dat na dlouhodob√Ω v√Ωkon model≈Ø.

Pro pr≈Ømysl to znamen√° nutnost p≈ôehodnotit strategie z√≠sk√°v√°n√≠ tr√©novac√≠ch dat. Zat√≠mco dosud p≈ôevl√°dal p≈ô√≠stup "ƒç√≠m v√≠ce dat, t√≠m l√©pe", tento v√Ωzkum ukazuje, ≈æe nekvalitn√≠ data mohou zp≈Øsobit trval√© po≈°kozen√≠ model≈Ø. To m√° d≈Øsledky pro cel√Ω ekosyst√©m AI - od v√Ωvoj√°≈ô≈Ø model≈Ø p≈ôes poskytovatele datov√Ωch sad a≈æ po koncov√© u≈æivatele, kte≈ô√≠ spol√©haj√≠ na v√Ωkon tƒõchto syst√©m≈Ø.

V√Ωzkum tak√© otev√≠r√° ot√°zky o budoucnosti webov√©ho obsahu. S rostouc√≠m mno≈æstv√≠m AI-generovan√©ho textu na internetu hroz√≠ riziko zpƒõtn√© vazby, kdy modely budou tr√©nov√°ny na obsahu vytvo≈ôen√©m p≈ôedchoz√≠mi generacemi AI, co≈æ m≈Ø≈æe v√©st k dal≈°√≠ degradaci kvality.

---

[ƒå√≠st p≈Øvodn√≠ ƒçl√°nek](https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/)

**Zdroj:** üî¨ Ars Technica
