---
author: Marisa Aigen
category: ai
date: '2025-11-10 23:06:42'
description: NovÃ¡ studie startupu Goodfire.ai ukazuje, Å¾e memorovÃ¡nÃ­ trÃ©ninkovÃ½ch
  dat a logickÃ© uvaÅ¾ovÃ¡nÃ­ v jazykovÃ½ch modelech probÃ­hajÃ­ ve vÃ½raznÄ› oddÄ›lenÃ½ch neurÃ¡lnÃ­ch
  drahÃ¡ch. OdstranÄ›nÃ­ pamÄ›Å¥ovÃ½ch komponent vÃ½raznÄ› snÃ­Å¾Ã­ schopnost pÅ™esnÃ© citace,
  aniÅ¾ by zÃ¡sadnÄ› ovlivnilo schopnost Å™eÅ¡it Ãºlohy.
importance: 3
layout: tech_news_article
original_title: Researchers isolate memorization from reasoning in AI neural networks
  - Ars Technica
publishedAt: '2025-11-10T23:06:42+00:00'
slug: researchers-isolate-memorization-from-reasoning-in
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: VÃ½zkumnÃ­ci oddÄ›lili v AI sÃ­tÃ­ch pamÄ›Å¥ovÃ© a logickÃ© mechanismy
url: https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg
---

## Souhrn
VÃ½zkum startupu Goodfire.ai naznaÄuje, Å¾e velkÃ© jazykovÃ© modely (LLM) vyuÅ¾Ã­vajÃ­ odliÅ¡nÃ© vnitÅ™nÃ­ mechanismy pro memorovÃ¡nÃ­ trÃ©ninkovÃ½ch dat a pro obecnÃ© â€reasoningâ€œ schopnosti. AutoÅ™i demonstrujÃ­, Å¾e cÃ­lenÃ½m zÃ¡sahem do konkrÃ©tnÃ­ch vÃ¡hovÃ½ch komponent lze zÃ¡sadnÄ› omezit pÅ™esnou reprodukci trÃ©ninkovÃ½ch dat, aniÅ¾ by doÅ¡lo k vÃ½znamnÃ© degradaci schopnosti modelu Å™eÅ¡it novÃ© Ãºlohy.

## KlÃ­ÄovÃ© body
- AnalÃ½za OLMo-7B ukazuje vÃ½raznÃ© oddÄ›lenÃ­ â€memorizationâ€œ a â€reasoningâ€œ drah ve stÅ™ednÃ­ch vrstvÃ¡ch sÃ­tÄ›.
- OdstranÄ›nÃ­m vybranÃ½ch vÃ¡hovÃ½ch komponent se snÃ­Å¾ila schopnost pÅ™esnÃ© citace trÃ©ninkovÃ½ch dat o cca 97 %, zatÃ­mco logickÃ© schopnosti zÅ¯staly pÅ™evÃ¡Å¾nÄ› zachovÃ¡ny.
- Komponenty s vyÅ¡Å¡Ã­ aktivitou na memorovanÃ½ch datech se systematicky soustÅ™edily v dolnÃ­ ÄÃ¡sti poÅ™adÃ­ podle tzv. curvature, zatÃ­mco komponenty pro obecnÃ½ text byly v hornÃ­ ÄÃ¡sti.
- VÃ½zkum naznaÄuje, Å¾e i zÃ¡kladnÃ­ aritmetika vyuÅ¾Ã­vÃ¡ stejnÃ© drÃ¡hy jako memorovÃ¡nÃ­, coÅ¾ zpochybÅˆuje pÅ™edstavu o â€ÄistÄ› logickÃ©mâ€œ poÄÃ­tÃ¡nÃ­ v dneÅ¡nÃ­ch LLM.
- ZjiÅ¡tÄ›nÃ­ mÃ¡ pÅ™Ã­mÃ© dopady na ochranu dat, auditovatelnost modelÅ¯ a regulaci ÃºnikÅ¯ trÃ©ninkovÃ½ch dat.

## Podrobnosti
Studie vychÃ¡zÃ­ z analÃ½zy otevÅ™enÃ©ho jazykovÃ©ho modelu OLMo-7B, vyvinutÃ©ho Allen Institute for AI. Goodfire.ai, menÅ¡Ã­ vÃ½zkumnÃ½ startup specializujÃ­cÃ­ se na interpretovatelnost a bezpeÄnost modelÅ¯ AI, se zamÄ›Å™il na strukturu vnitÅ™nÃ­ch vÃ¡h neuronovÃ© sÃ­tÄ›. PouÅ¾il metriku nazÃ½vanou â€curvatureâ€œ pro seÅ™azenÃ­ jednotlivÃ½ch vÃ¡hovÃ½ch komponent podle jejich chovÃ¡nÃ­ pÅ™i zpracovÃ¡nÃ­ vstupÅ¯. ZjednoduÅ¡enÄ› jde o zpÅ¯sob, jak kvantifikovat, jak silnÄ› a nelineÃ¡rnÄ› danÃ¡ komponenta reaguje na rÅ¯znÃ© typy dat.

VÃ½zkumnÃ­ci potÃ© porovnali aktivaci tÄ›chto komponent na dvou typech vstupÅ¯: (1) pÅ™esnÄ› memorovanÃ© pasÃ¡Å¾e z trÃ©ninkovÃ½ch dat a (2) novÃ©, na trÃ©ninku nepouÅ¾itÃ© texty. UkÃ¡zalo se, Å¾e spodnÃ­ch 50 % komponent podle curvature vykazuje zÅ™etelnÄ› vyÅ¡Å¡Ã­ aktivitu na memorovanÃ½ch textech (zhruba o 23 %), zatÃ­mco hornÃ­ch 10 % je aktivnÄ›jÅ¡Ã­ na obecnÃ©m textu (zhruba o 26 %). To naznaÄuje funkÄnÃ­ specializaci: dolnÃ­ ÄÃ¡st spektra obsluhuje pÅ™evÃ¡Å¾nÄ› zapamatovanÃ½ obsah, hornÃ­ ÄÃ¡st se podÃ­lÃ­ na obecnÄ›jÅ¡Ã­m zpracovÃ¡nÃ­ a odvozovÃ¡nÃ­.

KlÃ­ÄovÃ½ experiment spoÄÃ­val v â€chirurgickÃ©mâ€œ odstranÄ›nÃ­ nebo deaktivaci tÄ›ch komponent, kterÃ© byly identifikovÃ¡ny jako dominantnÄ› pamÄ›Å¥ovÃ©. Po tomto zÃ¡sahu se model stal vÃ½raznÄ› horÅ¡Ã­m v pÅ™esnÃ© reprodukci trÃ©ninkovÃ½ch pasÃ¡Å¾Ã­ (pokles o cca 97 %), ale jeho vÃ½kon v ÃºlohÃ¡ch vyÅ¾adujÃ­cÃ­ch obecnÃ© porozumÄ›nÃ­ textu a urÄitou formu reasoning se zhorÅ¡il jen minimÃ¡lnÄ›. PÅ™ekvapivÃ½m zjiÅ¡tÄ›nÃ­m je, Å¾e stejnÃ¡ pamÄ›Å¥ovÃ¡ infrastruktura zÅ™ejmÄ› podporuje i ÄÃ¡st schopnostÃ­ v zÃ¡kladnÃ­ aritmetice, coÅ¾ zpochybÅˆuje jednoduchÃ© dÄ›lenÃ­ na â€logickÃ©â€œ a â€pamÄ›Å¥ovÃ©â€œ vÃ½poÄty v souÄasnÃ½ch LLM.

Pro prÅ¯myslovou praxi to znamenÃ¡, Å¾e mÅ¯Å¾e bÃ½t technicky moÅ¾nÃ© navrhovat modely s omezenÃ½m nebo kontrolovanÃ½m memorovÃ¡nÃ­m, bez zÃ¡sadnÃ­ho poÅ¡kozenÃ­ uÅ¾iteÄnÃ½ch schopnostÃ­, jako je shrnovÃ¡nÃ­, generovÃ¡nÃ­ textu, pÅ™eklad nebo kÃ³dovÃ¡nÃ­. TakovÃ½ pÅ™Ã­stup mÅ¯Å¾e bÃ½t relevantnÃ­ pro poskytovatele AI sluÅ¾eb pÅ™es API, kteÅ™Ã­ ÄelÃ­ regulatornÃ­m poÅ¾adavkÅ¯m na ochranu trÃ©ninkovÃ½ch dat a sniÅ¾ovÃ¡nÃ­ rizika ÃºnikÅ¯ citlivÃ©ho obsahu.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tento vÃ½zkum je vÃ½znamnÃ½ z hlediska interpretovatelnosti a bezpeÄnosti AI modelÅ¯. Ukazuje, Å¾e Ãºnik trÃ©ninkovÃ½ch dat nenÃ­ pouze nevyhnutelnÃ½m vedlejÅ¡Ã­m efektem velikosti modelu, ale lze jej cÃ­lenÄ› technicky omezovat. To mÃ¡ pÅ™Ã­mÃ© dÅ¯sledky pro dodrÅ¾ovÃ¡nÃ­ ochrany osobnÃ­ch ÃºdajÅ¯, obchodnÃ­ho tajemstvÃ­ a autorskÃ½ch prÃ¡v, zejmÃ©na u poskytovatelÅ¯ generativnÃ­ AI ve velkÃ©m mÄ›Å™Ã­tku.

OddÄ›lenÃ­ pamÄ›Å¥ovÃ½ch a reasoning drah otevÃ­rÃ¡ moÅ¾nost navrhovat modely, kterÃ© lÃ©pe vyhovujÃ­ regulatornÃ­m rÃ¡mcÅ¯m a smluvnÃ­m poÅ¾adavkÅ¯m: napÅ™Ã­klad modely, kterÃ© nebudou schopny pÅ™esnÄ› citovat chrÃ¡nÄ›nÃ¡ dÃ­la, ale zachovajÃ­ schopnost analyzovat a vysvÄ›tlovat obsah. ZÃ¡roveÅˆ vÅ¡ak studie ukazuje, Å¾e nÄ›kterÃ© zdÃ¡nlivÄ› â€logickÃ©â€œ schopnosti (napÅ™. aritmetika) jsou Ãºzce svÃ¡zanÃ© s memorizaÄnÃ­mi strukturami. To naznaÄuje, Å¾e souÄasnÃ© LLM nejsou skuteÄnÃ© logickÃ© systÃ©my, ale statistickÃ© stroje s komplikovanÃ½m pÅ™ekryvem mezi pamÄ›tÃ­ a odvozovÃ¡nÃ­m. Pro vÃ½voj budoucÃ­ch modelÅ¯ to pÅ™edstavuje jak pÅ™Ã­leÅ¾itost pro pÅ™esnÄ›jÅ¡Ã­ kontrolu chovÃ¡nÃ­, tak varovÃ¡nÃ­, Å¾e odliÅ¡it â€bezpeÄnÃ©â€œ a â€rizikovÃ©â€œ komponenty nebude vÅ¾dy triviÃ¡lnÃ­.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/)

**Zdroj:** ğŸ”¬ Ars Technica
