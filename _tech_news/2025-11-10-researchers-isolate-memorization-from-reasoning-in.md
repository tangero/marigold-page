---
author: Marisa Aigen
category: ai
date: '2025-11-10 23:06:42'
description: NovÃ¡ studie startupu Goodfire.ai ukazuje, Å¾e velkÃ© jazykovÃ© modely majÃ­
  zÅ™etelnÄ› oddÄ›lenÃ© neuronovÃ© komponenty pro doslovnÃ© memorovÃ¡nÃ­ trÃ©ninkovÃ½ch dat
  a pro logickÃ© uvaÅ¾ovÃ¡nÃ­, coÅ¾ otevÃ­rÃ¡ cestu k pÅ™esnÄ›jÅ¡Ã­mu Å™Ã­zenÃ­ chovÃ¡nÃ­ AI.
importance: 3
layout: tech_news_article
original_title: Researchers isolate memorization from reasoning in AI neural networks
  - Ars Technica
publishedAt: '2025-11-10T23:06:42+00:00'
slug: researchers-isolate-memorization-from-reasoning-in
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: VÃ½zkum naznaÄuje oddÄ›lenÃ© drÃ¡hy pro memorovÃ¡nÃ­ a uvaÅ¾ovÃ¡nÃ­ v AI modelech
url: https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg
---

## Souhrn
VÃ½zkumnÃ­ci z Goodfire.ai pÅ™edloÅ¾ili experimentÃ¡lnÃ­ dÅ¯kazy, Å¾e velkÃ© jazykovÃ© modely (LLM) majÃ­ vÃ½raznÄ› oddÄ›lenÃ© neuronovÃ© drÃ¡hy pro memorovÃ¡nÃ­ trÃ©ninkovÃ½ch dat a pro obecnÃ© uvaÅ¾ovÃ¡nÃ­. UkazujÃ­, Å¾e selektivnÃ­m zÃ¡sahem do tÄ›chto drah lze dramaticky omezit schopnost modelu citovat trÃ©ninkovÃ¡ data, aniÅ¾ by se podstatnÄ› zhorÅ¡il jeho vÃ½kon v ÃºlohÃ¡ch vyÅ¾adujÃ­cÃ­ch logickÃ© myÅ¡lenÃ­ a zobecnÄ›nÃ­.

## KlÃ­ÄovÃ© body
- OddÄ›lenÃ© â€memorizaÄnÃ­â€œ a â€logickÃ©â€œ komponenty byly identifikovÃ¡ny v internÃ­ struktuÅ™e LLM.
- OdstranÄ›nÃ­ memorizaÄnÃ­ch cest snÃ­Å¾ilo schopnost pÅ™esnÃ©ho citovÃ¡nÃ­ trÃ©ninkovÃ½ch dat o cca 97 %, pÅ™i zachovÃ¡nÃ­ tÃ©mÄ›Å™ nezmÄ›nÄ›nÃ©ho vÃ½konu v ÃºlohÃ¡ch uvaÅ¾ovÃ¡nÃ­.
- AnalÃ½za byla demonstrovÃ¡na na modelu OLMo-7B (Allen Institute for AI) pomocÃ­ metriky oznaÄenÃ© jako â€curvatureâ€œ k seÅ™azenÃ­ vah.
- Komponenty spojenÃ© s memorovÃ¡nÃ­m se koncentrovaly ve spodnÃ­ ÄÃ¡sti Å¾ebÅ™Ã­Äku vah, komponenty pro zobecnÄ›nÃ­ a Å™eÅ¡enÃ­ Ãºloh naopak v hornÃ­ ÄÃ¡sti.
- ZjiÅ¡tÄ›nÃ­ naznaÄujÃ­, Å¾e i zÃ¡kladnÃ­ aritmetika je v tÄ›chto modelech ÄÃ¡steÄnÄ› obsluhovÃ¡na â€memorizaÄnÃ­miâ€œ drahami, nikoli ÄistÄ› abstraktnÃ­m â€logickÃ½mâ€œ modulem.

## Podrobnosti
Studie Goodfire.ai, menÅ¡Ã­ho vÃ½zkumnÃ©ho startupu zamÄ›Å™enÃ©ho na interpretovatelnost a bezpeÄnost AI modelÅ¯, se soustÅ™edÃ­ na mechanistickou analÃ½zu vnitÅ™nÃ­ struktury velkÃ½ch jazykovÃ½ch modelÅ¯. Na pÅ™Ã­kladu OLMo-7B, otevÅ™enÃ©ho modelu vyvinutÃ©ho Allen Institute for AI, autoÅ™i hodnotili jednotlivÃ© vÃ¡hovÃ© komponenty v konkrÃ©tnÃ­ch vrstvÃ¡ch modelu podle metriky nazÃ½vanÃ© â€curvatureâ€œ. Tato metrika mÄ›Å™Ã­, jak citlivÄ› danÃ¡ komponenta reaguje na zmÄ›ny v datech a jak se podÃ­lÃ­ na nelineÃ¡rnÃ­m chovÃ¡nÃ­ modelu.

PÅ™i porovnÃ¡nÃ­ aktivaÄnÃ­ch vzorcÅ¯ na datech, kterÃ¡ byla souÄÃ¡stÃ­ trÃ©ninku, a na novÃ½ch, netrÃ©ninkovÃ½ch textech se ukÃ¡zalo, Å¾e spodnÃ­ch 50 % komponent v danÃ© vrstvÄ› vykazuje vÃ½znamnÄ› vyÅ¡Å¡Ã­ aktivaci na memorovanÃ½ch pasÃ¡Å¾Ã­ch. Naopak hornÃ­ ÄÃ¡st Å¾ebÅ™Ã­Äku, pÅ™ibliÅ¾nÄ› 10 % komponent s nejvyÅ¡Å¡Ã­ â€curvatureâ€œ, se vÃ­ce aktivuje na obecnÃ½ text a Ãºlohy vyÅ¾adujÃ­cÃ­ zobecnÄ›nÃ­. Prakticky to umoÅ¾nilo â€chirurgickÃ½â€œ zÃ¡sah: odstranÄ›nÃ­m komponent identifikovanÃ½ch jako memorizaÄnÃ­ autoÅ™i dramaticky omezili schopnost modelu doslovnÄ› reprodukovat trÃ©ninkovÃ¡ data, ale vÃ½kon v ÃºlohÃ¡ch uvaÅ¾ovÃ¡nÃ­, porozumÄ›nÃ­ textu a Å™eÅ¡enÃ­ novÃ½ch Ãºloh zÅ¯stal tÃ©mÄ›Å™ zachovÃ¡n.

ZajÃ­mavÃ½m a potenciÃ¡lnÄ› kontroverznÃ­m zjiÅ¡tÄ›nÃ­m je, Å¾e i aritmetickÃ© schopnosti modelu, jako jsou jednoduchÃ© vÃ½poÄty, jsou ÄÃ¡steÄnÄ› realizovÃ¡ny pÅ™es stejnÃ© drÃ¡hy, kterÃ© nesou memorizaÄnÃ­ chovÃ¡nÃ­. To naznaÄuje, Å¾e pro nÄ›kterÃ© typy Ãºloh, kterÃ© vnÃ­mÃ¡me jako â€logickÃ©â€œ, model ve skuteÄnosti vyuÅ¾Ã­vÃ¡ komplexnÃ­ statistickÃ© a pamÄ›Å¥ovÃ© vzorce namÃ­sto oddÄ›lenÃ©ho, obecnÃ©ho mechanismu uvaÅ¾ovÃ¡nÃ­. Studie je ve formÃ¡tu preprintu a vÃ½sledky zatÃ­m nejsou nezÃ¡visle Å¡iroce replikovÃ¡ny, ale zapadajÃ­ do rostoucÃ­ho trendu mechanistickÃ© interpretovatelnosti, kterÃ½ se snaÅ¾Ã­ pÅ™evÃ©st chovÃ¡nÃ­ AI z ÄernÃ© skÅ™Ã­Åˆky na analyzovatelnou infrastrukturu.

## ProÄ je to dÅ¯leÅ¾itÃ©
Pokud se tyto vÃ½sledky potvrdÃ­, mohou mÃ­t pÅ™Ã­mÃ½ dopad na nÄ›kolik oblastÃ­. Pro poskytovatele LLM by moÅ¾nost cÃ­lenÄ› omezit memorovÃ¡nÃ­ znamenala lepÅ¡Ã­ kontrolu nad Ãºnikem citlivÃ½ch nebo autorsky chrÃ¡nÄ›nÃ½ch trÃ©ninkovÃ½ch dat, coÅ¾ je zÃ¡sadnÃ­ pro prÃ¡vnÃ­ a reputaÄnÃ­ rizika. Pro regulÃ¡tory a firmy nasazujÃ­cÃ­ AI systÃ©my by Å¡lo o konkrÃ©tnÃ­ technickÃ½ nÃ¡stroj, jak sladit vÃ½konnost modelÅ¯ s poÅ¾adavky na ochranu dat.

Z hlediska vÃ½zkumu bezpeÄnosti a alignmentu AI je existence oddÄ›litelnÃ½ch drah pro rÅ¯znÃ© typy chovÃ¡nÃ­ klÃ­ÄovÃ¡. UmoÅ¾Åˆuje navrhovat zÃ¡sahy, kterÃ© nepoÅ¡kozujÃ­ celkovou uÅ¾iteÄnost systÃ©mu, ale cÃ­lÃ­ na konkrÃ©tnÃ­ rizikovÃ© projevy (memorovÃ¡nÃ­, toxickÃ½ obsah, specifickÃ© prompt injection vzory). ZÃ¡roveÅˆ je nutnÃ¡ opatrnost: odstranÄ›nÃ­ memorizaÄnÃ­ch komponent mÅ¯Å¾e oslabit nÄ›kterÃ© uÅ¾iteÄnÃ© schopnosti, jako je pÅ™esnÃ¡ citace, znalost vzÃ¡cnÃ½ch faktÅ¯ nebo spolehlivÄ›jÅ¡Ã­ aritmetika. Tento vÃ½zkum proto nenÃ­ receptem na jednoduchÃ© â€opravyâ€œ AI, ale spÃ­Å¡e poÄÃ¡tkem systematiÄtÄ›jÅ¡Ã­ho, jemnÄ› odstupÅˆovanÃ©ho Å™Ã­zenÃ­ chovÃ¡nÃ­ modelÅ¯ na Ãºrovni jejich internÃ­ architektury.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/)

**Zdroj:** ğŸ”¬ Ars Technica
