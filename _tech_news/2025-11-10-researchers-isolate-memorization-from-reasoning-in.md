---
author: Marisa Aigen
category: ai
date: '2025-11-10 23:06:42'
description: NovÃ¡ studie startupu Goodfire.ai ukazuje, Å¾e schopnost modelÅ¯ AI pÅ™esnÄ›
  reprodukovat trÃ©ninkovÃ¡ data je oddÄ›litelnÃ¡ od jejich logickÃ©ho a aritmetickÃ©ho
  uvaÅ¾ovÃ¡nÃ­, coÅ¾ otevÃ­rÃ¡ cestu k cÃ­lenÃ©mu omezovÃ¡nÃ­ memorovÃ¡nÃ­ bez ztrÃ¡ty uÅ¾iteÄnÃ½ch
  schopnostÃ­.
importance: 3
layout: tech_news_article
original_title: Researchers isolate memorization from reasoning in AI neural networks
  - Ars Technica
publishedAt: '2025-11-10T23:06:42+00:00'
slug: researchers-isolate-memorization-from-reasoning-in
source:
  emoji: ğŸ”¬
  id: ars-technica
  name: Ars Technica
title: VÃ½zkumnÃ­ci oddÄ›lili v AI sÃ­tÃ­ch pamÄ›Å¥ovÃ© a logickÃ© drÃ¡hy
url: https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/
urlToImage: https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg
urlToImageBackup: https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprised_robot_2-1152x648.jpg
---

## Souhrn
VÃ½zkumnÃ½ tÃ½m ze startupu Goodfire.ai pÅ™edstavil analÃ½zu, kterÃ¡ naznaÄuje, Å¾e velkÃ© jazykovÃ© modely majÃ­ zÅ™etelnÄ› oddÄ›lenÃ© neuronovÃ© drÃ¡hy pro memorovÃ¡nÃ­ konkrÃ©tnÃ­ho textu a pro obecnÃ© â€reasoningâ€œ schopnosti, vÄetnÄ› zÃ¡kladnÃ­ aritmetiky. UkazujÃ­, Å¾e odstranÄ›nÃ­m vybranÃ½ch vÃ¡hovÃ½ch komponent lze dramaticky omezit schopnost modelu doslovnÄ› citovat trÃ©ninkovÃ¡ data, aniÅ¾ by vÃ½raznÄ› utrpÄ›l jeho vÃ½kon v logickÃ½ch ÃºlohÃ¡ch.

## KlÃ­ÄovÃ© body
- Goodfire.ai identifikoval oddÄ›lenÃ© neuronovÃ© komponenty odpovÄ›dnÃ© za memorovÃ¡nÃ­ a za obecnÃ© uvaÅ¾ovÃ¡nÃ­.
- PÅ™i odstranÄ›nÃ­ memorizaÄnÃ­ch komponent klesla schopnost pÅ™esnÃ©ho citovÃ¡nÃ­ trÃ©ninkovÃ½ch dat o cca 97 %, zatÃ­mco logickÃ© schopnosti zÅ¯staly tÃ©mÄ›Å™ zachovÃ¡ny.
- AnalÃ½za byla provÃ¡dÄ›na mimo jinÃ© na modelu OLMo-7B od Allen Institute for AI.
- Komponenty spojenÃ© s memorovÃ¡nÃ­m se soustÅ™edily v dolnÃ­ ÄÃ¡sti Å¾ebÅ™Ã­Äku podle tzv. curvature metriky, zatÃ­mco komponenty pro obecnÃ½ text a Å™eÅ¡enÃ­ Ãºloh v hornÃ­ ÄÃ¡sti.
- ZÃ¡kladnÃ­ aritmetickÃ© operace se pÅ™ekvapivÄ› vÃ¡Å¾ou spÃ­Å¡e na stejnÃ© drÃ¡hy jako memorovÃ¡nÃ­ neÅ¾ na â€logickÃ©â€œ obvody.

## Podrobnosti
Goodfire.ai, menÅ¡Ã­ vÃ½zkumnÃ½ startup zamÄ›Å™enÃ½ na interpretovatelnost a bezpeÄnost modelÅ¯ AI, publikoval preprint, ve kterÃ©m systematicky analyzuje vnitÅ™nÃ­ strukturu jazykovÃ©ho modelu OLMo-7B (open-source model Allen Institute for AI). CÃ­lem bylo zjistit, zda jsou schopnosti modelu jako pÅ™esnÃ¡ reprodukce trÃ©ninkovÃ©ho textu a Å™eÅ¡enÃ­ novÃ½ch Ãºloh zaloÅ¾enÃ© na stejnÃ½ch, nebo odliÅ¡nÃ½ch parametrech.

VÃ½zkumnÃ­ci pouÅ¾ili metodu zaloÅ¾enou na metrice â€curvatureâ€œ, kterÃ¡ hodnotÃ­, jak citlivÃ© jsou jednotlivÃ© vÃ¡hy modelu na zmÄ›ny vstupu a jak se podÃ­lejÃ­ na rÅ¯znÃ½ch typech Ãºloh. VÃ¡hy v jednÃ© z vnitÅ™nÃ­ch vrstev (napÅ™. vrstva 22) seÅ™adili podle tÃ©to metriky a nÃ¡slednÄ› zkoumali jejich aktivaci pÅ™i dvou typech dat: memorovanÃ½ch (tj. text shodnÃ½ nebo velmi blÃ­zkÃ½ trÃ©ninkovÃ½m vzorkÅ¯m) a nememorovanÃ½ch (novÃ½, obecnÃ½ text).

UkÃ¡zalo se, Å¾e spodnÃ­ch 50 % vÃ¡hovÃ½ch komponent vykazovalo vÃ½raznÄ› vyÅ¡Å¡Ã­ aktivitu na memorovanÃ½ch textech, zatÃ­mco hornÃ­ch 10 % se aktivovalo vÃ­ce u obecnÃ©ho textu a Ãºloh vyÅ¾adujÃ­cÃ­ch zobecnÄ›nÃ­. Tato relativnÄ› ÄistÃ¡ separace umoÅ¾nila experimentÃ¡lnÃ­ zÃ¡sah: odstranÄ›nÃ­ (â€vynulovÃ¡nÃ­â€œ) spodnÃ­ch komponent vedlo k zÃ¡sadnÃ­mu omezenÃ­ schopnosti doslova citovat trÃ©ninkovÃ¡ data, ale vÃ½kon v testech logickÃ©ho uvaÅ¾ovÃ¡nÃ­ a obecnÃ©ho porozumÄ›nÃ­ zÅ¯stal pÅ™evÃ¡Å¾nÄ› zachovÃ¡n.

ZajÃ­mavÃ½m a potenciÃ¡lnÄ› kontroverznÃ­m zjiÅ¡tÄ›nÃ­m je, Å¾e nÄ›kterÃ© aritmetickÃ© schopnosti modelu â€“ zÃ¡kladnÃ­ poÄty a jednoduchÃ© operace â€“ byly vÃ­ce provÃ¡zÃ¡ny s memorizaÄnÃ­mi drahami neÅ¾ s obvody, kterÃ© model vyuÅ¾Ã­vÃ¡ k Å™eÅ¡enÃ­ obecnÃ½ch Ãºloh. To naznaÄuje, Å¾e ÄÃ¡st â€matematickÃ½ch schopnostÃ­â€œ souÄasnÃ½ch modelÅ¯ mÅ¯Å¾e bÃ½t spÃ­Å¡e nauÄenÃ½ vzorec a asociace neÅ¾ skuteÄnÃ© symbolickÃ© uvaÅ¾ovÃ¡nÃ­.

## ProÄ je to dÅ¯leÅ¾itÃ©
Studie je relevantnÃ­ pro vÃ½voj bezpeÄnÄ›jÅ¡Ã­ch a regulacÃ­m lÃ©pe vyhovujÃ­cÃ­ch modelÅ¯ AI. Pokud lze technicky oddÄ›lit a cÃ­lenÄ› potlaÄit pamÄ›Å¥ovÃ© drÃ¡hy, je moÅ¾nÃ© snÃ­Å¾it riziko Ãºniku chrÃ¡nÄ›nÃ½ch trÃ©ninkovÃ½ch dat (osobnÃ­ Ãºdaje, internÃ­ dokumenty, licencovanÃ½ obsah), aniÅ¾ by bylo nutnÃ© obÄ›tovat uÅ¾iteÄnÃ© funkce modelu. To mÃ¡ pÅ™Ã­mÃ½ dopad na poskytovatele velkÃ½ch modelÅ¯, podnikovÃ© nasazenÃ­ AI i na prÃ¡vnÃ­ a regulatornÃ­ debaty kolem autorskÃ©ho prÃ¡va a ochrany dat.

Pro prÅ¯mysl to takÃ© znamenÃ¡, Å¾e se otevÃ­rÃ¡ cesta k jemnÄ›jÅ¡Ã­mu ladÄ›nÃ­ modelÅ¯: mÃ­sto hrubÃ½ch filtrÅ¯ vÃ½stupu lze zasahovat do konkrÃ©tnÃ­ch vrstev a komponent. SouÄasnÄ› vÃ½sledek zpochybÅˆuje nÄ›kterÃ¡ marketingovÃ¡ tvrzenÃ­ o â€logickÃ©mâ€œ charakteru schopnostÃ­ modelÅ¯, zejmÃ©na v oblasti aritmetiky. Z hlediska dlouhodobÃ©ho vÃ½voje to posiluje dÅ¯raz na interpretovatelnost a mechanistickou analÃ½zu neuronovÃ½ch sÃ­tÃ­ jako nezbytnÃ½ krok k dÅ¯vÄ›ryhodnÃ½m a lÃ©pe kontrolovatelnÃ½m systÃ©mÅ¯m AI.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://arstechnica.com/ai/2025/11/study-finds-ai-models-store-memories-and-logic-in-different-neural-regions/)

**Zdroj:** ğŸ”¬ Ars Technica
