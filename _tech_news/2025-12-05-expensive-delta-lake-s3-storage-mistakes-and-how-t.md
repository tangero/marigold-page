---
author: Marisa Aigen
category: cloudovÃ© ÃºloÅ¾iÅ¡tÄ›
date: '2025-12-05 20:40:00'
description: ÄŒlÃ¡nek rozebÃ­rÃ¡ bÄ›Å¾nÃ© chyby pÅ™i konfiguraci S3 bucketÅ¯ pro tabulky Delta
  Lake a nabÃ­zÃ­ Å™eÅ¡enÃ­ pro snÃ­Å¾enÃ­ nÃ¡kladÅ¯ a zlepÅ¡enÃ­ vÃ½konu. ZamÄ›Å™uje se na konflikty
  verzovÃ¡nÃ­, tÅ™Ã­dy ÃºloÅ¾iÅ¡Å¥ a pÅ™enos dat.
importance: 3
layout: tech_news_article
original_title: Expensive Delta Lake S3 Storage Mistakes (And How to Fix Them)
publishedAt: '2025-12-05T20:40:00+00:00'
slug: expensive-delta-lake-s3-storage-mistakes-and-how-t
source:
  emoji: ğŸ“°
  id: null
  name: Databricks.com
title: DrahÃ© chyby v ÃºloÅ¾iÅ¡ti S3 pro Delta Lake (a jak je opravit)
url: https://www.databricks.com/blog/expensive-delta-lake-s3-storage-mistakes-and-how-fix-them
urlToImage: https://www.databricks.com/sites/default/files/2025-12/expensive-delta-lake-s3-storage-mistakes-og-image.png
urlToImageBackup: https://www.databricks.com/sites/default/files/2025-12/expensive-delta-lake-s3-storage-mistakes-og-image.png
---

## Souhrn
ÄŒlÃ¡nek identifikuje ÄastÃ© chyby v nastavovÃ¡nÃ­ S3 bucketÅ¯ pro Delta Lake tabulky v Lakehouse architektuÅ™e, kterÃ© vedou k zbyteÄnÃ½m nÃ¡kladÅ¯m na ÃºloÅ¾iÅ¡tÄ› a sÃ­Å¥ovÃ½ provoz. Popisuje tÅ™i klÃ­ÄovÃ© oblasti: verzovÃ¡nÃ­ objektÅ¯ oproti verzovÃ¡nÃ­ tabulek, tÅ™Ã­dy ÃºloÅ¾iÅ¡Å¥ a nÃ¡klady na pÅ™enos dat. NabÃ­zÃ­ praktickÃ© kroky k detekci a opravÄ› pomocÃ­ nÃ¡strojÅ¯ Databricks a AWS sluÅ¾eb.

## KlÃ­ÄovÃ© body
- Konflikt mezi nativnÃ­m S3 object versioning a verzovÃ¡nÃ­m Delta Lake tabulek vede k duplicitnÃ­mu uklÃ¡dÃ¡nÃ­ dat a vyÅ¡Å¡Ã­m nÃ¡kladÅ¯m.
- NesprÃ¡vnÃ© pouÅ¾itÃ­ storage classes (hot, cool, cold, archive) brÃ¡nÃ­ automatickÃ©mu pÅ™esunu starÅ¡Ã­ch dat do levnÄ›jÅ¡Ã­ch tÅ™Ã­d.
- Lifecycle policies umoÅ¾ÅˆujÃ­ automatizaci pÅ™esunÅ¯ dat bez zÃ¡sahu do Delta Lake logÅ¯.
- Optimalizace pÅ™enosu dat mezi S3 a vÃ½poÄetnÃ­mi clustery sniÅ¾uje sÃ­Å¥ovÃ© poplatky.
- DoporuÄenÃ© nasazenÃ­ bucketÅ¯ zahrnuje oddÄ›lenÃ© buckety pro data a logy.

## Podrobnosti
CloudovÃ© ÃºloÅ¾iÅ¡tÄ› jako S3 tvoÅ™Ã­ zÃ¡klad Lakehouse architektury, kde Delta Lake slouÅ¾Ã­ k sprÃ¡vÄ› tabulek s podporou transakcÃ­, verzovÃ¡nÃ­ a ÄasovÃ©ho cestovÃ¡nÃ­. Delta Lake uklÃ¡dÃ¡ kaÅ¾dou transakci jako manifest soubor v JSON nebo Parquet formÃ¡tu v adresÃ¡Å™i _delta_log/, kterÃ½ odkazuje na podkladovÃ© Parquet soubory s daty. PÅ™i pÅ™idÃ¡nÃ­, ÃºpravÄ› nebo smazÃ¡nÃ­ dat se vytvÃ¡Å™ejÃ­ novÃ© soubory, coÅ¾ zajiÅ¡Å¥uje ACID vlastnosti bez nutnosti externÃ­ho verzovÃ¡nÃ­.

ProblÃ©m nastÃ¡vÃ¡, kdyÅ¾ se zapne nativnÃ­ S3 object versioning, kterÃ© verziuje kaÅ¾dÃ½ objekt samostatnÄ›. To je v rozporu s Delta Lake, protoÅ¾e obÄ› mechanismy Å™eÅ¡Ã­ retenci dat jinak: Delta Lake verzuje na Ãºrovni tabulky, S3 na Ãºrovni objektu. VÃ½sledek je duplicitnÃ­ ÃºloÅ¾iÅ¡tÄ› verzÃ­, coÅ¾ zvyÅ¡uje objem dat a nÃ¡klady. Å˜eÅ¡enÃ­ spoÄÃ­vÃ¡ v vypnutÃ­ S3 versioning pro Delta Lake buckety a spolÃ©hÃ¡nÃ­ se vÃ½hradnÄ› na Delta Lake time travel, kterÃ© umoÅ¾Åˆuje vrÃ¡tit tabulku do minulÃ©ho stavu pomocÃ­ pÅ™Ã­kazÅ¯ jako RESTORE TABLE.

DalÅ¡Ã­ oblastÃ­ jsou storage classes. S3 nabÃ­zÃ­ tÅ™Ã­dy jako Standard (hot pro ÄastÃ½ pÅ™Ã­stup), Intelligent-Tiering (automatickÃ½ pÅ™esun), Glacier (cold pro vzÃ¡cnÃ½ pÅ™Ã­stup) nebo Deep Archive (pro dlouhodobÃ© archivace). Pro Delta Lake tabulky s rostoucÃ­m objemem dat z ETL pipelineÅ¯ nebo dotazÅ¯ je ideÃ¡lnÃ­ nastavit lifecycle policies, kterÃ© po urÄitÃ© dobÄ› (napÅ™. 30 dnÅ¯) pÅ™esunou starÅ¡Ã­ Parquet soubory do levnÄ›jÅ¡Ã­ch tÅ™Ã­d. Databricks Unity Catalog pomÃ¡hÃ¡ monitorovat velikost tabulek a identifikovat kandidÃ¡ty na optimalizaci. NapÅ™Ã­klad pÅ™Ã­kaz DESCRIBE HISTORY tabulka ukÃ¡Å¾e verze a jejich velikosti.

NÃ¡klady na pÅ™enos dat (data transfer) mezi S3 a Databricks clustery lze minimalizovat vÃ½bÄ›rem clusterÅ¯ ve stejnÃ© AWS region a zÃ³nÄ›. PouÅ¾itÃ­ S3 Select nebo Databricks Delta Cache zrychluje ÄtenÃ­ bez plnÃ©ho stahovÃ¡nÃ­. Pro detekci problÃ©mÅ¯ slouÅ¾Ã­ AWS Cost Explorer a Databricks System Tables pro analÃ½zu ÃºloÅ¾iÅ¡Å¥.

## ProÄ je to dÅ¯leÅ¾itÃ©
S rostoucÃ­m objemem dat v Lakehouse architektuÅ™e mohou nÃ¡klady na S3 rychle pÅ™ekroÄit rozpoÄet, zejmÃ©na pokud ETL procesy generujÃ­ tisÃ­ce verzÃ­ dennÄ›. Optimalizace versioning a storage classes mÅ¯Å¾e snÃ­Å¾it nÃ¡klady o desÃ­tky procent bez ztrÃ¡ty funkÄnosti Delta Lake, jako je ÄasovÃ© cestovÃ¡nÃ­ nebo schema enforcement. V Å¡irÅ¡Ã­m kontextu big data ekosystÃ©mu to umoÅ¾Åˆuje Å¡kÃ¡lovat datovÃ© jezera udrÅ¾itelnÄ›, coÅ¾ je klÃ­ÄovÃ© pro firmy zÃ¡vislÃ© na Databricks a AWS. Bez tÄ›chto opatÅ™enÃ­ hrozÃ­ neefektivita, kterÃ¡ brzdÃ­ inovace v analÃ½ze dat.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.databricks.com/blog/expensive-delta-lake-s3-storage-mistakes-and-how-fix-them)

**Zdroj:** ğŸ“° Databricks.com
