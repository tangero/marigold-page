---
author: Marisa Aigen
category: ai regulace
date: '2025-12-30 02:32:33'
description: NÃ¡vrhovÃ© naÅ™Ã­zenÃ­ se zamÄ›Å™uje na obavy spojenÃ© s chatboti, jejichÅ¾ popularita
  v poslednÃ­ch mÄ›sÃ­cÃ­ch prudce vzrostla. Pravidla majÃ­ zajistit bezpeÄnost dÄ›tÃ­ a
  zabrÃ¡nit Å¡kodlivÃ½m radÃ¡m od AI.
importance: 4
layout: tech_news_article
original_title: China plans AI rules to protect children and tackle suicide risks
publishedAt: '2025-12-30T02:32:33+00:00'
slug: china-plans-ai-rules-to-protect-children-and-tackl
source:
  emoji: ğŸ“°
  id: null
  name: BBC News
title: ÄŒÃ­na plÃ¡nuje pravidla pro umÄ›lou inteligenci k ochranÄ› dÄ›tÃ­ a prevenci sebevraÅ¾d
url: https://www.bbc.com/news/articles/c8dydlmenvro
urlToImage: https://ichef.bbci.co.uk/news/1024/branded_news/0fa6/live/4c396340-e527-11f0-a17f-77b932673098.jpg
urlToImageBackup: https://ichef.bbci.co.uk/news/1024/branded_news/0fa6/live/4c396340-e527-11f0-a17f-77b932673098.jpg
---

## Souhrn
ÄŒÃ­nskÃ¡ Cyberspace Administration of China (CAC) zveÅ™ejnila nÃ¡vrh pÅ™Ã­snÃ½ch pravidel pro umÄ›lou inteligenci, kterÃ© majÃ­ chrÃ¡nit dÄ›ti pÅ™ed riziky a zabrÃ¡nit chatbÅ¯m v poskytovÃ¡nÃ­ rad vedoucÃ­ch k sebevraÅ¾dÄ› nebo nÃ¡silÃ­. VÃ½vojÃ¡Å™i AI budou muset implementovat personalizovanÃ¡ nastavenÃ­, ÄasovÃ© limity a mechanismy pro pÅ™edÃ¡nÃ­ konverzace lidskÃ©mu operÃ¡torovi v kritickÃ½ch situacÃ­ch. Tato regulace pÅ™ichÃ¡zÃ­ v dobÄ› rÅ¯stu popularity chatbotÅ¯ v ÄŒÃ­nÄ›, jako jsou DeepSeek, Z.ai nebo Minimax.

## KlÃ­ÄovÃ© body
- Ochrana dÄ›tÃ­: povinnost personalizovanÃ½ch nastavenÃ­, ÄasovÃ½ch limitÅ¯ pouÅ¾itÃ­ a souhlasu rodiÄÅ¯ pro sluÅ¾by emocionÃ¡lnÃ­ podpory.
- Prevence sebevraÅ¾dy: pÅ™i detekci tÃ©mat sebevraÅ¾dy nebo sebeubliÅ¾ovÃ¡nÃ­ musÃ­ chatbot pÅ™edat konverzaci ÄlovÄ›ku a upozornit rodiÄe nebo zÃ¡chrannÃ© kontakt.
- ZÃ¡kaz Å¡kodlivÃ©ho obsahu: AI nesmÃ­ generovat materiÃ¡ly podporujÃ­cÃ­ hazard, ohroÅ¾ujÃ­cÃ­ nÃ¡rodnÃ­ bezpeÄnost nebo naruÅ¡ujÃ­cÃ­ nÃ¡rodnÃ­ jednotu.
- Podpora bezpeÄnÃ©ho AI: povzbudÃ­ se vÃ½voj AI pro propagaci mÃ­stnÃ­ kultury a spoleÄnost pro seniory, pokud je technologie spolehlivÃ¡.
- VeÅ™ejnÃ© konzultace: CAC Å¾Ã¡dÃ¡ zpÄ›tnou vazbu od veÅ™ejnosti pÅ™ed finÃ¡lnÃ­m schvÃ¡lenÃ­m.

## Podrobnosti
Cyberspace Administration of China (CAC), ÄÃ­nskÃ½ regulaÄnÃ­ orgÃ¡n odpovÄ›dnÃ½ za kyberprostor, zveÅ™ejnil o vÃ­kendu nÃ¡vrh naÅ™Ã­zenÃ­, kterÃ© se zamÄ›Å™uje na rychle rostoucÃ­ oblast generativnÃ­ umÄ›lÃ© inteligence, zejmÃ©na chatbotÅ¯. Tyto systÃ©my, zaloÅ¾enÃ© na velkÃ½ch jazykovÃ½ch modelech (LLM), jako napÅ™Ã­klad ty od ÄÃ­nskÃ½ch firem DeepSeek, Z.ai nebo Minimax, zÃ­skaly v poslednÃ­ch mÄ›sÃ­cÃ­ch desÃ­tky milionÅ¯ uÅ¾ivatelÅ¯. DeepSeek se dostal na vrchol globÃ¡lnÃ­ch Å¾ebÅ™Ã­kÅ¯ stahovÃ¡nÃ­ aplikacÃ­, zatÃ­mco Z.ai a Minimax oznÃ¡mily plÃ¡ny na vstup na burzu, coÅ¾ signalizuje masivnÃ­ investice do tohoto segmentu.

NÃ¡vrh zavÃ¡dÃ­ konkrÃ©tnÃ­ opatÅ™enÃ­ pro ochranu dÄ›tÃ­: vÃ½vojÃ¡Å™i musÃ­ poskytnout personalizovanÃ¡ nastavenÃ­, kterÃ¡ omezÃ­ expozici rizikovÃ½m interakcÃ­m, nastavit dennÃ­ nebo hodinovÃ© limity pouÅ¾Ã­vÃ¡nÃ­ a vyÅ¾adovat souhlas zÃ¡konnÃ©ho zÃ¡stupce pÅ™ed aktivacÃ­ funkcÃ­ emocionÃ¡lnÃ­ho spoleÄenstvÃ­. EmotionÃ¡lnÃ­ spoleÄenstvÃ­ slouÅ¾Ã­ k simulaci lidskÃ©ho dialogu pro podporu duÅ¡evnÃ­ho zdravÃ­, ale bez regulace mÅ¯Å¾e vÃ©st k nevhodnÃ½m radÃ¡m. V pÅ™Ã­padech, kdy uÅ¾ivatel zmiÅˆuje sebevraÅ¾du nebo sebeubliÅ¾ovÃ¡nÃ­, musÃ­ systÃ©m okamÅ¾itÄ› pÅ™edat konverzaci lidskÃ©mu operÃ¡torovi a notifikovat rodiÄe nebo nouzovÃ½ kontakt, coÅ¾ pÅ™ipomÃ­nÃ¡ mechanismy v zÃ¡padnÃ­ch platformÃ¡ch jako Character.AI po incidentech s dÄ›tmi.

DalÅ¡Ã­ poÅ¾adavky zahrnujÃ­ zÃ¡kaz generovÃ¡nÃ­ obsahu podporujÃ­cÃ­ hazardnÃ­ hry, kterÃ© by mohly vÃ©st k zÃ¡vislosti, a striktnÃ­ kontroly proti materiÃ¡lÅ¯m ohroÅ¾ujÃ­cÃ­m nÃ¡rodnÃ­ bezpeÄnost, poctu nebo jednotu. CAC zÃ¡roveÅˆ podporuje vÃ½voj AI pro pozitivnÃ­ ÃºÄely, jako je propagace ÄÃ­nskÃ© kultury prostÅ™ednictvÃ­m generovanÃ©ho obsahu nebo nÃ¡stroje pro sociÃ¡lnÃ­ interakce seniorÅ¯, pokud splÅˆujÃ­ bezpeÄnostnÃ­ standardy. Tato regulace bude platit pro vÅ¡echny AI produkty a sluÅ¾by v ÄŒÃ­nÄ› po finÃ¡lnÃ­m schvÃ¡lenÃ­ a vyÅ¾aduje veÅ™ejnÃ© komentÃ¡Å™e. Pro ÄÃ­nskÃ© AI firmy to znamenÃ¡ nutnost investovat do bezpeÄnostnÃ­ch vrstev, jako jsou filtry obsahu a monitorovacÃ­ systÃ©my, coÅ¾ mÅ¯Å¾e zpomalit vÃ½voj, ale zvÃ½Å¡it dÅ¯vÄ›ryhodnost.

## ProÄ je to dÅ¯leÅ¾itÃ©
Tato regulace pÅ™edstavuje dalÅ¡Ã­ krok v ÄÃ­nskÃ© strategii kontroly umÄ›lÃ© inteligence, kde stÃ¡t balancuje mezi podporou inovacÃ­ a nÃ¡rodnÃ­ bezpeÄnostÃ­. Na rozdÃ­l od EU AI Act, kterÃ½ je rizikovÄ› orientovanÃ½, ÄÃ­nskÃ½ pÅ™Ã­stup klade dÅ¯raz na specifickÃ¡ rizika jako duÅ¡evnÃ­ zdravÃ­ a cenzuru, coÅ¾ ovlivnÃ­ globÃ¡lnÃ­ AI trh â€“ ÄÃ­nskÃ© modely jako DeepSeek jsou dostupnÃ© i mimo ÄŒÃ­nu. Pro uÅ¾ivatele to znamenÃ¡ bezpeÄnÄ›jÅ¡Ã­ interakce, ale potenciÃ¡lnÄ› mÃ©nÄ› volnÃ© AI; pro prÅ¯mysl to posÃ­lÃ­ tlak na etickÃ© standardy a mÅ¯Å¾e inspirovat podobnÃ© kroky jinde. V kontextu rÅ¯stu incidentÅ¯ s chatboti (napÅ™. sebevraÅ¾ednÃ© rady v USA) to podtrhuje nutnost globÃ¡lnÃ­ch bezpeÄnostnÃ­ch rÃ¡mcÅ¯, i kdyÅ¾ ÄÃ­nskÃ¡ verze zahrnuje politickÃ© prvky.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.bbc.com/news/articles/c8dydlmenvro)

**Zdroj:** ğŸ“° BBC News
