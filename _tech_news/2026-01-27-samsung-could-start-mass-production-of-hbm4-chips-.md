---
author: Marisa Aigen
category: hardware
companies:
- Samsung
- Nvidia
date: '2026-01-27 03:04:21'
description: ÄŒipy HBM3 a HBM3E od Samsungu, pouÅ¾Ã­vanÃ© v akcelerÃ¡torech umÄ›lÃ© inteligence,
  trpÄ›ly problÃ©my s vÃ½konem. SpoleÄnost je loni pÅ™epracovala, aby zÃ­skala schvÃ¡lenÃ­
  od Nvidia, pÅ™esto byly pouÅ¾ity jen v omezenÃ©m poÄtu akcelerÃ¡torÅ¯.
importance: 4
layout: tech_news_article
original_title: Samsung could start mass production of HBM4 chips next month for Nvidia
publishedAt: '2026-01-27T03:04:21+00:00'
slug: samsung-could-start-mass-production-of-hbm4-chips-
source:
  emoji: ğŸ“°
  id: null
  name: SamMobile
title: Samsung by mohl zahÃ¡jit hromadnou vÃ½robu ÄipÅ¯ HBM4 pÅ™Ã­Å¡tÃ­ mÄ›sÃ­c pro Nvidia
url: https://www.sammobile.com/news/samsung-hbm4-mass-production-start-next-month-nvidia/
urlToImage: https://www.sammobile.com/wp-content/uploads/2025/12/Nvidia-Vera-Rubin-NVL144-Tray-AI-Platform-GTC-2025-1200x675.jpg
urlToImageBackup: https://www.sammobile.com/wp-content/uploads/2025/12/Nvidia-Vera-Rubin-NVL144-Tray-AI-Platform-GTC-2025-1200x675.jpg
---

### Souhrn
Samsung plÃ¡nuje zahÃ¡jit hromadnou vÃ½robu ÄipÅ¯ HBM4 jiÅ¾ pÅ™Ã­Å¡tÃ­ mÄ›sÃ­c, pÅ™edevÅ¡Ã­m pro Nvidia, kterÃ¡ je dominantnÃ­m dodavatelem grafickÃ½ch procesorÅ¯ pro trÃ©nink velkÃ½ch jazykovÃ½ch modelÅ¯. Tato novÃ¡ generace vysokopÃ¡smovÃ© pamÄ›ti (High Bandwidth Memory) pÅ™ichÃ¡zÃ­ po Å™adÄ› problÃ©mÅ¯ s pÅ™edchozÃ­mi verzemi HBM3 a HBM3E, kterÃ© Samsung musel redesignovat. Nvidia by tak mohla rozÅ¡Ã­Å™it svou nabÃ­dku AI akcelerÃ¡torÅ¯ s vyÅ¡Å¡Ã­ kapacitou a rychlostÃ­ pamÄ›ti.

### KlÃ­ÄovÃ© body
- Samsung oÄekÃ¡vÃ¡ start masovÃ© produkce HBM4 v prosinci 2024, cÃ­lenÄ› pro Nvidia GPU.
- PÅ™edchozÃ­ HBM3E Äipy mÄ›ly problÃ©my s vÃ½konem a spolehlivostÃ­, coÅ¾ vedlo k redesignu v roce 2023.
- HBM4 nabÃ­dne aÅ¾ 16 vrstev pamÄ›ti s kapacitou aÅ¾ 16 Gb na kostku, coÅ¾ umoÅ¾nÃ­ vyÅ¡Å¡Ã­ propustnost dat pro AI trÃ©nink.
- Nvidia zatÃ­m spolupracuje pÅ™evÃ¡Å¾nÄ› se SK Hynix, ale Samsung se snaÅ¾Ã­ zÃ­skat vÄ›tÅ¡Ã­ podÃ­l na trhu.
- Tento krok posÃ­lÃ­ dodÃ¡vatelskÃ½ Å™etÄ›zec pro AI hardware v dobÄ› rostoucÃ­ poptÃ¡vky po vÃ½poÄetnÃ­ch clusterech.

### Podrobnosti
High Bandwidth Memory (HBM) je specializovanÃ¡ pamÄ›Å¥ovÃ¡ technologie navrÅ¾enÃ¡ pro vysokovÃ½konnÃ© aplikace, jako jsou grafickÃ© procesory (GPU) v akcelerÃ¡torech umÄ›lÃ© inteligence. Na rozdÃ­l od bÄ›Å¾nÃ© GDDR pamÄ›ti je HBM stackovÃ¡na vertikÃ¡lnÄ› pomocÃ­ through-silicon vias (TSV), coÅ¾ umoÅ¾Åˆuje extrÃ©mnÄ› vysokou pÃ¡smovou Å¡Ã­Å™ku â€“ aÅ¾ desÃ­tky terabajtÅ¯ za sekundu na jeden Äip. Nvidia ji vyuÅ¾Ã­vÃ¡ ve svÃ½ch nejvÃ½konnÄ›jÅ¡Ã­ch produktech, jako jsou H100 a nadchÃ¡zejÃ­cÃ­ Blackwell sÃ©rie (B200), kde slouÅ¾Ã­ k rychlÃ©mu pÅ™enosu dat mezi vÃ½poÄetnÃ­mi jÃ¡dry a pamÄ›tÃ­ bÄ›hem trÃ©ninku modelÅ¯ jako GPT nebo Llama.

Samsung, jeden z tÅ™Ã­ hlavnÃ­ch vÃ½robcÅ¯ HBM (spolu se SK Hynix a Micron), mÄ›l v minulosti potÃ­Å¾e. Jeho HBM3 Äipy vykazovaly niÅ¾Å¡Ã­ vÃ½kon v testech stability a teplotnÃ­ odolnosti oproti konkurentÅ¯m. V roce 2023 proto provedl redesign HBM3E, kterÃ½ zahrnoval vylepÅ¡enÃ­ mikrostruktury a materiÃ¡lÅ¯ pro lepÅ¡Ã­ signÃ¡lovou integritu. Nvidia toto schvÃ¡lenÃ­ udÄ›lila, ale omezenÄ› â€“ HBM3E od Samsungu se objevily jen v niÅ¾Å¡Ã­ch verzÃ­ch akcelerÃ¡torÅ¯, zatÃ­mco prÃ©miovÃ© modely zÅ¯staly na SK Hynix.

HBM4 pÅ™edstavuje dalÅ¡Ã­ skok: podporuje aÅ¾ 16-Hi stacky s hustotou 16 Gb na die, coÅ¾ znamenÃ¡ celkovou kapacitu aÅ¾ 288 GB na GPU v kombinaci s vÃ­ce kostkami. Propustnost dosÃ¡hne 1,6 TB/s a vÃ­ce, coÅ¾ je klÃ­ÄovÃ© pro zpracovÃ¡nÃ­ obÅ™Ã­ch datovÃ½ch sad v AI. Samsung tvrdÃ­, Å¾e dosÃ¡hl vÃ½tÄ›Å¾nosti nad 80 % v testovacÃ­ produkci a plÃ¡nuje dodÃ¡vky pro Nvidia H200 a Blackwell platformy. Tento krok je souÄÃ¡stÃ­ Å¡irÅ¡Ã­ strategie Koreje posÃ­lit pozici v AI dodavatelskÃ©m Å™etÄ›zci, kde Nvidia kontroluje pÅ™es 90 % trhu s AI GPU. BezpeÄnostnÃ­ aspekty, jako ochrana proti chybÃ¡m v pamÄ›ti (ECC), byly takÃ© vylepÅ¡eny, aby se minimalizovaly vÃ½padky bÄ›hem dlouhÃ½ch trÃ©ninkovÃ½ch cyklÅ¯ trvajÃ­cÃ­ch tÃ½dny.

### ProÄ je to dÅ¯leÅ¾itÃ©
Tato novinka urychlÃ­ expanzi AI infrastruktury, protoÅ¾e Nvidia ÄelÃ­ nedostatku pamÄ›ti pro svÃ© clustery, kterÃ© pohÃ¡nÄ›jÃ­ sluÅ¾by jako ChatGPT nebo xAI Grok. Samsungovo zapojenÃ­ diverzifikuje dodÃ¡vatele, sniÅ¾uje rizika zÃ¡vislosti na SK Hynix a mÅ¯Å¾e snÃ­Å¾it ceny HBM o 20â€“30 % dÃ­ky vÄ›tÅ¡Ã­ konkurenci. Pro prÅ¯mysl to znamenÃ¡ rychlejÅ¡Ã­ nasazenÃ­ novÃ½ch generacÃ­ AI modelÅ¯ s miliardami parametrÅ¯, kde pamÄ›Å¥ovÃ½ bottleneck byl dosud hlavnÃ­ pÅ™ekÃ¡Å¾kou. V Å¡irÅ¡Ã­m kontextu posiluje to geopolitickou roli jihokorejskÃ½ch firem v AI ekosystÃ©mu, kde USA (Nvidia) spolÃ©hajÃ­ na asijskou vÃ½robu. DlouhodobÄ› by HBM4 mohlo umoÅ¾nit efektivnÄ›jÅ¡Ã­ edge AI aplikace v datech centrech i autonomnÃ­ch systÃ©mech, ale zÃ¡visÃ­ na finÃ¡lnÃ­m schvÃ¡lenÃ­ Nvidia a Å¡kÃ¡lovatelnosti vÃ½roby.

---

[ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek](https://www.sammobile.com/news/samsung-hbm4-mass-production-start-next-month-nvidia/)

**Zdroj:** ğŸ“° SamMobile
