<!DOCTYPE html>
<html lang="cs">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ÄŒÃ­na a Amerika se musÃ­ vÃ¡Å¾nÄ› zabÃ½vat riziky AI | Marigold.cz Tech News</title>
    <meta name="description" content="ZÃ¡vod o vedenÃ­ v vojenskÃ©, zpravodajskÃ© a komerÄnÃ­ AI â€“ a o globÃ¡lnÃ­ adopci americkÃ½ch nebo ÄÃ­nskÃ½ch modelÅ¯ â€“ se jen zintenzivnÃ­. Jako nÃ¡rodnÃ­ bezpeÄnostnÃ­ pora">
    <link rel="canonical" href="https://www.marigold.cz/tech-news/2026-01-02/china-and-america-must-get-serious-about-ai-risk/">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #374151; background: #f3f4f6; }
        .container { max-width: 800px; margin: 0 auto; padding: 2rem; }
        .tech-news-article { background: white; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); padding: 2rem; margin: 2rem 0; }
        .source-info { display: flex; align-items: center; gap: 0.75rem; margin-bottom: 1rem; flex-wrap: wrap; }
        .source-emoji { font-size: 1.5rem; }
        .source-name { font-weight: 600; color: #374151; }
        .importance-indicator { display: flex; gap: 2px; margin-left: auto; }
        .star { color: #fbbf24; font-size: 1.2rem; }
        .star.empty { color: #d1d5db; }
        .article-title { font-size: 2rem; font-weight: 700; line-height: 1.2; margin-bottom: 1rem; color: #111827; }
        .article-meta { display: flex; align-items: center; gap: 1rem; font-size: 0.875rem; color: #6b7280; margin-bottom: 1.5rem; }
        .category { padding: 0.25rem 0.75rem; border-radius: 1rem; font-weight: 500; font-size: 0.75rem; text-transform: uppercase; background: #e5e7eb; color: #374151; }
        .article-image { margin: 1.5rem 0; border-radius: 8px; overflow: hidden; }
        .article-image img { width: 100%; height: auto; display: block; }
        .article-content { font-size: 1.125rem; line-height: 1.7; margin-bottom: 2rem; }
        .article-content h2 { font-size: 1.5rem; margin: 1.5rem 0 1rem; color: #111827; }
        .article-content p { margin-bottom: 1rem; }
        .article-footer { border-top: 1px solid #e5e7eb; padding-top: 1.5rem; }
        .read-more-btn { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.75rem 1.5rem; background: #3b82f6; color: white; text-decoration: none; border-radius: 8px; font-weight: 500; }
        .read-more-btn:hover { background: #2563eb; }
        .original-title { margin-top: 1rem; color: #6b7280; font-size: 0.875rem; }
        .back-link { display: inline-block; margin-bottom: 1rem; color: #3b82f6; text-decoration: none; }
        .back-link:hover { text-decoration: underline; }
        .archive-notice { background: #fef3c7; border: 1px solid #f59e0b; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; font-size: 0.875rem; color: #92400e; }
        @media (max-width: 640px) {
            .container { padding: 1rem; }
            .tech-news-article { padding: 1.5rem; margin: 1rem 0; }
            .article-title { font-size: 1.5rem; }
            .source-info { flex-direction: column; align-items: flex-start; }
            .importance-indicator { margin-left: 0; margin-top: 0.5rem; }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="/tech-news/" class="back-link">&larr; ZpÄ›t na Tech News</a>

        <div class="archive-notice">
            Tento ÄlÃ¡nek je z archivu. Byl publikovÃ¡n 02.01.2026.
        </div>

        <article class="tech-news-article">
            <header>
                <div class="source-info">
                    <span class="source-emoji">ğŸ“°</span>
                    <span class="source-name">Livemint</span>
                    <div class="importance-indicator">
                        <span class="star">â˜…</span><span class="star">â˜…</span><span class="star">â˜…</span><span class="star">â˜…</span><span class="star empty">â˜†</span>
                    </div>
                </div>

                <h1 class="article-title">ÄŒÃ­na a Amerika se musÃ­ vÃ¡Å¾nÄ› zabÃ½vat riziky AI</h1>

                <div class="article-meta">
                    <time datetime="2026-01-02T10:00:36+00:00">02.01.2026</time>
                    <span class="category">ai rizika</span>
                </div>
            </header>

            
            <div class="article-image">
                <img src="https://www.livemint.com/lm-img/img/2025/12/31/1600x900/logo/China_US_PS_AFP_1767179428162_1767179438515.jpg" alt="ÄŒÃ­na a Amerika se musÃ­ vÃ¡Å¾nÄ› zabÃ½vat riziky AI" loading="lazy">
            </div>
        

            <div class="article-content">
                <h3>Souhrn</h3>
<p>Jake Sullivan, bÃ½valÃ½ nÃ¡rodnÃ­ bezpeÄnostnÃ­ poradce USA, vyzÃ½vÃ¡ ÄŒÃ­nu a SpojenÃ© stÃ¡ty k rozvoji trvalÃ© diplomacie na vysokÃ© Ãºrovni ohlednÄ› rizik umÄ›lÃ© inteligence. Navazuje na spoleÄnÃ© prohlÃ¡Å¡enÃ­ prezidentÅ¯ Bidena a Si Å¤in-pchinga z listopadu 2024, kterÃ© zdÅ¯razÅˆuje nutnost udrÅ¾et lidskou kontrolu nad rozhodovÃ¡nÃ­m o pouÅ¾itÃ­ jadernÃ½ch zbranÃ­. Tento krok ukazuje, Å¾e i pÅ™i intenzivnÃ­ soutÄ›Å¾i o globÃ¡lnÃ­ vedenÃ­ v AI lze dosÃ¡hnout pokroku v Å™Ã­zenÃ­ rizik.</p>
<h3>KlÃ­ÄovÃ© body</h3>
<ul>
<li>SpoleÄnÃ© prohlÃ¡Å¡enÃ­ USA a ÄŒÃ­ny z listopadu 2024 o lidskÃ© kontrole nad jadernÃ½mi zbranÄ›mi v Ã©Å™e AI.</li>
<li>Rok vyjednÃ¡vÃ¡nÃ­ pÅ™ekonal skepticismus ÄÃ­nskÃ© strany vÅ¯Äi americkÃ½m nÃ¡vrhÅ¯m na snÃ­Å¾enÃ­ rizik.</li>
<li>SetkÃ¡nÃ­ diplomatÅ¯ a expertÅ¯ v Å½enevÄ› na zaÄÃ¡tku roku 2024.</li>
<li>VÃ½zva k pokraÄujÃ­cÃ­mu dialogu na Ãºrovni vrcholovÃ½ch pÅ™edstavitelÅ¯ pÅ™i soubÄ›Å¾nÃ© soutÄ›Å¾i o AI vedenÃ­.</li>
<li>PotenciÃ¡l pro dalÅ¡Ã­ kroky v Å™Ã­zenÃ­ nÃ¡rodnÄ› bezpeÄnostnÃ­ch rizik spojenÃ½ch s AI.</li>
</ul>
<h3>Podrobnosti</h3>
<p>ÄŒlÃ¡nek vychÃ¡zÃ­ z autorovy zkuÅ¡enosti jako nÃ¡rodnÃ­ho bezpeÄnostnÃ­ho poradce, kde koordinoval pÅ™Ã­pravu USA na Å¡irokÃ© spektrum hrozeb vÄetnÄ› tÄ›ch souvisejÃ­cÃ­ch s rychlÃ½m vÃ½vojem AI v civilnÃ­ch i vojenskÃ½ch aplikacÃ­ch. KlÃ­ÄovÃ½m milnÃ­kem je prohlÃ¡Å¡enÃ­ z listopadu 2024, kdy Biden a Si Å¤in-pching poprvÃ© spoleÄnÄ› uznaly potÅ™ebu zachovat lidskou kontrolu nad jadernÃ½mi zbranÄ›mi. Tento bod, i kdyÅ¾ zdÃ¡nlivÄ› samozÅ™ejmÃ½, vyÅ¾adoval vÃ­ce neÅ¾ rok intenzivnÃ­ch jednÃ¡nÃ­. ÄŒÃ­nskÃ¡ strana je tradiÄnÄ› skeptickÃ¡ vÅ¯Äi nÃ¡vrhÅ¯m USA na snÃ­Å¾enÃ­ rizik, zejmÃ©na kdyÅ¾ Rusko podobnÃ© formulace blokovalo v multilaterÃ¡lnÃ­ch fÃ³rech. ÃšspÄ›ch bilaterÃ¡lnÃ­ch rozhovorÅ¯ tak vytvÃ¡Å™Ã­ trhlinu mezi PekÃ­ngem a Moskvou, coÅ¾ posiluje pozici USA.</p>
<p>DÅ™Ã­ve v roce 2024 se v Å½enevÄ› konala prodlouÅ¾enÃ¡ setkÃ¡nÃ­ expertÅ¯ obou zemÃ­, kterÃ¡ poloÅ¾ila zÃ¡klady pro tento dialog. Sullivan zdÅ¯razÅˆuje, Å¾e rychlost vÃ½voje AI â€“ od velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM) jako GPT nebo ÄÃ­nskÃ½ch ekvivalentÅ¯ po autonomnÃ­ systÃ©my pro zpravodajstvÃ­ a vojenskÃ© operace â€“ zvyÅ¡uje rizika nechtÄ›nÃ© eskalace. NapÅ™Ã­klad AI by mohla ovlivnit rozhodovÃ¡nÃ­ v kritickÃ½ch situacÃ­ch, jako je detekce hrozeb nebo cÃ­lenÃ­ zbranÃ­, coÅ¾ by mohlo vÃ©st k chybÃ¡m s katastrofÃ¡lnÃ­mi nÃ¡sledky. Pro ÄŒÃ­nu i USA jde o strategickou soutÄ›Å¾: kdo ovlÃ¡dne globÃ¡lnÃ­ standardy AI modelÅ¯, ten ovlivnÃ­ ekonomiku, bezpeÄnost i geopolitiku. Sullivan proto navrhuje udrÅ¾et dialog i pÅ™i maximalizaci nÃ¡rodnÃ­ch vÃ½hod, podobnÄ› jako v jinÃ½ch oblastech zbrojenÃ­.</p>
<p>Tento pÅ™Ã­stup kontrastuje s absencÃ­ multilaterÃ¡lnÃ­ch dohod, kde ÄŒÃ­na a Rusko Äasto kooperujÃ­ proti ZÃ¡padu. Pro prÅ¯mysl znamenÃ¡, Å¾e firmy jako OpenAI, Google DeepMind nebo ÄÃ­nskÃ© Baidu a Tencent musÃ­ poÄÃ­tat s rostoucÃ­ regulacÃ­, kterÃ¡ by mohla omezit export technologiÃ­ nebo sdÃ­lenÃ­ dat.</p>
<h3>ProÄ je to dÅ¯leÅ¾itÃ©</h3>
<p>Tento diplomatickÃ½ pokrok nastavuje precedens pro globÃ¡lnÃ­ governance AI, kde absence dohod hrozÃ­ zÃ¡vodnÃ½m zbranÄ›nÃ­m v autonomnÃ­ch systÃ©mech. Pro uÅ¾ivatele a prÅ¯mysl to znamenÃ¡ potenciÃ¡lnÃ­ stabilizaci: mÃ©nÄ› rizik neoÄekÃ¡vanÃ½ch incidentÅ¯, jako je chyba AI v kritickÃ© infrastruktuÅ™e, ale zÃ¡roveÅˆ zpomalenÃ­ inovacÃ­ kvÅ¯li bezpeÄnostnÃ­m omezenÃ­m. V Å¡irÅ¡Ã­m kontextu posiluje to pozici USA v soutÄ›Å¾i s ÄŒÃ­nou, kde americkÃ© modely (napÅ™. od OpenAI) dominujÃ­ v komerÄnÃ­m sektoru, zatÃ­mco ÄÃ­nskÃ© vedou v masovÃ© adopci. Bez takovÃ©ho dialogu by rostoucÃ­ integrace AI do vojenskÃ½ch systÃ©mÅ¯ mohla vÃ©st k nestabilitÄ›, podobnÄ› jako v minulosti u jadernÃ½ch zbranÃ­. CelkovÄ› to podtrhuje nutnost expertÅ¯ na AI bezpeÄnost, aby ovlivÅˆovali politiku a zabraÅˆovali scÃ©nÃ¡Å™Å¯m, kde algoritmy pÅ™ebÃ­rajÃ­ klÃ­ÄovÃ¡ rozhodnutÃ­.</p>
<hr />
<p><a href="https://www.livemint.com/opinion/columns/us-china-ai-risks-national-security-diplomacy-technology-global-stability-11767179324869.html">ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek</a></p>
<p><strong>Zdroj:</strong> ğŸ“° Livemint</p>
            </div>

            <footer class="article-footer">
                <a href="https://www.livemint.com/opinion/columns/us-china-ai-risks-national-security-diplomacy-technology-global-stability-11767179324869.html" target="_blank" rel="noopener" class="read-more-btn">
                    ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek &rarr;
                </a>

                <div class="original-title"><small>PÅ¯vodnÃ­ nÃ¡zev: China and America must get serious about AI risk</small></div>
            </footer>
        </article>

        <p style="text-align: center; color: #6b7280; font-size: 0.875rem; margin-top: 2rem;">
            &copy; 2026 <a href="https://www.marigold.cz" style="color: #3b82f6;">Marigold.cz</a>
        </p>
    </div>
</body>
</html>
