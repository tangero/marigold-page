<!DOCTYPE html>
<html lang="cs">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>V√Ωzkumn√≠ci prok√°zali, ≈æe tr√©nink na "nekvalitn√≠ch datech" vede k degradaci jazykov√Ωch model≈Ø | Marigold.cz Tech News</title>
    <meta name="description" content="Studie z americk√Ωch univerzit ukazuje, ≈æe jazykov√© modely tr√©novan√© na kr√°tk√Ωch, popul√°rn√≠ch a povrchn√≠ch tweetech vykazuj√≠ hor≈°√≠ v√Ωsledky v testech a ztr√°cej√≠ ">
    <link rel="canonical" href="https://www.marigold.cz/tech-news/2025-10-23/researchers-show-that-training-on-junk-data-can-le/">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #374151; background: #f3f4f6; }
        .container { max-width: 800px; margin: 0 auto; padding: 2rem; }
        .tech-news-article { background: white; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); padding: 2rem; margin: 2rem 0; }
        .source-info { display: flex; align-items: center; gap: 0.75rem; margin-bottom: 1rem; flex-wrap: wrap; }
        .source-emoji { font-size: 1.5rem; }
        .source-name { font-weight: 600; color: #374151; }
        .importance-indicator { display: flex; gap: 2px; margin-left: auto; }
        .star { color: #fbbf24; font-size: 1.2rem; }
        .star.empty { color: #d1d5db; }
        .article-title { font-size: 2rem; font-weight: 700; line-height: 1.2; margin-bottom: 1rem; color: #111827; }
        .article-meta { display: flex; align-items: center; gap: 1rem; font-size: 0.875rem; color: #6b7280; margin-bottom: 1.5rem; }
        .category { padding: 0.25rem 0.75rem; border-radius: 1rem; font-weight: 500; font-size: 0.75rem; text-transform: uppercase; background: #e5e7eb; color: #374151; }
        .article-image { margin: 1.5rem 0; border-radius: 8px; overflow: hidden; }
        .article-image img { width: 100%; height: auto; display: block; }
        .article-content { font-size: 1.125rem; line-height: 1.7; margin-bottom: 2rem; }
        .article-content h2 { font-size: 1.5rem; margin: 1.5rem 0 1rem; color: #111827; }
        .article-content p { margin-bottom: 1rem; }
        .article-footer { border-top: 1px solid #e5e7eb; padding-top: 1.5rem; }
        .read-more-btn { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.75rem 1.5rem; background: #3b82f6; color: white; text-decoration: none; border-radius: 8px; font-weight: 500; }
        .read-more-btn:hover { background: #2563eb; }
        .original-title { margin-top: 1rem; color: #6b7280; font-size: 0.875rem; }
        .back-link { display: inline-block; margin-bottom: 1rem; color: #3b82f6; text-decoration: none; }
        .back-link:hover { text-decoration: underline; }
        .archive-notice { background: #fef3c7; border: 1px solid #f59e0b; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; font-size: 0.875rem; color: #92400e; }
        @media (max-width: 640px) {
            .container { padding: 1rem; }
            .tech-news-article { padding: 1.5rem; margin: 1rem 0; }
            .article-title { font-size: 1.5rem; }
            .source-info { flex-direction: column; align-items: flex-start; }
            .importance-indicator { margin-left: 0; margin-top: 0.5rem; }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="/tech-news/" class="back-link">&larr; Zpƒõt na Tech News</a>

        <div class="archive-notice">
            Tento ƒçl√°nek je z archivu. Byl publikov√°n 23.10.2025.
        </div>

        <article class="tech-news-article">
            <header>
                <div class="source-info">
                    <span class="source-emoji">üî¨</span>
                    <span class="source-name">Ars Technica</span>
                    <div class="importance-indicator">
                        <span class="star">‚òÖ</span><span class="star">‚òÖ</span><span class="star">‚òÖ</span><span class="star">‚òÖ</span><span class="star empty">‚òÜ</span>
                    </div>
                </div>

                <h1 class="article-title">V√Ωzkumn√≠ci prok√°zali, ≈æe tr√©nink na "nekvalitn√≠ch datech" vede k degradaci jazykov√Ωch model≈Ø</h1>

                <div class="article-meta">
                    <time datetime="2025-10-23T21:20:48+00:00">23.10.2025</time>
                    <span class="category">umƒõl√° inteligence</span>
                </div>
            </header>

            
            <div class="article-image">
                <img src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1908316227-1152x648.jpg" alt="V√Ωzkumn√≠ci prok√°zali, ≈æe tr√©nink na "nekvalitn√≠ch datech" vede k degradaci jazykov√Ωch model≈Ø" loading="lazy">
            </div>
        

            <div class="article-content">
                <h2>Souhrn</h2>
<p>V√Ωzkumn√≠ci z Texas A&amp;M, University of Texas a Purdue University publikovali studii, kter√° kvantifikuje dopady tr√©ninku velk√Ωch jazykov√Ωch model≈Ø na nekvalitn√≠ch datech. Jejich v√Ωzkum ukazuje, ≈æe kontinu√°ln√≠ tr√©nink na &ldquo;junk&rdquo; obsahu z webu vede k trval√©mu poklesu v√Ωkonu model≈Ø, co≈æ auto≈ôi p≈ôirovn√°vaj√≠ k lidsk√©mu &ldquo;brain rot&rdquo; - degradaci kognitivn√≠ch schopnost√≠ zp≈Øsoben√© konzumac√≠ trivi√°ln√≠ho online obsahu.</p>
<h2>Kl√≠ƒçov√© body</h2>
<ul>
<li>V√Ωzkumn√≠ci definovali &ldquo;LLM brain rot hypot√©zu&rdquo; - kontinu√°ln√≠ p≈ôedtr√©nink na nekvalitn√≠ch webov√Ωch textech zp≈Øsobuje trval√Ω kognitivn√≠ √∫padek jazykov√Ωch model≈Ø</li>
<li>Pro testov√°n√≠ pou≈æili dataset 100 milion≈Ø tweet≈Ø z HuggingFace, kter√© rozdƒõlili na &ldquo;junk&rdquo; a kontroln√≠ skupinu</li>
<li>Jako &ldquo;junk&rdquo; data identifikovali tweety s vysokou m√≠rou engagement (lajky, retweety), ale kr√°tkou d√©lkou a povrchn√≠m obsahem</li>
<li>Druh√° metrika hodnocen√≠ vyu≈æ√≠vala GPT-4o k identifikaci tweet≈Ø se &ldquo;s√©mantickou nekvalitou&rdquo; - konspiraƒçn√≠ teorie, p≈ôehnan√© tvrzen√≠, nepodlo≈æen√° prohl√°≈°en√≠</li>
<li>Modely tr√©novan√© na tƒõchto datech vykazovaly hor≈°√≠ v√Ωsledky v benchmarkov√Ωch testech</li>
</ul>
<h2>Podrobnosti</h2>
<p>V√Ωzkum vych√°z√≠ z existuj√≠c√≠ch studi√≠ o dopadu nekvalitn√≠ho online obsahu na lidsk√Ω mozek. Podobnƒõ jako lid√©, kte≈ô√≠ konzumuj√≠ velk√© objemy trivi√°ln√≠ho a intelektu√°lnƒõ nen√°roƒçn√©ho obsahu, mohou trpƒõt probl√©my s pozornost√≠, pamƒõt√≠ a soci√°ln√≠m pozn√°v√°n√≠m, i jazykov√© modely vykazuj√≠ podobn√© symptomy degradace p≈ôi tr√©ninku na obdobn√Ωch datech.</p>
<p>Kl√≠ƒçovou v√Ωzvou v√Ωzkumu bylo objektivn√≠ definov√°n√≠ toho, co p≈ôedstavuje &ldquo;nekvalitn√≠&rdquo; obsah. V√Ωzkumn√≠ci zvolili dva p≈ô√≠stupy. Prvn√≠ vych√°zel z p≈ôedpokladu, ≈æe &ldquo;brain rot&rdquo; u lid√≠ je d≈Øsledkem internetov√© z√°vislosti, proto jako junk data oznaƒçili tweety maximalizuj√≠c√≠ engagement trivi√°ln√≠m zp≈Øsobem - konkr√©tnƒõ popul√°rn√≠ tweety s vysok√Ωm poƒçtem interakc√≠, ale kr√°tkou d√©lkou. Hypot√©za byla, ≈æe popul√°rnƒõj≈°√≠, ale krat≈°√≠ tweety bud—É—Ç pova≈æov√°ny za nekvalitn√≠ data.</p>
<p>Druh√Ω p≈ô√≠stup vyu≈æ√≠val marketingov√Ω v√Ωzkum k definici &ldquo;s√©mantick√© kvality&rdquo; samotn√Ωch tweet≈Ø. Pomoc√≠ komplexn√≠ho promptu pro GPT-4o v√Ωzkumn√≠ci identifikovali tweety zamƒõ≈ôen√© na povrchn√≠ t√©mata jako konspiraƒçn√≠ teorie, p≈ôehnan√© n√°roky, nepodlo≈æen√° tvrzen√≠ nebo povrchn√≠ lifestyle obsah.</p>
<p>V√Ωsledky studie maj√≠ z√°sadn√≠ dopady na souƒçasn√Ω v√Ωvoj AI, kdy se firmy pot√Ωkaj√≠ s nedostatkem kvalitn√≠ch tr√©novac√≠ch dat a ƒçasto sahaj√≠ k syntetick√Ωm dat≈Øm nebo m√©nƒõ kvalitn√≠m zdroj≈Øm.</p>
<h2>Proƒç je to d≈Øle≈æit√©</h2>
<p>Tato studie p≈ôich√°z√≠ v kritick√©m okam≈æiku pro v√Ωvoj velk√Ωch jazykov√Ωch model≈Ø. S vyƒçerp√°v√°n√≠m kvalitn√≠ch ve≈ôejnƒõ dostupn√Ωch dat se firmy st√°le ƒçastƒõji obracej√≠ k alternativn√≠m zdroj≈Øm, vƒçetnƒõ soci√°ln√≠ch s√≠t√≠ a synteticky generovan√©ho obsahu. V√Ωzkum poskytuje prvn√≠ kvantitativn√≠ d≈Økazy o tom, jak z√°sadn√≠ dopad m√° kvalita tr√©novac√≠ch dat na dlouhodob√Ω v√Ωkon model≈Ø.</p>
<p>Pro pr≈Ømysl to znamen√° nutnost p≈ôehodnotit strategie z√≠sk√°v√°n√≠ tr√©novac√≠ch dat. Zat√≠mco dosud p≈ôevl√°dal p≈ô√≠stup &ldquo;ƒç√≠m v√≠ce dat, t√≠m l√©pe&rdquo;, tento v√Ωzkum ukazuje, ≈æe nekvalitn√≠ data mohou zp≈Øsobit trval√© po≈°kozen√≠ model≈Ø. To m√° d≈Øsledky pro cel√Ω ekosyst√©m AI - od v√Ωvoj√°≈ô≈Ø model≈Ø p≈ôes poskytovatele datov√Ωch sad a≈æ po koncov√© u≈æivatele, kte≈ô√≠ spol√©haj√≠ na v√Ωkon tƒõchto syst√©m≈Ø.</p>
<p>V√Ωzkum tak√© otev√≠r√° ot√°zky o budoucnosti webov√©ho obsahu. S rostouc√≠m mno≈æstv√≠m AI-generovan√©ho textu na internetu hroz√≠ riziko zpƒõtn√© vazby, kdy modely budou tr√©nov√°ny na obsahu vytvo≈ôen√©m p≈ôedchoz√≠mi generacemi AI, co≈æ m≈Ø≈æe v√©st k dal≈°√≠ degradaci kvality.</p>
<hr />
<p><a href="https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/">ƒå√≠st p≈Øvodn√≠ ƒçl√°nek</a></p>
<p><strong>Zdroj:</strong> üî¨ Ars Technica</p>
            </div>

            <footer class="article-footer">
                <a href="https://arstechnica.com/ai/2025/10/researchers-show-that-training-on-junk-data-can-lead-to-llm-brain-rot/" target="_blank" rel="noopener" class="read-more-btn">
                    ƒå√≠st p≈Øvodn√≠ ƒçl√°nek &rarr;
                </a>

                <div class="original-title"><small>P≈Øvodn√≠ n√°zev: Researchers show that training on ‚Äújunk data‚Äù can lead to LLM ‚Äúbrain rot‚Äù - Ars Technica</small></div>
            </footer>
        </article>

        <p style="text-align: center; color: #6b7280; font-size: 0.875rem; margin-top: 2rem;">
            &copy; 2025 <a href="https://www.marigold.cz" style="color: #3b82f6;">Marigold.cz</a>
        </p>
    </div>
</body>
</html>
