<!DOCTYPE html>
<html lang="cs">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>â€KÅ™estnÃ­ otec AIâ€œ je â€velmi smutnÃ½â€œ z toho, ÄÃ­m se stalo jeho celoÅ¾ivotnÃ­ dÃ­lo | Marigold.cz Tech News</title>
    <meta name="description" content="Geoffrey Hinton vyjÃ¡dÅ™il znepokojenÃ­, Å¾e umÄ›lÃ¡ inteligence, kterou pomohl vyvinout, pÅ™edstavuje rizika, kterÃ¡ nejsou dostateÄnÄ› brÃ¡na vÃ¡Å¾nÄ›.">
    <link rel="canonical" href="https://www.marigold.cz/tech-news/2026-01-21/the-godfather-of-ai-says-hes-very-sad-about-what-h/">
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; line-height: 1.6; color: #374151; background: #f3f4f6; }
        .container { max-width: 800px; margin: 0 auto; padding: 2rem; }
        .tech-news-article { background: white; border-radius: 12px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); padding: 2rem; margin: 2rem 0; }
        .source-info { display: flex; align-items: center; gap: 0.75rem; margin-bottom: 1rem; flex-wrap: wrap; }
        .source-emoji { font-size: 1.5rem; }
        .source-name { font-weight: 600; color: #374151; }
        .importance-indicator { display: flex; gap: 2px; margin-left: auto; }
        .star { color: #fbbf24; font-size: 1.2rem; }
        .star.empty { color: #d1d5db; }
        .article-title { font-size: 2rem; font-weight: 700; line-height: 1.2; margin-bottom: 1rem; color: #111827; }
        .article-meta { display: flex; align-items: center; gap: 1rem; font-size: 0.875rem; color: #6b7280; margin-bottom: 1.5rem; }
        .category { padding: 0.25rem 0.75rem; border-radius: 1rem; font-weight: 500; font-size: 0.75rem; text-transform: uppercase; background: #e5e7eb; color: #374151; }
        .article-image { margin: 1.5rem 0; border-radius: 8px; overflow: hidden; }
        .article-image img { width: 100%; height: auto; display: block; }
        .article-content { font-size: 1.125rem; line-height: 1.7; margin-bottom: 2rem; }
        .article-content h2 { font-size: 1.5rem; margin: 1.5rem 0 1rem; color: #111827; }
        .article-content p { margin-bottom: 1rem; }
        .article-footer { border-top: 1px solid #e5e7eb; padding-top: 1.5rem; }
        .read-more-btn { display: inline-flex; align-items: center; gap: 0.5rem; padding: 0.75rem 1.5rem; background: #3b82f6; color: white; text-decoration: none; border-radius: 8px; font-weight: 500; }
        .read-more-btn:hover { background: #2563eb; }
        .original-title { margin-top: 1rem; color: #6b7280; font-size: 0.875rem; }
        .back-link { display: inline-block; margin-bottom: 1rem; color: #3b82f6; text-decoration: none; }
        .back-link:hover { text-decoration: underline; }
        .archive-notice { background: #fef3c7; border: 1px solid #f59e0b; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; font-size: 0.875rem; color: #92400e; }
        @media (max-width: 640px) {
            .container { padding: 1rem; }
            .tech-news-article { padding: 1.5rem; margin: 1rem 0; }
            .article-title { font-size: 1.5rem; }
            .source-info { flex-direction: column; align-items: flex-start; }
            .importance-indicator { margin-left: 0; margin-top: 0.5rem; }
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="/tech-news/" class="back-link">&larr; ZpÄ›t na Tech News</a>

        <div class="archive-notice">
            Tento ÄlÃ¡nek je z archivu. Byl publikovÃ¡n 21.01.2026.
        </div>

        <article class="tech-news-article">
            <header>
                <div class="source-info">
                    <span class="source-emoji">ğŸ“°</span>
                    <span class="source-name">Business Insider</span>
                    <div class="importance-indicator">
                        <span class="star">â˜…</span><span class="star">â˜…</span><span class="star">â˜…</span><span class="star">â˜…</span><span class="star empty">â˜†</span>
                    </div>
                </div>

                <h1 class="article-title">â€KÅ™estnÃ­ otec AIâ€œ je â€velmi smutnÃ½â€œ z toho, ÄÃ­m se stalo jeho celoÅ¾ivotnÃ­ dÃ­lo</h1>

                <div class="article-meta">
                    <time datetime="2026-01-21T12:00:58+00:00">21.01.2026</time>
                    <span class="category">umÄ›lÃ¡ inteligence</span>
                </div>
            </header>

            
            <div class="article-image">
                <img src="https://i.insider.com/69709f50e1ba468a96aa669b?width=1200&format=jpeg" alt="â€KÅ™estnÃ­ otec AIâ€œ je â€velmi smutnÃ½â€œ z toho, ÄÃ­m se stalo jeho celoÅ¾ivotnÃ­ dÃ­lo" loading="lazy">
            </div>
        

            <div class="article-content">
                <h2>Souhrn</h2>
<p>Geoffrey Hinton, pÅ™ezdÃ­vanÃ½ kÅ™estnÃ­ otec umÄ›lÃ© inteligence dÃ­ky svÃ½m prÅ¯kopnickÃ½m pracÃ­m na neuronovÃ½ch sÃ­tÃ­ch, v rozhovoru pro Business Insider prohlÃ¡sil, Å¾e je velmi smutnÃ½ z vÃ½voje AI, kterou sÃ¡m pomohl vytvoÅ™it. ObÃ¡vÃ¡ se, Å¾e rychlÃ½ pokrok v tÃ©to technologii pÅ™inÃ¡Å¡Ã­ existenciÃ¡lnÃ­ rizika pro lidstvo, jako je pÅ™ekroÄenÃ­ lidskÃ© inteligence superinteligentnÃ­mi systÃ©my, ale spoleÄnost a firmy tyto hrozby podceÅˆujÃ­. Hinton, nositel Nobelovy ceny za fyziku z roku 2024 za objevy v oblasti umÄ›lÃ½ch neuronovÃ½ch sÃ­tÃ­, volÃ¡ po vÄ›tÅ¡Ã­ regulaci vÃ½voje AI.</p>
<h2>KlÃ­ÄovÃ© body</h2>
<ul>
<li>Hinton rezignoval na svou pozici v Google v kvÄ›tnu 2023, aby mohl otevÅ™enÄ› mluvit o rizicÃ­ch AI bez omezenÃ­ firemnÃ­ politiky.</li>
<li>Odhaduje pravdÄ›podobnost, Å¾e pokroÄilÃ¡ AI zniÄÃ­ lidstvo, na 10 aÅ¾ 20 procent, a varuje pÅ™ed zneuÅ¾itÃ­m pro Å¡Ã­Å™enÃ­ dezinformacÃ­ nebo vÃ½voj biologickÃ½ch zbranÃ­.</li>
<li>DoporuÄuje pauzu v trÃ©ninku velkÃ½ch modelÅ¯ AI delÅ¡Ã­ neÅ¾ Å¡est mÄ›sÃ­cÅ¯ a regulaci podobnou jadernÃ© energii.</li>
<li>AI systÃ©my jako velkÃ© jazykovÃ© modely (LLM) se rychle zlepÅ¡ujÃ­ v podvÃ¡dÄ›nÃ­ a manipulaci, coÅ¾ zvyÅ¡uje rizika.</li>
<li>VlÃ¡dy podle nÄ›j nereagujÃ­ dostateÄnÄ› rychle, zatÃ­mco firmy jako OpenAI a Google urychlujÃ­ vÃ½voj.</li>
</ul>
<h2>Podrobnosti</h2>
<p>Geoffrey Hinton, britsko-kanadskÃ½ informatyk, je jednÃ­m z klÃ­ÄovÃ½ch tvÅ¯rcÅ¯ modernÃ­ umÄ›lÃ© inteligence. V 80. letech minulÃ©ho stoletÃ­ vyvinul algoritmus backpropagation, kterÃ½ umoÅ¾Åˆuje efektivnÃ­ trÃ©nink vÃ­cevrstvÃ½ch neuronovÃ½ch sÃ­tÃ­, a podÃ­lel se na convolutional neural networks (CNN), pouÅ¾Ã­vanÃ½ch pro rozpoznÃ¡vÃ¡nÃ­ obrazÅ¯. Tyto technologie byly dlouho ignorovÃ¡ny, dokud v roce 2012 tÃ½m pod jeho vedenÃ­m vyhrÃ¡l ImageNet soutÄ›Å¾ s modelem AlexNet, coÅ¾ spustilo Ã©ru deep learningu. Od tÃ© doby se stal viceprezidentem Google Brain, kde pomÃ¡hal budovat systÃ©my pro zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka a vize.</p>
<p>V nedÃ¡vnÃ©m rozhovoru pro Business Insider Hinton popsal svÅ¯j smutek z toho, jak se jeho vÃ½zkum zmÄ›nil v nÃ¡stroje s potenciÃ¡lem pro zlo. KonkrÃ©tnÄ› zmÃ­nil, Å¾e souÄasnÃ© LLM jako GPT-4 nebo Gemini dokÃ¡Å¾ou generovat pÅ™esvÄ›dÄivÃ© lÅ¾i a deepfakes, coÅ¾ usnadÅˆuje Å¡Ã­Å™enÃ­ dezinformacÃ­ bÄ›hem voleb nebo konfliktÅ¯. DÃ¡le varoval pÅ™ed schopnostÃ­ AI hackovat poÄÃ­taÄovÃ© systÃ©my, navrhovat chemickÃ© zbranÄ› nebo biologickÃ© patogeny, kterÃ© by mohly bÃ½t levnÄ›jÅ¡Ã­ neÅ¾ stÃ¡vajÃ­cÃ­ metody vÃ½voje zbranÃ­. Podle nÄ›j AI brzy pÅ™ekonÃ¡ lidskou inteligenci vÄ›tÅ¡iny ÃºkolÅ¯ a mÅ¯Å¾e se stÃ¡t autonomnÃ­, s cÃ­li nesluÄitelnÃ½mi s lidskÃ½mi zÃ¡jmy.</p>
<p>Hinton kritizoval firmy jako OpenAI, kterÃ© pÅ™eruÅ¡ily dobrovolnou pauzu v trÃ©ninku modelÅ¯ v bÅ™eznu 2023, navzdory varovÃ¡nÃ­m stovek expertÅ¯ v otevÅ™enÃ©m dopise. Rezignace z Google mu umoÅ¾nila volnÄ› diskutovat tyto tÃ©mata; dÅ™Ã­ve byl vÃ¡zÃ¡n nekonkurenÄnÃ­mi smlouvami. V kontextu souÄasnÃ©ho vÃ½voje, kdy modely jako Llama od Meta nebo Claude od Anthropic dosahujÃ­ ÃºrovnÄ› lidskÃ© expertizy v programovÃ¡nÃ­ a medicÃ­nÄ›, jeho slova podtrhujÃ­ nutnost bezpeÄnostnÃ­ch opatÅ™enÃ­, jako je alignment â€“ zajiÅ¡tÄ›nÃ­, aby AI sledujely lidskÃ© hodnoty. NicmÃ©nÄ› Hinton pÅ™iznÃ¡vÃ¡, Å¾e alignment je technicky obtÃ­Å¾nÃ©, protoÅ¾e modely se uÄÃ­ na datech plnÃ½ch lidskÃ½ch chyb a biasÅ¯.</p>
<h2>ProÄ je to dÅ¯leÅ¾itÃ©</h2>
<p>ProhlÃ¡Å¡enÃ­ Hintona mÃ¡ vÃ½jimeÄnou vÃ¡hu, protoÅ¾e pochÃ¡zÃ­ od ÄlovÄ›ka, kterÃ½ poloÅ¾il zÃ¡klady souÄasnÃ© AI. V Å¡irÅ¡Ã­m ekosystÃ©mu urychluje debatu o regulaci: EvropskÃ¡ unie pÅ™ijÃ­mÃ¡ AI Act, kterÃ½ klasifikuje systÃ©my podle rizik, zatÃ­mco USA a ÄŒÃ­na zÅ¯stÃ¡vajÃ­ opatrnÃ© kvÅ¯li soutÄ›Å¾i. Pro uÅ¾ivatele to znamenÃ¡ vÄ›tÅ¡Ã­ opatrnost pÅ™i spolÃ©hÃ¡nÃ­ na AI nÃ¡stroje pro kritickÃ© rozhodnutÃ­, jako je diagnÃ³za nemocÃ­ nebo finanÄnÃ­ poradenstvÃ­. PrÅ¯mysl ÄelÃ­ tlaku na investice do bezpeÄnosti â€“ napÅ™Ã­klad OpenAI zaloÅ¾ila bezpeÄnostnÃ­ tÃ½m, ale mnozÃ­ analytici pochybujÃ­ o jeho efektivitÄ› kvÅ¯li rychlosti vÃ½voje. Pokud se rizika neÅ™eÅ¡Ã­, mÅ¯Å¾e to vÃ©st k incidentÅ¯m, kterÃ© zpÅ¯sobÃ­ veÅ™ejnÃ© backlashi a zpomalÃ­ inovace. Hintonovo varovÃ¡nÃ­ tak pÅ™ipomÃ­nÃ¡, Å¾e AI nenÃ­ jen nÃ¡stroj efektivity, ale potenciÃ¡lnÃ­ hrozba, vyÅ¾adujÃ­cÃ­ globÃ¡lnÃ­ koordinaci podobnou klimatickÃ½m dohodÃ¡m.</p>
<hr />
<p><a href="https://www.businessinsider.com/godfather-ai-geoffrey-hinton-on-ai-sad-dangerous-2026-1">ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek</a></p>
<p><strong>Zdroj:</strong> ğŸ“° Business Insider</p>
            </div>

            <footer class="article-footer">
                <a href="https://www.businessinsider.com/godfather-ai-geoffrey-hinton-on-ai-sad-dangerous-2026-1" target="_blank" rel="noopener" class="read-more-btn">
                    ÄŒÃ­st pÅ¯vodnÃ­ ÄlÃ¡nek &rarr;
                </a>

                <div class="original-title"><small>PÅ¯vodnÃ­ nÃ¡zev: The 'Godfather of AI' says he's 'very sad' about what his life's work has become</small></div>
            </footer>
        </article>

        <p style="text-align: center; color: #6b7280; font-size: 0.875rem; margin-top: 2rem;">
            &copy; 2026 <a href="https://www.marigold.cz" style="color: #3b82f6;">Marigold.cz</a>
        </p>
    </div>
</body>
</html>
