---
author: Patrick Zandl
post_excerpt: NovÃ¡ verze open source AI LLM Llama 4 mÃ¡ vÃ¡lcovat konkurenty jak cenou, tak vÃ½konem a pÅ™edevÅ¡Ã­m neskuteÄnÃ½m kontextovÃ½m oknem 10 milionÅ¯ tokenÅ¯. Meta se tak rÃ¡zem posouvÃ¡ na Å¡pici peletonu. 
audiooff: true
categories:
- AI
- Meta
- Llama
date: 2025-04-05
layout: post
title: "Meta pÅ™edstavuje Llama 4 - open source LLM s obrovskÃ½m kontextem i vÃ½konem"
thumbnail: https://www.marigold.cz/assets/llama4.jpeg
---

Meta prÃ¡vÄ› vydala novou verzi svÃ©ho open source LLM, kterÃ½ se jmenuje Llama 4. Ve skuteÄnosti jde o tÅ™i novÃ© modely: Llama 4 Scout, Llama 4 Maverick a Llama 4 Behemoth, kterÃ© se liÅ¡Ã­ poÄtem aktivnÃ­ch parametrÅ¯ a schopnostmi - a samozÅ™ejmÄ› takÃ© poÅ¾adovanou hardware vÃ½bavou. A to je to dÅ¯leÅ¾itÃ©: novÃ¡ Llama 4 umÃ­ bÄ›Å¾et na pomÄ›rnÄ› pÅ™Ã­znivÃ© sestavÄ› hardware, pÅ™itom nabÃ­zÃ­ skvÄ›lÃ½ vÃ½kon a open source prostÅ™edÃ­. A co je naprosto famÃ³znÃ­, je kontextovÃ© okno na 10 milionÅ¯ tokenÅ¯, coÅ¾ je 10x vÃ­ce neÅ¾ dnes nabÃ­zÃ­ nejpokroÄilejÅ¡Ã­ LLM Google Gemini. JistÄ›, rozsah kontextu se projevuje na vÃ½konu, proto bude zajÃ­mavÃ© sledovat, jak se to projevÃ­ v praxi, prÃ¡vÄ› pÅ™i pouÅ¾itÃ­ velkÃ©ho kontextu, kterÃ½ je dnes dÅ¯leÅ¾itÃ½ napÅ™Ã­klad pÅ™i programovÃ¡nÃ­. K dlouhÃ©mu kontextu si povÃ­me detailnÃ­ vysvÄ›tlenÃ­ na zÃ¡vÄ›r. 


ğŸ“Š **TÅ™i novÃ© modely:**
â€¢ **Llama 4 Scout:** 17B aktivnÃ­ch parametrÅ¯ s 16 experty, dokÃ¡Å¾e bÄ›Å¾et na jedinÃ© H100 GPU
â€¢ **Llama 4 Maverick:** 17B aktivnÃ­ch parametrÅ¯ se 128 experty, vÃ½jimeÄnÃ¡ multimodÃ¡lnÃ­ schopnost
â€¢ **Llama 4 Behemoth:** 288B aktivnÃ­ch parametrÅ¯, stÃ¡le ve vÃ½voji, jiÅ¾ nynÃ­ pÅ™edÄÃ­ GPT-4.5, Claude Sonnet 3.7 a Gemini 2.0 Pro v STEM benchmarcÃ­ch

ğŸ’¡ **KlÃ­ÄovÃ© technologickÃ© prÅ¯lomy:**
â€¢ PrvnÃ­ nativnÄ› multimodÃ¡lnÃ­ modely Mety vyuÅ¾Ã­vajÃ­cÃ­ architekturu mixture-of-experts (MoE)
â€¢ PrÅ¯lomovÃ© kontextovÃ© okno 10M tokenÅ¯ u Llama 4 Scout (10x vÃ­ce neÅ¾ nabÃ­zÃ­ Google)
â€¢ TrÃ©nink na vÃ­ce neÅ¾ 30 bilionech tokenÅ¯ (dvojnÃ¡sobek oproti Llama 3)
â€¢ Podpora pro 200 jazykÅ¯ s 10x vÃ­ce multilingvÃ¡lnÃ­mi tokeny neÅ¾ pÅ™edchozÃ­ verze
â€¢ ZpracovÃ¡nÃ­ rÅ¯znorodÃ½ch dat vÄetnÄ› textu, obrazu a videa

âš–ï¸ **VÃ½raznÃ© zlepÅ¡enÃ­ v oblasti vyvÃ¡Å¾enÃ­ a bezpeÄnosti:**
â€¢ SnÃ­Å¾enÃ­ mÃ­ry odmÃ­tnutÃ­ odpovÄ›dÃ­ na kontroverznÃ­ tÃ©mata ze 7% na mÃ©nÄ› neÅ¾ 2%
â€¢ DosaÅ¾enÃ­ politickÃ© vyvÃ¡Å¾enosti srovnatelnÃ© s modelem Grok, s vÃ½raznÄ› menÅ¡Ã­m poÄtem nevyvÃ¡Å¾enÃ½ch odpovÄ›dÃ­
â€¢ Open-source bezpeÄnostnÃ­ nÃ¡stroje vÄetnÄ› Llama Guard, Prompt Guard a CyberSecEval
â€¢ VÃ½vojÃ¡Å™i mohou integrovat ochrannÃ© prvky proti potenciÃ¡lnÄ› Å¡kodlivÃ½m vstupÅ¯m a vÃ½stupÅ¯m

ğŸ”¥ **VÃ½konnostnÃ­ pÅ™ednosti:**
â€¢ Llama 4 Scout pÅ™ekonÃ¡vÃ¡ Gemma 3, Gemini 2.0 Flash-Lite a Mistral 3.1
â€¢ Llama 4 Maverick pÅ™edÄÃ­ GPT-4o a Gemini 2.0 Flash v Å™adÄ› benchmarkÅ¯
â€¢ SrovnatelnÃ© vÃ½sledky s [DeepSeek](/item/deepseek/) v3 v oblasti uvaÅ¾ovÃ¡nÃ­ a kÃ³dovÃ¡nÃ­ - s polovinou aktivnÃ­ch parametrÅ¯
â€¢ BezkonkurenÄnÃ­ pomÄ›r vÃ½konu a nÃ¡kladÅ¯, chatovacÃ­ verze skÃ³ruje 1417 ELO na LMArena

![Llama 4 a vÃ½konnostnÃ­ benchmarky](https://www.marigold.cz/assets/llama4-vykon.png)

VÃ½bornÃ© jsou takÃ© cenovÃ© parametry pro pÅ™Ã­pad, Å¾e chcete pouÅ¾Ã­t Llama 4 pÅ™es API a nechcete ji instalovat na vlastnÃ­ servery:

![CenovÃ© parametry Llama 4](https://www.marigold.cz/assets/llama4-ceny-parametry.jpg)

MusÃ­m Å™Ã­ct, Å¾e je to velmi pÅ™Ã­jemnÃ© pÅ™ekvapenÃ­. I kdyÅ¾ jsou to zatÃ­m jen papÃ­rovÃ¡ data a osobnÃ­ zkuÅ¡enost chybÃ­, vypadÃ¡ to velmi slibnÄ› a Meta jistÄ› nebude slibovat nÄ›co, co alespoÅˆ pÅ™ibliÅ¾nÄ› nenÃ­ pravda. Na vÄ›tÅ¡Ã­ testovÃ¡nÃ­ si musÃ­m poÄkat na zaÄÃ¡tek tÃ½dne, aÅ¾ si trochu uvolnÃ­m mÃ­sto na serverech :)

VÃ­ce informacÃ­ o modelech Llama 4 vÄetnÄ› detailÅ¯ o trÃ©ninku a benchmarcÃ­ch: [https://go.fb.me/gmjohs](https://go.fb.me/gmjohs).

â¬‡ï¸ [StÃ¡hnout Llama 4 mÅ¯Å¾ete zde](https://go.fb.me/bwwhe9).

## Architektura iRoPE Äili jak se Meta dostala k desetimilionovÃ©mu kontextu. 

Deset milionÅ¯ tokenÅ¯ nenÃ­ vÅ¯bec maliÄkost, to je mimo jinÃ© tÅ™eba 20 hodin videa, kterÃ© si mÅ¯Å¾e Llama 4 Scout nacpat do pamÄ›ti. Za tÃ­mto prÅ¯lomem stojÃ­ architektura iRoPE. 

Architektura iRoPE, kterou vyvinul tÃ½m Meta pro modely Llama 4, pÅ™edstavuje inovativnÃ­ pÅ™Ã­stup k Å™eÅ¡enÃ­ jednoho z nejvÄ›tÅ¡Ã­ch problÃ©mÅ¯ souÄasnÃ½ch jazykovÃ½ch modelÅ¯ - efektivnÃ­ prÃ¡ce s extrÃ©mnÄ› dlouhÃ½m kontextem. NÃ¡zev iRoPE znamenÃ¡ _"interleaved Rotary Position Embedding"_, tedy proklÃ¡danÃ© rotaÄnÃ­ poziÄnÃ­ kÃ³dovÃ¡nÃ­.

TradiÄnÃ­ transformerovÃ© architektury majÃ­ problÃ©m se zpracovÃ¡nÃ­m velmi dlouhÃ½ch textÅ¯ ze dvou dÅ¯vodÅ¯. Za prvÃ©, standardnÃ­ attention mechanismus mÃ¡ kvadratickou sloÅ¾itost, coÅ¾ znamenÃ¡, Å¾e pamÄ›Å¥ovÃ© a vÃ½poÄetnÃ­ nÃ¡roky dramaticky rostou s dÃ©lkou vstupu. Za druhÃ©, poziÄnÃ­ kÃ³dovÃ¡nÃ­, kterÃ© umoÅ¾Åˆuje modelu rozliÅ¡ovat poÅ™adÃ­ slov, se obtÃ­Å¾nÄ› extrapoluje na dÃ©lky vÃ½raznÄ› pÅ™esahujÃ­cÃ­ trÃ©novacÃ­ data.

Architektura iRoPE elegantnÄ› Å™eÅ¡Ã­ tyto problÃ©my kombinacÃ­ dvou typÅ¯ pozornostnÃ­ch vrstev, kterÃ© se v modelu vzÃ¡jemnÄ› proklÃ¡dajÃ­ (odtud "interleaved" v nÃ¡zvu). 

*PrvnÃ­ typ tvoÅ™Ã­ lokÃ¡lnÃ­ vrstvy*, kterÃ© pouÅ¾Ã­vajÃ­ tradiÄnÃ­ rotaÄnÃ­ poziÄnÃ­ kÃ³dovÃ¡nÃ­ (RoPE). Tyto vrstvy zpracovÃ¡vajÃ­ pouze krÃ¡tkÃ© Ãºseky textu, typicky do 8K tokenÅ¯, a jsou zodpovÄ›dnÃ© za zachycenÃ­ jemnÃ½ch mÃ­stnÃ­ch souvislostÃ­ a jazykovÃ½ch vzorÅ¯. KlÃ­Äovou optimalizacÃ­ je, Å¾e text rozdÄ›lujÃ­ na menÅ¡Ã­ ÄÃ¡sti, kterÃ© zpracovÃ¡vajÃ­ paralelnÄ›, coÅ¾ vÃ½raznÄ› zvyÅ¡uje efektivitu.

*DruhÃ½ typ pÅ™edstavujÃ­ globÃ¡lnÃ­ vrstvy*, kterÃ© na rozdÃ­l od lokÃ¡lnÃ­ch vrstev zpracovÃ¡vajÃ­ celÃ½ dlouhÃ½ kontext bez pouÅ¾itÃ­ poziÄnÃ­ch embedingÅ¯. To je revoluÄnÃ­ myÅ¡lenka - tyto vrstvy se nesnaÅ¾Ã­ rozliÅ¡ovat konkrÃ©tnÃ­ pozice, ale soustÅ™edÃ­ se na sÃ©mantickÃ© vztahy mezi rÅ¯znÃ½mi ÄÃ¡stmi textu. TÃ­m, Å¾e se model nemusÃ­ spolÃ©hat na poziÄnÃ­ informace, dokÃ¡Å¾e lÃ©pe generalizovat na dÃ©lky daleko pÅ™esahujÃ­cÃ­ trÃ©novacÃ­ data.

SÃ­la architektury spoÄÃ­vÃ¡ prÃ¡vÄ› v proklÃ¡dÃ¡nÃ­ tÄ›chto dvou typÅ¯ vrstev. LokÃ¡lnÃ­ vrstvy poskytujÃ­ pÅ™esnÃ© modelovÃ¡nÃ­ blÃ­zkÃ½ch vztahÅ¯, zatÃ­mco globÃ¡lnÃ­ vrstvy umoÅ¾ÅˆujÃ­ modelu "vidÄ›t" a propojovat vzdÃ¡lenÃ© ÄÃ¡sti kontextu. Takto dokÃ¡Å¾e model efektivnÄ› pracovat s kontextem o dÃ©lce 10 milionÅ¯ tokenÅ¯, i kdyÅ¾ byl trÃ©novÃ¡n na mnohem kratÅ¡Ã­ch sekvencÃ­ch (maximÃ¡lnÄ› 256K tokenÅ¯).

DalÅ¡Ã­m dÅ¯leÅ¾itÃ½m aspektem je Å™eÅ¡enÃ­ problÃ©mu "zploÅ¡tÄ›nÃ­" pozornosti. S rostoucÃ­ dÃ©lkou kontextu totiÅ¾ mechanismus pozornosti pÅ™irozenÄ› ztrÃ¡cÃ­ schopnost zamÄ›Å™it se na dÅ¯leÅ¾itÃ© informace - pozornost se "rozptyluje" napÅ™Ã­Ä mnoha tokeny. TÃ½m Meta vyvinul speciÃ¡lnÃ­ techniku teplotnÃ­ho Å¡kÃ¡lovÃ¡nÃ­, kterou aplikujÃ­ pouze bÄ›hem inference a pouze na globÃ¡lnÃ­ vrstvy. Tato technika pomÃ¡hÃ¡ modelu udrÅ¾et "ostrou" pozornost i pÅ™i prÃ¡ci s extrÃ©mnÄ› dlouhÃ½mi kontexty, aniÅ¾ by to negativnÄ› ovlivnilo jeho vÃ½kon na krÃ¡tkÃ½ch textech.

KlÃ­ÄovÃ½m vhledem celÃ©ho pÅ™Ã­stupu je zmÄ›na perspektivy - mÃ­sto snahy trÃ©novat model pÅ™Ã­mo na velmi dlouhÃ½ch sekvencÃ­ch (coÅ¾ by bylo extrÃ©mnÄ› nÃ¡roÄnÃ© na vÃ½poÄetnÃ­ zdroje), tÃ½m Meta pÅ™eformuloval problÃ©m jako dosaÅ¾enÃ­ "nekoneÄnÃ©ho kontextu". To vedlo k nÃ¡vrhu architektury, kterÃ¡ dokÃ¡Å¾e elegantnÄ› extrapolovat z krÃ¡tkÃ½ch trÃ©novacÃ­ch sekvencÃ­ na mnohem delÅ¡Ã­ vstupy pÅ™i reÃ¡lnÃ©m pouÅ¾itÃ­. Tento pÅ™Ã­stup je nejen praktiÄtÄ›jÅ¡Ã­ z hlediska trÃ©ninku, ale takÃ© lÃ©pe Å¡kÃ¡luje smÄ›rem k budoucÃ­m modelÅ¯m s jeÅ¡tÄ› delÅ¡Ã­m kontextem.