---
author: Patrick Zandl
audio: true
categories:
- AI
- Context Engineering
- LLM
- RAG
- Agenti
layout: post
post_excerpt: Context Engineering nahrazuje prompt engineering jako klÃ­Äovou dovednost. V Äem je novÃ½ a proÄ je tak dÅ¯leÅ¾itÃ½ pÅ™edevÅ¡Ã­m v prostÅ™edÃ­ agentÅ¯?
summary_points:
- Context Engineering pÅ™edstavuje evoluci od statickÃ©ho psanÃ­ instrukcÃ­ k dynamickÃ©mu sestavovÃ¡nÃ­ kontextu pro jazykovÃ© modely
- Å est zÃ¡kladnÃ­ch typÅ¯ kontextu zahrnuje instrukce, poÅ¾adavky, znalosti, pamÄ›Å¥, nÃ¡stroje a vÃ½sledky nÃ¡strojÅ¯ podle Hurynova modelu
- KV-cache hit rate je nejkritiÄtÄ›jÅ¡Ã­ metrika pro produkÄnÃ­ agenty s aÅ¾ desetinÃ¡sobnÃ½m rozdÃ­lem v nÃ¡kladech mezi cached a uncached tokeny
- Budoucnost smÄ›Å™uje k autonomnÃ­m systÃ©mÅ¯m schopnÃ½m generovat vlastnÃ­ kontext a sebezdokonalovÃ¡nÃ­
title: "Context Engineering: NovÃ¡ disciplÃ­na pro tvorbu spolehlivÃ½ch AI systÃ©mÅ¯"
thumbnail: https://www.marigold.cz/assets/context-engineering.png
---

Context Engineering pÅ™edstavuje zajÃ­mavÃ½ posun v pÅ™Ã­stupu k tvorbÄ› AI systÃ©mÅ¯ zaloÅ¾enÃ½ch na velkÃ½ch jazykovÃ½ch modelech. ZnÃ­ to velmi technicky, ale rychle zjistÃ­te, Å¾e to je nÄ›co velmi logickÃ©ho a oÄekÃ¡vatelnÃ©ho. NamÃ­sto toho, aby kontextem bylo to, co zadÃ¡te v promptu, se kontextem stÃ¡vÃ¡ vÅ¡echno, co se problÃ©mu mÅ¯Å¾e tÃ½kat. Jak?

ZatÃ­mco tradiÄnÃ­ prompt engineering se zamÄ›Å™uje na psanÃ­ dokonalÃ½ch instrukcÃ­, _Context Engineering_ Å™eÅ¡Ã­ ten samÃ½ problÃ©m komplexnÄ›ji, pomocÃ­ dynamickÃ©ho sestavovÃ¡nÃ­ vÅ¡ech informacÃ­, kterÃ© model potÅ™ebuje (nebo mÅ¯Å¾e potÅ™ebovat) pro ÃºspÄ›Å¡nÃ© splnÄ›nÃ­ Ãºkolu. Podle odbornÃ­kÅ¯ jako je Tobi LÃ¼tke, zakladatel spoleÄnosti Shopify (a velkÃ½ propagÃ¡tor pojmu _Context Engineering_), jde o _"umÄ›nÃ­ poskytnutÃ­ veÅ¡kerÃ©ho kontextu potÅ™ebnÃ©ho k tomu, aby byla Ãºloha pro jazykovÃ½ model vÄ›rohodnÄ› Å™eÅ¡itelnÃ¡"_.

Tato disciplÃ­na nabÃ½vÃ¡ na vÃ½znamu s rozvojem AI agentÅ¯, kde kvalita kontextu Äasto rozhoduje o ÃºspÄ›chu a neÃºspÄ›chu celÃ©ho agentnÃ­ho systÃ©mu. VÄ›tÅ¡ina souÄasnÃ½ch selhÃ¡nÃ­ agentÅ¯ jiÅ¾ nenÃ­ zpÅ¯sobena nedostatky samotnÃ½ch modelÅ¯, ale prÃ¡vÄ› nedokonalÃ½m poskytnutÃ­m souvisejÃ­cÃ­ch informacÃ­, tedy kontextu. TakÅ¾e, kdyÅ¾ se dnes bavÃ­me o _kontextovÃ©m inÅ¾enÃ½rstvÃ­_, bavÃ­me se takÃ© pÅ™edevÅ¡Ã­m o prÃ¡ci s agentnÃ­mi systÃ©my, nikoliv o nÄ›jakÃ©m zadÃ¡vÃ¡nÃ­ jedoduchÃ©ho promptu pÅ™es ChatGPT... 

Abychom si to nÄ›jak pÅ™irovnali: zatÃ­mco _prompt engineering_ si mÅ¯Å¾eme pÅ™edstavit jako ÄerstvÃ©ho absolventa srÅ¡Ã­cÃ­ho nabiflovanÃ½mi znalostmi, kterÃ½ pÅ™ichÃ¡zÃ­ do zabÄ›hlÃ©ho firemnÃ­ho tÃ½mu, _context engineering_ je naopak zkuÅ¡enÃ½m seniornÃ­m ÄlovÄ›kem, kterÃ½ ve firmÄ› strÃ¡vil mnoho let a vÃ­, co kde a jak funguje... 

### Definice kontextu v modernÃ­ch AI systÃ©mech

Kontext v prostÅ™edÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ pÅ™ekraÄuje hranice jednoduchÃ©ho textu, kterÃ½ uÅ¾ivatel zadÃ¡ do modelu. PÅ™edstavuje komplexnÃ­ soubor strukturovanÃ½ch informacÃ­ poskytovanÃ½ch modelu v okamÅ¾iku inference. 

ZatÃ­mco tradiÄnÃ­ prompt engineering pracoval s kontextem jako s jednoduchÃ½m Å™etÄ›zcem, Context Engineering rozklÃ¡dÃ¡ kontext na strukturovanÃ© komponenty:

> kontext = sestavenÃ­(instrukce, znalosti, nÃ¡stroje, pamÄ›Å¥, stav, dotaz)

Tato formalizace umoÅ¾Åˆuje systematickÃ½ pÅ™Ã­stup k optimalizaci jednotlivÃ½ch komponent kontextu namÃ­sto intuitivnÃ­ho ladÄ›nÃ­ textovÃ½ch Å¡ablon.

### Å est zÃ¡kladnÃ­ch typÅ¯ kontextu podle Hurynova modelu

Dnes uvaÅ¾ujeme o Å¡esti zÃ¡kladnÃ­ch typech kontextu, kterÃ© tvoÅ™Ã­ zÃ¡klad kaÅ¾dÃ©ho efektivnÃ­ho AI systÃ©mu. To poskytuje strukturovanÃ½ pÅ™Ã­stup k nÃ¡vrhu kontextu pro rÅ¯znÃ© scÃ©nÃ¡Å™e pouÅ¾itÃ­.

#### Instrukce a systÃ©movÃ© pokyny

**Instrukce** definujÃ­ zÃ¡kladnÃ­ chovÃ¡nÃ­ modelu bÄ›hem konverzace a zahrnujÃ­ nÄ›kolik klÃ­ÄovÃ½ch elementÅ¯: _Definice role_ specifikuje, jak mÃ¡ model vystupovat - napÅ™Ã­klad jako odbornÃ½ asistent, programÃ¡tor nebo analytik. _Motivace a obchodnÃ­ hodnota_ vysvÄ›tluje, proÄ je Ãºkol dÅ¯leÅ¾itÃ½ a jakÃ½ mÃ¡ Å¡irÅ¡Ã­ kontext. _PoÅ¾adovanÃ© vÃ½sledky_ definujÃ­ konkrÃ©tnÃ­ oÄekÃ¡vÃ¡nÃ­ a kritÃ©ria ÃºspÄ›chu.

VÃ½zkum dokumentovanÃ½ v pÅ™Ã­spÄ›vku [Human Delegation Behavior in Human-AI Collaboration: The Effect of Contextual Information](https://arxiv.org/abs/2401.04729) ukazuje, Å¾e poskytnutÃ­ strategickÃ©ho kontextu nad rÃ¡mec pouhÃ© specifikace Ãºkolu vÃ½raznÄ› zlepÅ¡uje autonomii AI systÃ©mÅ¯. Modely s jasnÄ› definovanÃ½m ÃºÄelem a obchodnÃ­m kontextem vykazujÃ­ lepÅ¡Ã­ schopnost rozhodovÃ¡nÃ­ a menÅ¡Ã­ tendenci k odchÃ½lenÃ­ od stanovenÃ©ho cÃ­le.

#### PoÅ¾adavky a implementaÄnÃ­ postupy

DruhÃ¡ kategorie definuje konkrÃ©tnÃ­ **kroky a omezenÃ­** pro vykonÃ¡nÃ­ Ãºkolu. Zahrnuje specifikaci krokÅ¯ uvaÅ¾ovÃ¡nÃ­, postupy Å™eÅ¡enÃ­ a konkrÃ©tnÃ­ akce, kterÃ© mÃ¡ model podniknout. Konvence definujÃ­ styl komunikace, pravidla pro psanÃ­ kÃ³du nebo nÃ¡vrh systÃ©mÅ¯. OmezenÃ­ pokrÃ½vajÃ­ vÃ½konnostnÃ­ poÅ¾adavky, bezpeÄnostnÃ­ aspekty, testovacÃ­ pokrytÃ­ a regulatornÃ­ poÅ¾adavky.

DÅ¯leÅ¾itou souÄÃ¡stÃ­ jsou formÃ¡ty odpovÄ›dÃ­ - zda mÃ¡ model generovat JSON, XML nebo prostÃ½ text. PozitivnÃ­ i negativnÃ­ pÅ™Ã­klady pomÃ¡hajÃ­ modelu pochopit poÅ¾adovanÃ© chovÃ¡nÃ­. NegativnÃ­ pÅ™Ã­klady jsou obzvlÃ¡Å¡Å¥ cennÃ© pro Å™eÅ¡enÃ­ problÃ©mÅ¯ identifikovanÃ½ch bÄ›hem analÃ½zy chyb.

#### ZnalostnÃ­ bÃ¡ze a externÃ­ kontext

Znalosti pÅ™edstavujÃ­ informace, kterÃ© model potÅ™ebuje pro splnÄ›nÃ­ Ãºkolu, ale nejsou souÄÃ¡stÃ­ jeho pÅ™edtrÃ©novanÃ½ch parametrÅ¯. ExternÃ­ kontext zahrnuje domÃ©novÃ© informace jako obchodnÃ­ strategie, trÅ¾nÃ­ data a systÃ©movÃ© informace o celkovÃ½ch cÃ­lech a dalÅ¡Ã­ch agentech nebo sluÅ¾bÃ¡ch.

KontextovÃ© informace o Ãºkolu zahrnujÃ­ workflow procesy, dokumentaci specifikacÃ­, procedury, zÃ¡znamy a strukturovanÃ¡ data ve formÄ› promÄ›nnÃ½ch, tabulek a JSON/XML struktur. ModernÃ­ implementace vyuÅ¾Ã­vajÃ­ pokroÄilÃ© RAG (Retrieval-Augmented Generation) systÃ©my schopnÃ© naÄÃ­tat relevantnÃ­ informace z rozsÃ¡hlÃ½ch znalostnÃ­ch bÃ¡zÃ­ v reÃ¡lnÃ©m Äase.

### PamÄ›Å¥ovÃ© systÃ©my

PamÄ›Å¥ v kontextu AI systÃ©mÅ¯ se dÄ›lÃ­ na krÃ¡tkodobou a dlouhodobou. KrÃ¡tkodobÃ¡ pamÄ›Å¥ zahrnuje pÅ™edchozÃ­ zprÃ¡vy v konverzaci, historii chatu a aktuÃ¡lnÃ­ stav vÄetnÄ› krokÅ¯ uvaÅ¾ovÃ¡nÃ­ a prÅ¯bÄ›hu Å™eÅ¡enÃ­. DlouhodobÃ¡ pamÄ›Å¥ obsahuje sÃ©mantickÃ© informace jako fakta, preference uÅ¾ivatelÅ¯ a domÃ©novÃ© znalosti, episodickÃ© zkuÅ¡enosti z pÅ™edchozÃ­ch interakcÃ­ a procedurÃ¡lnÃ­ instrukce z dÅ™Ã­vÄ›jÅ¡Ã­ch session.

PamÄ›Å¥ nenÃ­ souÄÃ¡stÃ­ promptu, kterÃ½ uÅ¾ivatel mÅ¯Å¾e zadat. MÅ¯Å¾e bÃ½t automaticky pÅ™ipojena orchestraÄnÃ­ vrstvou nebo pÅ™Ã­stupnÃ¡ jako nÃ¡stroj. ProdukÄnÃ­ systÃ©my jako [MemGPT](https://github.com/cpacker/MemGPT) implementujÃ­ sofistikovanÃ© pamÄ›Å¥ovÃ© architektury inspirovanÃ© operaÄnÃ­mi systÃ©my.

### NÃ¡stroje a externÃ­ funkce

NÃ¡stroje umoÅ¾ÅˆujÃ­ modelÅ¯m interakci s externÃ­mi systÃ©my a rozÅ¡iÅ™ujÃ­ jejich schopnosti nad rÃ¡mec generovÃ¡nÃ­ textu. KaÅ¾dÃ½ nÃ¡stroj musÃ­ mÃ­t jasnou dokumentaci popisujÃ­cÃ­ ÃºÄel, zpÅ¯sob pouÅ¾itÃ­, nÃ¡vratovÃ© hodnoty a parametry. Definice nÃ¡strojÅ¯ spotÅ™ebovÃ¡vÃ¡ tokeny v kontextovÃ©m oknÄ› a ovlivÅˆuje vÃ½kon systÃ©mu.

Popisy nÃ¡strojÅ¯ fungujÃ­ jako mikro-prompty, kterÃ© Å™Ã­dÃ­ uvaÅ¾ovÃ¡nÃ­ agentÅ¯. Popisy poskytovanÃ© standardnÃ­mi protokoly jako [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol) jsou Äasto nedostateÄnÃ© a nezohledÅˆujÃ­ specifickÃ½ kontext domÃ©ny. Proto je nutnÃ© pÅ™izpÅ¯sobit dokumentaci nÃ¡strojÅ¯ konkrÃ©tnÃ­m potÅ™ebÃ¡m aplikace.

### VÃ½sledky nÃ¡strojÅ¯ a orchestrace

PoslednÃ­m typem kontextu jsou vÃ½sledky volÃ¡nÃ­ nÃ¡strojÅ¯. Pro vyvolÃ¡nÃ­ funkce pouÅ¾Ã­vÃ¡ model speciÃ¡lnÃ­ formÃ¡t interpretovanÃ½ systÃ©mem. OrchestraÄnÃ­ vrstva nÃ¡slednÄ› pÅ™ipojuje speciÃ¡lnÃ­ zprÃ¡vu se vÃ½sledky do seznamu zprÃ¡v. Tento mechanismus umoÅ¾Åˆuje modelÅ¯m pracovat se skuteÄnÃ½mi daty a vykonÃ¡vat konkrÃ©tnÃ­ akce v reÃ¡lnÃ©m svÄ›tÄ›.

## RozdÃ­l mezi ukÃ¡zkovÃ½mi a produkÄnÃ­mi systÃ©my

Kvalita kontextu pÅ™edstavuje hlavnÃ­ rozdÃ­l mezi jednoduchÃ½mi ukÃ¡zkami a "magickÃ½mi" produkÄnÃ­mi AI agenty. Philip Schmid na svÃ©m blogu demonstruje tento rozdÃ­l na pÅ™Ã­kladu plÃ¡novÃ¡nÃ­ schÅ¯zky na zÃ¡kladÄ› emailu: _"Ahoj, jenom se ptÃ¡m, jestli mÃ¡Å¡ zÃ­tra Äas na rychlou synchronizaci."_

UkÃ¡zkovÃ½ agent s chudÃ½m kontextem vidÃ­ pouze uÅ¾ivatelÅ¯v poÅ¾adavek a nic dalÅ¡Ã­ho. VÃ½stup je sice funkÄnÄ› sprÃ¡vnÃ½, ale neuÅ¾iteÄnÃ½: _"DÄ›kuji za vaÅ¡i zprÃ¡vu. ZÃ­tra mi to vyhovuje. MÅ¯Å¾u se zeptat, na jakou dobu jste myslel?"_

ProdukÄnÃ­ agent s bohatÃ½m kontextem pÅ™ed volÃ¡nÃ­m modelu rozÅ¡iÅ™uje kontext o informace z kalendÃ¡Å™e (kterÃ½ ukazuje plnou obsazenost), historii emailÅ¯ s danou osobou (pro urÄenÃ­ vhodnÃ©ho neformÃ¡lnÃ­ho tÃ³nu), kontaktnÃ­ seznam (pro identifikaci klÃ­ÄovÃ©ho partnera) a nÃ¡stroje pro odesÃ­lÃ¡nÃ­ pozvÃ¡nek. VÃ½sledek je vÃ½raznÄ› kvalitnÄ›jÅ¡Ã­: _"Ahoj Honzo! ZÃ­tra mÃ¡m nabitÃ½ program, celÃ½ den schÅ¯zky za sebou. ÄŒtvrtek dopoledne volno, pokud ti to vyhovuje? Poslal jsem pozvÃ¡nku, dej vÄ›dÄ›t, jestli je to tak OK."_

## Vizualizace kontextovÃ©ho inÅ¾enÃ½rstvÃ­

```mermaid
graph LR
    Root["6 typÅ¯ kontextu<br/>pro AI agenty"] 
    
    Root --- Instructions["ğŸ“‹ Instrukce"]
    Root --- Examples["ğŸ’¡ PÅ™Ã­klady"] 
    Root --- Knowledge["ğŸ“š Znalosti"]
    Root --- Memory["ğŸ§  PamÄ›Å¥"]
    Root --- Tools["ğŸ”§ NÃ¡stroje"]
    Root --- Results["ğŸ VÃ½sledky nÃ¡strojÅ¯"]
    
    Instructions --- Role["Role (Kdo)"]
    Role --- RoleDesc["PovzbuzenÃ­ LLM jednat jako persona<br/>napÅ™. PM, kodÃ©r, trÅ¾nÃ­ analytik"]
    
    Instructions --- Objective["CÃ­l"]
    Objective --- ObjDesc["ProÄ je to dÅ¯leÅ¾itÃ©<br/>(motivace, Å¡irÅ¡Ã­ cÃ­l, obchodnÃ­ hodnota)"]
    Objective --- Strategic["ğŸ’¡ PoskytnutÃ­ strategickÃ©ho kontextu<br/>zlepÅ¡uje AI autonomii<br/>arXiv:2401.04729"]
    
    Instructions --- Requirements["PoÅ¾adavky (Jak)"]
    Requirements --- Steps["Kroky (uvaÅ¾ovÃ¡nÃ­, Ãºkoly, akce)"]
    Requirements --- Conventions["Konvence (styl/tÃ³n, pravidla kÃ³dovÃ¡nÃ­)"]
    Requirements --- Constraints["OmezenÃ­ (vÃ½kon, bezpeÄnost, regulace)"]
    Requirements --- Format["FormÃ¡t odpovÄ›di (JSON, XML, prostÃ½ text)"]
    
    Examples --- BehaviorEx["PÅ™Ã­klady chovÃ¡nÃ­"]
    BehaviorEx --- Positive1["PozitivnÃ­"]
    BehaviorEx --- Negative1["NegativnÃ­"]
    Negative1 --- NegTip["ğŸ’¡ NegativnÃ­ pÅ™Ã­klady pomÃ¡hajÃ­<br/>Å™eÅ¡it problÃ©my z analÃ½zy chyb"]
    
    Examples --- ResponseEx["PÅ™Ã­klady odpovÄ›dÃ­"]
    ResponseEx --- Positive2["PozitivnÃ­"]
    ResponseEx --- Negative2["NegativnÃ­"]
    
    Knowledge --- External["ExternÃ­ kontext"]
    External --- Domain["DomÃ©na (strategie, obchodnÃ­ model, trÅ¾nÃ­ fakta)"]
    External --- System["SystÃ©m (celkovÃ© cÃ­le, ostatnÃ­ agenti/sluÅ¾by)"]
    
    Knowledge --- TaskContext["Kontext Ãºkolu"]
    TaskContext --- Workflow["Workflow (proces, pÅ™edÃ¡vÃ¡nÃ­)"]
    TaskContext --- Documents["Dokumenty (specifikace, procedury, logy)"]
    TaskContext --- StructuredData["StrukturovanÃ¡ data (promÄ›nnÃ©, tabulky, JSON/XML)"]
    
    Memory --- ShortTerm["KrÃ¡tkodobÃ¡ pamÄ›Å¥"]
    ShortTerm --- Messages["PÅ™edchozÃ­ zprÃ¡vy, historie chatu"]
    ShortTerm --- State["Stav (kroky uvaÅ¾ovÃ¡nÃ­, prÅ¯bÄ›h)"]
    ShortTerm --- Session["ğŸ’¡ ÄŒasto existuje v rÃ¡mci session"]
    
    Memory --- LongTerm["DlouhodobÃ¡ pamÄ›Å¥"]
    LongTerm --- Semantic["SÃ©mantickÃ¡ (fakta, preference, znalosti)"]
    LongTerm --- Episodic["EpizodickÃ¡ (zkuÅ¡enosti, interakce)"]
    LongTerm --- Procedural["ProcedurÃ¡lnÃ­ (instrukce z pÅ™edchozÃ­ch session)"]
    LongTerm --- Storage["ğŸ’¡ UloÅ¾eno v databÃ¡zi nebo souborovÃ©m systÃ©mu"]
    LongTerm --- Attached["ğŸ’¡ Automaticky pÅ™ipojeno orchestraÄnÃ­ vrstvou"]
    LongTerm --- Tool["ğŸ’¡ PÅ™Ã­stupnÃ© jako nÃ¡stroj"]
    
    Tools --- Description["Popis"]
    Description --- WhatItDoes["Co to dÄ›lÃ¡"]
    Description --- HowToUse["Jak to pouÅ¾Ã­t"]
    Description --- ReturnValue["NÃ¡vratovÃ¡ hodnota"]
    
    Tools --- Parameters["Parametry"]
    Parameters --- Type["Typ"]
    Parameters --- ParamDesc["Popis"]
    Parameters --- Required["Je vyÅ¾adovÃ¡n"]
    Parameters --- ParamExamples["PÅ™Ã­klady"]
    
    Tools --- ToolTips["ğŸ’¡ SpeciÃ¡lnÃ­ 'functions' blok v LLM kontextu<br/>SpotÅ™ebovÃ¡vÃ¡ vstupnÃ­ tokeny"]
    Tools --- MicroPrompts["ğŸ’¡ Popisy jako mikro-prompty pro uvaÅ¾ovÃ¡nÃ­"]
    Tools --- MCPLimits["ğŸ’¡ MCP servery Äasto nedostateÄnÃ©<br/>neuvaÅ¾ujÃ­ specifickÃ½ kontext domÃ©ny"]
    
    Results --- CallFormat["ğŸ’¡ VolÃ¡nÃ­ funkce speciÃ¡lnÃ­m formÃ¡tem<br/>interpretovanÃ½m systÃ©mem"]
    Results --- Response["ğŸ’¡ OrchestraÄnÃ­ vrstva odpovÃ­dÃ¡<br/>pÅ™ipojenÃ­m zprÃ¡vy do seznamu"]
    
    classDef mainNode fill:#2563eb,stroke:#1e40af,stroke-width:3px,color:#fff
    classDef categoryNode fill:#3b82f6,stroke:#2563eb,stroke-width:2px,color:#fff
    classDef detailNode fill:#e0f2fe,stroke:#0277bd,stroke-width:1px,color:#333
    classDef tipNode fill:#fff3cd,stroke:#ffc107,stroke-width:2px,color:#333
    
    class Root mainNode
    class Instructions,Examples,Knowledge,Memory,Tools,Results categoryNode
    class Role,Objective,Requirements,BehaviorEx,ResponseEx,External,TaskContext,ShortTerm,LongTerm,Description,Parameters detailNode
    class Strategic,NegTip,Session,Storage,Attached,Tool,ToolTips,MicroPrompts,MCPLimits,CallFormat,Response tipNode
```


### TechnickÃ© implementace a architektury

#### RAG systÃ©my a naÄÃ­tÃ¡nÃ­ informacÃ­

RAG (Retrieval-Augmented Generation) pÅ™edstavuje klÃ­Äovou komponentu modernÃ­ch _Context Engineering_ systÃ©mÅ¯. ZÃ¡kladnÃ­ RAG implementace naÄÃ­tajÃ­ relevantnÃ­ dokumenty na zÃ¡kladÄ› podobnosti s dotazem. PokroÄilÃ© systÃ©my vyuÅ¾Ã­vajÃ­ adaptivnÃ­ strategie, kdy se rozhodovÃ¡nÃ­ o naÄÃ­tÃ¡nÃ­ informacÃ­ provÃ¡dÃ­ dynamicky na zÃ¡kladÄ› sloÅ¾itosti dotazu. TÃ­m se systÃ©my vymaÅˆujÃ­ z dÃ©lkovÃ©ho omezenÃ­ kontextu, kterÃ© by jinak bylo potÅ™eba u jednotlivÃ½ch LLM uplatÅˆovat. 

ModulÃ¡rnÃ­ RAG architektury umoÅ¾ÅˆujÃ­ kombinovÃ¡nÃ­ vÃ­ce zdrojÅ¯ informacÃ­ - strukturovanÃ½ch databÃ¡zÃ­, grafovÃ½ch databÃ¡zÃ­ znalostÃ­ a real-time API. Agentic RAG systÃ©my jdou jeÅ¡tÄ› dÃ¡l a implementujÃ­ sebereflexi, kdy agent vyhodnocuje kvalitu naÄtenÃ½ch informacÃ­ a podle potÅ™eby dohledÃ¡vÃ¡ dalÅ¡Ã­ zdroje.

#### SprÃ¡va pamÄ›ti a persistence kontextu

PersistentnÃ­ pamÄ›Å¥ovÃ© architektury Å™eÅ¡Ã­ problÃ©m udrÅ¾ovÃ¡nÃ­ kontextu napÅ™Ã­Ä dlouhÃ½mi konverzacemi. SystÃ©my jako [Mem0](https://github.com/mem0ai/mem0) poskytujÃ­ Å¡kÃ¡lovatelnou dlouhodobou pamÄ›Å¥ pro produkÄnÃ­ AI agenty. EpizodickÃ¡ pamÄ›Å¥ uklÃ¡dÃ¡ konkrÃ©tnÃ­ interakce a zkuÅ¡enosti, zatÃ­mco sÃ©mantickÃ¡ pamÄ›Å¥ obsahuje fakta a obecnÃ© znalosti.

KontinuÃ¡lnÃ­ uÄenÃ­ umoÅ¾Åˆuje systÃ©mÅ¯m aktualizovat svÃ© znalosti na zÃ¡kladÄ› novÃ½ch informacÃ­ bez nutnosti pÅ™etrÃ©novÃ¡nÃ­. Konsolidace pamÄ›ti optimalizuje uklÃ¡dÃ¡nÃ­ dÅ¯leÅ¾itÃ½ch informacÃ­ a odstraÅˆuje redundantnÃ­ nebo zastaralÃ© Ãºdaje.

#### Orchestrace vÃ­ce agentÅ¯

KomunikaÄnÃ­ protokoly mezi agenty vyuÅ¾Ã­vajÃ­ strukturovanÃ© formÃ¡ty pro vÃ½mÄ›nu informacÃ­ a koordinaci akcÃ­. Model Context Protocol (MCP) definuje standardnÃ­ zpÅ¯sob sdÃ­lenÃ­ kontextu mezi rÅ¯znÃ½mi AI systÃ©my. Agent-to-Agent Protocol (A2A)specifikuje mechanismy pro pÅ™Ã­mou komunikaci a spoluprÃ¡ci.

DistribuovanÃ© systÃ©my agentÅ¯ Å™eÅ¡Ã­ sloÅ¾itÃ© Ãºlohy rozdÄ›lenÃ­m prÃ¡ce mezi specializovanÃ© komponenty. KaÅ¾dÃ½ agent mÃ¡ svou oblast expertÃ­zy a kontext optimalizovanÃ½ pro specifickÃ© Ãºkoly. KoordinaÄnÃ­ mechanismy zajiÅ¡Å¥ujÃ­ koherenci a vyhÃ½bÃ¡nÃ­ se konfliktÅ¯m.

### PraktickÃ© poznatky z produkÄnÃ­ho nasazenÃ­

SÃ¡m Å¾Ã¡dnÃ© podstatnÃ© zkuÅ¡enosti v tomto ohledu zatÃ­m nemÃ¡m, takÅ¾e jsem se podÃ­val jinam a naÅ¡el pÃ¡r zajÃ­mavÃ½ch poznÃ¡mek. 

ZkuÅ¡enosti tÃ½mu Manus AI, vedenÃ½ Yichaem 'Peak' Ji, pÅ™inÃ¡Å¡ejÃ­ zajÃ­mavÃ© poznatky z reÃ¡lnÃ©ho nasazenÃ­ Context Engineering v produkÄnÃ­m prostÅ™edÃ­. Podle Ji: _"Context engineering se ukÃ¡zal bÃ½t experimentÃ¡lnÃ­ vÄ›dou - nÃ¡Å¡ agentnÃ­ framework jsme pÅ™estavÄ›li ÄtyÅ™ikrÃ¡t, pokaÅ¾dÃ© po objevenÃ­ lepÅ¡Ã­ho zpÅ¯sobu tvarovÃ¡nÃ­ kontextu."_

#### Optimalizace KV-cache jako klÃ­ÄovÃ¡ metrika

KV-cache hit rate pÅ™edstavuje nejkritiÄtÄ›jÅ¡Ã­ metriku pro produkÄnÃ­ AI agenty. Ji zdÅ¯razÅˆuje: _"Pokud bych si mÄ›l vybrat jen jednu metriku, tvrdil bych, Å¾e KV-cache hit rate je nejdÅ¯leÅ¾itÄ›jÅ¡Ã­ metrika pro produkÄnÃ­ho AI agenta. PÅ™Ã­mo ovlivÅˆuje latenci i nÃ¡klady."_

> **KV-cache hit rate** je metrika udÃ¡vajÃ­cÃ­, kolik procent tokenÅ¯ v kontextu jazykovÃ½ model mÅ¯Å¾e znovu vyuÅ¾Ã­t z jiÅ¾ vypoÄÃ­tanÃ© cache namÃ­sto novÃ©ho vÃ½poÄtu pozornostnÃ­ho mechanismu. KdyÅ¾ model zpracovÃ¡vÃ¡ text, uklÃ¡dÃ¡ si key-value pÃ¡ry pro kaÅ¾dÃ½ token do cache. Pokud pÅ™ijde novÃ½ poÅ¾adavek s identickÃ½m prefixem (zaÄÃ¡tkem kontextu), model mÅ¯Å¾e tyto uloÅ¾enÃ© vÃ½poÄty znovu pouÅ¾Ã­t a pÅ™eskoÄit na prvnÃ­ odliÅ¡nÃ½ token. _Hit rate_ tak udÃ¡vÃ¡ pomÄ›r "recyklovanÃ½ch" tokenÅ¯ k celkovÃ©mu poÄtu tokenÅ¯ v kontextu.
> Pro AI agenty je tato metrika kritickÃ¡, protoÅ¾e jejich kontexty rostou s kaÅ¾dou akcÃ­ a pozorovÃ¡nÃ­m, pÅ™iÄemÅ¾ prefix (systÃ©movÃ½ prompt a poÄÃ¡teÄnÃ­ instrukce) zÅ¯stÃ¡vÃ¡ Äasto identickÃ½. VysokÃ¡ _hit rate_ dramaticky sniÅ¾uje Äas do prvnÃ­ho tokenu (TTFT) a nÃ¡klady, tÅ™eba u Claude Sonnet je rozdÃ­l v cenÄ› keÅ¡ovanÃ½ch a nekeÅ¡ovanÃ½ch tokenÅ¯ desetinÃ¡sobnÃ½.  Proto jsou agenti navrÅ¾eni s append-only kontextem a stabilnÃ­mi prefixy, aby maximalizovali znovuvyuÅ¾itÃ­ cache napÅ™Ã­Ä iteracemi.

KonkrÃ©tnÃ­ ÄÃ­selnÃ© Ãºdaje ukazujÃ­ dramatickÃ© rozdÃ­ly:
- PomÄ›r vstupnÃ­ch a vÃ½stupnÃ­ch tokenÅ¯ u agentÅ¯ dosahuje prÅ¯mÄ›rnÄ› **100:1** (ve srovnÃ¡nÃ­ s chatboty)
- Cached tokeny u Claude Sonnet stojÃ­ **0.30 USD/MTok**, zatÃ­mco uncached **3 USD/MTok** - **desetinÃ¡sobnÃ½ rozdÃ­l**

**PraktickÃ¡ doporuÄenÃ­ pro optimalizaci KV-cache:**

1. **StabilnÃ­ prefix promptu** - vyhÃ½bÃ¡nÃ­ se napÅ™Ã­klad ÄasovÃ½m znaÄkÃ¡m v system promptu, protoÅ¾e i pidi-zmÄ›na mÅ¯Å¾e zneplatit cache od danÃ©ho tokenu dÃ¡l
2. **Append-only kontext** - zabrÃ¡nÄ›nÃ­ ÃºpravÃ¡m pÅ™edchozÃ­ch akcÃ­ a pozorovÃ¡nÃ­, zajiÅ¡tÄ›nÃ­ deterministickÃ© serializace JSON objektÅ¯
3. **ExplicitnÃ­ cache breakpointy** - pro providery nebo frameworky nepodporujÃ­cÃ­ automatickÃ© inkrementÃ¡lnÃ­ prefix caching

### UÄenÃ­ z chyb jako indikÃ¡tor agentickÃ©ho chovÃ¡nÃ­

KlÃ­Äovou praktickou radou je **zachovÃ¡nÃ­ neÃºspÄ›Å¡nÃ½ch akcÃ­ v kontextu**. Ji argumentuje: _"MazÃ¡nÃ­ selhÃ¡nÃ­ odstraÅˆuje dÅ¯kazy. A bez dÅ¯kazÅ¯ se model nemÅ¯Å¾e adaptovat."_

KdyÅ¾ model vidÃ­ neÃºspÄ›Å¡nou akci a vÃ½slednÃ© pozorovÃ¡nÃ­ nebo stack trace, implicitnÄ› aktualizuje svÃ© vnitÅ™nÃ­ pÅ™esvÄ›dÄenÃ­ a sniÅ¾uje pravdÄ›podobnost opakovÃ¡nÃ­ stejnÃ© chyby. Ji povaÅ¾uje **error recovery za jeden z nejjasnÄ›jÅ¡Ã­ch indikÃ¡torÅ¯ skuteÄnÃ©ho agentickÃ©ho chovÃ¡nÃ­**.


## OmezenÃ­ a vÃ½zvy souÄasnÃ½ch systÃ©mÅ¯

OmezenÃ­ kontextovÃ©ho okna pÅ™edstavuje stÃ¡le zÃ¡kladnÃ­ problÃ©m, pÅ™estoÅ¾e se postupnÄ› rozÅ¡iÅ™uje poÄet tokenÅ¯, kterÃ© lze v rÃ¡mci kontextovÃ©ho okna zvlÃ¡dnout. VÃ½poÄetnÃ­ nÃ¡roÄnost zpracovÃ¡nÃ­ rozsÃ¡hlÃ½ch kontextÅ¯ vyÅ¾aduje znaÄnÃ© zdroje. UdrÅ¾ovÃ¡nÃ­ koherence napÅ™Ã­Ä rozÅ¡Ã­Å™enÃ½mi kontexty je i nadÃ¡le technickou vÃ½zvou a je potÅ™eba najÃ­t pÅ™Ã­stupy, kterÃ© technickou nÃ¡roÄnost (a tÃ­m i cenu) tlaÄÃ­ dolÅ¯.

DynamickÃ¡ adaptace kontextu v reÃ¡lnÃ©m Äase pÅ™inÃ¡Å¡Ã­ sloÅ¾itost v podobÄ› latence a synchronizace vÃ­ce zdrojÅ¯ dat. BezpeÄnost a soukromÃ­ citlivÃ½ch informacÃ­ v kontextovÃ½ch pipeline vyÅ¾aduje sofistikovanÃ© Å¡ifrovacÃ­ a kontrolnÃ­ mechanismy.

## BudoucÃ­ smÄ›ry vÃ½voje

NekoneÄnÃ½ kontext pÅ™edstavuje dlouhodobÃ½ cÃ­l pro skuteÄnÄ› neomezenÃ© zpracovÃ¡nÃ­ informacÃ­. Komprese kontextu umoÅ¾Åˆuje efektivnÃ­ reprezentaci rozsÃ¡hlÃ½ch znalostÃ­ v omezenÃ©m prostoru. MultimodÃ¡lnÃ­ integrace spojuje text, obrÃ¡zky, audio a dalÅ¡Ã­ datovÃ© typy do jednotnÃ©ho kontextu.

AdaptivnÃ­ systÃ©my budou schopny samooptimalizace kontextu na zÃ¡kladÄ› zpÄ›tnÃ© vazby a vÃ½sledkÅ¯. AutonomnÃ­ generovÃ¡nÃ­ kontextu umoÅ¾nÃ­ systÃ©mÅ¯m vytvÃ¡Å™et vlastnÃ­ znalostnÃ­ bÃ¡ze a iterativnÄ› je vylepÅ¡ovat.

KognitivnÃ­ architektury inspirovanÃ© lidskÃ½m mozkem implementujÃ­ rozdÄ›lenÃ­ mezi pracovnÃ­ pamÄ›tÃ­, dlouhodobou pamÄ›tÃ­ a pozornostnÃ­mi mechanismy. Tyto systÃ©my jednou budou schopny sofistikovanÃ©ho uvaÅ¾ovÃ¡nÃ­ o tom, kterÃ© informace jsou v danÃ©m okamÅ¾iku nejrelevantnÄ›jÅ¡Ã­. ZatÃ­m tady ale nejsme a je tu celÃ¡ Å™ada vÃ½zev a prostoru pro zlepÅ¡enÃ­. 

Context Engineering nicmÃ©nÄ› zjevnÄ› pÅ™edstavuje klÃ­Äovou disciplÃ­nu pro tvorbu spolehlivÃ½ch AI systÃ©mÅ¯ schopnÃ½ch fungovat v produkÄnÃ­m prostÅ™edÃ­. PÅ™echod od jednoduchÃ©ho prompt engineering k systematickÃ©mu navrhovÃ¡nÃ­ kontextu umoÅ¾Åˆuje vytvÃ¡Å™enÃ­ skuteÄnÄ› uÅ¾iteÄnÃ½ch AI asistentÅ¯ a autonomnÃ­ch agentÅ¯, kterÃ© chÃ¡pou celÃ© tÃ©ma v Å¡irÅ¡Ã­ch souvislostech. 

## Zdroje a dalÅ¡Ã­ informace

- [PaweÅ‚ Huryn's Context Engineering Template](https://github.com/phuryn/examples/tree/main/prompts/context_engineering)
- [Awesome Context Engineering Repository](https://github.com/Meirtz/Awesome-Context-Engineering)
- [The New Skill in AI is Not Prompting, It's Context Engineering](https://www.philschmid.de/context-engineering)
- [Context Engineering for AI Agents: Lessons from Building Manus](https://blog.manus.ai/context-engineering) - Yichao 'Peak' Ji
- [LangChain Blog: The Rise of Context Engineering](https://blog.langchain.com/the-rise-of-context-engineering/)
- [Model Context Protocol Specification](https://github.com/modelcontextprotocol)
