---
audio_url:
author: Patrick Zandl
categories:
- AI
layout: post
post_excerpt: Co znamenÃ¡ AI pro ÄŒesko, jakÃ© jsou jejÃ­ rizika, vÃ½zvy a pÅ™Ã­leÅ¾itosti? Dnes vÃ¡m pÅ™edstavÃ­m oktagon rizik, kterÃ¡ AI pÅ™inÃ¡Å¡Ã­.
thumbnail: https://www.marigold.cz/assets/oktagon-rizik-ai.png
title: ğŸ¯ Oktagon rizik AI -  KÅ™ehkÃ¡ pozornost v kÅ™ehkÃ©m svÄ›tÄ›
---

Pozornost je vÅ¡e, co potÅ™ebujete. Tak se jmenuje [jedna z nejcitovanÄ›jÅ¡Ã­ch vÄ›deckÃ½ch pracÃ­](https://en.wikipedia.org/wiki/Attention_Is_All_You_Need) poslednÃ­ho stoletÃ­. A ano, ve skuteÄnosti se vÄ›nuje mechanismu pozornosti pro zpracovÃ¡nÃ­ sekvenÄnÃ­ch dat a jejÃ­ slÃ¡va tkvÃ­ v tom, Å¾e se stala zÃ¡kladem technologie TransformÃ¡torÅ¯ a tÃ­m fakticky odstartovala modernÃ­ Ã©ru AI. Z nÃ¡zvu bychom pÅ™itom soudili, Å¾e jde o vÃ½znamnou prÃ¡ci adolescentnÃ­ behaviorÃ¡lnÃ­ psychologie nebo nÃ¡vod k pochopenÃ­ dneÅ¡nÃ­ho svÄ›ta.

Pokud odmyslÃ­me miliardy dolarÅ¯, kterÃ© tato prÃ¡ce â€donutilaâ€œ spÃ¡lit firmy jako OpenAI, Microsoft nebo Google, ve skuteÄnosti tomu tak je. PrÃ¡ci _["Attention is All You Need"](https://arxiv.org/abs/1706.03762)_ lze zevÅ¡eobecnit jako matematickÃ½ popis toho, **jak je v komplexnÃ­ch systÃ©mech klÃ­ÄovÃ¡ schopnost soustÅ™ednÄ› a selektivnÄ› zamÄ›Å™it pozornost na relevantnÃ­ informace**. A takÃ© jako pÅ™Ã­klad toho, jak se matematika a pokroÄilÃ¡ kybernetika dotÃ½kÃ¡ samotnÃ© podstaty lidstvÃ­. CoÅ¾ mÃ¡ zajÃ­mavÃ½ dÅ¯sledek: jeÅ¡tÄ› nikdy se neinvestovaly takovÃ© obrovskÃ© sumy do snahy o pochopenÃ­ fungovÃ¡nÃ­ lidskÃ©ho chÃ¡pÃ¡nÃ­ svÄ›ta, emociÃ¡lnÃ­ch procesÅ¯ a fungovÃ¡nÃ­ uvaÅ¾ovÃ¡nÃ­, jako v momentÄ›, kdy tyto procesy obrovskÃ© firmy chÃ¡pou jako pÅ™Ã­leÅ¾itost pÅ™eloÅ¾it je do ÄÃ­sel a promÃ­tnout do poÄÃ­taÄÅ¯. UmÄ›lÃ¡ inteligence nenÃ­ zaloÅ¾enÃ¡ jen na zkopÃ­rovÃ¡nÃ­ vÅ¡eho lidskÃ©ho vÄ›dÄ›nÃ­, ale na snaze o napodobenÃ­ lidskÃ©ho vÄ›domÃ­. A tak si zaÄÃ­nÃ¡me uvÄ›domovat, Å¾e stejnÃ© tvrzenÃ­ obsahuje epistemologie, kterÃ¡ tvrdÃ­, Å¾e **znalosti vznikajÃ­ prostÅ™ednictvÃ­m vztahÅ¯ mezi jednotlivÃ½mi informacemi**, nikoli jen jejich mechanickÃ½m zpracovÃ¡nÃ­m. Paralelu mÅ¯Å¾eme najÃ­t ve fenomenologickÃ©m pojetÃ­ vÄ›domÃ­, kterÃ© zdÅ¯razÅˆuje, Å¾e **vÄ›domÃ­ je vÅ¾dy "vÄ›domÃ­m nÄ›Äeho"** â€“ naÅ¡e mysl se pÅ™irozenÄ› zamÄ›Å™uje na urÄitÃ© aspekty reality a jinÃ© nechÃ¡vÃ¡ v pozadÃ­.

SprÃ¡vnÄ› zamÄ›Å™enÃ¡ pozornost je nÄ›co, co nÃ¡Å¡ svÄ›t potÅ™ebuje. ProtoÅ¾e **nÃ¡Å¡ svÄ›t se stal kÅ™ehkÃ½m**. Jak se stal kÅ™ehkÃ½m? JeÅ¡tÄ› nedÃ¡vno jsme soudili, Å¾e zÃ¡sadnÃ­ problÃ©my naÅ¡eho svÄ›ta lze rozdÄ›lit do tÅ™Ã­ hlavnÃ­ch kategoriÃ­:

- **klimatickÃ¡ zmÄ›na** vytvÃ¡Å™ejÃ­cÃ­ sociodemografickÃ© tlaky, hrozÃ­cÃ­ masovou migracÃ­ a obrovskÃ½mi agrokulturnÃ­mi promÄ›nami

- prohlubujÃ­cÃ­ se **majetkovÃ¡ nerovnost** rozÅ¡iÅ™ujÃ­cÃ­ vliv obrovskÃ½ch korporacÃ­ a superbohatÃ½ch jedincÅ¯ schopnÃ½ch finanÄnÄ› konkurovat stÃ¡tnÃ­m celkÅ¯m

- **nedÅ¯vÄ›ra mas** ve schopnost elit Å™eÅ¡it problÃ©my

JenÅ¾e pÅ™ed dvÄ›mi lety, kdyÅ¾ jsem psal svoji knihu [MÃ½ty a nadÄ›je digitÃ¡lnÃ­ho svÄ›ta](https://www.melvil.cz/kniha-myty-a-nadeje-digitalniho-sveta/), jsem byl optimistickÃ½ ohlednÄ› toho, zda lze tyto â€vÃ½vrtkyâ€œ zvlÃ¡dnout, aÄkoliv jiÅ¾ tehdy se trojice tÄ›chto problÃ©mÅ¯ promÃ­tala do politickÃ© nestability vzbuzovanÃ© populistickÃ½mi politiky touÅ¾Ã­cÃ­mi po moci a superbohÃ¡ÄÅ¯ touÅ¾Ã­cÃ­ch po nÃ¡vratu ke starÃ½m dobrÃ½m ÄasÅ¯m. Pak pÅ™iÅ¡la vÃ¡lka na UkrajinÄ›, v Izraeli, na spadnutÃ­ je vpÃ¡d ÄŒÃ­ny na Tchajwan Äi vÃ¡lka Indie a PakistÃ¡nu - a to nepoÄÃ­tÃ¡m lokÃ¡lnÃ­, mÃ©nÄ› sofistikovanÃ© konflikty, kterÃ© se dotÃ½kajÃ­ statisÃ­cÅ¯. A je to Francis Fukuyama, kdo prohlaÅ¡uje, Å¾e demokracie nebyla nikdy v takovÃ©m ohroÅ¾enÃ­, jako nynÃ­.

Do tohoto kÅ™ehkÃ©ho stavu svÄ›ta, v nÄ›mÅ¾ se kymÃ¡cejÃ­ vÅ¡echny dosavadnÃ­ jistoty, vstupuje umÄ›lÃ¡ inteligence s prohlÃ¡Å¡enÃ­m â€Pozornost je vÅ¡e, co potÅ™ebujeteâ€œ. ZamÄ›Å™me tedy pozornost na **oktagon rizik, kterÃ¡ AI pÅ™inÃ¡Å¡Ã­**.

![Oktagon rizi, kterÃ¡ AI pÅ™inÃ¡Å¡Ã­](/assets/oktagon-rizik-ai.png)

Na obrÃ¡zku je vidÄ›t mÅ¯j nÃ¡vrh takovÃ©ho oktagonu: **osmiÄky zÃ¡sadnÃ­ch rizik, jeÅ¾ AI do svÄ›ta pÅ™inÃ¡Å¡Ã­ nebo je posiluje**. Å½lutÄ› jsou rizika novÃ¡, rÅ¯Å¾ovÄ› prouhloubenÃ­ stÃ¡vajÃ­cÃ­ch vÃ½zev. PojÄme se u nich v bodech zastavit:

### 1â€¯|â€¯DigitÃ¡lnÃ­ suverenita a ÄipovÃ© â€Å¾eleznÃ© oponyâ€œ

Pokud opravdu bude moci AI doplÅˆovat Äi nahrazovat lidskou prÃ¡ci (a zdÃ¡ se, Å¾e ano), budou nÃ¡rody, kultury a jazyky, kterÃ© nebudou mÃ­t je respektujÃ­cÃ­ AI, znevÃ½hodnÄ›ny, protoÅ¾e AI pro nÄ› nebude plnohodnotnÄ› fungovat. Vznikne AI propast, kterou mÅ¯Å¾e strÃ¡Å¾it nÄ›kolik firem, jeÅ¾ ji umoÅ¾nÃ­ pÅ™ekonÃ¡vat jen nÄ›komu. Bez vlastnÃ­ datovÃ© a vÃ½poÄetnÃ­ infrastruktury se Evropa stane jen pasivnÃ­m pÅ™Ã­jemcem pravidel rozhodnutÃ½ch jinde, ztratÃ­ schopnost ovlivÅˆovat svoji budoucnost. StejnÃ½m problÃ©mem zÃ¡vislosti je ta hardwarovÃ¡. PokroÄilÃ© Äipy se dnes vyrÃ¡bÄ›jÃ­ na ÃºzkÃ©m pÃ¡su tchajwanskÃ©ho pobÅ™eÅ¾Ã­ a americkÃ© kontroly vÃ½vozu vytvÃ¡Å™ejÃ­ â€kÅ™emÃ­kovou oponuâ€œ rozdÄ›lujÃ­cÃ­ stÃ¡ty na ty, kterÃ© se k pokroÄilÃ½m ÄipÅ¯m dostanou a nedostanou. HardwarovÃ¡ zÃ¡vislost se promÃ­tÃ¡ do geopolitickÃ© zÃ¡vislosti, dokud vÃ½robnÃ­ Å™etÄ›zec ÄipÅ¯ zÅ¯stane extrÃ©mnÄ› koncentrovanÃ½. ÄŒÃ­na se za extrÃ©mnÃ­ch nÃ¡kladÅ¯ snaÅ¾Ã­ tuto zÃ¡vislost zlomit.

_Pokud se podaÅ™Ã­ zvÄ›tÅ¡ovat otevÅ™enost tohoto Å™etÄ›zce napÅ™Ã­klad platformami ARM/RISC-V a vÃ½robnÃ­mi ÄipovÃ½mi alternativami, mÅ¯Å¾e se opona postupnÄ› rozptÃ½lit._

### 2 | KorporativnÃ­ privatizace versus veÅ™ejnÃ¡ sprÃ¡va

O povaze AI dnes rozhoduje nÄ›kolik mÃ¡lo firem hnanÃ½ch nikoliv neziskovÃ½m poslÃ¡nÃ­m prospÄ›t, aÄkoliv tak tvrdÃ­, ale ziskem. Dokud jsou klÃ­ÄovÃ¡ aktiva i standardy vâ€¯rukou nÄ›kolika korporacÃ­, zÅ¯stane vliv mezinÃ¡rodnÃ­ch Ãºmluv omezenÃ½. VeÅ™ejnost tÃ©to privatizaci kreativnÃ­ sfÃ©ry tleskÃ¡, protoÅ¾e povaÅ¾uje politickÃ© elity za zkompromitovanÃ©, neakceschopnÃ© a domnÃ­vÃ¡ se, firemnÃ­ lÃ­dÅ™i si poradÃ­ tak, Å¾e kromÄ› svÃ©ho zisku i zlepÅ¡Ã­ svÄ›t. Je to trvalÃ© dilema urÄenÃ© k neustÃ¡lÃ©mu hledÃ¡nÃ­ rovnovÃ¡hy: pÅ™Ã­liÅ¡ slabÃ© globÃ¡lnÃ­ normy selÅ¾ou; pÅ™Ã­liÅ¡ silnÃ© (povinnÃ© otevÅ™enÃ© modely, sdÃ­lenÃ­ knowâ€‘how) odradÃ­ inovÃ¡tory. NavÃ­c USA a ÄŒÃ­na si vybraly â€nÃ¡rodnÃ­ Å¡ampionyâ€œ a vnÃ­majÃ­ zÃ¡polenÃ­ v AI jako strategickÃ© mÄ›Å™enÃ­ sil, v nÄ›mÅ¾ nenÃ­ prostor pro omezenÃ­.

_NemÄ›la by to bÃ½t prÃ¡vÄ› Evropa, kdo bude prosazovat AI jako open-source technologii a tÃ­m navazovat na tÅ™Ã­tisÃ­ciletou tradici univerzitnÃ­ho sdÃ­lenÃ­ vÄ›dÄ›nÃ­ a myÅ¡lenkovÃ© otevÅ™enosti?_

### 3 | AgentickÃ¡ AI a AGI

Dnes je AI v roli poradce: pouÅ¾Ã­vÃ¡me ji pro dÃ­lÄÃ­ Ãºkony, tÄ›Å¾Ã­me z jejÃ­ schopnosti propojovat encyklopedickÃ© znalosti. AutonomnÃ­ agenti, kteÅ™Ã­ budou samostatnÄ› vykonÃ¡vat rozsÃ¡hlÃ© Äinnosti, teprve pÅ™ichÃ¡zejÃ­. Agenti budou erodovat uÅ¾ivatelskou kontrolu i sociÃ¡lnÃ­ zisky, jiÅ¾ dnes se firmy ve snaze je etablovat napojujÃ­ bez vÄ›tÅ¡Ã­ch bezpeÄnostnÃ­ch brzd na vÅ¡emoÅ¾nÃ© systÃ©my, aniÅ¾ by uÅ¾ivatelÃ© chÃ¡pali podstatu nebezpeÄÃ­ tohoto propojenÃ­. ZatÃ­mco se soustÅ™edÃ­me na hypotetickou apokalypsu, kterou zpÅ¯sobÃ­ univerzÃ¡lnÃ­ umÄ›lÃ¡ inteligence v budoucnu, nevnÃ­mÃ¡me znaÄnÃ¡ rizika agentickÃ© AI, kterÃ¡ prÃ¡vÄ› pÅ™ichÃ¡zÃ­. Do teoretickÃ© superinteligence se investujÃ­ miliardy, do robustnosti souÄasnÃ½ch systÃ©mÅ¯ jen drobky. A pÅ™Ã­kladem mÅ¯Å¾e bÃ½t evropskÃ½ EU AI Act: mÃ¡me detailnÃ­ pravidla pro hypotetickÃ© scÃ©nÃ¡Å™e budoucnosti, ale tÃ©mÄ›Å™ Å¾Ã¡dnÃ¡ pro rizika, jeÅ¾ jsou tady, napÅ™Ã­klad pro prÃ¡ci se zdroji dat.

_MÄ›li bychom zohlednit rizika kolapsu souÄasnÃ½ch systÃ©mÅ¯ a investovat do jejich robustnosti._

### 4 | Produktivita

UmÄ›lÃ¡ inteligence mÃ¡ znamenat prudkÃ½ rÅ¯st produktivity, kdy se spÃ¡lenÃ¡ elektÅ™ina a oÅ¡oupanÃ½ kÅ™emÃ­k promÄ›nÃ­ v nÃ¡hradu rutinnÃ­ch i kreativnÃ­ch ÄinnostÃ­ drahÃ½ch a nespolehlivÃ½ch lidÃ­. Historie nicmÃ©nÄ› ukazuje, Å¾e prvnÃ­ch nÄ›kolik desetiletÃ­ trvÃ¡, neÅ¾ se novÃ¡ technologie â€propÃ­Å¡eâ€œ do rÅ¯stu reÃ¡lnÃ½ch mezd, nejprve se dobÃ½vÃ¡ renta pro majitele vÃ½robnÃ­ho prostÅ™edku. Pokud komerÄnÃ­ model zÅ¯stane rent-extractionâ€‘first, mÅ¯Å¾e dojÃ­t kâ€¯ tzv. soâ€‘so automation â€“ mÃ¡lo produktivity, hodnÄ› substituce prÃ¡ce. PrvnÃ­ studie na Ãºrovni firem z â€¯callâ€‘center a softwarovÃ©ho vÃ½voje uÅ¾ ukazujÃ­ 14â€‘30â€¯% nÃ¡rÅ¯sty vÃ½stupu dÃ­ky LLM, ale makroefekt se zdÃ¡ zatÃ­m mizivÃ½.

_KlÃ­Ä je vâ€¯ difÃºzi a organizaÄnÃ­m redesignu â€“ nikoliv v â€¯samotnÃ© technologii._

### 5 | Nerovnost a trh prÃ¡ce

VÃ½zkumy z â€¯odvÄ›tvÃ­ zdravotnictvÃ­, zÃ¡kaznickÃ½ch sluÅ¾eb, logistiky a vÃ½roby uÅ¾ ukazujÃ­ dvojÃ­ efekt: AI znaÄnÄ› zvyÅ¡uje produktivitu vâ€¯ rolÃ­ch sâ€¯ niÅ¾Å¡Ã­m formÃ¡lnÃ­m vzdÄ›lÃ¡nÃ­m, pokud slouÅ¾Ã­ jako â€œdruhÃ© mozkyâ€ pracovnÃ­kÅ¯; naopak nejvÃ­ce Å¡kodÃ­, kdyÅ¾ je nasazena k ÄistÃ© substituci bez paralelnÃ­ch investic do Å¡kolenÃ­ aâ€¯ sdÃ­lenÃ© sprÃ¡vy dat. **Bez tÄ›chto doplÅˆkovÃ½ch opatÅ™enÃ­ se rÃ½suje â€dvoupatrovÃ¡ spoleÄnostâ€œ**: ÃºzkÃ¡ elita AIâ€‘kapitalistÅ¯ a fragmentovanÃ¡ gigâ€‘ekonomika s omezenou vyjednÃ¡vacÃ­ silou. Technologie, kterÃ¡ jen tÄ›snÄ› zvlÃ¡dÃ¡ lidskÃ½ Ãºkol, sniÅ¾uje mzdovÃ½ podÃ­l, ale nepÅ™idÃ¡ produktivitu â€“ typicky uâ€¯ poloâ€‘automatickÃ½ch pokladen. NÃ­zko kvalifikovanÃ­ pracovnÃ­ci Äasto nemajÃ­ kapacitu pÅ™evzÃ­t novÃ© â€œmetaâ€‘Ãºkolyâ€ (diagnostika, interpretace dat, podpora AI systÃ©mÅ¯ tam, kde zatÃ­m nezvlÃ¡dajÃ­), takÅ¾e firmy tyto pracovnÃ­ky nahrazujÃ­, mÃ­sto aby doplÅˆovali jejich schopnosti. PÅ™itom komplementÃ¡rnÃ­ Å¡kolenÃ­ a nÃ¡slednÃ½ pÅ™esun lidÃ­ na Ãºkoly vyÅ¾adujÃ­cÃ­ Ãºsudek a empatii by zvÃ½Å¡il produktivitu iâ€¯ mzdy.

_AI mÅ¯Å¾e bÃ½t eskalÃ¡tor, po â€¯kterÃ©m se na trhu prÃ¡ce vyvezou i mÃ©nÄ› kvalifikovanÃ­. OvÅ¡em jen pokud kolektivnÄ› investujeme do dovednostÃ­, sdÃ­lenÃ½ch dat a pracovnÃ­ch prÃ¡v. Jinak se z eskalÃ¡toru stane vÃ½tah, kterÃ½m jezdÃ­ jen vyvolenÃ­ do svÃ©ho loftu._

### 6 â€¯| â€¯AI vâ€¯obrannÃ© politice

OÄekÃ¡vÃ¡nÃ­ rozsÃ¡hlÃ½ch ozbrojenÃ½ch geopolitickÃ½ch konfliktÅ¯ zatÃ­m mÃ­rnilo vÄ›domÃ­ technologickÃ© pÅ™evahy ZÃ¡padu. JenÅ¾e poslednÃ­ konflikty ukazujÃ­, Å¾e drony za tisÃ­ce dolarÅ¯ mohou niÄit tanky za miliony. ZÃ¡pad naopak â€ztrÃ¡cÃ­ dechâ€œ vâ€¯bezpilotnÃ­ch a autonomnÃ­ch systÃ©mech, protoÅ¾e spolÃ©hÃ¡ na komerÄnÃ­ platformy a podceÅˆuje hromadnÃ© nasazovÃ¡nÃ­ levnÃ½ch dronÅ¯. USA a NATO setrvÃ¡vajÃ­ uâ€¯ malÃ½ch sÃ©riÃ­ Å¡piÄkovÃ½ch a drahÃ½ch dronÅ¯, zatÃ­mco konkurenti sÃ¡zÃ­ na kvantitu aâ€¯ rychlÃ½ upgrade levnÃ½ch platforem. NÃ­zkÃ¡ cena a opensource autopilotnÃ­ systÃ©my jako Ardupilot, PX4 umoÅ¾ÅˆujÃ­ neâ€‘stÃ¡tnÃ­m aktÃ©rÅ¯m nasadit kvazivojenskÃ© kapacity.

Zda AI pÅ™inese strategickou paritu, nebo novou nerovnovÃ¡hu, bude zÃ¡viset mÃ©nÄ› na Å¡piÄkovÃ© inovaci na nobelistickÃ© Ãºrovni a vÃ­ce na tom, kdo dokÃ¡Å¾e vyrÃ¡bÄ›t (a nakupovat) levnÃ© a dostateÄnÄ› chytrÃ© platformy ve velkÃ©m. â€¯

_Bez reforem akviziÄnÃ­ch procesÅ¯ a investic do domÃ¡cÃ­ho ÄipovÃ©ho Å™etÄ›zce hrozÃ­ ZÃ¡padu, Å¾e zÅ¯stane technologicky elitnÃ­, ale ÄÃ­selnÄ› podkritickÃ½ hrÃ¡Ä vâ€¯ boji o vzduÅ¡nou a informaÄnÃ­ pÅ™evahu._

### 7 | KlimatickÃ¡ stopa a energie

UmÄ›lÃ¡ ingeligence nespotÅ™ebovÃ¡vÃ¡ jen kÅ™emÃ­k, ale takÃ© - a pÅ™edevÅ¡Ã­m - elektrickou energii. Tu nelze nijak nahradit, je potÅ™eba ji jen vyrobit a pokud zaÄne AI masovnÄ› vstupovat do trhu lidskÃ© prÃ¡ce, bude poptÃ¡vka po elektÅ™inÄ› rÅ¯st. CÃ­lem musÃ­ bÃ½t bezemisnÃ­ elektÅ™ina a tady potÅ™ebujeme mnoho prÅ¯lomÅ¯. Blackout na PyrenejskÃ©m poloostrovÄ› jasnÄ› ukazuje, Å¾e rychle se promÄ›ÅˆujÃ­cÃ­ elektrickÃ© sÃ­tÄ› jsou kÅ™ehkÃ© a nÃ¡chylnÃ© ke stabilitÄ› a spoleÄnost nemÅ¯Å¾e bez elektÅ™iny zÅ¯stat dlouho. Zde budou potÅ™eba masivnÃ­ zmÄ›ny a investice a ten, kdo je zvlÃ¡dne, mÃ¡ Å¡anci na trhu AI uspÄ›t. LaÄnost AI po elektÅ™inÄ› a touha gigantÅ¯ ji ukojit snad povede k aktivnÃ­mu hledÃ¡nÃ­ Å™eÅ¡enÃ­ tohoto dilematu. TvrzenÃ­, Å¾e efektivita modernÃ­ch GPU a algoritmÅ¯ vychÃ½lÃ­ energetickou bilanci pÅ™Ã­znivÄ›, nenÃ­ realistickÃ©. ExponentiÃ¡lnÃ­ poptÃ¡vku po inferenci (douÄovÃ¡nÃ­ AI) nelze donekoneÄna â€odehrÃ¡tâ€œ efektivnÄ›jÅ¡Ã­mi Äipy. Bez prÅ¯lomu v â€¯nÃ­zkouhlÃ­kovÃ©m baseloadu (fÃºze, SMR) se problÃ©m jen odsouvÃ¡.

_KlimatickÃ¡ stopa AI nenÃ­ osudem, ale vÃ½sledkem inovaÄnÃ­ aâ€¯ politickÃ© rovnovÃ¡hy.â€¯ Objem emisÃ­ zâ€¯ elektÅ™iny pro datacentra se neurÄuje nÄ›jakou nevyhnutelnou fyzikÃ¡lnÃ­ kÅ™ivkouâ€¯. ZÃ¡visÃ­ na tom, jak rychle zlepÅ¡ujeme technologickou ÃºÄinnostâ€¯ a souÄasnÄ› â€¯jakÃ© cenovÃ©, regulaÄnÃ­ a infrastrukturnÃ­ signÃ¡ly nastavÃ­ vlÃ¡dy a trh. NapÅ™Ã­klad emisnÃ­ povolenky._

### 8 â€¯| â€¯VzdÄ›lÃ¡vÃ¡nÃ­ a kolektivnÃ­ inteligence

AI je nesmÃ­rnÄ› silnÃ¡ ve vzdÄ›lÃ¡vÃ¡nÃ­ a zjednoduÅ¡enÄ› Å™eÄeno, pokud AI dostane Ãºkol dÃ­tÄ› nauÄit, tak jej nauÄÃ­. Adaptive tutoring dokÃ¡Å¾e v reÃ¡lnÃ©m Äase sbÃ­rat data o vÃ½konu a stylu uÄenÃ­ jednotlivce, upravit Ãºlohy a vysvÄ›tlenÃ­ tak, aby podchytilo slabÃ© momenty kaÅ¾dÃ©ho Å¾Ã¡ka a urychlilo pokrok tÄ›ch rychlejÅ¡Ã­ch. V pÅ™Ã­padech, kde chybÄ›jÃ­ asistenti, speciÃ¡lnÃ­ pedagogovÃ© Äi dostateÄnÃ¡ rozvrÅ¾enÃ­ hodin, mÅ¯Å¾e AI vÃ½raznÄ› snÃ­Å¾it vÃ½padky a zlepÅ¡it vÃ½sledky. JenÅ¾e v ÄÃ­ch rukou budou tyto systÃ©my? Bez sdÃ­lenÃ½ch, veÅ™ejnÄ› vlastnÄ›nÃ½ch datovÃ½ch platforem se stane vzdÄ›lÃ¡vÃ¡nÃ­ pÅ™edmÄ›tem â€extraktivnÃ­ch rentâ€œ. Bez robustnÃ­ch veÅ™ejnÃ½ch ekosystÃ©mÅ¯ AI vzdÄ›lÃ¡vacÃ­ nÃ¡stroje prohloubÃ­ digitÃ¡lnÃ­ propast mezi bohatÃ½m a chudÃ½m vzdÄ›lÃ¡nÃ­m. StÃ¡t by mÄ›l definovat open-source rozhranÃ­, certifikovat etiku AI ve Å¡kolstvÃ­ a financovat â€edukativnÃ­ cloudâ€œ, kde se kumulujÃ­ a sdÃ­lejÃ­ anonymizovanÃ¡ studentskÃ¡ data. Ne se propadat do de-facto â€vendor lock-inâ€œ, jako jsme dopustili v ÄŒesku pÅ™es Google Classroom a BakalÃ¡Å™e.

_Bez prÃ¡vnÃ­ho rÃ¡mce pro vlastnictvÃ­ a sdÃ­lenÃ­ dat, Å¡koly nevlastnÃ­ vÃ½sledky AI-analÃ½z svÃ½ch Å¾Ã¡kÅ¯. To podkopÃ¡vÃ¡ veÅ™ejnou zodpovÄ›dnost a auditovatelnost. VzdÄ›lÃ¡vacÃ­ AI (a systÃ©m vzdÄ›lÃ¡vÃ¡nÃ­ obecnÄ›) nemÃ¡ bÃ½t pÅ™edmÄ›tem konkurenÄnÃ­ch uzavÃ­rek, ale veÅ™ejnÃ½m zboÅ¾Ã­m. Jinak riskujeme fragmentovanÃ½ systÃ©m, kde se â€personalizovanÃ¡ vÃ½ukaâ€œ stane prÃ©miovou sluÅ¾bou jen pro vyvolenÃ©._

### AI zvyÅ¡uje kÅ™ehkost svÄ›ta

ZnÃ­ to hrozivÄ›. A graf vypadÃ¡ dÄ›sivÄ›, alespoÅˆ pokud teorii grafÅ¯ znÃ¡te. Jak je to vÃ¡Å¾nÃ©?

**Riziko â€balkanizace AIâ€œ je reÃ¡lnÃ©** â€“ exportnÃ­ kontroly a datovÃ¡ lokalizace mohou vytvoÅ™it technobloky, jejichÅ¾ standardy se budou vzÃ¡jemnÄ› vyluÄovat.

**Makroâ€‘produktivity se nedoÄkÃ¡me bez organizaÄnÃ­ inovace**; stÃ¡ty by mÄ›ly podporovat komplementÃ¡rnÃ­ investice (reskilling, datovÃ© trusty) spÃ­Å¡e neÅ¾ pÅ™Ã­mÃ© dotace na modely. A mÄ›ly by zabrÃ¡nit tomu, aby vÃ½nos z AI pÅ™ipadl jen jednotlivcÅ¯m, neboÅ¥ AI je podstaveno na prÃ¡ci vÅ¡ech generacÃ­.

**BezpeÄnostnÃ­ debata** se musÃ­ pÅ™esunout od hypotetickÃ©ho AGI k â€¯aktuÃ¡lnÃ­m externÃ­m zneuÅ¾itÃ­m a systÃ©movÃ© robustnosti.

**EnergetickÃ¡ stopa AI** se stane limitujÃ­cÃ­m faktorem; bez dekarbonizace vÃ½roby ÄipÅ¯ a elektÅ™iny skonÄÃ­ debata u uhlÃ­kovÃ½ch kvÃ³t na vÃ½poÄet.

AÄkoliv "oktagon rizik" a celkovÃ¡ kÅ™ehkost svÄ›ta mohou pÅ¯sobit znepokojivÄ›, je dÅ¯leÅ¾itÃ© si uvÄ›domit, Å¾e **budoucnost nenÃ­ pÅ™edem danÃ¡**. MÃ¡me schopnost ji aktivnÄ› utvÃ¡Å™et.

**Evropa mÃ¡ ojedinÄ›lÃ© okno stÃ¡t se â€tÅ™etÃ­m pÃ³lemâ€œ** â€“ pokud spÃ¡ruje regulaci jakoÅ¾to formu smÄ›Å™ovÃ¡nÃ­ s â€¯vlastnÃ­ infrastrukturou a kapitÃ¡lem pro Å¡kÃ¡lovÃ¡nÃ­ startupÅ¯.

**ÄŒesko mÃ¡ ÃºÅ¾asnou pozici**, kdy disponuje stÃ¡le vysoce rozvinutou a edukovanou spoleÄnost a tÅ™Ã­du pracujÃ­cÃ­ch a zÃ¡roveÅˆ nenÃ­ uzamÄeno v ÃºspÄ›Å¡nÃ© ekonomickÃ© minulosti. DÃ­ky tomu mÅ¯Å¾e bez obav inovovat a pÅ™edstihnout stÃ¡ty jako NÄ›mecko a Francie pÅ™itahovanÃ© zpÄ›t do jejich ÃºspÄ›Å¡nÃ© analogovÃ© ekonomickÃ© Ã©ry.

VÄ›nujme pozornost tomu, na Äem zÃ¡leÅ¾Ã­. Ne TiktokovÃ½m videÃ­m, populistickÃ©mu blÃ¡bolenÃ­ a masovÃ© zÃ¡bavÄ›. MÃ¡me tu pÃ¡r tÃ©mat, kterÃ¡ jsou dÅ¯leÅ¾itÃ¡ a kterÃ¡ jsou dÅ¯stojnou vÃ½zvou pro nejlepÅ¡Ã­ mozky naÅ¡eho svÄ›ta!

**Budujme AI soustÅ™edÄ›nou na ÄlovÄ›ka.** MasivnÄ› investujme do celoÅ¾ivotnÃ­ho vzdÄ›lÃ¡vÃ¡nÃ­, rekvalifikacÃ­ a rozvoje dovednostÃ­, kterÃ© AI doplÅˆuje â€“ kritickÃ© myÅ¡lenÃ­, kreativita, emoÄnÃ­ inteligence, komplexnÃ­ Å™eÅ¡enÃ­ problÃ©mÅ¯ a digitÃ¡lnÃ­ gramotnost. AI nemusÃ­ bÃ½t jen o substituci, ale pÅ™edevÅ¡Ã­m o augmentaci lidskÃ½ch schopnostÃ­.

AktivnÄ› prosazujme **vÃ½voj AI v souladu s etickÃ½mi principy** transparentnosti, spravedlnosti a odpovÄ›dnosti.

PokraÄujme **v investicÃ­ch do vlastnÃ­ vÃ½poÄetnÃ­ infrastruktury**, vÃ½zkumu a podpory talentÅ¯, aby se snÃ­Å¾ila zÃ¡vislost na externÃ­ch aktÃ©rech a podpoÅ™ila vlastnÃ­ inovace respektujÃ­cÃ­ evropskÃ© hodnoty a jazykovou rozmanitost.

**Podporujme otevÅ™enÃ© standardy a platformy**. NedopusÅ¥me dalÅ¡Ã­ â€uzamykÃ¡nÃ­â€œ a â€vyluÄovÃ¡nÃ­â€œ z infrastruktury, kterÃ¡ mÃ¡ bÃ½t veÅ™ejnÃ¡.

Hledejme mechanismy, kterÃ© zajistÃ­, Å¾e produktivita zÃ­skanÃ¡ dÃ­ky AI se **promÃ­tne do zlepÅ¡enÃ­ kvality Å¾ivota** Å¡irokÃ© populace, nikoli jen do ziskÅ¯ ÃºzkÃ© skupiny.

Podporujme firmy a organizace v redesignu pracovnÃ­ch procesÅ¯ tak, aby **AI efektivnÄ› integrovaly a vytvÃ¡Å™ely novÃ©, smysluplnÃ© role** pro lidi.

AktivnÄ› podporujme **vÃ½voj energeticky mÃ©nÄ› nÃ¡roÄnÃ½ch algoritmÅ¯ a hardwaru**. Investujme **do obnovitelnÃ½ch a bezemisnÃ­ch zdrojÅ¯ energie** pro napÃ¡jenÃ­ datovÃ½ch center. VyuÅ¾ijme potenciÃ¡l AI pro modelovÃ¡nÃ­ klimatickÃ½ch zmÄ›n, optimalizaci energetickÃ½ch sÃ­tÃ­, vÃ½voj novÃ½ch udrÅ¾itelnÃ½ch materiÃ¡lÅ¯ a ochranu biodiverzity.

**VzdÄ›lÃ¡vejme spoleÄnost**, jak rozpoznÃ¡vat dezinformace vÄetnÄ› tÄ›ch generovanÃ½ch AI a jak kriticky pÅ™istupovat k informacÃ­m. VytvÃ¡Å™ejme platformy pro veÅ™ejnou diskusi a participaci na rozhodovÃ¡nÃ­ o smÄ›Å™ovÃ¡nÃ­ a regulaci AI. DemokratickÃ¡ kontrola nad takto mocnou technologiÃ­ je klÃ­ÄovÃ¡.

KÅ™ehkost svÄ›ta a vÃ½zvy spojenÃ© s umÄ›lou inteligencÃ­ nejsou dÅ¯vodem k paralÃ½ze, ale vÃ½zvou k akci.

ZvlÃ¡dneme to!