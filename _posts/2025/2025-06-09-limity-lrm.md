---
author: Patrick Zandl
categories:
- AI
- LRM
layout: post
post_excerpt: NedÃ¡vnÃ¡ studie Apple odhaluje dosti zÃ¡sadnÃ­ omezenÃ­ v architektuÅ™e uvaÅ¾ujÃ­cÃ­ch
  jazykovÃ½ch modelÅ¯ (Large Reasoning Models) a zpochybÅˆuje jejich skuteÄnÃ© uvaÅ¾ovacÃ­
  schopnosti. Je to jen vlnka na jezeÅ™e nadÄ›jÃ­, Å¾e modely jako o3 nebo deepseek-r1
  jsou schopny kvalitativnÃ­ch posunÅ¯, Äi vÃ¡Å¾nÃ½ problÃ©m?
summary_points:
- Apple studie zpochybÅˆuje skuteÄnÃ© uvaÅ¾ovacÃ­ schopnosti Large Reasoning Models (LRM).
- StandardnÃ­ benchmarky LRM trpÃ­ kontaminacÃ­ dat a neumoÅ¾ÅˆujÃ­ kontrolovanÃ© experimenty.
- LRM vykazujÃ­ tÅ™Ã­-reÅ¾imovou vÃ½konnost s kolapsem pÅ™i vysokÃ© sloÅ¾itosti problÃ©mÅ¯.
- Studie odhalila architektonickÃ© limity LRM a potÅ™ebu novÃ½ch pÅ™Ã­stupÅ¯ k inferencÃ­m.
thumbnail: null
title: Limity souÄasnÃ½ch uvaÅ¾ujÃ­cÃ­ch jazykovÃ½ch modelÅ¯ -  AnalÃ½za skuteÄnÃ½ch schopnostÃ­
  LRM'
---

NedÃ¡vnÃ¡ studie Apple odhaluje dosti zÃ¡sadnÃ­ omezenÃ­ v architektuÅ™e uvaÅ¾ujÃ­cÃ­ch jazykovÃ½ch modelÅ¯ (Large Reasoning Models) a zpochybÅˆuje jejich skuteÄnÃ© uvaÅ¾ovacÃ­ schopnosti. Je to jen vlnka na jezeÅ™e nadÄ›jÃ­, Å¾e modely jako o3 nebo deepseek-r1 jsou schopny kvalitativnÃ­ch posunÅ¯, Äi vÃ¡Å¾nÃ½ problÃ©m? 


PoslednÃ­ generace jazykovÃ½ch modelÅ¯, oznaÄovanÃ¡ jako Large Reasoning Models (LRM) - VelkÃ© modely uvaÅ¾ovÃ¡nÃ­, pÅ™edstavuje modely jako OpenAI o1/o3, [DeepSeek](/item/deepseek/)-R1 nebo Claude 3.7 Sonnet Thinking. Tyto systÃ©my se vyznaÄujÃ­ generovÃ¡nÃ­m rozsÃ¡hlÃ½ch "myÅ¡lenkovÃ½ch" procesÅ¯ pÅ™ed poskytnutÃ­m odpovÄ›di, tzv. obsÃ¡hlÃ© Å™etÄ›zce Ãºvah (chain-of-thought, CoT).  CoÅ¾ mÃ¡ simulovat lidskÃ© uvaÅ¾ovÃ¡nÃ­. Navzdory slibnÃ½m vÃ½sledkÅ¯m na standardnÃ­ch benchmarcÃ­ch vÅ¡ak zÅ¯stÃ¡vÃ¡ otÃ¡zka, zda skuteÄnÄ› dochÃ¡zÃ­ k zobecnitelnÃ©mu uvaÅ¾ovÃ¡nÃ­, nebo jde o sofistikovanÄ›jÅ¡Ã­ formu pattern matchingu. A tuto otÃ¡zku se pokusil zodpovÄ›dÄ›t Apple v studii, kterÃ¡ se zamÄ›Å™ila na analÃ½zu uvaÅ¾ovacÃ­ch schopnostÃ­ tÄ›chto modelÅ¯. Studie se pÅ™Ã­znaÄnÄ› jmenuje [Iluze myÅ¡lenÃ­: PorozumÄ›nÃ­ silnÃ½m strÃ¡nkÃ¡m a omezenÃ­m modelÅ¯ uvaÅ¾ovÃ¡nÃ­ z pohledu sloÅ¾itosti problÃ©mÅ¯](https://machinelearning.apple.com/research/illusion-of-thinking).

Na zaÄÃ¡tek si vÃ½zkumnÃ­ci stanovily dvÄ› hypotÃ©zy:

**HypotÃ©za 1:**
Zda LRM skuteÄnÄ› umÄ›jÃ­ generalizovat proces â€myÅ¡lenÃ­â€œ na novÃ© Ãºlohy, nebo spÃ­Å¡e sofistikovanÄ› napodobujÃ­ vzory z trÃ©ninkovÃ½ch dat, pÅ™Ã­padnÄ› provÃ¡dÄ›jÃ­ komplexnÃ­ pattern matching.

**HypotÃ©za 2:**
Zda navyÅ¡ovÃ¡nÃ­ vÃ½poÄetnÃ­ho rozpoÄtu a dÃ©lky generovanÃ©ho â€myÅ¡lenÃ­â€œ skuteÄnÄ› zlepÅ¡uje Å™eÅ¡enÃ­ sloÅ¾itÄ›jÅ¡Ã­ch problÃ©mÅ¯, nebo modely narÃ¡Å¾ejÃ­ na urÄitou hranici, za kterou selhÃ¡vajÃ­ bez ohledu na dalÅ¡Ã­ zdroje.

## MetodologickÃ½ problÃ©m souÄasnÃ©ho hodnocenÃ­

StandardnÃ­ evaluace LRM trpÃ­ nÄ›kolika zÃ¡sadnÃ­mi nedostatky. PÅ™edevÅ¡Ã­m se spolÃ©hajÃ­ na etablovanÃ© matematickÃ© a programÃ¡torskÃ© benchmarky, kterÃ© Äasto obsahujÃ­ data z trÃ©novacÃ­ch sad. Tato kontaminace se pak odrÃ¡Å¾Ã­ ve zdÃ¡nlivÃ©m vÃ½konu.  Testy navÃ­c neumoÅ¾ÅˆujÃ­ kontrolovanÃ© experimentÃ¡lnÃ­ podmÃ­nky napÅ™Ã­Ä rÅ¯znÃ½mi ÃºrovnÄ›mi sloÅ¾itosti a neposkytujÃ­ vhled do struktury a kvality samotnÃ½ch uvaÅ¾ovacÃ­ch procesÅ¯.

AutoÅ™i studie proto navrhli alternativnÃ­ pÅ™Ã­stup zaloÅ¾enÃ½ na kontrolovanÃ½ch puzzle prostÅ™edÃ­ch, kterÃ© umoÅ¾ÅˆujÃ­:

- **PÅ™esnÃ© Å™Ã­zenÃ­ sloÅ¾itosti** prostÅ™ednictvÃ­m Ãºpravy parametrÅ¯ pÅ™i zachovÃ¡nÃ­ logickÃ© struktury
- **Eliminaci kontaminace dat** pouÅ¾itÃ­m novÃ½ch, specificky navrÅ¾enÃ½ch problÃ©mÅ¯  
- **DÅ¯raz na algoritmickÃ© uvaÅ¾ovÃ¡nÃ­** s jasnÄ› definovanÃ½mi pravidly
- **RigorÃ³znÃ­ hodnocenÃ­** pomocÃ­ deterministickÃ½ch simulÃ¡torÅ¯

## ExperimentÃ¡lnÃ­ design

VÃ½zkumnÃ­ci vyuÅ¾ili ÄtyÅ™i typy puzzlÃ­ s rÅ¯znÃ½mi charakteristikami sloÅ¾itosti, napÅ™. HanojskÃ© vÄ›Å¾e, pÅ™esouvÃ¡nÃ­ figurek, pÅ™echod pÅ™es Å™eku, sklÃ¡dÃ¡nÃ­ blokÅ¯). UmoÅ¾ÅˆujÃ­ tak pÅ™esnÃ© Å™Ã­zenÃ­ sloÅ¾itosti a eliminaci efektu â€nauÄenÃ½châ€œ Å™eÅ¡enÃ­. A mÄ›Å™Ã­ nejen finÃ¡lnÃ­ sprÃ¡vnost, ale i strukturu a kvalitu mezikrokÅ¯ v Å™etÄ›zci uvaÅ¾ovÃ¡nÃ­.

KaÅ¾dÃ© puzzle bylo testovÃ¡no s postupnÄ› rostoucÃ­ sloÅ¾itostÃ­, pÅ™iÄemÅ¾ byly analyzovÃ¡ny prÃ¡vÄ› nejenom finÃ¡lnÃ­ odpovÄ›di, tak mezilehlÃ© kroky v "myÅ¡lenkovÃ½ch" procesech modelÅ¯.

## KlÃ­ÄovÃ¡ zjiÅ¡tÄ›nÃ­

### TÅ™Ã­-reÅ¾imovÃ¡ architektura vÃ½konnosti

AnalÃ½za odhalila konzistentnÃ­ vzorec napÅ™Ã­Ä vÅ¡emi testovanÃ½mi modely:

1.	NÃ­zkÃ¡ sloÅ¾itost:
- StandardnÃ­ LLM bez explicitnÃ­ho myÅ¡lenÃ­ Äasto dosahujÃ­ lepÅ¡Ã­ch vÃ½sledkÅ¯ i vyÅ¡Å¡Ã­ efektivity.
- LRM v tÃ©to oblasti Äasto â€pÅ™emÃ½Å¡lÃ­ zbyteÄnÄ› dlouhoâ€œ (overthinking).
2.	StÅ™ednÃ­ sloÅ¾itost:
LRM zaÄÃ­najÃ­ mÃ­t vÃ½hodu dÃ­ky schopnosti dÃ©le rozebÃ­rat problÃ©m, obÄas naleznou Å™eÅ¡enÃ­ po delÅ¡Ã­m zkouÅ¡enÃ­ rÅ¯znÃ½ch cest.
- RozdÃ­l ve vÃ½konu mezi â€thinkingâ€œ a â€non-thinkingâ€œ modely roste ve prospÄ›ch LRMs.
3.	VysokÃ¡ sloÅ¾itost:
- DochÃ¡zÃ­ k â€kolapsuâ€œ obou typÅ¯ modelÅ¯: pravdÄ›podobnost ÃºspÄ›chu padÃ¡ na nulu.
- ZajÃ­mavÃ© je, Å¾e prÃ¡vÄ› v tÃ©to fÃ¡zi modely zaÄnou paradoxnÄ› spotÅ™ebovÃ¡vat mÃ©nÄ› vÃ½poÄetnÃ­ho vÃ½konu na myÅ¡lenÃ­ (zkracujÃ­ Å™etÄ›zec Ãºvah), pÅ™estoÅ¾e sloÅ¾itost problÃ©mu roste a majÃ­ dostateÄnÃ½ [token](/ai/tokeny-versus-slova/) budget.

### ParadoxnÃ­ Å¡kÃ¡lovacÃ­ limity

NejpÅ™ekvapivÄ›jÅ¡Ã­m objevem je kontraintuitivnÃ­ vztah mezi sloÅ¾itostÃ­ problÃ©mu a investovanÃ½m "uvaÅ¾ovacÃ­m" ÃºsilÃ­m. Modely nejprve zvyÅ¡ujÃ­ poÄet thinking [tokenÅ¯](/ai/tokeny-versus-slova/) ÃºmÄ›rnÄ› se sloÅ¾itostÃ­, ale pÅ™i dosaÅ¾enÃ­ kritickÃ©ho prahu zaÄÃ­najÃ­ ÃºsilÃ­ sniÅ¾ovat - navzdory dostupnÃ©mu token budgetu a rostoucÃ­ obtÃ­Å¾nosti problÃ©mÅ¯.

Tento jev naznaÄuje fundamentÃ¡lnÃ­ architektonickÃ© omezenÃ­ v souÄasnÃ½ch LRM, kde systÃ©my nejsou schopny efektivnÄ› alokovat vÃ½poÄetnÃ­ zdroje pÅ™i inference pro nejtÄ›Å¾Å¡Ã­ problÃ©my.

### SelhÃ¡nÃ­ pÅ™i exaktnÃ­m vÃ½poÄtu

ZvlÃ¡Å¡tÄ› alarmujÃ­cÃ­ je zjiÅ¡tÄ›nÃ­, Å¾e poskytnutÃ­ kompletnÃ­ho algoritmu Å™eÅ¡enÃ­ nevedlo ke zlepÅ¡enÃ­ vÃ½konnosti. Modely selhÃ¡valy i pÅ™i pouhÃ©m vykonÃ¡vÃ¡nÃ­ pÅ™edepsanÃ½ch krokÅ¯, coÅ¾ odhaluje limity nejen v objevovÃ¡nÃ­ strategiÃ­, ale i v konzistentnÃ­m logickÃ©m ovÄ›Å™ovÃ¡nÃ­ a v provÃ¡dÄ›nÃ­ ÃºkolÅ¯ krok po kroku.

NapÅ™Ã­klad v HanojskÃ½ch vÄ›Å¾Ã­ch dosÃ¡hly modely sprÃ¡vnÃ½ch sekvencÃ­ pÅ™es 100 krokÅ¯, zatÃ­mco v River Crossing selhaly jiÅ¾ po 4 krocÃ­ch u problÃ©mÅ¯ s kratÅ¡Ã­m celkovÃ½m Å™eÅ¡enÃ­m. Tato nekonzistence naznaÄuje, Å¾e vÃ½konnost nenÃ­ primÃ¡rnÄ› funkcÃ­ dÃ©lky sekvence, ale spÃ­Å¡e dostupnosti podobnÃ½ch vzorcÅ¯ v trÃ©novacÃ­ch datech.

## AnalÃ½za myÅ¡lenkovÃ½ch procesÅ¯

DetailnÃ­ rozbor postupu uvaÅ¾ovÃ¡nÃ­ odhalil urÄitÃ© zÃ¡konitosti Äi vzorce:

- **U jednoduchÃ½ch problÃ©mÅ¯**: Distribuce nesprÃ¡vnÃ½ch Å™eÅ¡enÃ­ je posunuta smÄ›rem ke konci uvaÅ¾ovÃ¡nÃ­ ve srovnÃ¡nÃ­ se sprÃ¡vnÃ½mi Å™eÅ¡enÃ­mi
- **U stÅ™ednÄ› sloÅ¾itÃ½ch problÃ©mÅ¯**: OpaÄnÃ½ trend - sprÃ¡vnÃ¡ Å™eÅ¡enÃ­ se objevujÃ­ pozdÄ›ji v sekvenci
- **U vysokÃ© sloÅ¾itosti**: Absence jakÃ½chkoli sprÃ¡vnÃ½ch Å™eÅ¡enÃ­ v celÃ©m prÅ¯bÄ›hu uvaÅ¾ovÃ¡nÃ­

Tyto vzorce dokumentujÃ­ omezenou schopnost samoopravy souÄasnÃ½ch LRM a potvrzujÃ­ hypotÃ©zu o existenci Å¡kÃ¡lovacÃ­ch bariÃ©r dneÅ¡nÃ­ho pÅ™Ã­stupu k AI prostÅ™ednictvÃ­m uvaÅ¾ujÃ­cÃ­ch jazykovÃ½ch modelÅ¯.

## Implikace pro vÃ½voj AI

VÃ½sledky zpochybÅˆujÃ­ souÄasnÃ© paradigma, Å¾e zvÃ½Å¡enÃ­ _inference-time resoning_ ÄasÅ¯  automaticky vede k lepÅ¡Ã­m reasoning schopnostem. MÃ­sto toho naznaÄujÃ­ existenci architektonickÃ½ch bottleneckÅ¯, kterÃ© brÃ¡nÃ­ efektivnÃ­mu Å¡kÃ¡lovÃ¡nÃ­ na sloÅ¾itÃ© problÃ©my.

> ğŸ’¡ **Inference-time reasoning** je schopnost AI modelu provÃ¡dÄ›t sloÅ¾itÃ© uvaÅ¾ovacÃ­ procesy bÄ›hem samotnÃ©ho pouÅ¾Ã­vÃ¡nÃ­ (inference), nikoli pouze spolÃ©hat na znalosti nauÄenÃ© bÄ›hem trÃ©ninku. Jde o proces, kdy model "pÅ™emÃ½Å¡lÃ­" nad problÃ©mem v reÃ¡lnÃ©m Äase a generuje mezikroky pÅ™ed poskytnutÃ­m finÃ¡lnÃ­ odpovÄ›di.


Pro nasazenÃ­ v reÃ¡lnÃ©m svÄ›tÄ› znamenajÃ­ tato zjiÅ¡tÄ›nÃ­, Å¾e souÄasnÃ© LRM:

- Mohou bÃ½t uÅ¾iteÄnÃ© pro problÃ©my stÅ™ednÃ­ sloÅ¾itosti s dobÅ™e definovanÃ½mi vzorci
- Nejsou spolehlivÃ© pro skuteÄnÄ› sloÅ¾itÃ© plÃ¡novacÃ­ Ãºlohy
- VyÅ¾adujÃ­ opatrnost pÅ™i aplikacÃ­ch vyÅ¾adujÃ­cÃ­ch konzistentnÃ­ logickÃ© ovÄ›Å™ovÃ¡nÃ­

### SmÄ›ry dalÅ¡Ã­ho vÃ½zkumu

Studie identifikuje nÄ›kolik kritickÃ½ch oblastÃ­ pro pokraÄujÃ­cÃ­ vÃ½zkum:

**ArchitektonickÃ© inovace**: PotÅ™eba novÃ½ch pÅ™Ã­stupÅ¯ k inferencÃ­m, kterÃ© pÅ™ekonajÃ­ souÄasnÃ© Å¡kÃ¡lovacÃ­ limity.

**TrÃ©novacÃ­ metodologie**: ZkoumÃ¡nÃ­ technik, kterÃ© by vedly k robustnÄ›jÅ¡Ã­mu algoritmickÃ©mu uvaÅ¾ovÃ¡nÃ­ mÃ­sto spolÃ©hÃ¡nÃ­ na pattern matching.

**EvaluaÄnÃ­ frameworky**: RozÅ¡Ã­Å™enÃ­ kontrolovanÃ½ch experimentÃ¡lnÃ­ch prostÅ™edÃ­ na Å¡irÅ¡Ã­ spektrum uvaÅ¾ovacÃ­ch Ãºloh.


## ZÃ¡vÄ›r

V Å™adÄ› pÅ™Ã­padÅ¯ se modely chovajÃ­ â€zdÃ¡nlivÄ› inteligentnÄ›â€œ, ale selhÃ¡vajÃ­ v generalizaci, v exekuci jasnÃ½ch pravidel nebo v plÃ¡novÃ¡nÃ­ pro opravdu sloÅ¾itÃ© Ãºlohy. Studie takÃ© nenaznaÄuje, Å¾e samotnÃ¡ velikost modelu nebo vÃ­ce dat problÃ©m vyÅ™eÅ¡Ã­. BariÃ©ra je spÃ­Å¡e v architektuÅ™e a schopnosti symbolickÃ© manipulace.

Tato studie poskytuje empiricky podloÅ¾enÃ½ pohled na skuteÄnÃ© schopnosti souÄasnÃ½ch Large Reasoning Models. ZatÃ­mco tyto systÃ©my pÅ™edstavujÃ­ pokrok v urÄitÃ½ch domÃ©nÃ¡ch, jejich fundamentÃ¡lnÃ­ omezenÃ­ v zobecnitelnÃ©m uvaÅ¾ovÃ¡nÃ­ jsou zÃ¡sadnÄ›jÅ¡Ã­, neÅ¾ pÅ¯vodnÄ› pÅ™edpoklÃ¡dÃ¡no.

VÃ½sledky nenaznaÄujÃ­, Å¾e reasoning modely jsou bezcennÃ©, ale spÃ­Å¡e definujÃ­ jasnÃ© hranice jejich pouÅ¾itÃ­. Pro vÄ›deckou komunitu to znamenÃ¡ potÅ™ebu pÅ™ehodnotit souÄasnÃ© pÅ™Ã­stupy k design inference-time reasoning a hledÃ¡nÃ­ novÃ½ch architektonickÃ½ch Å™eÅ¡enÃ­, kterÃ¡ by pÅ™ekonala identifikovanÃ© Å¡kÃ¡lovacÃ­ bariÃ©ry.

VnÃ­mÃ¡m zde nÄ›kolik otevÅ™enÃ½ch otÃ¡zek:

1. JakÃ½m zpÅ¯sobem lze modely nauÄit skuteÄnou generalizaci uvaÅ¾ovacÃ­ch postupÅ¯, nikoliv pouze **pattern matching** (tedy _zaloÅ¾enÃ© na rozpoznÃ¡vÃ¡nÃ­ vzorcÅ¯_) a napodobovÃ¡nÃ­ povrchovÃ½ch struktur?
2. Je moÅ¾nÃ© kombinovat souÄasnÃ© LLM s explicitnÃ­mi symbolickÃ½mi moduly nebo plÃ¡novaÄi pro zvÃ½Å¡enÃ­ robustnosti reasoning?
3. Do jakÃ© mÃ­ry jsou limity zpÅ¯sobeny architekturou modelu, RL trÃ©ninkem, nebo samotnÃ½m charakterem dat?


RozhodujÃ­cÃ­ bude, zda se podaÅ™Ã­ vyvinout systÃ©my skuteÄnÄ› schopnÃ© algoritmickÃ©ho uvaÅ¾ovÃ¡nÃ­, nebo zda zÅ¯staneme omezeni na sofistikovanÃ© metody, kterÃ© v podstatÄ› pouze rozpoznÃ¡vajÃ­ vzorce z trÃ©novacÃ­ch dat.