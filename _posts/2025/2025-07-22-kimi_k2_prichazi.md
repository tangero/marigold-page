---
author: Patrick Zandl
categories:
- AI
- Moonshot AI
- Kimi K2
- DeepSeek
layout: post
post_excerpt: Čína má být hony daleko za USA v AI, jenže vůbec. Na přelomu roku ten dojem rozbil DeepSeek, nyní přichází Kimi K2, který se jako open-source model má vyrovnat nejsilnějším americkým modelům. Použil na to několik chytrých triků...
summary_points:
- Kimi K2 má bilion parametrů s 32 miliardami aktivních, používá MoE architekturu
- Výkonnost 97,4% na MATH-500 překonává GPT-4.1 s 92,4%
- Cenová politika 0,15 dolaru za milion vstupních tokenů je o 30% levnější než Gemini 2.5 Flash
- Architektura přímo vychází z open-source DeepSeek V3 se čtyřmi klíčovými úpravami
- Trénování proběhlo na 15,5 trilionech tokenů s náklady kolem 5 milionů dolarů
- Model zaměřený na automatizované úkoly bez chain-of-thought uvažování
thumbnail: https://www.geeky-gadgets.com/wp-content/uploads/2025/07/kimi-k2-ai-model-review_optimized.jpg
title: "🇨🇳 Je Kimi K2 další čínský průlom v AI?"
---

Čína má být hony daleko za USA v AI, jenže vůbec. Na přelomu roku ten dojem rozbil DeepSeek, nyní přichází Kimi K2, který se jako open-source model má vyrovnat nejsilnějším americkým modelům. Použil na to několik chytrých triků...

Čínský startup Moonshot AI vydal 11. července 2025 open-source model Kimi K2, který má představovat další milník v rozvoji čínských jazykových modelů. S bilionem celkových parametrů se jedná o dosud největší veřejně dostupný open-source model, který podle testů dosahuje výkonnosti srovnatelné s komerčními řešeními od OpenAI a Anthropic.

Hlavní technologický průlom tkví v optimalizátoru MuonClip. Ten jako první umožnil stabilní trénování obřího modelu MoE (mixture-of-experts) na omezených čipech Nvidia H800 bez jediného výpadku. Výsledkem je křivka ztrát, kterou výzkumníci nazývají „nejkrásnější v historii strojového učení“[^1].

### Technická architektura a specifikace

Kimi K2 využívá architekturu Mixture-of-Experts (MoE) s celkem 384 experty, z nichž se pro každý dotaz aktivuje osm, což představuje zhruba 32 miliard parametrů. Tento přístup umožňuje zpracování rozsáhlých úloh při zachování výpočetní efektivity - aktivuje se pouze potřebná část modelu namísto celé struktury - zapojují se do řešení problému pouze ti experti, kteří k tomu mají co říct... 

| Parametr                  | Kimi K2          | DeepSeek V3     | GPT-4.1          |
| ------------------------- | ---------------- | --------------- | ---------------- |
| Celkový počet vah         | 1,0 bilionu      | 685 miliard     | neuveřejněno     |
| Aktivních vah na dotaz    | 32 miliardy      | 37 miliardy     | ~220 miliard     |
| Trénovací tokeny          | 15,5 bilionu     | 14,8 bilionu    | odhad 13 bilionů |
| Optimizer (optimalizátor) | MuonClip 2. řádu | AdamW           | neuveřejněno     |
| Odhadované náklady        | ~120 milionů Kč  | ~140 milionů Kč | ~2,3 miliardy Kč |


Model přímo navazuje na open-source architekturu DeepSeek V3, kterou tým Moonshot upravil ve čtyřech klíčových bodech. Počet expertů zvýšili z původních 256 na 384 po zjištění, že scaling laws platí i pro řídkost _(sparsity)_. Současně snížili počet "hlav pozornosti" _(attention heads)_ pro kompenzaci vyššího počtu expertů. Pouze první vrstvu ponechali jako hustou _(dense)_, zatímco všechny ostatní používají MoE pro maximalizaci efektivity. Všechny experty umístili do jedné skupiny namísto rozdělení do více skupin.

> Termín attention heads (česky „hlavy pozornosti“) pochází z mechanismu self-attention, který je klíčovou součástí architektury transofmátorů, na níž jsou postaveny dnešní jazykové modely jako Kimi K2, GPT nebo DeepSeek. Jedna attention head je samostatná výpočetní větev v mechanismu self-attention, která:
> - analyzuje vztahy mezi všemi tokeny v sekvenci (např. slovy ve větě),
> - má vlastní váhy (matice pro klíče, dotazy, hodnoty: Q, K, V),
> - se zaměřuje (attention) na jiné aspekty vstupu než ostatní hlavy.
> Více attention heads umožňuje modelu „dívat se“ na vstup z různých perspektiv současně:
> - jedna hlava může detekovat syntaktické vazby,
> - jiná může sledovat významové souvislosti,
> - další může sledovat strukturu vět nebo závislosti napříč větami.
> V klasické architektuře transfomátorů (např. BERT, GPT-2) je běžné mít 12–96 attention heads, podle velikosti modelu.

### Průlom v optimalizaci tréninku

Klíčovou technickou inovací Kimi K2 je použití [optimalizéru MuonClip](https://app.studyraid.com/en/read/30083/1291932/muonclip-optimizer-for-training-stability) místo [standardního AdamW](https://optimization.cbe.cornell.edu/index.php?title=AdamW). MuonClip přidává druhou úroveň pozorování, které sleduje nejen jak se model učí prostřednictvím gradientů, ale také jak se tyto gradienty mění. Tato metoda umožňuje ostřejší a stabilnější aktualizace během tréninku.

Druhým prvkem je mechanismus QK-clipping v pozornostní vrstvě, který funguje jako pojistka proti destabilizaci systému. Když model kalkuluje vztahy mezi slovy násobením 'query' a 'key' vah, QK-clipping omezuje tyto hodnoty před jejich případnou spirálou mimo kontrolu.

Výsledkem je trénování na 15,5 trilionech tokenů - zhruba padesátkrát více než GPT-3 - bez jediného loss spike, katastrofického pádu nebo restartu. Stabilita tréninku významně snížila náklady na přibližně 5 milionů dolarů, což je zlomek běžných nákladů na modely této velikosti.

## Výkonnostní parametry a srovnání

V benchmark testech Kimi K2 dosahuje 97,4% úspěšnosti na MATH-500, zatímco GPT-4.1 dosahuje 92,4%. Na LiveCodeBench dosahuje 53,7% oproti 44,7% u GPT-4.1. V oblasti automatizovaného programování (SWE-bench Verified) dosahuje 65,8% a na MultiPL-E coding tasks 85,7%.

Praktické testování ukázalo schopnosti srovnatelné s Claude 4. Při vytváření kompletní PDF chat aplikace s FastAPI backendem a JavaScript frontendem Kimi K2 dodal funkční řešení, přestože trvalo dvakrát déle než u Claude. Výsledná aplikace byla bez chyb a nevyžadovala ladění.

Model vyniká v kreativním psaní, kde podle benchmarků dosahuje nejlepších výsledků mezi současnými modely. Na rozdíl od reasoning modelů negeneruje dlouhé řetězce uvažování před odpovědí, ale byl rozsáhle trénován pomocí posilujícího učení.

A čeština? Provedl jsem pár pokusů, musím říct, že výsledky jsou hodně impresivní. Například jsem použil svůj prompt "patrikizátor", který používám na ladění textů. Jeho smyslem je vytahat technické informace a udělat z nich čitelný text, což se mu o sobě samém (Kimi K2) podařilo lépe, než se daří Claude Sonet 4. 


## Cenová strategie a dostupnost

Moonshot AI stanovil ceny na 0,15 dolaru za milion vstupních tokenů a 2,50 dolaru za milion výstupních tokenů. To představuje 30% úsporu oproti Gemini 2.5 Flash a řádové snížení nákladů oproti Claude 4 Opus (15/75 dolarů) nebo GPT-4.1 (2/8 dolarů).

Vyšší verbóznost modelu však zvyšuje praktické náklady na provoz. Podle analýzy Artificial Analysis používá Kimi K2 až o 30% méně tokenů než Claude 4 Sonnet v maximálním režimu, ale téměř trojnásobek při vypnutém uvažování.

## Obchodní pozadí Moonshot AI

Společnost založil Yang Zhilin, absolvent Tsinghua University s PhD z Carnegie Mellon, který pracoval v Meta AI a Google Brain. Na rozdíl od DeepSeek, který financuje hedge fund High Flyer, Moonshot operuje s tradičním VC financováním v hodnotě 1 miliardy dolarů s Alibaba jako největším investorem. Musí tedy rychleji ukázat zisk. Jejich recept je překvapivě prozaický: nabídnout výkon drahých modelů za desetinu ceny.


Moonshot se zaměřuje výhradně na individuální uživatele prostřednictvím [chatbota Kimi](https://www.kimi.com/), který používá přes 100 milionů čínských uživatelů. 

Při pohledu [na ceník API](https://platform.moonshot.ai/docs/pricing/chat) je rozdíl markantní. Kimi K2 účtuje 3,50 Kč za milion vstupních tokenů a 58 Kč za milion výstupních. Claude 3.5 Sonnet přitom žádá 29 Kč/290 Kč. Pro firmy, které denně zpracovávají miliony tokenů, jde o úsporu ve statisících měsíčně.

**Jak mění ekosystém?**

První týden po vydání se Kimi K2 vyšplhalo na první místo v žebříčku využití na platformě OpenRouter, před Grok 4 a Llama 3.1. Za tím stojí kombinace tří faktorů:
- Komerční licence Apache 2.0 umožňuje firmám model přímo hostovat ve vlastní infrastruktuře bez obav z právních postihů.
- Velikost aktivních vah 32 miliard znamená, že se vejde na čtyři A100 80 GB – konfigurace dostupná i menším českým firmám.
- Zaměření na agentní úlohy – model je trénovaný především na volání funkcí, práci s nástroji a kódování, což jsou oblasti, kde se dá snadno měřit ROI.

Pokud Kimi K2 přidá v příští verzi řetězové myšlení (chain-of-thought) a vyladí politickou cenzuru (což řeší například Perplexity svou úpravou), může se stát prvním open-source modelem, který opravdu nahradí Claude Sonnet ve firmách. Zvlášť když jeho provozní náklady jsou srovnatelné s provozem interního systému, nikoli s placením dolarů za každý dotaz.

Silicon Valley zatím reaguje zdrženlivě. OpenAI stále odkládá vydání vlastního open-source modelu a Anthropic drží ceny vysoko. Mezitím čínské laboratoře dokazují, že se dá jet i rychleji a levněji. Kimi K2 není jen technologický skok, ale varovný signál: algoritmické inovace začínají převážovat nad čistým výkonem hardwaru.


### Vztah k DeepSeek a open-source kultuře

Kimi K2 přímo staví na architektuře DeepSeek V3. Inženýr Liu Shaowei z Moonshot na platformě Zhihu vysvětlil, že před zahájením tréninku K2 provedli rozsáhlé experimenty s architekturou modelů, ale žádná navržená architektura nedokázala překonat DeepSeek V3.

"Důvod je jednoduchý: architektura V3 byla validována a zůstává efektivní ve velkém měřítku, zatímco naše 'nové architektury' ještě neprošly dostatečnou large-scale validací," uvedl Liu.

Tento přístup ilustruje sílu open-source kultury v čínském AI výzkumu. Jak poznamenal inženýr Su Jianlin: "Rozhodli jsme se vzdát hold DeepSeek replikováním jejich MLA designu."

Úspěch DeepSeek změnil postoj Yang Zhilina k open source. Ještě v únoru 2024 tvrdil, že open-source modely nemohou rychle dohnat closed-source řešení. Po úspěchu DeepSeek však Moonshot vydal K2 jako open-source.

### Technologie pro automatizované úkoly

Moonshot označuje K2 jako "open agentic intelligence" s důrazem na automatizované schopnosti. Model byl trénován na masivních objemech syntetických dat vytvořených speciálně pro napodobení real-life aplikací a optimalizován pro tool-calling.

Vývojový proces zahrnoval generování stovek scénářů (food delivery, sociální sítě), tisíců nástrojů a stovek tisíc různých agentů s různými system prompty a sadami nástrojů. Následně proběhly large-scale simulace agentů s hodnocením podle kritérií úspěšnosti.

Na rozdíl od _chain-of-thought_ modelů, K2 nevyžaduje dlouhé uvažovací sekvence před odpovědí, což ho činí vhodným pro praktické automatizované úkoly vyžadující rychlé execution.

### Vliv na globální AI ekosystém

Vydání Kimi K2 potvrzuje, že čínské laboratoře mohou vytvářet konkurenceschopné modely i různými jinými cestami než DeepSeek. Moonshot prokázal, že i s tradičním VC financováním a investorskými tlaky lze dosáhnout špičkových výsledků.

Západní laboratoře jako OpenAI, které odložily vydání vlastních open-source modelů, ztrácejí kontrolu nad narrativem v open-source oblasti. Perplexity již oznámila plány na post-training K2 pro své uživatele, což umožní necenzurovanou verzi modelu podobně jako u DeepSeek R1.

Model je v souladu s čínskými zákony, což znamená omezení při dotazech na citlivá politická témata. Tato omezení však platformy jako Perplexity obcházejí vlastním post-trainingem. Proto je důležité, že je fork Kimi K2 dostupný přes americké firmy. Podle dashboardu Openrouteru má K2 provoz vyšší, než nedávno představený Grok 4. 

Kimi K2 představuje důkaz, že inovace v oblasti AI efektivity se přesunuly do Pekingu namísto Palo Alta. Dva významné algoritmické průlomy - Group-Relative PPO od DeepSeek a MuonClip od Moonshot - publikované pod permisivními licencemi během šesti měsíců posunuly těžiště výzkumu směrem k Číně.

## Technické odkazy a dostupnost

Model Kimi K2 je dostupný prostřednictvím [Moonshot AI API](https://platform.moonshot.cn) a [Hugging Face](https://huggingface.co/moonshot-ai). Technická dokumentace a implementační detaily jsou publikovány na [Moonshot AI blogu](https://www.moonshot.ai/blog) a [GitHubu](https://github.com/moonshot-ai).

Kompletní kódová základna včetně MuonClip optimizéru bude uvolněna v následujících týdnech podle oznámení vývojového týmu na platformě Zhihu.

[^1]: Jde o velmi hladký, monotónně klesající graf, který zobrazuje, jak se chyba modelu (ztrátová funkce) během trénování neustále zmenšuje – bez výkyvů, stagnací či náhlých skoků. Taková dokonale pravidelná křivka je v praxi obřích jazykových modelů výjimečná; obvykle se grafy „kousají“ a trénink musí restartovat. Když se tohle nestane, působí to na výzkumníky esteticky a technicky – odtud ta nadsázka „nejkrásnější“. _(toto vysvětlení pro vás napsal Kimi K2 a vysvětlil mi, jak dát poznámku pod čarou v markdown formátování)_