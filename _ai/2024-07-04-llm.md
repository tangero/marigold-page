---
date: 2024-07-05
layout: post
order: 1
title: Jak fungují velké jazykové modely LLM - co se děje po zadání promptu
---

Fungování velkých jazykových modelů (LLM) po zadání promptu je proces, který kombinuje algoritmy, masivní [neuronové sítě](/ai/neuronove-site/) a komplexní zpracování dat. Abyste měli lepší představu, jak moderní AI na bázi LLM funguje, je dobré podívat se krok za krokem, jak tento proces probíhá od okamžiku, kdy uživatel zadá prompt, až po generování finální odpovědi.

### 1. Zadání promptu
Vše začíná, když uživatel [zadá textový prompt](/ai/prompt/) do rozhraní LLM. Tento prompt může být otázka, instrukce, nebo jakýkoli jiný textový vstup. Například: “Vysvětli mi, jak funguje fotosyntéza u rostlin.”

### 2. Tokenizace
Jakmile je prompt zadán, prvním krokem je tokenizace. Tokenizace rozděluje text na menší jednotky zvané [tokeny](/ai/tokeny-versus-slova/). Tyto [tokeny](/ai/tokeny-versus-slova/) mohou být slova, části slov, nebo dokonce jednotlivé znaky, v závislosti na použitém tokenizačním algoritmu. Ve [zvláštním článku vysvětluji](/ai/tokenizace-textu/), jaký je rozdíl mezi slovy a [tokeny](/ai/tokeny-versus-slova/) a proč se mechanismus [tokenů](/ai/tokeny-versus-slova/) používá. 
Pro náš příklad by tokenizace mohla vypadat takto:
[“Vysvětli”, “mi”, “,”, “jak”, “funguje”, “foto”, “syntéza”, “u”, “rostlin”, “.”]

Moderní LLM často používají metody tokenizace jako *Byte-Pair Encoding (BPE)* nebo *SentencePiece*, které umožňují efektivnější zpracování méně častých slov a různých jazyků. Všimněte si, že slovo “fotosyntéza” bylo rozděleno na dva [tokeny](/ai/tokeny-versus-slova/).

### 3. Numerická reprezentace
Po tokenizaci je každý [token](/ai/tokeny-versus-slova/) převeden na numerickou reprezentaci pomocí velkého vyhledávacího slovníku, kde každý [token](/ai/tokeny-versus-slova/) má přiřazené unikátní číslo.

### 4. Kontextové okno
LLM mají omezený počet [tokenů](/ai/tokeny-versus-slova/), které mohou zpracovat najednou, tzv. *kontextové okno*. Toto okno může být například 2048 nebo 4096 tokenů, u nejmodernějších LLM i statisíce tokenů. Vše v tomto okně slouží jako kontext pro generování odpovědi, tedy informace, která může být relevantní a použita k upřesnění generované odpovědi. 

### 5. Zpracování neuronovou sítí
Nyní přichází na řadu jádro LLM - *masivní [neuronová síť](/ai/neuronove-site/)*, obvykle založená na architektuře *[Transformátorů](/ai/transformatory/)*. Tato síť se skládá z mnoha vrstev a může mít miliardy parametrů.

**a) Token embeddings vrstva**
První vrstva po samotné tokenizaci převádí numerické reprezentace tokenů na vektory s plovoucí desetinnou čárkou, které zachycují sémantické vlastnosti tokenů.

Po tokenizaci je každému tokenu přiřazeno jeho ID ze slovníku (např. token "kočka" má ID 587). Tato ID jsou pak převedena na vektory s plovoucí desetinnou čárkou - tzv. embeddings. Je to v podstatě vyhledávací tabulka (lookup table), kde každému ID je přiřazen vektor čísel (například vektor o délce 768 nebo 1024 dimenzí). Tyto vektory jsou nastaveny během trénování tak, aby tokeny s podobným významem měly podobné vektorové reprezentace - zachycují tedy sémantické vlastnosti tokenů.
Příklad:

- Slovo "kočka" (ID 587) → [0.2, -0.5, 0.1, ..., 0.3]
- Slovo "kocour" (ID 892) → [0.19, -0.48, 0.15, ..., 0.28]
(podobný vektor, protože významy jsou podobné)
- Slovo "auto" (ID 245) → [-0.8, 0.2, -0.4, ..., -0.1]
(velmi odlišný vektor, protože význam je odlišný)

**b) Pozornostní mechanismus (Self-attention)**
Klíčovou součástí [architektury Transformátorů](/ai/transformatory) je mechanismus pozornosti (attention mechanism). Mechanismus pozornosti umožňuje rozhodnout se, jaká část z jinak "plochého" textového vstupu je více či méně hodná pozornosti. Pro každý token ve vstupní sekvenci tento mechanismus vypočítává:

1. Query (Q) - dotaz: co token "hledá"
2. Key (K) - klíč: čím token "odpovídá" na dotazy
3. Value (V) - hodnota: jakou informaci token "poskytuje"

Funguje to následovně:
- Pro každý token se jeho Query porovná s Keys všech ostatních tokenů (včetně sebe sama)
- Toto porovnání vytvoří "attention scores" - čísla určující, jak moc by měl daný token věnovat pozornost ostatním tokenům
- Tyto skóre se normalizují pomocí softmax funkce na pravděpodobnostní distribuci
- Nakonec se vypočtené attention scores použijí jako váhy pro Values příslušných tokenů

Příklad:
Věta: *"Kočka, která honí myš, je černá."*
- Když model zpracovává slovo "je", mechanismus pozornosti mu umožní zaměřit se silně na slovo "kočka", protože to je podmět věty
- Při zpracování slova "černá" se model může znovu zaměřit na "kočka", protože to je předmět, který je popisován. 
Tím počítač z jinak plochého sdělení může pochopit, že to, co honí myš, je kočka a tato kočka je černá. 

Moderní LLM typicky používají:
- Multi-head attention: několik pozornostních mechanismů běžících paralelně
- Masked attention v případě generativních modelů: při generování může model věnovat pozornost pouze předchozím tokenům, ne budoucím

Tento mechanismus je klíčový pro schopnost LLM porozumět kontextu a dlouhodobým závislostem v textu.

**c) Feed-forward vrstvy (FFN)**
Po tom, co attention mechanismus umožnil obohatil tokeny o potřebný kontext, přichází feed-forward síť (FFN). Ta představuje možnost, jak pro každý token zpracovat a tedy "promyslet" všechny informace, které nyní dostává. 

Představte si to jako třífázový proces:

1. Rozšíření informací
- Token nejprve "rozbalí" všechny svoje informace do většího prostoru
- Je to jako když si rozložíte puzzle na větší stůl a obrátíte obrázkem nahoru, abyste lépe viděli všechny dílky

2. Zpracování informací 
- Aplikuje se aktivační funkce (GELU/ReLU), která některé informace zvýrazní a jiné potlačí
- Je to jako když z rozložených dílků puzzle vyberete ty, které jsou pro vás v danou chvíli důležité - třeba ty okrajové

3. Shrnutí
- Nakonec se všechny zpracované informace opět "sbalí" do původní velikosti
- Jako když poskládáte vybrané dílky puzzle zpět do kompaktního celku

Důležité je, že každý token tímto procesem prochází samostatně - je to jeho "osobní čas na přemýšlení" o všem, co se dozvěděl z attention mechanismu. 

Proto je tento proces velmi náročný na výpočetní sílu a čas a dělá to problematickým zpracování rozsáhlých kontextů, tedy rozsáhlých vstupů, například rozsáhlých textů. Každý jednotlivý token musí být propočítán s ohledem na všechny ostatní tokeny. 

Výsledek se pak přičte k původním informacím tokenu (jako když si k původním poznámkám přidáte nové postřehy) a celé se to "učeše" pomocí normalizace, aby další vrstvy mohly efektivně pracovat s aktualizovanými informacemi.

### 6. Generování výstupu
Po zpracování vstupního promptu neuronovou sítí začíná proces generování odpovědi. Tento proces je iterativní a probíhá token po tokenu. 



**a) Predikce dalšího tokenu**
Model používá své vnitřní reprezentace a naučené vztahy k predikci pravděpodobnostního rozdělení nad všemi možnými následujícími tokeny.  Například:

"Petr šel do obchodu koupit..."

V tomto momentě model:
1. Vezme všechna možná slova ze svého slovníku (třeba 50 000 možností)
2. Každému slovu přiřadí pravděpodobnost, že by mělo být další v pořadí
3. Například:
   - "chleba" - 35% pravděpodobnost
   - "mléko" - 25% pravděpodobnost
   - "jablka" - 15% pravděpodobnost
   - "auto" - 0.001% pravděpodobnost
   - (a tak dále pro všechna slova)

Model přiřazuje vyšší pravděpodobnosti slovům, která dávají v daném kontextu největší smysl. Slova, která nedávají smysl (jako "auto" v našem příkladu nákupu), dostanou velmi nízkou pravděpodobnost.

Tento proces se opakuje pro každé další slovo, přičemž každé nově přidané slovo ovlivňuje pravděpodobnosti slov následujících.

**b) Výběr tokenu**
Z tohoto pravděpodobnostního rozdělení je vybrán další token. LLM obvykle používají techniku zvanou sampling, kdy vybírají z několika nejpravděpodobnějších možností. To do jisté míry přidává elementy kreativity a variability do odpovědí, tzn. odpovědi na stejné prompty jsou různé. Je významnou součástí ladění modelu nastavení samplingu, tedy rozpětí pravděpodobností, z nichž model vybírá. Tedy to, jestli v našem případě může vybírat ze slov chleba, mléko, ale i ještě jablko, nebo už je jablko příliš málo pravděpodobné. Toto nastavení vytváří rozpětí mezi nudnými a správnými odpověďmi a inspirativními nebo šílenými na druhém pólu... 

**c) Zpětná vazba**
Vybraný token je přidán k dosud vygenerovanému výstupu a také je použit jako vstup pro další krok generování. Tento proces se opakuje, dokud není vygenerován speciální token označující konec sekvence, nebo dokud není dosaženo maximální délky výstupu.

### 7. Post-processing
Po vygenerování surového výstupu následuje detokenizace (převod tokenů zpět na čitelný text), případná filtrace obsahu a formátování.

### 8. Zobrazení odpovědi
Konečně, zpracovaná a formátovaná odpověď je zobrazena uživateli.

## Klíčové koncepty a pokročilé techniky

Nyní, když jsme prošli základní proces, pojďme se podívat na některé klíčové koncepty a pokročilé techniky, které jsou důležité pro pochopení fungování moderních LLM.

### 1. Princip predikce následujícího slova

Je důležité pochopit, že jádrem fungování LLM je předpovídání následujícího slova (nebo tokenu) na základě předchozího kontextu. Tento jednoduchý princip je základem pro všechny sofistikované schopnosti, které LLM vykazují.

### 2. Fáze trénování

Před samotným použitím prochází LLM třemi hlavními fázemi trénování:

a) Pre-training: Model se učí předpovídat další slovo na obrovském množství textových dat, získávajíc tak široké znalosti o jazyce a světě.

b) Instruction fine-tuning: Model se učí reagovat na konkrétní instrukce a otázky, což mu pomáhá chovat se více jako asistent.

c) Reinforcement Learning from Human Feedback (RLHF): Tato fáze dále vylepšuje model tak, aby jeho odpovědi byly více v souladu s lidskými preferencemi a hodnotami.

### 3. Emergentní schopnosti

S rostoucí velikostí modelu a množstvím tréninkových dat se u LLM objevují emergentní schopnosti - schopnosti, které nebyly explicitně natrénovány. Mezi tyto schopnosti patří například:

- Řešení víceúrovňových úloh
- Few-shot learning (schopnost učit se z několika příkladů)
- Řešení matematických problémů
- Generování kódu

### 4. Techniky pro zlepšení výkonu

Existuje několik technik, které mohou výrazně zlepšit výkon LLM:

a) Chain-of-thought prompting: přístup, kdy model “myslí krok za krokem”, což může zlepšit jeho schopnost řešit komplexní úlohy. Tento přístup vlastně rozkládá úlohu na jednodušší úlohy, přičemž LLM (stejně jako člověk) lépe zvládá více zřetězených jednodušších úloh, než jednu složitou.  Model tak dostává “pracovní paměť” v podobě mezivýsledků, které jsou součástí kontextu pro další generování.

b) Few-shot learning: Pokud je poskytnuto v promptu několik příkladů, může to pomoci modelu lépe pochopit požadovaný formát nebo styl odpovědi. Proto také prompty obohacujeme žádostmi, v jakém formátu či stylu a odborností požadujeme výstupy, aby to LLM nemusel odhadovat. 

c) Retrieval-Augmented Generation (RAG): Kombinace LLM s vyhledáváním v externí databázi znalostí může zlepšit přesnost a aktuálnost odpovědí. Tato technika je zvláště užitečná pro překonání omezení spojených s cut-off datem tréninkových dat.

### 5. Omezení a výzvy

I přes své schopnosti mají LLM několik významných omezení:

a) [Halucinace](/ai/halucinace-ai/): LLM mohou někdy generovat nepravdivé nebo zavádějící informace, zejména když jsou dotázány na něco, co je mimo jejich tréninkový dataset. To je částečně způsobeno tím, že model je trénován pouze na generování pravděpodobného textu, ne nutně fakticky správného textu. [Podrobněji probíráme zde](/ai/halucinace-ai/).

b) Kontextové okno: Omezená velikost kontextového okna limituje schopnost modelu pracovat s velmi dlouhými dokumenty nebo udržet kontext v dlouhých konverzacích.

c) Aktuálnost informací: LLM jsou omezeny na informace, na kterých byly natrénovány, a nemohou přímo přistupovat k aktuálním informacím (pokud nejsou kombinovány s RAG).

d) Etické otázky: Použití LLM vznáší řadu etických otázek, včetně potenciálních předsudků, vlivu na soukromí a autorských práv.

## Závěr

Fungování LLM po zadání promptu je proces, který kombinuje hluboké strojové porozumění jazyku s pokročilými algoritmy [strojového učení](/ai/strojove-uceni-machine-learning/). Je podle mne velmi zajímavé, jak je to na jednu stranu odlišné od lidského postupu uvažování (to je ta část tokenizace, tedy převodu jazyka na čísla) a na stranu druhou je další postup už velmi podobný lidskému přemýšlení a učení. 

Zároveň je důležité si uvědomit, že LLM stále mají svá omezení, zejména v oblasti [halucinací](/ai/halucinace-ai/). Proto je kritické myšlení a ověřování informací stále nezbytné. 

S pokračujícím výzkumem a vývojem v oblasti AI můžeme očekávat další vylepšení těchto systémů. Budoucí vývoj se pravděpodobně zaměří na překonávání současných omezení, jako je velikost kontextového okna, aktuálnost informací a problém [halucinací](/ai/halucinace-ai/). Zároveň můžeme očekávat pokrok v oblasti multimodálních modelů, které budou schopny zpracovávat nejen text, ale i obrázky, zvuky a videa v jednotném rámci.