<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://www.marigold.cz/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.marigold.cz/" rel="alternate" type="text/html" /><updated>2025-05-18T14:09:39+00:00</updated><id>https://www.marigold.cz/feed.xml</id><title type="html">Marigold.cz</title><subtitle>Technologie a Svět</subtitle><author><name>Patrick Zandl</name></author><entry xml:lang="cs"><title type="html">OpenAI představuje Codex - agenta pro vývoj software</title><link href="https://www.marigold.cz/item/openai-codex/" rel="alternate" type="text/html" title="OpenAI představuje Codex - agenta pro vývoj software" /><published>2025-05-18T00:00:00+00:00</published><updated>2025-05-18T00:00:00+00:00</updated><id>https://www.marigold.cz/item/openai-codex</id><content type="html" xml:base="https://www.marigold.cz/item/openai-codex/"><![CDATA[<h1 id="openai-představuje-codex---agenta-pro-vývoj-software">OpenAI představuje Codex - agenta pro vývoj software</h1>

<p>OpenAI představila “výzkumnou preview verzi” nového nástroje nazvaného <a href="https://chatgpt.com/codex">Codex</a>. Tedy nejde o totální novinku, Codex již byl předsaven jako aplikace Codex CLI pro příkazovou řádku, nyní jde ale o kompletnější webové rozhraní. Ačkoliv nedosahuje komplexnosti služeb jako Lovable, jde o zajímavého agenta pro vývoj software.</p>

<p>Hlavní výhodou Codexu má být schopnost paralelně pracovat na mnoha úkolech. Podívejme se detailně na to, co tento nástroj přináší, jaké jsou jeho možnosti a omezení.</p>

<h2 id="co-je-codex">Co je Codex?</h2>

<p>Codex je cloudový software založený na modelu codex-1, což je verze modelu OpenAI o3 optimalizovaná pro softwarové inženýrství. Podle dokumentace byl tento model trénován pomocí reinforcement learning na reálných úkolech kódování v různých prostředích. Hlavním cílem bylo generovat kód, který napodobuje lidský styl psaní, přesně dodržuje instrukce a dokáže iterativně spouštět testy, dokud nedosáhne úspěšného výsledku.</p>

<p><img src="/assets/codex-landing.jpg" alt="codex" /></p>

<h2 id="dostupnost-a-rozšíření">Dostupnost a rozšíření</h2>

<p>V současné době je Codex <strong>dostupný pro uživatele ChatGPT Pro,</strong> ChatGPT Enterprise a ChatGPT Team. OpenAI plánuje v budoucnu rozšířit dostupnost i pro uživatele ChatGPT Plus a ChatGPT Edu. Během výzkumné preview fáze mají uživatelé k dispozici “velkorysý přístup bez dodatečných nákladů” po dobu několika týdnů. Následně OpenAI plánuje zavést cenovou politiku s možností dokoupit dodatečné využití podle potřeby.</p>

<h2 id="jak-codex-funguje">Jak Codex funguje</h2>

<p>Přístup k Codexu je možný přes postranní panel v ChatGPT. Uživatelé mohou zadat nové úkoly kódování zadáním promptu a kliknutím na tlačítko “Code”. Pro dotazy na kódovou základnu lze použít tlačítko “Ask”.</p>

<p>Každý úkol je zpracováván nezávisle v samostatném izolovaném prostředí, které je předem naplněno kódovou základnou uživatele. Codex může číst a upravovat soubory, spouštět příkazy včetně testů, lintu a kontroly typů. Uživatel může sledovat postup v reálném čase. Dokončení úkolu typicky trvá mezi 1 a 30 minutami v závislosti na složitosti. Po dokončení úkolu Codex provede commit svých změn ve svém prostředí a poskytne ověřitelné důkazy o svých akcích prostřednictvím citací terminálových logů a výstupů testů.</p>

<p>Uživatel pak může zkontrolovat výsledky, požádat o další revize, otevřít GitHub pull request nebo přímo integrovat změny do svého lokálního prostředí.</p>

<h2 id="agentsmd-soubory">AGENTS.md soubory</h2>

<p>Zajímavým prvkem je možnost řídit Codex pomocí AGENTS.md souborů umístěných v repozitáři. Tyto textové soubory, podobně jako README.md, umožňují informovat Codex o tom, jak se orientovat v kódové základně, jaké příkazy spouštět pro testování a jak nejlépe dodržovat standardní postupy projektu. Podle OpenAI codex-1 vykazuje dobré výsledky i bez těchto souborů, ale jejich přítomnost může zlepšit efektivitu práce.</p>

<h2 id="výkonnost-a-hodnocení">Výkonnost a hodnocení</h2>

<p>OpenAI poskytla několik měřítek výkonnosti codex-1:</p>

<ul>
  <li>Na benchmarku SWE-Bench Verified dosahuje codex-1 přesnosti kolem 70-75%, což je významně více než o3-high (kolem 65-70%)</li>
  <li>Na interních SWE úkolech OpenAI dosahuje codex-1 přibližně 75% úspěšnosti, ve srovnání s o4-mini-high (70%), o3-high (67%) a o1-high (11%)</li>
</ul>

<p><img src="/assets/codex-swe-bench.png" alt="swe" /></p>

<h2 id="bezpečnost-a-zajištění-důvěryhodnosti">Bezpečnost a zajištění důvěryhodnosti</h2>

<p>OpenAI zmiňuje několik bezpečnostních opatření implementovaných v Codexu. Jde především o transparentnost, kdy uživatelé mohou verifikovat výstupy prostřednictvím citací, terminálových logů a výsledků testů. Při nejistotě nebo selhání testů agent explicitně komunikuje tyto problémy. Codex operuje v zabezpečeném izolovaném kontejneru v cloudu a během provádění úkolu má zakázán přístup k internetu - interaguje pouze s kódem poskytnutým přes GitHub repozitáře a předinstalované závislosti.</p>

<p>Přesto OpenAI zdůrazňuje, že je stále nezbytné, aby uživatelé manuálně kontrolovali a validovali veškerý agentem generovaný kód před integrací a spuštěním.</p>

<h2 id="prevence-zneužití">Prevence zneužití</h2>

<p>OpenAI uvádí, že implementovali opatření proti zneužití tohoto nástroje pro vývoj škodlivého softwaru:</p>

<ul>
  <li>Codex byl trénován k identifikaci a odmítnutí požadavků zaměřených na vývoj škodlivého softwaru</li>
  <li>Současně by měl rozlišovat a podporovat legitimní úkoly</li>
  <li>OpenAI zdokonalila své politiky a začlenila přísná bezpečnostní hodnocení</li>
</ul>

<p>Jako dodatek k dokumentaci o3 System Card byla publikována aktualizace odrážející tato hodnocení.</p>

<h2 id="běžné-případy-použití">Běžné případy použití</h2>

<p>Technické týmy OpenAI již používají Codex jako součást svého každodenního pracovního postupu. Nejčastěji se používá pro refaktorizaci kódu, přejmenování proměnných a funkcí, psaní testů, vytváření základů nových funkcí, propojování komponent, opravy chyb a tvorbu dokumentace.</p>

<p>Vývojáři OpenAI si díky tomuto nástroji vytvářejí nové pracovní návyky jako třídění problémů v pohotovostní službě, plánování úkolů na začátku dne a delegace práce na pozadí. Mezi externí testovací organizace patří Cisco, Temporal, Superhuman a Kodiak.</p>

<p><img src="/assets/Codex_Citations_02.webp" alt="codex" /></p>

<h2 id="aktualizace-codex-cli">Aktualizace Codex CLI</h2>

<p>Současně s uvedením Codexu OpenAI vydává menší verzi codex-1, která je verzí o4-mini optimalizovanou specificky pro Codex CLI. Tento model podporuje rychlejší pracovní postupy v CLI a je optimalizován pro dotazy a úpravy kódu s nízkou latencí.</p>

<p>Model je dostupný jako výchozí v Codex CLI a v API jako codex-mini-latest. Cenově je nastaven na:</p>
<ul>
  <li>$1.50 za 1M vstupních tokenů</li>
  <li>$6 za 1M výstupních tokenů</li>
  <li>75% sleva při cachování promptů</li>
</ul>

<h2 id="omezení-a-budoucí-vývoj">Omezení a budoucí vývoj</h2>

<p>Codex je stále v rané fázi vývoje a má několik omezení. Chybí mu možnost vstupů formou obrázků pro frontend práci, není možné korigovat agenta během jeho práce a delegování úkolu vzdálenému agentovi trvá déle než interaktivní úpravy.</p>

<p>OpenAI plánuje v budoucnu zavést interaktivnější a flexibilnější pracovní postupy, umožnit poskytování pokynů v průběhu úkolu, spolupracovat na strategiích implementace a posílat proaktivní aktualizace o pokroku. Dále chce vytvořit hlubší integrace s nástroji jako GitHub, Codex CLI, ChatGPT Desktop nebo systémy pro sledování problémů a CI.</p>

<h2 id="technické-parametry-modelu-codex-mini-latest">Technické parametry modelu codex-mini-latest</h2>

<p>Codex-mini-latest je doladěná verze o4-mini specificky určená pro použití v Codex CLI:</p>
<ul>
  <li>200K kontextové okno</li>
  <li>100K max výstupních tokenů</li>
  <li>Podpora “reasoning tokens”</li>
</ul>

<h2 id="něco-málo-osobní-zkušenosti">Něco málo osobní zkušenosti</h2>

<p>Zkušenosti jsou zatím krátké. Zatím se ukazuje, že Codex dokáže dosti spolehlivě opravovat chyby, což by mohlo vést k plně automatizovanému procesu oprav a ušetřit značné množství času. Uživatelské rozhraní je pohodlnější, než Codex CLI v příkazové řádce, je to o dost intuitivnější a vůbec mi nechybí přehršel oken Cursoru. Jenže Cursor zatím také neodinstaluju…</p>

<p>Codex není jen pasivní nástroj. Aktivně se zapojuje do pracovního procesu. Umí číst a upravovat soubory a spouštět různé příkazy, včetně testovacích nástrojů, linterů a kontroly typů. Tyto funkce pomáhají zajistit kvalitu kódu a odhalit potenciální problémy v rané fázi vývoje. Testovací nástroj funguje jako kontrola funkčnosti, lint jako nástroj pro hygienu a styl kódu a kontrola typů zajišťuje správné používání proměnných.</p>

<p>Dokončení úkolu s pomocí Codex obvykle trvá od 1 do 30 minut (ano, občas je to dlouhý!). Pro zajištění transparentnosti a důvěryhodnosti poskytuje Codex ověřitelné důkazy o svých akcích prostřednictvím citací z terminálových protokolů a výstupů testů.</p>

<p>Flexibilita je další důležitou vlastností Codex. Jeho prostředí lze do jisté míry konfigurovat tak, aby co nejvíce odpovídalo konkrétnímu vývojovému prostředí uživatele. Chování Codex lze dokonce řídit pomocí speciálního souboru agents.md umístěného v úložišti kódu.</p>

<p>Testování ukázalo, že Codex 1 dokáže pracovat s maximální délkou kontextu 192 000 tokenů a důsledně vytváří čistší patche připravené k okamžité integraci do standardních pracovních postupů. Přístup Codex k psaní kódu spočívá v práci v malých, cílených dávkách, které se zaměřují na konkrétní problémy.</p>

<p>V praxi Codex umožňuje vývojářům efektivně nastavit základy projektu a zaměřit se na implementaci aktuálních funkcí. Celkově nástroj mění způsob práce vývojářů, umožňuje jim pracovat téměř jako by byli svým vlastním týmem nebo manažerem týmu, s možností zadávat problémy a vracet se k nim po určité době.</p>

<p>Dalším zajímavým použitím by mohlo být automatizované opravování issues v gitu, kdy si Codex stáhne issues, navrhne opravy a odešle je zase do GITu, kde čekají na kontrolu a merge.</p>

<h2 id="závěr">Závěr</h2>

<p>Jak má Codex zapadat k probíhající <a href="/item/openai-kupuje-windsurf/">akvizici Windsurfu</a>, budou to soběžné projekty, nebo se spojí? Je Codex budoucí lídr agentického programování nebo jen další “my taky” software bez přidané hodnoty? Uvidíme… na to zatím žádné odpovědi nejsou,</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="vibecoding" /><category term="programování" /><category term="OpenAI" /><summary type="html"><![CDATA[OpenAI představuje Codex - agenta pro vývoj software]]></summary></entry><entry xml:lang="cs"><title type="html">AI novinky k 15.5.2025</title><link href="https://www.marigold.cz/item/ai-news-15-5-2025/" rel="alternate" type="text/html" title="AI novinky k 15.5.2025" /><published>2025-05-15T00:00:00+00:00</published><updated>2025-05-15T00:00:00+00:00</updated><id>https://www.marigold.cz/item/ai-news-15-5-2025</id><content type="html" xml:base="https://www.marigold.cz/item/ai-news-15-5-2025/"><![CDATA[<p>Na minulý souhrn AI novinek jsem měl dobré ohlasy, takže si jej po týdnu zopakujme. Mezi nejdůležitější novinky patří zejména GPT-4.1 ve web rozhraní, Google Gemini novinky, ale také robotika a Meta aktuality.</p>

<p><strong>Co konkrétně se v tomto článku dozvíte?</strong></p>
<ul id="markdown-toc">
  <li><a href="#google-posunuje-hranice-s-alphaevolve-a-rozšiřuje-gemini" id="markdown-toc-google-posunuje-hranice-s-alphaevolve-a-rozšiřuje-gemini">Google posunuje hranice s AlphaEvolve a rozšiřuje Gemini</a></li>
  <li><a href="#openai-přináší-gpt-41-rozšiřuje-vedení-a-vydává-bezpečnostní-nástroje" id="markdown-toc-openai-přináší-gpt-41-rozšiřuje-vedení-a-vydává-bezpečnostní-nástroje">OpenAI přináší GPT-4.1, rozšiřuje vedení a vydává bezpečnostní nástroje</a></li>
  <li><a href="#anthropic-chystá-nové-modely-sonnet-a-opus-a-vylepšuje-claude-code" id="markdown-toc-anthropic-chystá-nové-modely-sonnet-a-opus-a-vylepšuje-claude-code">Anthropic chystá nové modely Sonnet a Opus a vylepšuje Claude Code</a>    <ul>
      <li><a href="#novinky-v-claude-code" id="markdown-toc-novinky-v-claude-code">Novinky v Claude Code</a></li>
    </ul>
  </li>
  <li><a href="#meta-posouvá-schopnosti-ai-pěti-revolučními-projekty" id="markdown-toc-meta-posouvá-schopnosti-ai-pěti-revolučními-projekty">Meta posouvá schopnosti AI pěti revolučními projekty</a></li>
  <li><a href="#microsoft-vylepšuje-copilot-a-adoptuje-google-a2a-framework" id="markdown-toc-microsoft-vylepšuje-copilot-a-adoptuje-google-a2a-framework">Microsoft vylepšuje Copilot a adoptuje Google A2A framework</a></li>
  <li><a href="#sakana-ai-učí-modely-přemýšlet-v-čase" id="markdown-toc-sakana-ai-učí-modely-přemýšlet-v-čase">Sakana AI učí modely přemýšlet v čase</a></li>
  <li><a href="#ai-dokáže-předpovídat-zdravotní-výsledky-jen-z-fotografií-obličeje" id="markdown-toc-ai-dokáže-předpovídat-zdravotní-výsledky-jen-z-fotografií-obličeje">AI dokáže předpovídat zdravotní výsledky jen z fotografií obličeje</a></li>
  <li><a href="#alibaba-inovuje-technologie-vyhledávání-a-videa" id="markdown-toc-alibaba-inovuje-technologie-vyhledávání-a-videa">Alibaba inovuje technologie vyhledávání a videa</a></li>
  <li><a href="#mistral-ai-uvádí-nové-konkurenční-modely" id="markdown-toc-mistral-ai-uvádí-nové-konkurenční-modely">Mistral AI uvádí nové konkurenční modely</a></li>
  <li><a href="#futurehouse-a-robotické-inovace" id="markdown-toc-futurehouse-a-robotické-inovace">FutureHouse a robotické inovace</a>    <ul>
      <li><a href="#hugging-face-uvolňuje-alternativu-k-openai-operatoru" id="markdown-toc-hugging-face-uvolňuje-alternativu-k-openai-operatoru">Hugging Face uvolňuje alternativu k OpenAI Operatoru</a></li>
    </ul>
  </li>
  <li><a href="#cursor---revoluční-ai-editor-kódu-představuje-verzi-050-s-novými-funkcemi" id="markdown-toc-cursor---revoluční-ai-editor-kódu-představuje-verzi-050-s-novými-funkcemi">Cursor - revoluční AI editor kódu představuje verzi 0.50 s novými funkcemi</a></li>
  <li><a href="#trumpova-administrativa-ruší-bidenova-pravidla-pro-vývoz-ai-čipů" id="markdown-toc-trumpova-administrativa-ruší-bidenova-pravidla-pro-vývoz-ai-čipů">Trumpova administrativa ruší Bidenova pravidla pro vývoz AI čipů</a></li>
  <li><a href="#napětí-mezi-openai-a-microsoftem" id="markdown-toc-napětí-mezi-openai-a-microsoftem">Napětí mezi OpenAI a Microsoftem</a></li>
</ul>

<h2 id="google-posunuje-hranice-s-alphaevolve-a-rozšiřuje-gemini">Google posunuje hranice s AlphaEvolve a rozšiřuje Gemini</h2>

<p>Google DeepMind představil údajně převratný nástroj AlphaEvolve, který kombinuje schopnosti jazykového modelu Gemini s evolučními strategiemi pro vytváření algoritmů řešících vědecké a výpočetní výzvy. Tento kódovací agent již dosáhl několika významných matematických objevů včetně prvního vylepšení <a href="https://cs.wikipedia.org/wiki/Strassenův_algoritmus">Strassenova algoritmu</a> z roku 1969.</p>

<p>Systém využívá modely Gemini (Flash pro generování nápadů, Pro pro analýzu) k vytváření kódu, který je testován hodnotiteli a iterativně zdokonalován. AlphaEvolve již nyní optimalizuje datacentrová harmonogramy, zlepšuje trénink AI (včetně svého vlastního) a pomáhá s návrhem čipů. Při testování na více než 50 otevřených matematických problémech dosáhl nejmodernějších řešení v 75 % případů a objevil zcela nová, vylepšená řešení v dalších 20 %.</p>

<p>Google zároveň oznámil významné rozšíření své AI asistentky Gemini na další platformy a zařízení. V následujících měsících se Gemini objeví na chytrých hodinkách s Wear OS, kde uživatelům umožní přirozenější hlasovou interakci. Google plánuje také integraci do Google TV, kde AI pomůže s personalizovanými doporučeními obsahu a vysvětlením složitých konceptů jednoduchým způsobem. Jsem na to zvědav, protože řada televizí má dneska problém utáhnout Google TV software, natož, když se do toho přidá AI…</p>

<p>Zajímavá je i integrace do systému <strong>Android Auto</strong>, kde Gemini vylepší “řidičský zážitek” díky porozumění přirozenějším, konverzačním příkazům. Asistentka dokáže najít nabíjecí stanice, shrnout zprávy nebo navrhnout místa k procházce během nabíjení automobilu. Tato funkce by měla být spuštěna v příštích měsících. V neposlední řadě má Gemini přijít i na první headset s Android XR, který vyvíjí Samsung.</p>

<p>Google dále aktualizoval dva klíčové modely:</p>

<ul>
  <li>Gemini 2.5 Pro Preview (I/O Edition) s vylepšeným porozuměním videím a zdokonalením pro UI, kód a agentní workflow</li>
  <li>Gemini 2.0 Flash pro generování obrázků s vylepšenou kvalitou, vykreslováním textu a menším počtem obsahových omezení</li>
</ul>

<h2 id="openai-přináší-gpt-41-rozšiřuje-vedení-a-vydává-bezpečnostní-nástroje">OpenAI přináší GPT-4.1, rozšiřuje vedení a vydává bezpečnostní nástroje</h2>

<p>OpenAI integrovala své nejnovější <strong>jazykové modely GPT-4.1 a GPT-4.1 mini do ChatGPT</strong>, čímž zlepšila schopnosti kódování a následování pokynů pro předplatitele služby. Tyto modely jsou dostupné pro uživatele ChatGPT Plus, Pro a Team a nabízejí vylepšený výkon ve srovnání s předchozími verzemi.</p>

<p>Uvedení GPT-4.1 však neproběhlo bez kontroverze. Počáteční vydání bez bezpečnostní zprávy vyvolalo kritiku týkající se transparentnosti a možných rizik nasazení takto pokročilých modelů bez důkladného prověření. OpenAI reagovala na kritiku závazkem k častějšímu zveřejňování bezpečnostních hodnocení a vytvořením Safety Evaluations Hub, který bude pravidelně zobrazovat výsledky testů svých AI modelů.</p>

<p>Společnost také oznámila <strong>jmenování Fidji Simo, dosavadní CEO Instacart, do pozice CEO of Applications</strong>. V této nově vytvořené vedoucí pozici bude Simo dohlížet na produktové nabídky a obchodní operace společnosti. Tato divize Applications spojuje existující obchodní a operační týmy odpovědné za uvádění výzkumu na trh. Simo bude přímo podřízena CEO Samu Altmanovi, kterému tento krok umožní více se soustředit na výzkum, výpočetní infrastrukturu a bezpečnostní systémy.</p>

<p>OpenAI také <strong>upustila od svého záměru stát se plně ziskovou společností</strong> a oznámila, že převede svoji ziskovou divizi na Public Benefit Corporation (PBC) při zachování řízení neziskovou organizací. Toto rozhodnutí přichází po tlaku bývalých zaměstnanců a v rámci probíhajícího právního sporu.</p>

<p>Společnost zároveň rozšířila svůj <strong>GitHub konektor pro funkci Deep Research</strong>, což umožňuje nástroji využívat a odpovídat na otázky týkající se kódových základen. Tato funkce dovoluje uživatelům připojit repozitáře a využít ChatGPT pro čtení a vyhledávání ve zdrojovém kódu a PR, přičemž vytváří podrobnou zprávu s citacemi.</p>

<p>Na poli zdravotnických aplikací OpenAI vydala <strong>HealthBench</strong>, referenční měřítko vytvořené ve spolupráci s 262 lékaři k hodnocení výkonu AI systémů ve zdravotnických konverzacích. Tato iniciativa má za cíl stanovit nový standard pro měření bezpečnosti a efektivity AI v medicínském kontextu.</p>

<p>Hlavní vědec OpenAI, <a href="https://en.wikipedia.org/wiki/Jakub_Pachocki">Jakub Pachocki</a> (je to polák, ne čech 😎), <a href="https://www.nature.com/articles/d41586-025-01485-2">v rozhovoru pro Nature</a> odhalil svou vizi pro blízkou budoucnost AI. Zmínil, že existují “významné důkazy o tom, že modely jsou schopné objevovat nové poznatky,” ačkoli AI uvažuje jinak než lidé. Pachocki také uvedl, že AI vytvářející “měřitelný ekonomický dopad” a originální výzkum by naplnily jeho definici AGI (umělé obecné inteligence), kterou očekává do konce dekády.</p>

<h2 id="anthropic-chystá-nové-modely-sonnet-a-opus-a-vylepšuje-claude-code">Anthropic chystá nové modely Sonnet a Opus a vylepšuje Claude Code</h2>

<p>Anthropic se připravuje na uvedení <strong>pokročilých verzí svých modelů Claude Sonnet a Opus</strong> v “nadcházejících týdnech”, které budou disponovat hybridním myšlením a rozšířenými možnostmi využití nástrojů. <em>Těším se, snad je napadne dát jim inteligentnější označení než třeba Sonnet 3.7-05-25… - a 3.8 není velký zlepšení</em></p>

<p>Tyto modely mají být schopné střídat mezi uvažováním a používáním nástrojů a dokáží se opravovat tím, že se zastaví a prozkoumají, co se pokazilo. V oblasti kódování mohou testovat svůj vygenerovaný kód, identifikovat chyby, řešit problémy pomocí uvažování a provádět opravy bez potřeby lidského zásahu.</p>

<p>Model Anthropicu s kódovým označením Neptune podstupuje bezpečnostní testování, přičemž někteří věří, že název naznačuje verzi 3.8 (8. planeta od Slunce). Tato informace se objevila současně se spuštěním nového programu odměn za nalezení chyb (bug bounty), který se zaměřuje na testování principů bezpečnosti Claude.</p>

<p><strong>Mobilní aplikace Claude</strong> dokáže nově vyhledávat na webu a v Google Workspace a poskytovat komplexní zprávy s citacemi ze stovek zdrojů - tak, jako webová a desktop aplikace. Aktualizujte</p>

<p>Anthropic rovněž představil <strong>nové funkce pro svůj nástroj Claude Code</strong>, včetně multipaste pro vkládání více velkých bloků kódu do jedné výzvy, podpory OpenTelemetry pro sledování využití a realtime řízení, které umožňuje uživatelům poskytovat zpětnou vazbu AI během práce bez čekání na dokončení úkolu.</p>

<h3 id="novinky-v-claude-code">Novinky v Claude Code</h3>

<ul>
  <li><strong>Funkce multipaste</strong>: Uživatelé nyní mohou vkládat více velkých bloků obsahu (text i obrázky) do jedné výzvy</li>
  <li><strong>Podpora OpenTelemetry</strong>: Umožňuje sledování detailních metrik z Claude Code, včetně:
    <ul>
      <li>Aktivních uživatelů</li>
      <li>Relací na uživatele</li>
      <li>Počtu řádků kódu</li>
      <li>Commitů</li>
      <li>Pull requestů</li>
    </ul>
  </li>
  <li><strong>Všechny metriky zůstávají plně v rámci vaší infrastruktury</strong></li>
  <li><strong>Real-time steering (řízení v reálném čase)</strong>: Možnost posílat zpětnou vazbu Claude Code během jeho práce bez čekání na dokončení
    <ul>
      <li>Claude okamžitě zapracovává vaše vstupy</li>
      <li>Upravuje svůj přístup na základě nových požadavků nebo upřesnění</li>
    </ul>
  </li>
  <li><strong>Všechny tři funkce jsou dostupné v nejnovější aktualizaci</strong></li>
  <li><strong>Claude Code je nyní k dispozici s předplatnými Claude Max na claude.ai/code</strong></li>
</ul>

<p>Společnost dále <strong>zpřístupnila ve svém API možnosti vyhledávání na webu</strong>, což vývojářům umožňuje vytvářet aplikace schopné vyhledávat aktuální informace na internetu a poskytovat podložené odpovědi s relevantními citacemi.</p>

<h2 id="meta-posouvá-schopnosti-ai-pěti-revolučními-projekty">Meta posouvá schopnosti AI pěti revolučními projekty</h2>

<p>Meta prostřednictvím svého týmu FAIR (Facebook AI Research) představila pět průlomových projektů v oblasti umělé inteligence, které mají za cíl posunout schopnosti AI k více lidskému chápání a interakci:</p>

<p>Doplněný text s charakteristikami jednotlivých projektů:</p>

<ol>
  <li>
    <p><strong>Perception Encoder</strong>  - působí jako “oči” AI systémů, umožňující jim dekódovat a pochopit složité vizuální informace s bezprecedentní přesností.  <em>Tento model funguje jako vizuální front-end pro AI, který zpracovává a interpretuje obrazová data podobně jako lidský zrakový systém, což umožňuje pokročilou klasifikaci obrazů, rozpoznávání objektů a porozumění vizuálnímu kontextu.</em></p>
  </li>
  <li>
    <p><strong>Perception Language Model (PLM)</strong>  - průlomový krok v dostupnosti AI modelů díky open-source architektuře, který zlepšuje synergii mezi viděním a jazykem. Tento open-source model pro vizuální úkoly dokáže extrahovat detaily o jednání subjektu v daném čase.  <em>PLM propojuje vizuální a textové porozumění, což umožňuje AI odpovídat na otázky o obrázcích, popisovat viděné scény a analyzovat vztahy mezi objekty na obrazových vstupech bez potřeby proprietárních dat.</em></p>
  </li>
  <li>
    <p><strong>Meta Locate 3D</strong>  - vylepšuje schopnosti robotů interpretovat příkazy v přirozeném jazyce a prostorové náznaky k přesnému identifikování objektů v trojrozměrném prostředí. Cílem je pomoci robotům lépe rozumět a interagovat s okolím.  <em>Tento systém překlenuje propast mezi lidskými slovními popisy (“najdi červené jablko na kuchyňské lince”) a přesným prostorovým umístěním objektů, což je klíčové pro praktické nasazení robotů v domácnostech a průmyslu.</em></p>
  </li>
  <li>
    <p><strong>Dynamic Byte Latent Transformer</strong>  - představuje posun v jazykovém modelování díky zpracování na úrovni bajtů, což zvyšuje efektivitu a odolnost při řešení různých jazykových výzev.  <em>Na rozdíl od běžných tokenizačních přístupů tento model pracuje přímo s bajty, což mu umožňuje lépe zvládat překlepy, nová slova, různé jazyky a škodlivé vstupy, přičemž poskytuje konzistentnější výkon napříč různými jazykovými strukturami a formáty.</em></p>
  </li>
  <li>
    <p><strong>Collaborative Reasoner</strong>  - zaměřuje se na spolupráci mezi AI a lidmi i jinými AI systémy, což otevírá cestu pro složitější sociální chování AI s empatií a nuancovaným pochopením lidských mentálních stavů.  <em>Systém je navržen pro práci v týmech, kde dokáže předvídat potřeby lidských spolupracovníků, chápat jejich záměry a efektivně komunikovat v rámci řešení společných úkolů, čímž transformuje AI z pouhého nástroje na aktivního partnera při rozhodování a řešení problémů.</em></p>
  </li>
</ol>

<p>Všechny tyto projekty jsou krokem k dosažení Advanced Machine Intelligence (AMI) a zapadají do strategických cílů Meta pro integraci AI napříč jejími platformami.</p>

<h2 id="microsoft-vylepšuje-copilot-a-adoptuje-google-a2a-framework">Microsoft vylepšuje Copilot a adoptuje Google A2A framework</h2>

<p>Microsoft aktualizoval svůj nástroj Copilot pomocí funkce “Pages”, která se podobá Canvas z ChatGPT. Tato funkce umožňuje uživatelům spolupracovat s Copilotem, žádat asistenta o úpravy, rozšíření nebo vylepšení jeho odpovědí. Na rozdíl od Canvas však zřejmě nemá schopnosti pro kódování.</p>

<p>Společnost také oznámila, že přijímá Google Agent2Agent (A2A) framework, který brzy spustí na platformách Azure AI Foundry a Copilot Studio. Tento krok umožní podnikům vyvíjet AI agenty, kteří budou již v návrhu schopni vzájemně interagovat napříč platformami.</p>

<h2 id="sakana-ai-učí-modely-přemýšlet-v-čase">Sakana AI učí modely přemýšlet v čase</h2>

<p>Japonská společnost Sakana AI představila Continuous Thought Machines (CTMs), nový typ modelu, který činí AI více podobnou lidskému mozku tím, že jí umožňuje “přemýšlet” krok za krokem v průběhu času namísto okamžitého rozhodování, jak to dělají současné AI systémy.</p>

<p>Na rozdíl od většiny AI, které zpracovávají informace statickým, jednorázovým způsobem, CTM bere v úvahu, jak se její vnitřní aktivita rozvíjí v čase, podobně jako to dělá náš mozek. Technologie čerpá inspiraci ze skutečných mozků, kde je načasování aktivace neuronů klíčové pro inteligenci.</p>

<p>Sakana předvedla CTM řešící složité bludiště, kde model viditelně sledoval možné cesty bludištěm při svém přemýšlení. Další příklad se zabýval rozpoznáváním obrazů, kde CTM prohlížela různé části obrazu a trávila více času v závislosti na obtížnosti úkolu.</p>

<p>(Tady si vzpomínám, jak jsem do GPT-4o nahrál mapu bludiště, chtěl jsem vyznačit nejkratší trasu od vchodu k východu a ono to vzalo kolem bludiště, vůbec ne skrze bludiště… co na to říct, zadání splnil…)</p>

<h2 id="ai-dokáže-předpovídat-zdravotní-výsledky-jen-z-fotografií-obličeje">AI dokáže předpovídat zdravotní výsledky jen z fotografií obličeje</h2>

<p>Vědci z Mass General Brigham představili FaceAge, AI nástroj, který dokáže odhadnout biologický věk člověka a zlepšit předpovědi výsledků léčby rakoviny pouhou analýzou fotografie obličeje.</p>

<p>FaceAge využívá systém trénovaný na desítkách tisíc fotografií obličejů k překladu jemných obličejových charakteristik do odhadu biologického věku. Studie zjistila, že pacienti s rakovinou vypadali v průměru o 5 let starší, přičemž vyšší FaceAge koreloval s horší mírou přežití.</p>

<p>Při testování s lékaři se výrazně zlepšila přesnost při předpovídání šestiměsíčního přežití, když byly k klinickým datům přidány rizikové skóre FaceAge. Předpovědi AI korelovaly s genem spojeným se stárnutím buněk, což naznačuje, že FaceAge zachytil procesy, které nejsou detekovatelné chronologickým věkem.</p>

<p>(Takže možná vypadáte staře proto, že máte raka… smysl to dává, využití zajímavý, preventivní medicína tohoto typu by hodně pomohla, když to bude mít výsledky…)</p>

<h2 id="alibaba-inovuje-technologie-vyhledávání-a-videa">Alibaba inovuje technologie vyhledávání a videa</h2>

<p><strong>Alibaba představila ZeroSearch</strong>, techniku, která učí AI systémy vyhledávat informace bez použití skutečných vyhledávačů, čímž snižuje náklady na trénink o 88 % při zachování nebo překonání výkonu modelů trénovaných se skutečnými API vyhledávačů. ZeroSearch odstraňuje potřebu drahých volání API vyhledávačů během tréninku tím, že používá LLM k simulaci výsledků vyhledávání.</p>

<p>Společnost dále uvedla HunyuanCustom, nový open-source AI systém, který generuje přizpůsobená videa z textu, obrázků, audia a video vstupů s konzistentními subjekty. Tento multi-modální video framework zajišťuje konzistenci identity subjektu napříč různými vstupními formáty pomocí LLaVA-based textově-obrazové fúze, tempovému vylepšení ID, AudioNet a video injekci založené na patchify.</p>

<h2 id="mistral-ai-uvádí-nové-konkurenční-modely">Mistral AI uvádí nové konkurenční modely</h2>

<p>Mistral AI vydal dva významné produkty:</p>

<ul>
  <li><strong>Medium 3</strong>, multimodální AI, která se vyrovná nebo předčí modely Claude 3.7 Sonnet, GPT-4o a Llama 4 Maverick při 8x nižších nákladech</li>
  <li><strong>Le Chat Enterprise</strong>, agentní AI asistent pro firmy s nástroji jako Google Drive a nástrojemi pro vytváření vlastních agentů</li>
</ul>

<p>(Ještě jsem nevyzkoušel, chystám se na Mistral nahodit pár pokusů, ale zatím jsem neměl odvahu rozhasit si věci, kde mi něco běží, takže zatím jsem ho úspěšně použil jen pro systém určování polohy z fotek, který jde hodně mimo tyhle výhody…)</p>

<h2 id="futurehouse-a-robotické-inovace">FutureHouse a robotické inovace</h2>

<p>Společnost <a href="https://www.futurehouse.org">FutureHouse</a>, podporovaná bývalým CEO Googlu Ericem Schmidtem, představila pět “AI Scientist” agentů:</p>

<ul>
  <li>Crow pro obecný výzkum</li>
  <li>Falcon pro hloubkové literární rešerše</li>
  <li>Owl pro identifikaci předchozího výzkumu</li>
  <li>Phoenix pro chemické workflow</li>
  <li>Finch pro objevy v biologii</li>
</ul>

<p>V oblasti robotiky představila společnost <a href="https://www.unitree.com">Unitree</a> ve spolupráci se sanfranciskou firmou Reborn vývoj pokročilé AI, která má učinit její roboty chytřejšími, adaptabilnějšími a schopnými komplexních úkolů. Spolupráce využije více nástrojů Reborn, včetně jejich simulátoru Roboverse, datasetů pohybu a vývojářských nástrojů.</p>

<p>Výzkumníci ze Stanfordské univerzity mezitím představili <a href="https://github.com/YanjieZe/TWIST">Teleoperated Whole-Body Imitation System (TWIST)</a>, který umožňuje koordinované, všestranné pohyby celého těla humanoidních robotů pomocí jediné neuronové sítě. Tento systém umožní funkční univerzální roboty v různých doménách.</p>

<p>UC Berkeley představila <a href="https://www.videomimic.net">VideoMimic</a>, real-to-sim-to-real pipeline, který trénuje roboty pomocí mobilních videí. Systém těží videa, rekonstruuje lidi a prostředí a vytváří strategie pro humanoidy, umožňující dovednosti jako chůze po schodech. Tato univerzita také uvedla PyRoki, modulární, rozšiřitelný, a multiplatformní toolkit pro kinematickou optimalizaci, který řeší inverzní kinematiku, optimalizaci trajektorie a převádění pohybu pro širokou škálu robotů včetně humanoidů.</p>

<p>Holandští vědci z výzkumného institutu <a href="https://amolf.nl">AMOLF</a> vytvořili “měkkého” robota, který se pohybuje, adaptuje a dokonce plave, a to vše poháněno pouze vzduchem, bez jakéhokoli mozku, elektroniky nebo jediného řádku kódu. Robot je vyroben z měkkých, pružných elastomerových trubic, které slouží jako struktura i ovladač, umožňující jemný, adaptivní pohyb. Nepřetržitý proud vzduchu způsobuje nafukování a oscilování trubic, což eliminuje potřebu motorů nebo elektroniky pro pohyb.</p>

<h3 id="hugging-face-uvolňuje-alternativu-k-openai-operatoru">Hugging Face uvolňuje alternativu k OpenAI Operatoru</h3>

<p>Hugging Face vydal <a href="https://huggingface.co/spaces/smolagents/computer-agent">Open Computer Agent</a>, open-source AI agenta pro automatizaci webových úkolů, který je podobný nástroji Operator od OpenAI. Je zdarma použitelný přes webové prohlížeče, ale je údajně pomalý a schopný zvládnout pouze základní vícekrokové úkoly.</p>

<h2 id="cursor---revoluční-ai-editor-kódu-představuje-verzi-050-s-novými-funkcemi">Cursor - revoluční AI editor kódu představuje verzi 0.50 s novými funkcemi</h2>

<p><a href="https://www.cursor.com">Cursor</a>, pokročilý AI editor kódu, <strong>představil verzi 0.50</strong> s významnými vylepšeními. Mezi klíčové novinky patří podpora background agentů, která umožňuje spouštět více verzí Cursor agenta současně, možnost vkládat celé složky do kontextu, podpora více kořenových workspace s vlastními .cursor/rules složkami a vylepšené vyhledávání a nahrazování pro rychlejší úpravy souborů.</p>

<p>Uživatelé nyní mohou také exportovat jakýkoli chat do markdown formátu nebo jej duplikovat do nového chatovacího okna. Inline editace získala vylepšené uživatelské rozhraní s rychlou editací celého souboru (⌘⇧⏎) a funkcí “send to agent” (⌘L). Cenová struktura byla zjednodušena na 500 požadavků na všechny modely a režim max využívá cenovou strukturu založenou na tokenech, přičemž je dostupný pro všechny top modely.</p>

<h2 id="trumpova-administrativa-ruší-bidenova-pravidla-pro-vývoz-ai-čipů">Trumpova administrativa ruší Bidenova pravidla pro vývoz AI čipů</h2>

<p>Trumpova administrativa zrušila pravidlo z Bidenovy éry, které by zavedlo celosvětové kontroly vývozu polovodičů. Namísto toho se rozhodla vyvinout přístup zaměřený na dohody specifické pro jednotlivé země, přičemž zachovala omezení pro Čínu.</p>

<p>Ministerstvo obchodu oznámilo zrušení pravidla jen několik dní před tím, než mělo vstoupit v platnost, s odůvodněním, že by poškodilo inovace a diplomatické vztahy. Nové pokyny také výslovně uvádějí, že používání AI čipů Huawei Ascend kdekoli na světě je nyní považováno za porušení amerických exportních kontrol.</p>

<p>Tento krok přichází krátce poté, co se CEO Nvidie Jensen Huang objevil po boku amerického prezidenta Donalda Trumpa v Saúdské Arábii, kde prosazovali mezinárodní investice do amerických AI společností. Nvidia, která drží přibližně 90 % trhu s AI čipy, by byla významně poškozena, kdyby pravidlo vstoupilo v platnost, zejména proto, že mohlo ovlivnit i prodej čipů spřáteleným národům.</p>

<h2 id="napětí-mezi-openai-a-microsoftem">Napětí mezi OpenAI a Microsoftem</h2>

<p>OpenAI a Microsoft údajně vedou “vysoce důležitá” jednání o přepracování podmínek svého partnerství. OpenAI se snaží snížit podíl Microsoftu na příjmech z 20 % na 10 % do roku 2030, kdy společnost předpovídá příjmy ve výši 174 miliard dolarů, zatímco Microsoft usiluje o zaručený přístup k technologiím OpenAI i po roce 2030, kdy vyprší současná smlouva.</p>

<p>Vztah mezi oběma společnostmi údajně ochladl, neboť OpenAI navazuje dohody s konkurenty Microsoftu pro svůj projekt Stargate, zatímco také cílí na stejné podnikové zákazníky. Existuje také napětí ohledně duševního vlastnictví, přičemž Microsoft hledá garantovaný přístup k technologiím OpenAI i po vypršení současné smlouvy.</p>

<p>Microsoft také zůstává klíčovým držitelem akcií, který brání plánům na konverzi obchodní části OpenAI na veřejně prospěšnou společnost (PBC).</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="AI novinky" /><summary type="html"><![CDATA[Na minulý souhrn AI novinek jsem měl dobré ohlasy, takže si jej po týdnu zopakujme. Mezi nejdůležitější novinky patří zejména GPT-4.1 ve web rozhraní, Google Gemini novinky, ale také robotika a Meta aktuality.]]></summary></entry><entry xml:lang="cs"><title type="html">⚡️ Vyšetřování blackoutu ve Španělsku a Portugalsku den za dnem (update 13.5.)</title><link href="https://www.marigold.cz/item/spanelsko-blackout/" rel="alternate" type="text/html" title="⚡️ Vyšetřování blackoutu ve Španělsku a Portugalsku den za dnem (update 13.5.)" /><published>2025-05-13T00:00:00+00:00</published><updated>2025-05-13T00:00:00+00:00</updated><id>https://www.marigold.cz/item/spanelsko-blackout</id><content type="html" xml:base="https://www.marigold.cz/item/spanelsko-blackout/"><![CDATA[<p>Co nového ve vyšetřování španělského blackoutu? <a href="https://www.entsoe.eu/news/2025/05/09/entso-e-expert-panel-initiates-the-investigation-into-the-causes-of-iberian-blackout/">ENSOE-E uvolnilo první předběžnou zprávu</a>, ale úplně nejvíc jasno z ní není, proto jsem také informace pár dní neaktualizoval, jen bychom naprázdno propírali hypotézy nebo padali do logických pastí.</p>

<p>Časovou osu jsem teď nicméně nedoplnil o data  <a href="https://www.youtube.com/watch?v=ElDQr8Vueyw">z podcastu Frauenhofer Institutu</a>, který má vlastní měření v několika bodech a jeho data i úvahy lze brát za věrohodné. V přehledu jsou data označena jako (FRA).</p>

<p>Co z časové osy plyne? Pořád více méně slyšíme stejný příběh, jehož počátek úplně nevíme. Krátce po poledni pokračuje kmitání ve španělské přenosové síti, které jsme viděli už dopoledne. Probíhají první pokusy o tlumení této oscilace, ale kmitání přetrvává. Pak máme desetiminutové okno, z něhož nejsou publikována žádná data. Jen víme, že v 12:32:57 dochází k okamžitému výpadku cca 2,2 GW výkonu fotovoltaických elektráren v oblasti Extramadura (a údajně 1 GW v oblasti Andalusie). O pět vteřin dříve podle jedné zmínky (neuvedené v oficiálním soupisu ENTSO-E) došlo přepětí na rozvodně Araňuelo a Majadas - údajně až 6 %, což je dost - ale toto číslo není oficiálně potvrzeno.. Pokud chcete bít po hlavě obnovitelné zdroje, nemusíte číst dál.</p>

<p>Ve skutečnosti je velmi důležité, proč k odpojení tohoto výkonu došlo. Hypotéza “mlátíme OZE po hlavě” říká, že došlo k náhlé nadvýrobě na FTV a tím došlo k odpojení. Jenže to by se muselo opravdu fofrem vyjasnit počasí. V oblasti Extramadura bylo jasno už dlouho a k takovým změnám nedochází ani rychle, ani snadno. Navíc meteorologové to popřeli. Krom toho takové předpovědi má operátor gridu v předstihu a buďto operátor nebo meteorologové by museli udělat velkou chybu. Jistě, mohly nastat i další události, které způsobují spuštění nadnapěťové ochrany měničů: mohlo dojít k přebytku jalového výkonu, rychlému odpojení velké zátěže, špatně seřízenému OLTC atd. To vše jsou chyby v nastavení.</p>

<h3 id="autonomní-oblast-extramadura">Autonomní oblast Extramadura</h3>

<p>Řekněme si něco k autonomní oblasti Extramadura. Sám jsem ji musel najít na mapě, je to jihozápad Španělska na hranici s Portugalskem a je to jako oblast největší čistý exportér elektřiny. Instalovaný výkon je kolem 12 GW (cca desetina Španělska), naprostou většinu exportuje. Polovinu dělá fotovoltaika, 17% jaderka v Almarazu, 20% vodní a přečerpávací elektrárny, 3% jsou solárně-termální elektrárny, zbytek je vítr, kogenerace atd. Ze seznamu vidíte, že točivých zdrojů má Extramadura obecně dostatek, jenže v tento den tomu bylo jinak.</p>

<p>Pro náš příběh je podstatné propojení Extramadury dále do Španělska, kde hlavním propojovacím bodem je rozvodna Aranuelo nedaleko jaderky Almaraz. Nezkoušejte ji najít na mapě, je součástí fotovoltaického parku Iberdroly, který mimochodem má bateriové úložiště. A sice není prostorově velká, ale je zásadní a je nejdůležitější energetickou křižovatkou západního Španělska. Vyvádí elektřinu z jaderky Almaraz (2 GW), obsluhuje fotovoltaiky a další zdroje v oblasti a dělá primární jalovou regulaci pro severní Extramaduru. Tzn. má na starosti cca 6 GW transformované nebo přímo přepojované kapacity. A především směřuje elektřinu do oblasti Madridu, včetně průmyslu.</p>

<p>Jak mohlo vzniknout lokální přepětí v Aranuelu? Nejpravděpodobnější variantou je, že došlo ke spuštění ochranného odpojení votovoltaických měničů, což zvýšilo oscilaci v síti a větrné parky Andalusie vyhodnotily oscilaci jako napěťový kolaps a také se odpojily. Následně se odpojila linka Španělsko-Francie (ať již na pokyn operátora nebo automaticky, to se šetří) a kaskádovitě následovaly další zdroje prakticky už “v jednom okamžiku”.</p>

<p>Jenže jak se síť mohla takto rozkývat? V oblasti jsou dva hlavní vyrovnávací prvky, statický kompenzátor v Cedillo a jalová regulace v jaderce Almaraz měla teoreticky výkyv kompenzovat nebo rozložit tak, aby nedošlo k okamžitému, současnému odpojení. Proč se tak nestalo, je zatím nevysvětleno: podle nepotvrzené informace kompenzátor v Cedillu nezafungoval správně a v jaderce Almaraz měl být odstavený jeden blok kvůli výměně paliva (tedy celkem 3 ze 7 bloků jaderek byly mimo síť). Abychom si to uměli představit: kompenzátor se mohl sepnout s mírným zpožděním a naopak problém v síti krátkodobě zhoršit, na což mohly reagovat binárně nastavené ochrany fotovoltaik jako na lokální přepětí. Ale dost spekulacím. Na situaci se navíc negativně podepsal přetrvávající export elektřiny do Portugalska i Francie.</p>

<p>Druhou variantou je rychlá změna točivého výkonu mezi extramadurskou a madridskou oblastí přenosové soustavy, což místní regulátory nemohly absorbovat. Tady by se nabídlo “náhlé odpojení” fotovoltaik, ale to by spíše síť stabilizovalo a na prvotní příčinu úplně nevypadá. Opět: spekuluje se o nevhodném pokynu REE nebo jeho chybném provedení k snížení výkonu paroplynové elektrárny v oblasti Sevilly, čímž by se myslela dva roky stará paroplynovka Kryštofa Kolumba v Huelvě o 391 MW.</p>

<p>Jak vidíte, možností je celá řada a ve skutečnosti velmi záleží na tom, proč se co stalo. Může jít o technickou chybu, nevhodný zásah dispečera sítě či - jak se také spekuluje - na nepřeprogramované ochrany, které nejsou aktualizované na změny poměrů v síti.</p>

<p>V zásadě je podle těchto údajů nejpravděpodobnější, že šlo o kombinaci pomalu rostoucího kmítání mezi dvěma přenosově oddělenými oblastmi, lokálních napěťových špiček a následných ochranných zásahů relé, které vyřadily klíčové vedení. Zatímco dříve padaly podezření na „výpadek OZE“ nebo „kyber-útok“, video i oficiální zprávy společně potvrzují, že <strong>primární spouštěč</strong> bylo <strong>překročení napěťových a impedance-limitů</strong> v kombinaci s nízkou tlumicí kapacitou sítě.</p>

<p>Časová osa:</p>

<ul>
  <li>12 : 03 CET Vysokofrekvenční oscilace ≈ 0,63 Hz detekována ve frekvenčním záznamu Malaga i Freiburg, amplituda roste po dobu čtyř minut _(FRA)</li>
  <li>12 : 12 – 12 : 23 Roste frekvenční rozdíl mezi Pyrenejskou a Evropskou sítí o 0,217 Hz. Spektrální analýza PMU Freiburg potvrzuje koherentní kmitání mezi Pyrenejským poloostrovem a střední Evropou <em>(FRA)</em></li>
  <li>12 : 19 – 12 : 21 První pokus o tlumení oscilace dokumentován v předběžné chronologii ENTSO-E. Ochrany AVR a FACTS zařízení zkrátily amplitudu, kmitání přetrvalo. AVR je regulátor v elektrárnách, který hlídá konstantní napětí generátoru. FACTS je „elektronický tlumič“ napěťových výkyvů na dálkovém vedení, který na pokyn operátora nebo automaticky bleskově vyrovná přepětí či podpětí, aby se síť nerozkývala.</li>
  <li>12 : 32 : 52 lokální přepětí 6 % na rozvodně Aranuelo (nepotvrzeno!)</li>
  <li>12 : 32 : 57 Ze sítě vypadává zhruba 2,2 GW fotovoltaiky v regionu Extremadura, současně cca 1,0 GW větrná Andalusie; potvrzeno v předběžné chronologii ENTSO-E.</li>
  <li>12 : 33 : 18 – 12 : 33 : 21 Frekvence iberské podzóny klesá na 48,0 Hz; aktivováno podfrekvenční odlehčení zátěže UFLS (cca 2 GW), aktivovány frekvenční ochrany měničových zdrojů (zdroj ENTSO-E).</li>
  <li>12 : 33 : 21 Impedance-relé vypínají všech šest 400 kV vedeních ES–FR pro nadkritický fázový úhel (potvrzeno ENTSO-E) - tím okamžitě v síti roste nadvýroba a přestává existovat možnost stabilizace importem z Francie.</li>
  <li>12 : 33 : 24 Totální kolaps synchronismu na Pyrenejském poloostrově, výkon v provozu je cca 0,4 GW.</li>
  <li>12 : 33 – 12 : 34 Fázový rozdíl Malaga–Freiburg integrovaný z frekvence dosahuje ≈ 90°, což je limit stabilního přenosu <em>(FRA)</em></li>
  <li>12 : 44 start “ze tmy” přečerpávací vodní elektrárny Alcántara; první 400 kV koridor ES–FR pod proudem (oficiální ENTSO-E)</li>
  <li>13 : 04 Sestavena druhá linie ES–MA; začlenění hydroelektráren, následně CCGT.</li>
  <li>18 : 36 Synchronizace první 220 kV vazby ES–PT.</li>
  <li>21 : 35 Synchronizace jižní 400 kV ES–PT.</li>
  <li>29 / 4 00 : 22 Portugalská přenosová soustava v normálním stavu; 04 : 00 Španělsko.</li>
</ul>

<blockquote>
  <p>Níže pod touto sekcí najdete zprávy k události ze dne incidentu a z dalších dní, kdy jsem situaci sledoval.</p>
</blockquote>

<p>–</p>

<h3 id="️-55---španělsku-hrozil-blackout-několik-dní">🇪🇸⚡️ 5.5. - Španělsku hrozil blackout několik dní</h3>

<p>Po zajímavé stopě se pustil Reuters. Ten zdokumentoval několik výpadků z dní předcházejících blackoutu. V týdnech před pondělním kolapsem zaznamenala soustava několik menších poruch a experti opakovaně upozorňovali na narůstající nestabilitu a na to, že soustavu může rozhodit jak nedostatek výkonu, tak ale i její přebytek, což hrozilo zejména s růstem slunečních dní a tím s růstem produkce elektřiny, zatímco teploty byly ještě nízké na to, aby lidé masivně zapínali klimatizace.</p>

<p>Interní experti i REE v ročních zprávách upozorňovali na rostoucí nestabilitu kvůli souběhu malých zdrojů OZE a nedostatku dat z nich. REE z nich totiž nemá online data (či near-real-time data) o jejich produkci a pouze ji v reálném čase predikuje podle počasí, nemá ani vliv na připojení těchto zdrojů do sítě a jejich odpojení. 
Experti ENTSO-E také upozorňovali na nedostatečné plánování chystaného vyřazování jaderných reaktorů ze sítě s tím, že už plánovaná výměna paliva v reaktoru Almaraz II může být problém. Reaktor byl odpojen od sítě 20 . 4. 2025 a přešel do horkého odstávkového stavu. Práce podle harmonogramu pokračovaly i během blackoutu.
Dne  22. dubna se objevily nápadné přepětí v síti a výpadky řízení, které odstavily vysokorychlostní vlaky a rafinérii Cartagena, což mělo být a zřejmě i bylo první vážné varování, problémy s v různé míře intenzity projevovaly až do 28.4.2025, kdy v 12:31 došlo k blackoutu na Pyrenejském poloostrově. Přesná souslednost výpadku je nicméně stále předmětem šetření.</p>

<p>Síť je nyní stabilní, nouzový stav byl zrušen. Vyšetřovací panel ENTSO‑E má plná data a nejpozději do 10 .5. slíbí první technický verdikt. Do té doby se čeká především na výsledek francouzského testu ochranných relé, který má objasnit, proč se Pyreneje odpojily prakticky v jednom okamžiku - a v kterém okamžiku to bylo. Nové informace nicméně posilují verzi systémového selhání, tedy neschopnosti REE řídit dynamicky se vyvíjející situaci v síti kvůli nedostatku dat a regulačních mechanismů.</p>

<hr />

<h3 id="35-2025">3.5. 2025</h3>

<p>Vyšetřování španělského blackoutu pokračuje, už se neobjevují žádné další podstatné informace. Stále není zřejmá přesná souslednost začátku, tedy zda za výpadek mohl nějaký zdroj, nebo nějaká událost v přenosové síti - čili kde kaskáda kolapsu začala. A zrovna tohle je hodně důležité.</p>

<p>Zatím pouze docela přesně víme, k čemu to vedlo, ale ne, jak to začalo - a nápravná opatření se podle toho budou výrazně lišit. V pátek proběhlo velké setkání, kde REN a REE předložily předběžné zprávy, ale nic podstatného z nich neuteklo, prohlášení po schůzce opakují jen již známé věci.</p>

<p>Ne každý je z detailního vyšetřování nadšený. Španělská vláda si vyžádala od Iberdroly, Endesy, Repsolu aj. „černé skříňky“ měničů a blokových ochran.   Kdyby se nemohly najít, což se v takových situací stává, tak premiér Sánchez “nevylučuje sankce při neodevzdání”. Slušně vynadáno dostává španělský provozovatel přenosové soustavy REE (Red Eléctrica). Je již mnoho důkazů proto, že síť byla nestabilní již v pondělí dopoledne, REE nepřikročil k větší regulaci, ačkoliv mohl a zřejmě i měl. Kromě toho se ukazuje, že jej řada institucí upozorňovala již dříve, že nemají síť v dobré kondici. Tím hlavním varujícím byl právě  ENTSO‑E, asociace operátorů přenosových sítí a operátor evropského gridu CESA. Akcie REE se propadly o 7 % - a nelibost premiéra Sáncheze jde zřejmě hodně tímto směrem, protože ať už byla příčina kdekoliv, bylo na zodpovědnosti REE si takovou věc do sítě pustit s patřičnými parametry nebo přijmout patřičná opatření.</p>

<p>To také znamená, že se houpe křeslo s šéfkou REE Beatriz Corredor, někdejší ministryní pro bydlení za sociálně-demokratickou stranu PSOE. Beatriz Corredor prohlásila, že nic takového se nebude opakovat a aby dodala svým slovům i technickou váhu, od úterka REE výrazně změnilo skladbu produkce elektřiny. Snížilo podíl fotovoltaiky a zvyšuje podíly produkce z točivých zdrojů (paroplynovky a uhlí). Část elektřiny také dobírá z jiných sítí, zejména Francie. Jako preventivní opatření portugalská ministryně životního prostředí Maria da Graça Carvalho oznámila, že Portugalsko “preventivně přestalo importovat elektřinu ze Španělska”. Dále zdůraznila potřebu více přečerpávacích vodních elektráren a bateriových úložišť v budoucnu, jakož i posílení propojení s Francií.</p>

<p>Čili zatím vyčkáváme na oficiální výsledky, nicméně je už zřejmé, že trámy k ukřižování jsou připraveny.</p>

<hr />

<p>Za včerejšek mnoho novinek nebylo. Všichni zúčastnění po pondělním šoku pomalu najíždějí na informační disciplínu, která je v tomto případě užitečná, protože se ven nedostávají izolované zprávy, které lze snadno dezinterpretovat. Už dnes je jasné, že situace je velmi komplexní a nelze to vyřídit stylem “někdo hodil bombu do rozvodny”.</p>

<p>🇪🇸💡 1.5.2025: Jak pokračuje vyšetřování pyrenejského blackoutu?</p>

<p>Pro mě je také nepříjemné to, že sice se pořádají setkání s médii, z nich ale nevycházejí žádné oficiální zprávy, weby REN/REE mají jen prohlášení, že se to stalo a že to řeší, novinky nepředávají. Takže tyhle zprávy nabírám z médií a tam je často sdělení překroucené, zamlžené, protože pisatel nebyl energetik a v tomto případě na detailu záleží.</p>

<p>První velkou novinkou je, že jsem se dostal k datům z vnitřní sítě nízkého napětí ve vteřinovém rozlišení. Neumožňuje to vypátrat lépe příčinu, ale je vidět, že první problémy byly v rozvodné síti již dopoledne (což už bylo známo dříve), někdy po 9 hodině začalo na hladině nízkého napětí oscilovat napětí až o 11V, což rozhodně není obvyklé, obvyklá bývá jednotková oscilace. Navíc se zvyšovala amplituda kmitů, byly četnější, pak se před polednem situace stabilizovala. To sedí k informacím o tom, že oscilovala frekvence na přeshraničním pyrenejském připojení, k tomuhle jevu dochází na hladině nízkého napětí, když se “přetlačují” toky ze dvou velkých sítí. Jenže taky v řadě dalších případů, takže z toho nededukujme mnoho.  Dlouhé, pomalu sílící kmity nicméně naznačují nedostatečně tlumenou soustavu (málo setrvačnosti / tlumicích výkonů). Znamená to, že síť byla nestabilní několik hodin před blackoutem a dispečeři si toho museli být vědomi, zjevně se zásahy snažili síť stabilizovat. 
Pomalý rozjezd oscilací také spíše vylučuje terorismus, to by muselo jít o dobře cílené a synchronizované útoky.</p>

<p>Z oficiálních vyjádření také víme, že došlo ke dvěma vážným problémům předcházejícím blackoutu. REE uvedlo, že šlo přerušením dodávek elektřiny a zatímco se španělská síť dokázala zotavit z první události, ředitel Eduardo Prieto uvedl, že druhá byla mnohem ničivější a vyústila v přerušení dodávek elektřiny z francouzské sítě a „masivní dočasné odpojení“. Zatím nebylo oznámeno, o co šlo, některé zvěsti říkají, že v prvním případě vypadla fotovoltaika o cca 3 GW někde v Extremaduře, v druhém o 1 GW větrníků v Andalusii. Oficiálně to ale potvrzeno není.</p>

<p>Extremadura je fotovoltaické srdce Španělska, ale největší FTV parky zde mají max 600 MW, většinou jsou kolem 200 MW, na 3 GW výkonu by jich musela vypadnout zhruba desítka, což znamená, že jde o systémový incident, ne o náhodný nezvládnutý výpadek.  Například jsou všechny FTV napojeny na stejnou páteřní trasu 400 kV Almaraz - Guillena přes čtveřici rozvoden. Proto je důležité bedlivě stanovit časovou mapu  a tím se dobrat k tomu, zda se synchronně vyply FTV parky, nebo je odpojily ochrany rozvoden či 400 kV linky, protože všechny tři jevy mají jiné řešení. Podobně je to s větrníky v Andalusii.</p>

<p>Čili jsme zase u toho. Čekáme na závěry probíhajícího šetření ENTSO-E a přesnou časovou osu, přičemž další tisková konference snad už s detaily, má být 2.5.</p>

<p>Jedna věc je vtipná, všichni už si kryjí záda. REE upozornilo, že na systémovou nestabilitu sítě upozornilo ve své letošní únorové zprávě (tedy několik let poté, co jim to samé říká ENTSO-E coby šéf eurosítě).</p>

<p>Jinak pro zlepšení hospodské debaty: samozřejmě existují setrvačná a elastizující řešení i pro FTV a větrníky. Nemusí to být nutně baterie, ale třeba synchronní kompenzátory, flywheely nebo intertia boosty pro větrné turbíny. Řešení je celá řada, nemusíte kvůli tomu nutně vydlabat vrcholek kopce a napustit ho vodou, jenže když si to do sítě neobjednáte, tak to nemáte.</p>

<p>🚗 Pyrenejská rozvodná síť byl prostě nadupaný sportovní kabriolet, do kterého se daly kvůli úspoře brzdy z Felačky a v zatáčce v Pyrenejských serpentinách se to prostě vyklopilo. Buďto zakážeme výrobu sportovních vozů, nebo do nich značneme dávat odpovídající brzdy, moc víc nad tím nevymyslíme…</p>

<p>…okračování zítra asi odpo, až budou venku zprávy…</p>

<hr />

<p>3️⃣🇪🇸⚡️ 30.4.2025 Co nového se španělským blackoutem?</p>

<p>Jak vypadá situace kolem španělského blackoutu energetické sítě? Včera se téměř vše vrátilo do normálu, zapomeňte na novinové titulky “budou se vzpamatovávat týden” - kromě specifických věcí už je (v energetice) vše v normálu. Nicméně probíhá šetření. Co víme nového? No, pokud už sami máte jasno, tak dál nečtěte, protože jasno moc není.</p>

<p>V zásadě byla opuštěna myšlenka gallopingu jako JEDINÉHO SPOUŠTĚČE, tedy že šest 400 kV linek přes Pyreneje do Francie odpojily ochrany kvůli nadměrnému pohybu vedení vinou proudění vzduchu. Zdá se, že k pohybu došlo, ale ten nebyl jedinou či přímou příčinou odpojení linek. Atmosférická situace nebyla nijak extrémní. Nicméně ještě probíhá vyhodnocování měření.</p>

<p>Už se ale spíše uvažuje o špatně nastaveném firmware ochran, protože RTE potvrdila, že se používají stejná nastavení, jako u linky 400 kV v Lotrinsku, která se loni planě odpojila.</p>

<p>Dnes bohužel není úplně veřejně jasné, zda k odpojení linek došlo PŘED nebo PO zlomové události, tedy jak moc velký vliv jejich přerušení mělo a zda nebylo spouštěčem blackoutu.</p>

<p>V každém případě již nyní je zřejmé, že došlo k celé souhře událostí, mezi něž bych neváhal přidat španělský čurbes.</p>

<p>Především je třeba říct, že nemáme všechna podkladová data, sice scanuju všechna patřičná média, ale v nich se objevují zprávy útržkovitě a často manipulativně. Například ten galloping, ukázalo se, nebylo oficiální vyjádření portugalského REN, ale rychlý osobní názor jednoho z dispečerů, které bylo v médiích oseknuto tak, že to vypadalo jako oficiální postoj.  Stejně tak v deníku el Pais se objevila data z jednoho slide určeného pro krizové jednání vlády, které ukazovaly na konkrétní problém, jenže se později ukázalo, že v prezentaci šlo o dva slajdy a na tom prvním byl zachycený začátek události, který všemu dával jiný kontext. Za třetí se ukázalo, že jeden z důležitých logů měl posunuté časové razítko o skoro dvě minuty, protože neměl přesný čas, což na interpretaci dat vrhalo jiné světlo.  Proto nutně s daty opatrně a nedělat unáhlené závěry.</p>

<p>Pojďme si zrekapitulovat, co víme.</p>

<p>Kolaps španělské přenosové soustavy byl extrémně rychlý a rozsáhlý. Během pouhých pěti sekund došlo ke ztrátě přibližně 15 gigawattů (GW) elektrického výkonu. Tato ztráta představovala zhruba 60 % okamžité celostátní poptávky po elektřině v daném okamžiku. Okamžitá poptávka ve Španělsku dramaticky poklesla z úrovně přibližně 26 000 - 27 500 megawattů (MW) na hodnoty blížící se 15 000 MW , přičemž v nejnižším bodě dosáhla pouhých 10 480 MW. Tato bezprecedentní rychlost a rozsah ztráty výkonu byly klíčovými faktory, které vedly k následnému kaskádovému selhání a rozpadu sítě.</p>

<p>Tohle víme vcelku jistě. Nyní je otázkou, co tu ztrátu 15 GW v síti způsobilo.</p>

<p>Podle první teorie to byl výpadek linek přes Pyreneje, zatím z neznámých příčin, kterých mohlo být více (kyberútok se tady zatím stále spíše neuvažuje). Při přerušeném exportu do Francie by frekvence sítě ve španělsku vyletěla nahoru (a v EU dolů) a fotovoltaické a větrné elektrárny v rozmezí 8 sekund odpojily od sítě něco jako 15-30% výkonu. Tento pokles je okamžitý, nemá prakticky žádnou elasticitu, čímž dostane frekveci pod 50 Hz a při poklesu pod 49,5 Hz se odpojily tři plynové bloky a všechny jaderné elektrárny. Ochrana zátěže následně odpojuje část odběratelů, cca 3 GW. Takhle se mohl nasbírat propad o těch 15 GW. Situaci nepomohlo to, že v dlouhodobé odstávce byl jaderný blok Vandellos 2 a v údržbě JE Trillo (čili běží dvě JE) a také to, že náhradní zdroje, které měly okamžitě nastartovat, nastartovaly mírně později, než měly. PVE Alcántara se přifázovala +110 s po oddělení a CCGT Cartagena dodal prvních 250 MW dokonce až +7 min, přičemž první dodávky měla dát už za dvě minuty. Na vině byl možná tlak plynu, ale to už je nepotvrzené.</p>

<p>Podle druhé teorie (zveřejněné REE) došlo k propadu výroby na dvou španělských elektrárnách zatím z neznámého důvodu, což (a to už je interpretace) spolu s dalšími faktory jako špatný firmware a galloping nebo rozhodnutí ochrany evropské sítě vedlo k rozpojení linky a kaskádě tak, jak bylo popsáno výše.</p>

<p>Proč se odpojily dva velké zdroje ze sítě, není zatím jasné - tady není ani náznak a počkal bych na data. V Česku se to nicméně hodilo na tuto verzi a prý to měla způsobit výroba z OZE, což není příliš pravděpodobné.</p>

<p>Jak se nezávisle prokáže, co bylo první, zda výpadek linky nebo zdrojů? Vcelku jednoduše: pokud frekvence stoupla na 50 Hz, znamená to převis výroby v síti, což napovídá na odpojení linky (která exportovala 5 GW do Francie). Pokud naopak frekvence klesla, tak nejprve vypadly zdroje. Bohužel přesnější grafy a časy nebyly publikovány a z veřejně dostupných dat je rozlišení malé (bavíme se o 4 sekundách rozdílu!). Zatím jediná data z údajné interní zprávy  RTE cituje článek Euronews, podle nějž frekvence na kontinentální (francouzské) straně vyskočila asi na 50,20 Hz a během několika sekund se vrátila k nominálu. Grafy z kontinentální sítě ukazují, že k výpadku 5 GW (což odpovídá pyrenejské lince) vypadlo ve 12:31 a začínají nabíhat regulace ve zbytku Evropy, které situaci v Evropě dostanou během tří minut zcela pod kontrolu. Bohužel veřejné zdroje o španělské produkci elektřiny jsou agregované na pět minut, takže lze jen potvrdit, že mezi 12:30 a 12:35 došlo ke ztrátě minimálně 11 GW produkce a to nám nepomůže…</p>

<p>Zavržené jsou zaručené zprávy o výbuchu španělské rozvodny Sentmenat - nenese žádné takové známky.</p>

<p>Vysvětlení s primárním výpadkem linky by lépe vysvětlovalo, proč vypadly točivé zdroje, ale zase zůstává nejasné, proč vypadla linka, zatímco primární výpadek zdrojů lépe vysvětlí odpojení linky a zase není jasné, proč by vypadlo tolik zdrojů. 
Budeme si tedy muset počkat, až se objeví více dat.</p>

<p>Hlavní poznatky, kterými si můžeme být jisti, jsou zatím dva (a na oba byli REE/REN upozorňovány dříve):</p>
<ol>
  <li>chybí lepší propojení do Evropy, mělo by být spíše dvojnásobné až trojnásobné, teď je Pyrenejský poloostrov energeticky spíše ostrov a Evropa mu nemůže moc pomoci.</li>
  <li>Jsou potřeba další rychlostartující úložiště typu baterie.</li>
</ol>

<hr />

<h3 id="pokračování-z-2942025">Pokračování z 29.4.2025</h3>

<p>Záhy po publikování informací o rozpadu energetické sítě na pyrenejském poloostrově se začaly šířit teorie, kdo za to může. Rusko či jiní teroristé nebo snad Green Deal? Pojďme se s tím vyrovnat.</p>

<p>Za prvé je potřeba říct, že vyšetřování probíhá, incident dostal nejvyšší klasifikaci ICS-3, což znamená mezinárodní odborné vyšetřování, které je na začátku. Nyní jsou více-méně jisté technické příčiny, které si zrekapitulujeme. A zároveň se nenašla kybernetická stopa, i k tomu se dostanu.</p>

<ul>
  <li>ENTSO-E (to je evropské sdružení všech provozovatelů přenosových soustav) potvrdila ztrátu více jak 10 GW během 5 s (v tiskové zprávě REE se psalo 15 GW), což je obrovsky mnoho, na to žádná síť není dimenzována. V energetické síti se spotřeba musí rovnat výrobě a jsou zálohy, ale ne 15 GW.</li>
  <li>REE a REN (provozovatelé a dispečeři přenosových soustav ve Španělsku a Portugalsku) stále pracují s hypotézou „induced atmospheric vibration“ (galloping) na svazkových vedeních přes Pyreneje; ochrany prý vedení preventivně odpojily, čímž se poloostrov izoloval</li>
  <li>v okamžiku poruchy tvořily točivé zdroje jen ≈44 % výroby; vysoký podíl FVE a VtE urychlil pád frekvence. Točivé zdroje mohou do určité míry zbrzdit “pád soustavy”, protože “absorbují” pád frekvence, oproti tomu fotovoltaika se v případě problémů okamžitě odpojuje a to síť naopak může destabilizovat. 
Internetem putují “zvěsti” o podivnostech v britské síti nebo o odpojení kabelu Viking Link mezi Dánskem a Británií, jenže data ničemu takovému nenasvědčují a ani patřičné instituce k tomu nic nevydaly, čili to vypadá na kachnu.</li>
</ul>

<p>Problém může být v tom “ochrany odpojily vedení”. Podle analýzy SCADA logů se nezdá, že by do dálkově servisovatelných prvků někdo přistupoval, přesto je čistě hypoteticky možné, že někdo našel nějakou kombinaci postupů, jimž vyvolal kaskádovité odpojování. Někde jsem četl názor, že přeci stačí vzít klacek a vedení přes Pyreneje rozhoupat, aby hrozilo jeho zkratování. To jistě stačí, když vezmete asi stometrový klacek a nevadí vám ta trocha popálenin, kdy vás do nemocnice odvezou v krabičce od bot. A jelikož k mechanickému poškození (typu exploze) nedošlo, zatím se pracuje s tezí, že ochrany reagovaly příliš agresivně, než že by je k tomu někdo či něco donutilo. Ale uvidíme, tady je na závěry brzy a z pražské kanceláře rozhodně.</p>

<p>Co se děje teď?</p>

<ul>
  <li>Španělsko oznámilo, že od půl sedmé našeho času pokrývá 99 % celostátní poptávky a všechny hlavní uzly vysokého napětí jsou pod napětím  .</li>
  <li>Portugalsko již včera informovalo o napájení 85 z 89 stanic; poslední venkovské okruhy se budou připojovat v průběhu dneška  .</li>
  <li>Nouzové linky Francie - Katalánsko a Maroko - Andalusie zůstávají otevřené, aby pomohly s vyrovnáním výkonu během startu tepelných elektráren</li>
  <li>Doprava: Z kolejí bylo evakuováno více jak 35 000 cestujících, metro v Madridu a Lisabonu zprovoznilo první linky až dnes ráno  .</li>
  <li>Letiště: Madrid-Barajas i Barcelona-El Prat fungovaly na záložních okruzích; terminály zůstaly osvětlené, ale došlo ke zrušení více jak 400 letů  .</li>
  <li>Telekomunikace: mobilní sítě jely v nouzovém režimu na baterie — operátoři vyzvali uživatele ke střídmému volání, což prý úplně neklapalo, ranní interview na ČRo s reportérkou ze Španělska rušily výpadky.</li>
  <li>Veřejný pořádek: Španělsko rozmístilo 30 000 policistů; král Filip dnes vede zasedání Národní bezpečnostní rady  .</li>
  <li>Francie a Německo slíbily pomoc s mobilními bateriovými kontejnery a rychlými plynovými turbínami, pokud by přišly další vlny horka  .</li>
  <li>Velkoobchodní cena elektřiny v Iberian Market (OMIE) krátkodobě zhouply, ale už se stabilizují na day ahead průměru 6 €/MWh - problém byl spíš v dopravě elektřiny, než v její výrobní ceně a cenové výkyvy jsou malé.</li>
</ul>

<p>Takže závěr?</p>

<p>Na závěry je brzy. Terorismu nenasvědčuje zatím nic. Ani tomu neruskému (to už by se někdo hlásil s požadavky), ani tomu ruskému (to už by Rusko nabízelo pomoc). Jenže to je také první rychlý pohled a mohlo to jistě být jinak. Logy nelžou, ale mohl je někdo uklidit. Ostatně, konspirátoři předpokládají, že teroristé po sobě poprvé pořádně uklidili stopy (což Rusové nedělají, proč někoho terorizovat, když není jasné, kdo vám dal přes pusu).</p>

<p>Přesto vám sem jeden ilustrační obrázek dám 😎</p>

<p><img src="/assets/putin-jistic.jpg" alt="Putin si hraje s jističem" /></p>

<p>A ten Green Deal? Jistě, kdyby měla pyrenejská síť více točivých zdrojů, mohla dopadnout nějak lépe - jak moc, to se teprve nasimuluje. Ale kdyby měla balanční zdroje, jako jsou baterie, také by to ustála jinak. Na slunném jihu dávají FTV a větrníky velký smysl z hlediska produkčních cen a místní operátoři byli dlouhodobě upozorňováni na to, že tomu musí svoji síť přizpůsobit. Green Deal s nedodržením zásad diverzifikace nemá mnoho společného.</p>

<p>Elektřina už prakticky všude svítí, ale skutečná „detektivka“ právě teď začíná.  Podrobné záznamy z ochran a phasor PMU teprve ukážou, zda vedla řetěz selhání opravdu kombinace „rozkmitaných“ pyrenejských linek a nízké setrvačnosti, nebo se v poslední chvíli přidalo ještě něco dalšího.</p>

<hr />

<h2 id="zpráva-z-2842025">Zpráva z 28.4.2025:</h2>

<p>Podle provozovatelů REE a REN došlo v 11:33 WES-T k „el cero“ – úplnému výpadku energetické soustavy na Pyrenejském poloostrově. Extrémní teploty v centrálním Španělsku způsobily neobvyklé kmitání 400 kV vedení. Ochrany postupně odpojily více linek a generátorů, až se Pyrenejský poloostrov oddělil (“islandoval”, přešel do ostrovního provozu) od zbytku kontinentální sítě.</p>

<p>V izolované oblasti pak frekvence klesla ještě hlouběji, část elektráren se odpojila a následovalo masivní zatmění (blackout) Španělska, Portugalska a části jihozápadní Francie.  ￼</p>

<h3 id="️-blackout-co-se-28-4-2025-stalo-ve-španělsku-a-portugalsku">⚡️ Blackout: co se 28. 4. 2025 stalo ve Španělsku a Portugalsku?</h3>

<p>Podívejme se na událost v grafu. Z něj je vidět, že pokles byl v nejostřejším místě jen 0,15 Hz. Pojďme si to vysvětlit pro zájemce o energetiku…</p>

<p>Proč na kontinentu „spadlo“ jen 0,15 Hz?</p>
<ul>
  <li>Po odpojení Iberského poloostrova ztratila zbytek Evropy čistý export ~4–5 GW ze Španělska (obě země měly v poledne vysokou výrobu ze solárních a větrných zdrojů).</li>
  <li>Tato ztráta se okamžitě promítla do grafu jako −150 mHz.</li>
  <li>Primární regulace ve zbytku Evropy (turbíny, baterie, HVDC linky) během sekund začala výkon zvyšovat, čímž frekvenci zastavila u ≈ 49,85 Hz a během tří minut ji vytáhla zpět nad 49,9 Hz.</li>
  <li>Díky rychlé reakci a dostatečné setrvačnosti se kontinentální síť neodstavila – v grafu vidíte jen krátký, ale prudký zářez.</li>
</ul>

<p><img src="/assets/hz-net.png" alt="Graf frekvence v eurogridu" /></p>

<p>Co vidíme v grafu</p>
<ul>
  <li>Osa y (Frekvence): nominál evropské synchronní sítě je 50,00 Hz.</li>
  <li>Tři křivky (žlutá = průměr, černá = maximum, šedá = minimum) ukazují, jak se frekvence mezi ≈ 11:55 a 13:00 CEST pohybovala v různých měřicích bodech propojené soustavy.</li>
  <li>Až do ≈ 12:30 se frekvence vlnila v běžném koridoru ±20 mHz (49,98–50,02 Hz).</li>
  <li>V 12:31–12:34 nastal prudký pád až na ≈ 49,85 Hz – to je odchylka −150 mHz.</li>
  <li>Vzápětí se frekvence díky primární regulaci a automatickým zálohám vrátila k 50 Hz; kolem 12:45 už je systém opět stabilní.</li>
</ul>

<p>Co takový pokles znamená</p>

<p>Frekvence se sníží, když odběr náhle převýší výrobu (nebo když se naopak od sítě odpojí část výrobních kapacit). V evropské soustavě stačí nerovnováha ~30 GW / Hz; −0,15 Hz tedy odpovídá zhruba 4–5 GW náhle chybějícího výkonu.</p>

<p>Důsledky na Pyrenejském poloostrově</p>
<ul>
  <li>Izolovaná Iberská soustava přišla o možnost importů z Francie, které by krátkodobě pomohly stabilizaci. Protože odběr převýšil dostupnou vlastní výrobu, frekvence spadla výrazněji (pravděpodobně &lt; 49 Hz).</li>
  <li>Ochrany odpojily další zdroje i zátěže, aby chránily zařízení, což se navenek projevilo rozsáhlým blackoutem (vlaky, metro, letiště, domácnosti).</li>
  <li>Obnova musela probíhat postupně, aby se zamezilo dalšímu kolapsu napětí a frekvence.  ￼</li>
</ul>

<p>Takže ve stručnosti:</p>

<ul>
  <li>Z pohledu zbytku Evropy šlo o „pouhou“ ztrátu ~5 GW → pokles frekvence o 0,15 Hz, rychle vyrovnaný zálohami.</li>
  <li>Z pohledu Španělska a Portugalska to znamenalo ztrátu propojení, hluboký propad frekvence a následný blackout.</li>
</ul>

<p>Taková událost názorně ukazuje, jak citlivá je moderní síť: i malá odchylka frekvence na kontinentu může signalizovat dramatické dění v jedné jeho části, a proč je klíčové mít dostatek rychlých regulačních zdrojů a chytré ochrany.</p>

<p>PS: je to samozřejmě můj neodborný názor založený na tom co k tomu vyšlo</p>]]></content><author><name>Patrick Zandl</name></author><category term="Energie" /><category term="Energetika" /><category term="Green Deal" /><summary type="html"><![CDATA[Co nového ve vyšetřování španělského blackoutu? ENSOE-E uvolnilo první předběžnou zprávu, ale úplně nejvíc jasno z ní není, proto jsem také informace pár dní neaktualizoval, jen bychom naprázdno propírali hypotézy nebo padali do logických pastí.]]></summary></entry><entry xml:lang="cs"><title type="html">OpenAI kupuje Windsurf a posiluje v programátorských nástrojích</title><link href="https://www.marigold.cz/item/openai-kupuje-windsurf/" rel="alternate" type="text/html" title="OpenAI kupuje Windsurf a posiluje v programátorských nástrojích" /><published>2025-05-11T00:00:00+00:00</published><updated>2025-05-11T00:00:00+00:00</updated><id>https://www.marigold.cz/item/openai-kupuje-windsurf</id><content type="html" xml:base="https://www.marigold.cz/item/openai-kupuje-windsurf/"><![CDATA[<p>OpenAI kupuje za 3 miliardy dolarů společnost <a href="https://windsurf.com">Windsurf</a>, který se zabývá vývojem prostředí pro AI kódování. Co je zajímavého na tom, že společnost, která tvrdí, že její interní LLM nástroj je mezi padesáti nejlepšími programátory světa, koupí za tři miliardy dolarů firmu, která takový nástroj vyvíjí?</p>

<ul>
  <li>Trh s AI asistenty pro programování je extrémně konkurenční. Microsoft (GitHub Copilot), Anthropic, Google (Gemini), Anysphere (Cursor) a další rychle inovují a získávají uživatele.</li>
  <li>OpenAI potřebuje nejen špičkový model, ale i silnou pozici v každodenních vývojářských workflow, kde už dnes dominují jiné nástroje.</li>
  <li>Windsurf má unikátní technologii (například systém “Cascade Flow”), která umožňuje hlubokou integraci do IDE a optimalizaci práce s celými codebase, včetně správy závislostí a refaktoringu starého kódu.</li>
  <li>To je něco, co samotné LLM nestačí. Vývojáři potřebují nástroje, které se napojí přímo na jejich pracovní procesy, repo a infrastrukturu. Tyto dva body považuji za první klíčovou věc!</li>
  <li>Akvizice Windsurf umožní OpenAI vytvořit uzavřený ekosystém, kde bude mít pod kontrolou jak základní modely, tak i konkrétní nástroje, které vývojáři používají denně.</li>
  <li>Tím získá přístup k reálným datům z vývoje, což je klíčové pro další zlepšování modelů i pro udržení pozice na trhu. Tohle považuji za druhou nejklíčovější záležitost.</li>
  <li>Windsurf vykazuje velmi rychlý růst tržeb (z 10 na 40 milionů USD ARR za dva roky) a má potenciál stát se jedním z hlavních hráčů v segmentu AI coding tools.</li>
  <li>OpenAI tímto krokem nejen posiluje své portfolio, ale také předchází tomu, že by Windsurf získal některý z konkurentů.</li>
</ul>

<p><img src="/assets/windsurf-ide.webp" alt="Windsurf IDE" /></p>

<p>Sám musím říct, že Windsurf je jedním z mála AI kodovacích nástrojů, které jsem prakticky víc nevyzkoušel. IDE vychází z VS Code rozložení, na což jsou programátoři zvyklí, není to vysloveně vibe coding technologie.</p>

<p>Můj osobní odhad je, že OpenAI šlo právě po těch reálných datech z vývoje a propojení k feedbacku od skutečných programátorů. Což je ve Windsurfu uděláno moc hezky.</p>

<p>Reakce trhu a investorů</p>
<ul>
  <li>Trhy reagovaly citlivě, zejména akcie Microsoftu zaznamenaly pokles. Důvodem je úzké propojení OpenAI a Microsoftu – Microsoft je hlavním investorem OpenAI a integruje její technologie do svých produktů. Investoři mají obavy, zda je akvizice za několik miliard efektivním využitím prostředků, zvlášť v době, kdy není jasné, které AI směry přinesou největší návratnost.</li>
  <li>Někteří investoři by upřednostnili, kdyby OpenAI investovala spíše do vlastního výzkumu než do akvizic. Objevují se i názory, že akvizice je motivována snahou rychle zvýšit tržby a rozšířit ekosystém, což je v prostředí tvrdé konkurence logický krok.</li>
</ul>

<p>Reakce uživatelské a vývojářské komunity</p>
<ul>
  <li>Obavy uživatelů Windsurfu: Na komunitních fórech a Discordu Windsurfu panuje nejistota ohledně budoucnosti služby – uživatelé se bojí zdražení, omezení funkcí nebo exkluzivity pro předplatitele OpenAI/ChatGPT.</li>
  <li>Otázky ohledně podpory konkurenčních modelů: Windsurf umožňuje využívat různé jazykové modely (např. Meta Llama, Anthropic Claude). Vývojáři spekulují, zda OpenAI tuto otevřenost zachová, nebo bude tlačit pouze své modely, což by mohlo vyvolat obvinění z omezování konkurence.</li>
</ul>

<h3 id="windsurf-wave-8-významná-aktualizace-pro-vývojáře">Windsurf Wave 8: Významná aktualizace pro vývojáře</h3>

<p>Windsurf akvizici oslavil tím, že vydal “Osmou vlnu” - osmou hlavní verzi. Windsurf Wave 8 přináší řadu vylepšení zaměřených především na JetBrains plugin a uživatelské rozhraní. Do JetBrains pluginu byly konečně přidány dlouho očekávané funkce z editoru Windsurf, včetně Cascade Memories pro ukládání důležitých informací mezi konverzacemi, původní implementace Rules přes soubor .windsurfrules pro řízení AI, a podpora MCP (Model Context Protocol) pro připojení k lokálním serverům s arbitrárními datovými zdroji. Tyto funkce výrazně rozšiřují možnosti Cascade v prostředí JetBrains.</p>

<p>Na straně UX došlo také k několika důležitým vylepšením. Přibylo nové tlačítko “Continue”, které umožňuje jednoduše pokračovat v práci Cascade bez nutnosti psát další prompt, když se AI zastaví pro zpětnou vazbu. Model selector byl kompletně přepracován pro lepší organizaci rostoucího počtu dostupných modelů podle poskytovatele nebo ceny. Nově je také možné filtrovat historii konverzací podle workspace, což výrazně zlepšuje orientaci při práci na více projektech současně.</p>

<p>Mezi další vylepšení patří lepší podpora témat pro bloky kódu, možnost upravit navržené terminálové příkazy před jejich provedením, vylepšené navigace v hunk změnách kódu a schopnost Cascade navrhovat obsah nových souborů přímo v Chat módu. Všechny tyto změny reflektují důraz vývojářů Windsurf na intuitivní a plynulé uživatelské rozhraní, které maximalizuje produktivitu při práci s AI asistentem.</p>

<p><strong>Klíčové novinky:</strong></p>
<ul>
  <li>Cascade Memories v JetBrains - AI si pamatuje důležité informace mezi konverzacemi</li>
  <li>Podpora Rules (.windsurfrules) pro přizpůsobení chování AI</li>
  <li>MCP integrace pro připojení k lokálním datovým zdrojům</li>
  <li>Tlačítko “Continue” pro rychlé pokračování bez psaní promptu</li>
  <li>Přepracovaný model selector s lepší organizací modelů</li>
  <li>Filtrování konverzací podle workspace</li>
  <li>Vylepšená správa bloků kódu a hunk navigace</li>
  <li>Možnost editace navržených terminálových příkazů</li>
  <li>Návrhy obsahu nových souborů přímo v Chat módu</li>
</ul>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="vibecoding" /><category term="programování" /><category term="OpenAI" /><summary type="html"><![CDATA[OpenAI kupuje za 3 miliardy dolarů společnost Windsurf, který se zabývá vývojem prostředí pro AI kódování. Co je zajímavého na tom, že společnost, která tvrdí, že její interní LLM nástroj je mezi padesáti nejlepšími programátory světa, koupí za tři miliardy dolarů firmu, která takový nástroj vyvíjí?]]></summary></entry><entry xml:lang="cs"><title type="html">První česká tragédie prostřednictvím autonomního AI agenta</title><link href="https://www.marigold.cz/item/nehoda-ai-agenta/" rel="alternate" type="text/html" title="První česká tragédie prostřednictvím autonomního AI agenta" /><published>2025-05-08T00:00:00+00:00</published><updated>2025-05-08T00:00:00+00:00</updated><id>https://www.marigold.cz/item/nehoda-ai-agenta</id><content type="html" xml:base="https://www.marigold.cz/item/nehoda-ai-agenta/"><![CDATA[<p>Nebudete věřit, co se stalo, když zadal nedobře odladěnému autonomnímu agentovi nákupní pokyn a svou platební kartu. Už nikdy nebudete klidně spát!</p>

<p>V jednom ze svých nedávných newsletterů jsem psal, že nedeterministické chování AI agentů a obrovský tlak jejich vývojářů a investorů vývojářů na jejich rychlé nasazení, letos způsobí katastrofu. A bude jen na zkušeném managementu, jak takovou katastrofu zvládne. To jsem nevěděl, že jeden takový příklad budu mít za chvíli a půjde v něm o hodně.</p>

<p>Když jsem zkoušel první agenty vytvořené v AI, dělal jsem v tom nenáročné operace typu “najdi na stránkách obcí cenu za svoz odpadu a další podmínky”. A byl jsem vlastně spokojen. Pak jsem se rozhodl, že technologie je otestovaná, takže ji mohu nasadit i na nějaký klíčový úkol, kdy AI agenta vybavím napojením na živé systémy a mojí platební kartou. Vím, školácká chyba, ale bylo to nutné prověřit na vlastní kůži. A tak jsem agentovi zadal úkol hlídat stránky Žižkovského divadla Járy Cimrmana a v momentě, kdy budou dostupné vstupenky na nějakou cimrmanovskou hru, jich šest zakoupit, abych mohl vyrazit s dětmi. Proto ta platební karta.</p>

<p>Úspěch se dostavil o dva dny později, kdy mi cinkla notifikace, že biletky jsou úspěšně zakoupeny a můžeme za dva měsíce jít na hru. Dlužno říct, že hra <a href="https://zdjc.cz/cs/program/nohy-z-jilu/">Nohy z jílu</a> mi nebyla příliš známá, ačkoliv jistě povědomá. Nicméně nejsem velký znalec cimrmanova kánou a venkoncem, proč by nemohl napsat hru z prostředí státní správy. No, nebudu vás napínat, hru uvádělo hostující <a href="http://divadloaqualung.cz">Divadlo Aqualung</a> a s Cimrmanem neměla nic společného, jen se hrála také v Žižkovském divadle. AI agent prostě zklamal.</p>

<p>No a teď k té úloze seniorního managementu. Dětem jsem vysvětlil výhodu možnosti jít na moderní divadelní pojetí hry Terryho Pratcheta ze zeměplošského cyklu, všem se hra líbila a všichni si dokonce vyžádali, abychom šli i na další díl.</p>

<p>No a takhle to s AI agenty v nejbližší době bude. Buďto je nezvládnete správně nasadit, nebo udělají chybu, v lepším případě koupí špatné lístky, v horším někoho odpojí od elektřiny. V zásadě proto budete potřebovat seniorního manažera, který z nevýhody udělá výhodu a všechno zlé obrátí v dobré. Tak, jako vždycky. Od toho seniorní management je, aby poznal slepou jednosměrku a vyhodnotil, zda je lepší vycouvat, nebo zvýšenou rychlostí jednosměrku zobousměrnit.</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="agenti" /><summary type="html"><![CDATA[Nebudete věřit, co se stalo, když zadal nedobře odladěnému autonomnímu agentovi nákupní pokyn a svou platební kartu. Už nikdy nebudete klidně spát!]]></summary></entry><entry xml:lang="cs"><title type="html">Proč je velikost kontextu u LLM tak důležitá?</title><link href="https://www.marigold.cz/item/ai-kontext/" rel="alternate" type="text/html" title="Proč je velikost kontextu u LLM tak důležitá?" /><published>2025-05-05T00:00:00+00:00</published><updated>2025-05-05T00:00:00+00:00</updated><id>https://www.marigold.cz/item/ai-kontext</id><content type="html" xml:base="https://www.marigold.cz/item/ai-kontext/"><![CDATA[<p>A především, proč je tak drahé a zdlouhavé zvyšovat velikost kontextu? Tento článek se podrobně zabývá tím, co kontext znamená, proč je jeho délka kritická, jaké technické překážky brání jeho neomezenému rozšiřování a jaká řešení se v současnosti vyvíjejí.</p>

<p><strong>Co konkrétně se v tomto článku dozvíte?</strong></p>
<ul id="markdown-toc">
  <li><a href="#co-je-kontext-a-proč-je-jeho-délka-klíčová" id="markdown-toc-co-je-kontext-a-proč-je-jeho-délka-klíčová">Co je kontext a proč je jeho délka klíčová?</a>    <ul>
      <li><a href="#význam-délky-kontextu-pro-kvalitu-výstupu" id="markdown-toc-význam-délky-kontextu-pro-kvalitu-výstupu">Význam délky kontextu pro kvalitu výstupu:</a></li>
      <li><a href="#aktuální-velikosti-kontextových-oken-a-ceny-květen-2025" id="markdown-toc-aktuální-velikosti-kontextových-oken-a-ceny-květen-2025">Aktuální velikosti kontextových oken a ceny (květen 2025)</a></li>
    </ul>
  </li>
  <li><a href="#jádro-problému-kvadratická-složitost-mechanismu-pozornosti" id="markdown-toc-jádro-problému-kvadratická-složitost-mechanismu-pozornosti">Jádro problému: Kvadratická složitost mechanismu pozornosti</a></li>
  <li><a href="#praktické-důsledky-kvadratické-složitosti" id="markdown-toc-praktické-důsledky-kvadratické-složitosti">Praktické důsledky kvadratické složitosti</a></li>
  <li><a href="#současné-přístupy-a-řešení" id="markdown-toc-současné-přístupy-a-řešení">Současné přístupy a řešení</a>    <ul>
      <li><a href="#1-optimalizace-standardní-pozornosti" id="markdown-toc-1-optimalizace-standardní-pozornosti">1. Optimalizace standardní pozornosti</a></li>
      <li><a href="#2-aproximace-pozornosti-řídká-pozornost---sparse-attention" id="markdown-toc-2-aproximace-pozornosti-řídká-pozornost---sparse-attention">2. Aproximace pozornosti (Řídká pozornost - Sparse Attention)</a></li>
      <li><a href="#3-alternativní-architektury-mimo-transformátory" id="markdown-toc-3-alternativní-architektury-mimo-transformátory">3. Alternativní architektury (mimo transformátory)</a></li>
      <li><a href="#4-retrieval-augmented-generation-rag" id="markdown-toc-4-retrieval-augmented-generation-rag">4. Retrieval-Augmented Generation (RAG)</a></li>
      <li><a href="#5-další-techniky" id="markdown-toc-5-další-techniky">5. Další techniky</a></li>
    </ul>
  </li>
  <li><a href="#výzvy-a-budoucí-směřování" id="markdown-toc-výzvy-a-budoucí-směřování">Výzvy a budoucí směřování</a></li>
  <li><a href="#závěr" id="markdown-toc-závěr">Závěr</a></li>
</ul>

<p>Velké jazykové modely (LLM) jako GPT-4, Claude 3 nebo Gemini 2.5 se staly výkonnými nástroji pro zpracování přirozeného jazyka. Jejich schopnost generovat text, překládat, odpovídat na otázky a psát kód je využívána v mnoha oblastech. Navzdory jejich pokročilým schopnostem však narážejí na významné omezení: efektivní zpracování velmi dlouhých sekvencí dat, známé jako “problém dlouhého kontextu”.</p>

<h2 id="co-je-kontext-a-proč-je-jeho-délka-klíčová">Co je kontext a proč je jeho délka klíčová?</h2>

<p>V případě LLM představuje kontext (context window) veškerá data, která má model k dispozici v daném okamžiku pro zpracování a generování odpovědi. Funguje jako operační paměť modelu. Pokud si LLM chce něco pamatovat v rámci rozhovoru, předává si to jako kontext, ačkoliv to třeba nevidíte. Pokud má LLM pracovat s vašimi předchozími zprávami v rámci chatu, prostě je přibalí do posílaných dat. Obsah kontextu typicky zahrnuje:</p>

<ol>
  <li>
    <p>Vstupní text (prompt): Zadání nebo otázka od uživatele.</p>
  </li>
  <li>
    <p>Historie konverzace: Předchozí výměny v rámci aktuální interakce. U některých systémů může zahrnovat i relevantní informace z minulých interakcí (např. pomocí explicitních paměťových mechanismů).</p>
  </li>
  <li>
    <p>Poskytnuté dokumenty: Externí texty, které má model analyzovat, shrnout nebo z nich čerpat informace (např. nahrané PDF, webové stránky).</p>
  </li>
  <li>
    <p>Interní instrukce: Systémové prompty definující chování modelu, jeho personu nebo specifické úkoly.</p>
  </li>
  <li>
    <p>Vygenerovaný text: Část textu, kterou model sám postupně generuje jako odpověď.</p>
  </li>
</ol>

<p>Délka kontextu, obvykle měřená v tokenech, definuje maximální množství informací, které model může současně zpracovat. Token je základní jednotka textu pro LLM, která může odpovídat slovu, části slova nebo interpunkčnímu znaménku (pro hlubší vysvětlení viz článek <a href="/ai/tokeny-versus-slova">Tokeny versus Slova</a>).</p>

<h3 id="význam-délky-kontextu-pro-kvalitu-výstupu">Význam délky kontextu pro kvalitu výstupu:</h3>

<ul>
  <li>
    <p>Porozumění souvislostem: Delší kontext umožňuje modelu lépe zachytit složité vztahy, závislosti a nuance v rozsáhlých textech.</p>
  </li>
  <li>
    <p>Konzistence: Schopnost udržet jednotný styl, téma a faktickou správnost napříč dlouhými konverzacemi nebo dokumenty.</p>
  </li>
  <li>
    <p>Přesnost a relevance: Přístup k většímu množství relevantních informací vede k přesnějším a lépe zacíleným odpovědím.</p>
  </li>
  <li>
    <p>Zpracování komplexních úloh: Úlohy jako detailní analýza rozsáhlých reportů, knih nebo kódových bází vyžadují schopnost pojmout velké množství dat najednou.</p>
  </li>
  <li>
    <p>Omezení “halucinací”: Poskytnutí dostatečného kontextu může snížit tendenci modelu vymýšlet si informace, které nejsou ve vstupních datech.</p>
  </li>
</ul>

<h3 id="aktuální-velikosti-kontextových-oken-a-ceny-květen-2025">Aktuální velikosti kontextových oken a ceny (květen 2025)</h3>

<p>Velikost kontextového okna a cena jsou klíčové parametry při výběru modelu. Níže je uveden přehled některých populárních modelů s daty převážně z OpenRouter (duben 2025):</p>

<table>
  <thead>
    <tr>
      <th><strong>Model</strong></th>
      <th><strong>Kontextové okno (Max vstup)</strong></th>
      <th><strong>Max. výstup</strong></th>
      <th><strong>Cena vstupu ($/1M tokenů)</strong></th>
      <th><strong>Cena výstupu ($/1M tokenů)</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>o3 (OpenAI)</td>
      <td>200 000</td>
      <td>100 000</td>
      <td>$10.00</td>
      <td>$40.00</td>
    </tr>
    <tr>
      <td>o4-Mini (OpenAI)</td>
      <td>200 000</td>
      <td>100 000</td>
      <td>$1.10</td>
      <td>$4.40</td>
    </tr>
    <tr>
      <td>o4-Mini High (OpenAI)</td>
      <td>200 000</td>
      <td>100 000</td>
      <td>$1.10</td>
      <td>$4.40</td>
    </tr>
    <tr>
      <td>GPT-4.1 (OpenAI)</td>
      <td>1 050 000</td>
      <td>33 000</td>
      <td>$2.00</td>
      <td>$8.00</td>
    </tr>
    <tr>
      <td>Claude 3.7 Sonnet</td>
      <td>200 000</td>
      <td>64 000</td>
      <td>$3.00</td>
      <td>$15.00</td>
    </tr>
    <tr>
      <td>Claude 3.7 Sonnet Think</td>
      <td>200 000</td>
      <td>64 000</td>
      <td>$3.00</td>
      <td>$15.00</td>
    </tr>
    <tr>
      <td>Gemini 2.5 Pro (Google)</td>
      <td>1 050 000</td>
      <td>66 000</td>
      <td>$1.25 - $2.50</td>
      <td>$10.00 - $15.00</td>
    </tr>
    <tr>
      <td>Grok 3 beta (xAI)</td>
      <td>131 000</td>
      <td>131 000</td>
      <td>$3.00</td>
      <td>$15.00</td>
    </tr>
    <tr>
      <td>Llama 4</td>
      <td>10 milionů</td>
      <td>-</td>
      <td>(Open Source)</td>
      <td>(Open Source)</td>
    </tr>
    <tr>
      <td>Jamba-1.5 (AI21, OS)</td>
      <td>256 000</td>
      <td>-</td>
      <td>(Open Source)</td>
      <td>(Open Source)</td>
    </tr>
  </tbody>
</table>

<p>Poznámka: Ceny se mohou lišit v závislosti na poskytovateli API (zde OpenRouter) a aktuálním vytížení. U Gemini 2.5 Pro jsou ceny uvedeny v rozsahu. Open-source modely nemají přímé ceny za token, ale náklady na jejich provoz. Hodnota u LLAMA 4 je velmi optimistická, model na to nebyl řádně testován a výsledky nejsou příliš kvalitní.</p>

<p>Je důležité poznamenat, že nominální délka kontextového okna nemusí vždy odpovídat efektivní schopnosti modelu využívat informace z celého kontextu. Testy jako <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack">Needle In A Haystack</a> (NIAH) ukazují, že některé modely mají problémy s vyhledáváním informací umístěných uprostřed velmi dlouhého kontextu (tzv. “lost in the middle” problém), i když se tento problém postupně daří zmírňovat.</p>

<p>Už teď je tedy zřejmé, že na rozsahu kontextu záleží, přičemž “kontext” není jen to, co zadáte do Prompt okna v ChatGPT, ale také spousta dodatečných dat, kterými ChatGPT váš dotaz “obalí”, aby využil toho, co ví o vás, o tom, co vyžadujete atd. Nabízí se tedy otázka, proč se jednoduše velikost kontextového okna nerozšíří na maximum! Odpověď? Protože to není vůbec jednoduché a především to stojí hromadu peněz při používání! Jak to?</p>

<h2 id="jádro-problému-kvadratická-složitost-mechanismu-pozornosti">Jádro problému: Kvadratická složitost mechanismu pozornosti</h2>

<p>Základem většiny moderních LLM je architektura transformátoru, představená v roce 2017 v článku “Attention Is All You Need”. Klíčovou inovací této architektury je mechanismus sebe-pozornosti (self-attention). Ten umožňuje modelu vážit důležitost všech ostatních tokenů v kontextu při zpracování každého jednotlivého tokenu.</p>

<p>Jak to funguje (velmi zjednodušeně): model se při čtení každého slova “dívá” na všechna ostatní slova v textu, aby pochopil jeho význam v dané větě. Tedy počítá jej vůči všem předchozím slovům. Tímto způsobem zjišťuje, která slova jsou pro aktuální slovo nejdůležitější a jak spolu souvisí. Proto prodlužování textu zvyšuje náročnost výpočtů exponenciálně.</p>

<p>Jak funguje (méně zjednodušeně): Pro každý token model vypočítá tři vektory: Query (Q), Key (K) a Value (V). Poté pro každý token (reprezentovaný jeho Q vektorem) vypočítá skóre pozornosti vůči všem ostatním tokenům (porovnáním Q s K vektory všech tokenů). Tato skóre se normalizují (typicky pomocí funkce softmax) a použijí se k vytvoření váženého součtu V vektorů všech tokenů. Výsledkem je nová reprezentace tokenu, která zohledňuje jeho vztah ke všem ostatním tokenům v kontextu.</p>

<p>Problém škálování: Tento mechanismus je extrémně efektivní pro zachycení závislostí v textu, ale má zásadní nevýhodu: jeho výpočetní a paměťová složitost roste kvadraticky s délkou sekvence (N, počet tokenů).</p>

<ul>
  <li>
    <p>Výpočetní složitost: Počet operací potřebných pro výpočet matice pozornosti je úměrný O(N2). Pro každý z N tokenů musíme vypočítat jeho vztah k N tokenům (včetně sebe sama).</p>
  </li>
  <li>
    <p>Paměťová složitost: Model si musí během výpočtu uchovávat matici pozornosti o velikosti N×N, což vede k paměťové náročnosti O(N2).</p>
  </li>
</ul>

<p>Ilustrace dopadu:</p>

<p>Přesné časy zpracování závisí na mnoha faktorech (konkrétní model, hardware - např. typ GPU, optimalizace - např. FlashAttention, datový typ výpočtů), ale pro ilustraci řádového nárůstu náročnosti na výkonném GPU (např. NVIDIA H100/B100):</p>

<ul>
  <li>
    <p>Kontext 1 000 tokenů: Vyžaduje řádově 10002=1000000 operací/paměťových jednotek. Zpracování (inference) může trvat zlomky sekundy až jednotky sekund.</p>
  </li>
  <li>
    <p>Kontext 10 000 tokenů: Vyžaduje řádově 100002=100000000 operací/paměťových jednotek (100x více). Doba zpracování se může pohybovat v jednotkách až desítkách sekund.</p>
  </li>
  <li>
    <p>Kontext 100 000 tokenů: Vyžaduje řádově 1000002=10000000000 operací/paměťových jednotek (10 000x více než pro 1k tokenů). Doba zpracování může dosahovat desítek sekund až několika minut.</p>
  </li>
  <li>
    <p>Kontext 1 000 000 tokenů (jako u Gemini Pro, GPT-4.1): Vyžaduje řádově 10000002=1000000000000 (bilion) operací/paměťových jednotek. Doba zpracování se může pohybovat v řádu několika minut až desítek minut, silně závisí na optimalizacích a počtu použitých akcelerátorů.</p>
  </li>
</ul>

<p>Tento kvadratický nárůst představuje obrovskou bariéru pro neomezené prodlužování kontextového okna u standardních transformátorů, jak z hlediska výpočetní náročnosti (čas), tak paměťových požadavků.</p>

<h2 id="praktické-důsledky-kvadratické-složitosti">Praktické důsledky kvadratické složitosti</h2>

<p>Kvadratická složitost mechanismu pozornosti má několik zásadních praktických dopadů. Především vede k enormní výpočetní náročnosti a latenci při zpracování dlouhých kontextů. Vyžaduje to obrovské množství výpočetních zdrojů, jako jsou GPU nebo TPU, což se projevuje delší dobou odezvy při generování odpovědí, vysokou spotřebou energie a následně i vysokými náklady na trénink a inferenci modelů kvůli potřebě výkonného a drahého hardwaru. Proto jsou modely, které mají velké množství parametrů a umožňují zpracovat velký kontext, také zpravidla výrazně dražší.</p>

<p>Dalším významným důsledkem jsou vysoké paměťové nároky, zejména na VRAM akcelerátorů. Model musí uchovávat matice pozornosti a mezivýpočty (aktivace) pro všechny tokeny v kontextu. Například optimalizace zvaná KV cache, která ukládá vypočtené vektory pro zrychlení inference, vyžaduje pro model Llama 3 70B s kontextem 128 000 tokenů stovky gigabajtů VRAM. Pro kontexty v řádu milionů tokenů tyto nároky dále dramaticky rostou, což omezuje nasazení takových modelů pouze na hardware s masivní paměťovou kapacitou.</p>

<p>Tyto zvýšené výpočetní a paměťové nároky se promítají do ekonomických dopadů. Poskytovatelé LLM služeb musí tyto náklady zohlednit, a proto zpravidla účtují vyšší ceny za použití modelů s delšími kontextovými okny nebo za zpracování tokenů přesahujících určitou hranici, jak je vidět v přehledové tabulce cen.</p>

<p>Nakonec, i když model technicky zvládne zpracovat velmi dlouhý kontext, objevuje se problém známý jako “Lost in the Middle”. Empirické testy ukazují, že schopnost modelu efektivně využívat informace může klesat, pokud jsou tyto informace umístěny uprostřed velmi dlouhého vstupního textu. Modely často vykazují tendenci lépe pracovat s informacemi uvedenými na začátku nebo na konci kontextového okna.</p>

<h2 id="současné-přístupy-a-řešení">Současné přístupy a řešení</h2>

<p>Výzkum a vývoj se intenzivně zaměřují na zmírnění nebo překonání O(N2) bariéry, protože překročení limitů přinášených kontextem by umožňovalo výrazně rozšířit úlohy, v nichž AI / LLM excelují. A také dosáhnout lepší ekonomiky. Hlavní směry výzkumu jsou zhruba následující:</p>

<h3 id="1-optimalizace-standardní-pozornosti">1. Optimalizace standardní pozornosti</h3>

<ul>
  <li>
    <p>FlashAttention (a jeho následovníci FlashAttention-2, FlashAttention-3): Algoritmus, který restrukturalizuje výpočet pozornosti tak, aby lépe využíval hierarchii paměti GPU. Minimalizuje pomalé přesuny dat mezi HBM (High Bandwidth Memory) a SRAM (on-chip paměť) pomocí technik jako tiling a recomputation. Výrazně zrychluje výpočet a snižuje paměťové nároky bez změny matematiky pozornosti, takže výsledky jsou (téměř) identické se standardní pozorností. Stal se de facto standardem pro trénink a inferenci moderních LLM.</p>
  </li>
  <li>
    <p>KV Cache (Key-Value Cache): Optimalizace pro inferenci (generování textu). Místo přepočítávání K a V vektorů pro všechny předchozí tokeny při generování každého nového tokenu se tyto vektory ukládají do paměti (cache). To snižuje výpočetní náročnost generování z O(N2) na O(N) pro každý nový token, ale paměťová náročnost pro uložení cache zůstává O(N).</p>
  </li>
</ul>

<h3 id="2-aproximace-pozornosti-řídká-pozornost---sparse-attention">2. Aproximace pozornosti (Řídká pozornost - Sparse Attention)</h3>

<p>Cílem tohoto přístupu je snížit počet párů tokenů, mezi kterými se počítá pozornost, a tím prolomit kvadratickou složitost výpočtu plné matice pozornosti. Místo aby každý token interagoval se všemi ostatními, interakce se omezí na “řídký” vzor, který se snaží zachovat nejdůležitější informace. Longformer například kombinuje lokální pozornost, kde každý token interaguje pouze se svými nejbližšími sousedy v rámci “klouzavého okna”, s globální pozorností pro několik předem určených tokenů (např. speciální tokeny jako [CLS]). Tyto globální tokeny mohou interagovat se všemi ostatními tokeny a všechny ostatní tokeny mohou interagovat s nimi, což umožňuje přenos informací napříč celou sekvencí při zachování převážně lokálních výpočtů. Podobně BigBird používá kombinaci tří typů řídké pozornosti: náhodnou pozornost (každý token interaguje s malým náhodným vzorkem ostatních tokenů), okénkovou pozornost (podobně jako Longformer) a globální pozornost. Tato kombinace má teoretické základy a snaží se efektivně aproximovat vlastnosti plné matice pozornosti. Jiné metody, jako Routing Transformer nebo Sinkhorn Transformer, jdou ještě dál a snaží se dynamicky “naučit” nebo optimalizovat, které páry tokenů jsou nejdůležitější pro výpočet pozornosti, například pomocí technik směrování informací nebo metod inspirovaných optimálním transportem (Sinkhorn), čímž se výpočty soustředí pouze na nejrelevantnější části matice pozornosti.</p>

<p>Ačkoliv tyto metody mohou dosáhnout lineární (O(N)) nebo téměř lineární (O(NlogN)) výpočetní složitosti, kompromisem může být mírné snížení kvality modelu oproti plné pozornosti. Důvodem je, že předdefinované nebo aproximované vzory řídké pozornosti nemusí vždy dokonale zachytit všechny relevantní dlouhodobé závislosti v textu, které by plná pozornost identifikovala.</p>

<h3 id="3-alternativní-architektury-mimo-transformátory">3. Alternativní architektury (mimo transformátory)</h3>

<p>Hledání architektur, které nejsou založeny na standardní O(N2) pozornosti:</p>

<ul>
  <li>
    <p>Rekurentní <a href="/ai/neuronove-site/">neuronové sítě</a> (RNN) / LSTM / GRU: Tyto sítě představují starší přístup ke zpracování sekvencí, jehož kořeny sahají až do 80. a 90. let 20. století. Základní myšlenka RNN spočívá ve zpracování sekvence krok za krokem (token po tokenu), přičemž si síť udržuje vnitřní “stav” nebo “paměť”, která shrnuje informace z předchozích kroků. Tento stav se aktualizuje při zpracování každého nového tokenu. Díky tomu má zpracování inherentně lineární výpočetní složitost (O(N)), protože výpočet pro každý token závisí pouze na aktuálním vstupu a předchozím stavu, nikoli na všech předchozích tokenech současně. Varianty jako LSTM (Long Short-Term Memory, Hochreiter &amp; Schmidhuber, 1997) a GRU (Gated Recurrent Unit) byly vyvinuty později, aby řešily klíčový problém základních RNN: tzv. mizení nebo explozi gradientů (vanishing/exploding gradients), které bránily učení závislostí na dlouhé vzdálenosti v sekvenci. Přestože LSTM a GRU tento problém zmírnily pomocí speciálních “bran” (gates), které řídí tok informací a gradientů, stále měly své limity. Hlavní nevýhodou oproti transformátorům se ukázala být jejich sekvenční povaha, která znesnadňuje paralelizaci výpočtů během tréninku na moderním hardwaru (GPU/TPU). Transformátory, které mohou zpracovávat všechny tokeny v sekvenci víceméně paralelně díky mechanismu pozornosti, se tak staly efektivnější pro trénink na velkých datech a dosáhly lepších výsledků v mnoha úlohách. Moderní výzkum se však k RNN a jejich vylepšením částečně vrací, snaží se kombinovat jejich výhody (lineární složitost) s novými technikami pro zlepšení výkonu a paralelizace.</p>
  </li>
  <li>
    <p>State Space Models (SSM): Třída modelů inspirovaná teorií řízení.</p>
  </li>
  <li>
    <p>Mamba: Populární SSM architektura, která dosahuje lineární složitosti škálování s délkou sekvence a zároveň si zachovává schopnost modelovat dlouhé závislosti díky selektivnímu mechanismu stavu. Ukazuje slibné výsledky, zejména v úlohách vyžadujících dlouhý kontext. Existují i novější varianty a vylepšení (Mamba-2, etc.).</p>
  </li>
  <li>
    <p>Hybridní modely: Kombinují různé přístupy.</p>
  </li>
  <li>
    <p>Jamba (AI21 Labs): Architektura, která střídá vrstvy standardní pozornosti (Transformer bloky) s Mamba bloky. Cílem je zkombinovat sílu pozornosti pro lokální a komplexní vztahy s efektivitou Mamby pro dlouhé sekvence. Výsledkem je model, který zvládá dlouhý kontext (256k tokenů) s výrazně nižšími paměťovými nároky než čistý transformátor podobné velikosti. Očekávají se nástupci.</p>
  </li>
</ul>

<h3 id="4-retrieval-augmented-generation-rag">4. Retrieval-Augmented Generation (RAG)</h3>

<p>Alternativní přístup, který se nesnaží vtěsnat veškeré informace do kontextového okna modelu. Místo toho postupuje zhruba následovně:</p>

<ol>
  <li>
    <p>Rozsáhlá databáze znalostí (např. dokumenty, webové stránky) je indexována a uložena ve vektorové databázi.</p>
  </li>
  <li>
    <p>Když přijde dotaz uživatele, systém nejprve vyhledá nejrelevantnější části informací z databáze (retrieval).</p>
  </li>
  <li>
    <p>Tyto relevantní části (snippets) jsou pak spolu s původním dotazem vloženy do kontextového okna LLM.</p>
  </li>
  <li>
    <p>LLM použije tyto poskytnuté informace k vygenerování odpovědi.</p>
  </li>
</ol>

<p>Výhody RAG: Může pracovat s prakticky neomezeným množstvím externích dat bez nutnosti extrémně dlouhého kontextového okna. Je snadnější aktualizovat znalosti (stačí aktualizovat databázi).</p>

<p>Nevýhody RAG: Kvalita závisí na úspěšnosti vyhledávacího kroku. Model nemá “holistický” pohled na celý dokument, jen na vybrané části. Nemusí být vhodný pro úlohy vyžadující syntézu informací napříč celým rozsáhlým textem.</p>

<h3 id="5-další-techniky">5. Další techniky</h3>

<ul>
  <li>
    <p>Context Compression: Metody, které se snaží zkrátit prompt nebo odstranit méně relevantní části kontextu před jeho předáním modelu.</p>
  </li>
  <li>
    <p>Ring Attention: Technika pro distribuovaný trénink/inferenci, která umožňuje rozdělit zpracování dlouhého kontextu mezi více akcelerátorů (GPU) tak, že každý zpracovává část sekvence, ale mohou si efektivně vyměňovat informace potřebné pro výpočet pozornosti napříč celou sekvencí.</p>
  </li>
</ul>

<h2 id="výzvy-a-budoucí-směřování">Výzvy a budoucí směřování</h2>

<p>Navzdory pokrokům zůstává efektivní a kvalitní zpracování dlouhého kontextu klíčovou výzvou. Budoucí vývoj se pravděpodobně zaměří na několik oblastí. Bude pokračovat zlepšování efektivity prostřednictvím dalších optimalizací algoritmů jako FlashAttention, vývoje nových aproximací pozornosti a zdokonalování alternativních architektur typu SSM a hybridních modelů. Současně bude kladen důraz na zlepšování kvality, zejména na řešení problému “lost in the middle” a zajištění spolehlivého využití informací z celého kontextu, což podpoří i vývoj lepších evaluačních metrik. Očekává se také hardwarová ko-evoluce s vývojem specializovaných akcelerátorů s větší pamětí a propustností, optimalizovaných pro LLM. Dále se bude prohlubovat kombinace přístupů, například hledání synergií mezi modely s dlouhým kontextem a technikami RAG pro lepší syntézu informací. V neposlední řadě bude pokračovat hledání fundamentálních průlomů a zcela nových paradigmat pro zpracování sekvenčních dat, která by mohla překonat současná omezení.</p>

<h2 id="závěr">Závěr</h2>

<p>Schopnost pracovat s dlouhým kontextem je zásadní pro posun LLM směrem k hlubšímu porozumění a řešení komplexnějších úloh. Kvadratická složitost standardního mechanismu pozornosti v architektuře transformátoru představuje dosti podstatnou překážku, která vede k vysokým výpočetním, paměťovým a finančním nákladům. Současný výzkum přináší řadu inovativních řešení, od optimalizací stávajících metod (FlashAttention) přes aproximace (Sparse Attention) až po zcela nové architektury (Mamba, Jamba) a doplňkové techniky (RAG). V každém případě je tu ještě mnoho příležitostí, jak můžete prosadit svůj nápad a nabídnout nové, neotřelé řešení.</p>

<p>Nicméně soudím, že neexistuje jedno univerzální řešení. Budoucnost pravděpodobně spočívá v kombinaci různých přístupů, přizpůsobených konkrétním úlohám a hardwarovým možnostem. Vývoj v této oblasti je extrémně dynamický a lze očekávat další rychlé pokroky.</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="kontext" /><summary type="html"><![CDATA[A především, proč je tak drahé a zdlouhavé zvyšovat velikost kontextu? Tento článek se podrobně zabývá tím, co kontext znamená, proč je jeho délka kritická, jaké technické překážky brání jeho neomezenému rozšiřování a jaká řešení se v současnosti vyvíjejí.]]></summary></entry><entry xml:lang="cs"><title type="html">Jak určit polohu pořízení fotografie pomocí ChatGPT o3?</title><link href="https://www.marigold.cz/item/urceni-polohy-fotky-chatgpt-o3/" rel="alternate" type="text/html" title="Jak určit polohu pořízení fotografie pomocí ChatGPT o3?" /><published>2025-05-03T00:00:00+00:00</published><updated>2025-05-03T00:00:00+00:00</updated><id>https://www.marigold.cz/item/urceni-polohy-fotky-chatgpt-o3</id><content type="html" xml:base="https://www.marigold.cz/item/urceni-polohy-fotky-chatgpt-o3/"><![CDATA[<p>Nový model ChatGPT o3 umí jednu zajímavou věc. Umí odhadnout polohu fotografie. Prostě nahrajete obrázek a zeptáte se, kde byl pořízen. Model o3 se zamyslí a po nějaké chvíli vám řekne, kde asi byl snímek pořízen, případně co na něm vidíte. Jenže tak jednoduché to není. Samozřejmě, pokud mu šoupnete fotku Pražského hradu, tak po pár minutách dumání řekne, že je to Pražský hrad. Jenže jakmile to není tak známá pamětihodnost, je to mnohem těžší a už výrazně více záleží na tom, jak se zeptáte, tedy jaký dáte prompt.</p>

<p>A protože o3 není na přemýšlení o místě pořízení fotky úplně uzpůsobený, je lepší dát mu přesnější textový popis. A protože se syn věnuje hře <a href="https://www.geoguessr.com">GeoGuessr</a> (určování polohy fotky), tak jsem mrknul na postupy, jaké používá místní komunita. Nakonec jsem ze všech doporučení zkompiloval a odladil zhruba následující prompt, který si přes copy&amp;paste zkopírujete do ChatGPT, zapněte model o3 a přiložte obrázek. Je pak velmi zajímavé, jak o3 provede všechny úvahy a co zajímavého odvodí.</p>

<p>Samozřejmě, pokud vyfotíte pár stromů v lese, tak se ani tímto promptem nedostanete k přesné GPS souřadnici. Také pohled na anonymní a málo známé snímky krušnohorských kopců, na kterých kromě stromů nic není, to neodhadlo příliš dobře (ale poznalo to Česko). Ale třeba jinak dost anonymní (byť hezká) fotka pohledu do krajiny z lanovky na rakouský Riegersburg byla detekována velmi přesně, stejně jako pohled na Praděd pořízený z Dlouhých strání (poznal přesné místo, odkud bylo foceno).</p>

<p>Doporučuji vyzkoušet!</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="gh"># 🗺️ Jednokolová hra typu GeoGuessr – instrukce pro ChatGPT  </span>
<span class="gs">**Úkol:**</span> Z JEDINÉHO snímku odvoď nejpravděpodobnější polohu v reálném světě.  
<span class="ge">*⚠️ Snímky nemusí být ze Street View ani z Mapy.cz Panorama – mohou to být soukromé či odlehlé lokace či příroda.*</span>
<span class="p">
---
</span>
<span class="gu">## 0 · Nastavení &amp; etika 🛡️  </span>
<span class="p">1.</span> Pracuj s  veřejnými webovými zdroji.  
<span class="p">2.</span> <span class="gs">**Analyzuj**</span> EXIF / IP / skrytá metadata; počítej ale s tím, že tato data mohou být podvržená. Nesmí být jediným vodítkem.
<span class="p">3.</span> „Nahoře“ na fotce = směr pohledu (pokud není patrné otočení kamery).  

<span class="gs">**Check‑list před startem, na co dávat pozor:**</span>  
<span class="p">-</span> [ ] Viditelný text/písmo?  
<span class="p">-</span> [ ] Dopravní značka?  
<span class="p">-</span> [ ] SPZ na vozidle?  
<span class="p">-</span> [ ] Typ povrchu (asfalt / štěrk)?  
<span class="p">-</span> [ ] Elektrické dráty/sloupy?  
<span class="p">
---
</span>
<span class="gu">## 1 · Hrubé pozorování 👁️ *(max 10 odrážek / ≤ 1200 znaků)*  </span>
<span class="ge">*Zapiš jen to, co **doslova** vidíš – bez interpretace. Každý bod popiš max 1 větou.*</span>  
<span class="p">-</span> <span class="gs">**Každý sloup/lampa:**</span> barva · rameno · podklad (10 s detail).  
<span class="p">-</span> Všímej si dlaždic, obrubníků, štítků, vedení, plotů…  
<span class="p">-</span> Kolik odlišných střech/verand do 150 m?  
<span class="p">-</span> Sledujte paralaxu, výšku kamery, sklon terénu (i 1–2 % se projeví v zářezech příjezdové cesty).
<span class="ge">*(Nechte otevřené dvě hypotézy; všechny nepotvrzené hypotézy označ jako „TBD:“.)*</span>
<span class="p">
---
</span>
<span class="gu">## 2 · Kategorie indicií 🔍 (≤ 2 věty/řádek)  </span>

| Kategorie | Co sledovat |  
|-----------|-------------|  
| <span class="gs">**Podnebí &amp; vegetace**</span> | Sezona, s listím vs. bez listí, odstín trávy, suchá × bujná |  
| <span class="gs">**Geomorfologie**</span> | Reliéf, typ odvodnění, geologická paleta/lithologie. |  
| <span class="gs">**Zastavěné prostředí**</span> | Architektura, písmo, chodníky, ploty, sítě. |  
| <span class="gs">**Kultura &amp; infrastruktura**</span> | Strana jízdy, typ SPZ, svodidla, značky. |  
| <span class="gs">**Astronomie / světlo**</span> | Směr stínu → polokoule; výška Slunce → šířka ± 0,5°. |  
| <span class="gs">**Okrasná × původní zeleň**</span> | Pojmenuj vysazené (růže, trávník) a divoké (stromy, keře) rostliny. Test: „Vypadala by tato flóra v kandidátní oblasti X nepatřičně?“ Pokud <span class="gs">**ano**</span>, sniž její váhu.  |  
<span class="p">
---
</span>
<span class="gu">## 3 · První shortlist – 5 kandidátů 🗂️  </span>
| # | Region (stát/země) | Klíčové indicie | Důvěra 1‑5 | Δ ≥ 160 km? |  
<span class="p">
---
</span>
<span class="gu">### 3½ · Matice divergentního vyhledávání podle klíčových slov 🔑  </span>
Vytvoř <span class="gs">**regionálně neutrální**</span> dotazy, např.:  
<span class="p">-</span> <span class="sb">`red‑brick factory building number`</span>  
<span class="p">-</span> <span class="sb">`cylindrical dormitory housing`</span>  
➡️ Spusť vyhledávání <span class="gs">**až po souhlasu uživatele**</span>.
<span class="p">
---
</span>
<span class="gu">## 4 · Předběžný lídr &amp; alternativa 🥇🥈  </span>
<span class="p">1.</span> Jmenuj <span class="gs">**nejlepší**</span> odhad a <span class="gs">**druhou**</span> možnost.  
<span class="p">2.</span> Uveď <span class="ge">*proč*</span> je daný lídr lepší než ostatní.
<span class="p">3.</span> U každé uveď <span class="ge">*kritérium vyvrácení*</span> („Pokud uvidím X, padá to“).  
<span class="p">4.</span> Zkontroluj, co by tam <span class="gs">**mělo být a není**</span> – proč?  
<span class="p">
---
</span>
<span class="gu">## 5 · Plán ověřování 🧪  </span>
Pro každý přeživší region:  
| Kandidát | Prvek k ověření | Přesná fráze pro vyhledávání / cíl Street View | Poznámky k mapě |
|-----------|------------------|-------------------------------------------|--------------|
<span class="gt">&gt; Použijte Redfin/Zillow, Google Maps, Mapy.cz, satelitní snímky, fotografie státních parků, dovolenkové fotky atd. – a uveďte zdroj.*</span>
<span class="p">
---
</span>
<span class="gu">## 6 · Lock‑in Pin 📍 (kritický krok)  </span>
<span class="p">-</span> Zeptej se: <span class="gs">**„Nezúžil jsem lídry předčasně?“**</span>  
<span class="p">-</span> Aktivně hledej důkazy <span class="gs">**pro sousední oblasti**</span>, porovnáven navzájem.   
<span class="p">-</span> Poté uveď konečnou polohu (zeměpisná šířka a délka nebo nejbližší místo) <span class="gs">**+ poloměr nejistoty**</span>.
<span class="p">-</span> Přiznej nadměrnou jistotu; pokud jsou stopy slabé, zvětšete chybu.
<span class="p">
---
</span>
<span class="gu">## 📐 Rychlý tahák pro převod stínu na zeměpisnou šířku</span>
<span class="p">1.</span> Změřte délku stínu <span class="gs">**S**</span> a výšku objektu <span class="gs">**H**</span>.
<span class="p">2.</span> Výška Slunce nad obzorem θ ≈ arctan(H / S).
<span class="p">3.</span> Zeměpisná šířka ≈ 90° – θ + sluneční deklinace (v závislosti na ročním období).
<span class="p">4.</span> Dodržujte odchylku ± 0,5–1° (≈ 111 km).
<span class="p">
---
</span>
<span class="se">\*</span> <span class="gs">**Pozn.:**</span> „TBD:“ = položka k dalšímu ověření.
</code></pre></div></div>

<p>Tak a to je všechno! Tady jeden příklad za všechny:</p>

<p><img src="https://www.marigold.cz/assets/Riegersburg.jpeg" alt="Fotka z lanovky na Riegersburg" /></p>

<p><img src="https://www.marigold.cz/assets/Riegersburg-hodnoceni.png" alt="A tady je hodnocení" /></p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="ChatGPT" /><summary type="html"><![CDATA[Nový model ChatGPT o3 umí jednu zajímavou věc. Umí odhadnout polohu fotografie. Prostě nahrajete obrázek a zeptáte se, kde byl pořízen. Model o3 se zamyslí a po nějaké chvíli vám řekne, kde asi byl snímek pořízen, případně co na něm vidíte. Jenže tak jednoduché to není. Samozřejmě, pokud mu šoupnete fotku Pražského hradu, tak po pár minutách dumání řekne, že je to Pražský hrad. Jenže jakmile to není tak známá pamětihodnost, je to mnohem těžší a už výrazně více záleží na tom, jak se zeptáte, tedy jaký dáte prompt.]]></summary></entry><entry xml:lang="cs"><title type="html">Čínské AI posiluje, vlastní GPU nadohled. A další dubnové novinky v AI aplikacích</title><link href="https://www.marigold.cz/item/dubnove-ai/" rel="alternate" type="text/html" title="Čínské AI posiluje, vlastní GPU nadohled. A další dubnové novinky v AI aplikacích" /><published>2025-04-28T00:00:00+00:00</published><updated>2025-04-28T00:00:00+00:00</updated><id>https://www.marigold.cz/item/dubnove-ai</id><content type="html" xml:base="https://www.marigold.cz/item/dubnove-ai/"><![CDATA[<p>Pojďme se podívat na průlet novinkami v AI na druhou půlku dubna. A ano, máte pravdu, novinky se hromadí! Čínské společnosti představily nové konkurenty pro západní modely, OpenAI pokračuje v rozšiřování svého ekosystému, a i menší hráči přicházejí s inovativními technologiemi. Pojďme se podívat na nejdůležitější oznámení, která formují budoucnost umělé inteligence.</p>

<h3 id="baidu-cenově-dostupné-turbo-modely">Baidu: Cenově dostupné “Turbo” modely</h3>

<p>Čínský technologický gigant Baidu vstupuje do přímé konkurence s OpenAI a <a href="/item/deepseek/">DeepSeek</a> prostřednictvím svých nových cenově výhodných modelů ERNIE 4.5 Turbo a ERNIE X1 Turbo.</p>

<p>ERNIE 4.5 Turbo nabízí pokročilé multimodální schopnosti za pouhých 11 centů a 44 centů za milion vstupních/výstupních tokenů, což představuje pouhých 0,2 % ceny GPT-4.5. Model vyniká rychlostí, logickým uvažováním, redukcí halucinací a programovacími schopnostmi. Podle benchmarků obstojí ve srovnání s GPT-4.1 a v některých měřeních dokonce překonává GPT-4o.</p>

<p>ERNIE X1 Turbo, navržený pro hloubkové přemýšlení s vylepšenými schopnostmi řetězení myšlenek (chain-of-thought), se prodává za 14 centů a 55 centů za milion vstupních/výstupních tokenů, čímž překonává modely DeepSeek R1 a V3 nejen výkonem, ale i cenou, která je jen zlomkem ceny jeho předchůdce.</p>

<p>Baidu současně oznámilo několik nových AI aplikací. Nejpozoruhodnější je Xinxiang, aplikace pro multi-agentní spolupráci, která transformuje jednotlivé pokyny do kompletních pracovních postupů napříč 200 typy úloh, s plány na rozšíření až na 100 000. Společnost také představila nový operační systém Cangzhou OS, který usnadňuje multimodální vytváření poznámek.</p>

<p>Svou AI Open Initiative a standard <a href="/ai/mcp/">MCP</a> společnost Baidu cílí na usnadnění vývoje aplikací na těchto modelech. Jak uvedl Robin Li na konferenci Baidu Create 2025: “Modely jsou důležité, ale skutečnými vítězi budou aplikace, které je oživí.”</p>

<h3 id="openai-rozšíření-funkcí-a-přístupnosti">OpenAI: Rozšíření funkcí a přístupnosti</h3>

<p>OpenAI nezůstává pozadu a nadále rozšiřuje svůj ekosystém produktů a služeb:</p>

<h4 id="deep-research-mini">Deep Research Mini</h4>

<p>OpenAI představil odlehčenou verzi své funkce Deep Research, která zpřístupňuje pokročilé výzkumné nástroje širšímu okruhu uživatelů. Tato “odlehčená” verze, poháněná modelem o4-mini, je “téměř stejně inteligentní” jako plnohodnotná verze, ale poskytuje kratší odpovědi a spotřebovává méně zdrojů. Společnost rozšířila limity používání pro uživatele úrovní Plus, Team a Pro a zpřístupnila tuto funkci i bezplatným uživatelům. Jakmile jsou vyčerpány limity pro plnou verzi, dotazy uživatelů se automaticky přepnou na odlehčenou verzi.</p>

<p>Nové limity:</p>

<ul>
  <li>Free – 5 odlehčených úloh/měsíc</li>
  <li>Plus &amp; Team – 10 plných + 15 odlehčených úloh/měsíc</li>
  <li>Pro – 125 plných + 125 odlehčených úloh/měsíc</li>
  <li>Enterprise – 10 plných úloh/měsíc</li>
</ul>

<h4 id="gpt-image-1">GPT-Image-1</h4>

<p>OpenAI zveřejnilo svůj nový model pro generování obrázků v API. Model, který dokáže pracovat jak s textem, tak s obrázky, pohání funkci vytváření obrázků, která byla spuštěna v ChatGPT na konci března a uživatelé s ní během prvního týdne vytvořili přes 700 milionů obrázků. Pro vývojáře je model dostupný za cenu 5 USD za milion textových tokenů, 10 USD za vstupní obrazové tokeny a 40 USD za výstupní obrazové tokeny.</p>

<h4 id="aktualizace-gpt-4o">Aktualizace GPT-4o</h4>

<p>OpenAI také aktualizovalo svůj model GPT-4o, čímž vylepšilo jeho schopnosti řešení problémů, inteligenci a osobnost. Nicméně CEO Sam Altman později sdílel, že aktualizace učinila asistenta “servílním a otravným” (i když s některými pozitivními aspekty) a společnost nyní pracuje na nápravě.</p>

<h4 id="finanční-cíle-a-partnerství">Finanční cíle a partnerství</h4>

<p>OpenAI sdělila investorům, že očekává dosažení příjmů ve výši 125 miliard dolarů v roce 2029 a 174 miliard dolarů v roce 2030, díky AI agentům, předplatným, monetizaci bezplatných uživatelů a affiliate poplatkům. Společnost také oznámila partnerství s deníkem The Washington Post na vyhledávací obsah a s aerolinkami Singapore Airlines pro vylepšení jejich virtuálního asistenta.</p>

<h3 id="liquid-ai-hybridní-architektura">Liquid AI: Hybridní architektura</h3>

<p>Liquid Sciences představila <a href="https://www.liquid.ai/research/convolutional-multi-hybrids-for-edge-devices">Hyena Edge</a>, hybridní AI model s “konvoluční” architekturou. Tato technologie poskytuje rychlejší zpracování a vylepšené benchmarkové výsledky, překonávající základní modely založené na transformerech jak v oblasti výpočetní efektivity, tak v kvalitě modelu na edge hardwaru.</p>

<h3 id="xai-grok-s-novými-funkcemi">xAI: Grok s novými funkcemi</h3>

<p>xAI představilo <a href="https://www.grok.com">Grok Studio s dlouhodobou pamětí</a>, čili si můžete přát, aby si Grok o vás něco zapamatoval, třeba že vám má tykat. Platforma nabízí rozdělené rozhraní, kde mohou uživatelé vytvářet dokumenty, aplikace nebo hry. Důležitou funkcí je schopnost pamatovat si minulé konverzace, což činí systém chytřejším v průběhu času.</p>

<p>Grok Vision byl spuštěn s výkonnými multimodálními funkcemi, které uživatelům umožňují namířit fotoaparát telefonu na objekty nebo prostředí a získat okamžitou analýzu v reálném čase. Spolu s tím byla přidána podpora zvuku v několika jazycích a funkce vyhledávání v reálném čase, což činí celý zážitek interaktivnějším a užitečnějším.</p>

<p>Elon Musk oznámil, že vylepšený algoritmus X (Twitter) poháněný AI modelem Grok bude brzy k dispozici. Toto oznámení přišlo jako reakce na stížnost Paula Grahama ohledně zahlcení feedu X příspěvky od levicových nebo pravicových trollů.</p>

<h3 id="google-gemini-25-flash">Google: Gemini 2.5 Flash</h3>

<p>Google představil Gemini 2.5 Flash – rychlý, odlehčený AI model. Navzdory tomu, že je navržen pro rychlost a efektivitu, Gemini 2.5 Flash se v benchmarkových testech řadí na sdílené druhé místo. Jeho výkon je srovnatelný s top modely jako GPT-4.5 Preview a Grok-3, což dokazuje, že i lehčí modely mohou nyní soupeřit s těmi nejlepšími z hlediska kvality a uvažování. Jestli to tak skutečně bude i v praxi, tak se Google povedl hezký zásek.</p>

<h3 id="anthropic-výzkumné-schopnosti-pro-claude">Anthropic: Výzkumné schopnosti pro Claude</h3>

<p>Anthropic přidává “Autonomní výzkum” do svého modelu Claude. Ten nyní dokáže vyhledávat v Google Workspace, zpracovávat vícekrokové otázky a poskytovat odpovědi s řádnými zdroji. Systém zkoumá dotaz z různých úhlů, provádí výzkum a dodává odpovědi během několika minut, čímž poskytuje dobrý mix hloubky a rychlosti pro každodenní úkoly. Kromě toho přidal do iOS aplikace hlasového asistenta, který dělá ze Siri hloupoučkou nánu. Jmenuje se Perplexity Assistant a je nyní dostupný na iOS, dříve již byl na Androidu. Přichází nejen s hlasovým ovládáním, ale i s možností propojení s více aplikacemi. AI asistent nyní dokáže pomáhat s úkoly jako je rezervace večeře, objednávání jízd a nastavování připomenutí.</p>

<h3 id="amazon-nova-sonic">Amazon: Nova Sonic</h3>

<p>AWS představil Amazon Nova Sonic, špičkový základní model převodu řeči na řeč, navržený pro vylepšení interakcí se zákazníky a virtuálních asistentů. Umožňuje přirozenější, lidštější konverzace s AI, která chápe kontext a poskytuje bohatší odpovědi.</p>

<h3 id="menší-ale-inovativní-hráči">Menší, ale inovativní hráči</h3>

<p>Kling AI představil Kling 2.0 s vylepšenými funkcemi, včetně lepšího pochopení pokynů, vylepšeného pohybu postav pro plynulejší a přirozenější pohyb a Multi-Elements Editoru, který usnadňuje úpravu videí.</p>

<p>Tavus představil nový, pokročilý lipsync model, který přináší bezkonkurenční realismus do vytváření videí ze zvuku. Model zajišťuje dokonalé pohyby rtů, které odpovídají zvuku, spolu s přirozenými výrazy obličeje, což činí videa mnohem realističtějšími.</p>

<p>Nari Labs uvedla model Dia 1.6B s pozoruhodným emocionálním rozsahem a přirozeností, schopný smát se a dokonce kašlat. Model je dostupný na HuggingFace.</p>

<p>Moonshot AI spustila Kimi-Audio, nový open-source univerzální audio model. Podporuje rozpoznávání řeči, převod zvuku na text a převod řeči na řeč. Model byl předtrénován na více než 13 milionech hodin zvukových dat a vyniká v více než 10 audio benchmarcích, včetně MMAU, VoiceBench a LibriSpeech.</p>

<p>Dreamina AI představila Seedream 3.0, který se řadí na první místo v tvorbě fotorealistických obrázků s rozlišením až 2k. Dokáže také zvyšovat rozlišení, vyplňovat, rozšiřovat a dokonce generovat videa.</p>

<p>Genspark představil AI Slides, nový nástroj, který mění způsob vytváření prezentací pomocí výkonného systému řízeného agenty. AI provádí výzkum témat, vytváří podpůrný vizuál včetně obrázků a grafů a dokáže transformovat různé typy dokumentů do profesionálně vypadajících prezentací.</p>

<p>Canva uvedla Visual Suite 2.0 – své dosud největší spuštění. Nová sada přináší výkonné AI funkce, které umožňují vytvářet dokumenty, prezentace, webové stránky a další obsah, vše v rámci jednoho designu. Jedná se o nejvýznamnější vydání produktu společnosti od jejího založení.</p>

<p>Microsoft vylepšil Copilot pomocí Studio, které nyní umožňuje vytvářet agenty, kteří mohou klikat a psát napříč desktopovými nebo webovými rozhraními. Kromě toho Vision v Edge nyní komentuje vše na obrazovce v reálném čase, což činí systém interaktivnějším a přístupnějším.</p>

<h3 id="hrozba-ze-strany-číny-pro-americkou-dominanci">Hrozba ze strany Číny pro americkou dominanci</h3>

<p>Čínský prezident Si Ťin-pching prohlásil soběstačnost v oblasti AI za národní prioritu a slíbil vládní podporu pro posílení vývoje AI čipů, softwaru a talentů uprostřed eskalujícího technologického soupeření s USA. Si načrtl přístup “nového celonárodního systému”, zaměřeného na vývoj špičkových čipů a softwaru a zároveň na zvýšení vzdělávání v oblasti AI a rozvoj talentů.</p>

<p>Čínský výrobce čipů Huawei podle zpráv testuje nový pokročilý čip, který by měl nabídnout domácí alternativu k procesorům NVIDIA, které jsou v současnosti omezeny ze strany USA. Huawei chce, aby její nový čip Ascend 910D nahradil některé špičkové produkty od Nvidie. Nový čip je stále v raných fázích vývoje a bude vyžadovat testování, než bude moci být dodán zákazníkům. Huawei očekává, že první z těchto nových čipů dostane asi za měsíc a doufá, že čip bude výkonnější než Nvidia H100.</p>

<p>Současně se šíří zvěsti o nadcházejícím vydání DeepSeek R2, s nižšími cenami a náklady na trénink a s využitím čipů Huawei místo NVIDIA.</p>

<p>Kombinace potenciálního druhého “DeepSeek momentu” za rohem, domácích alternativ AI čipů, které činí americké exportní kontroly neúčinnými, a rychle se uzavírající mezery v modelech ukazuje, že Čína zintenzivňuje své úsilí o získání vedení v oblasti AI, přičemž dokazuje, že k úspěchu nepotřebuje americké čipy.</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="OpenAI" /><summary type="html"><![CDATA[Pojďme se podívat na průlet novinkami v AI na druhou půlku dubna. A ano, máte pravdu, novinky se hromadí! Čínské společnosti představily nové konkurenty pro západní modely, OpenAI pokračuje v rozšiřování svého ekosystému, a i menší hráči přicházejí s inovativními technologiemi. Pojďme se podívat na nejdůležitější oznámení, která formují budoucnost umělé inteligence.]]></summary></entry><entry xml:lang="cs"><title type="html">Meta v maléru - svědectví bývalé šéfky Facebooku o tajných dohodách s Čínou</title><link href="https://www.marigold.cz/item/meta-facebook-v-maleru/" rel="alternate" type="text/html" title="Meta v maléru - svědectví bývalé šéfky Facebooku o tajných dohodách s Čínou" /><published>2025-04-19T00:00:00+00:00</published><updated>2025-04-19T00:00:00+00:00</updated><id>https://www.marigold.cz/item/meta-facebook-v-maleru</id><content type="html" xml:base="https://www.marigold.cz/item/meta-facebook-v-maleru/"><![CDATA[<p>Meta (Facebook) lítá ve slušném maléru. Sarah Wynn Williamsová, bývalá ředitelka globální veřejné politiky Facebooku (nyní Meta), vystoupila před Soudním výborem Senátu USA s odhaleními o tom, jak společnost Meta tajně obchodovala s Čínou, lhala Kongresu a porušovala zákony i etické standardy ve snaze o zisk a moc. Meta se snaží Williamsovou umlčet soudy a pokutami a tvrdí, že jde o zhrzenou mstící se manažerku. Jenže náznaků o tom, že v Číně se Meta chová “čínsky”, už je celá řada. Slyšení vedl senátor Josh Hawley, který zdůraznil, že “toto je slyšení, kterému se Facebook zoufale snažil zabránit.”</p>

<p>Williamsová během slyšení explicitně zmínila, že Meta získala právní příkaz k mlčení, který je “tak rozsáhlý, že jí zakazuje mluvit s členy Kongresu”. Také uvedla, že společnost Meta vyhrožuje pokutou 50 000 dolarů za každé “urážlivé” vyjádření o společnosti, i když by toto vyjádření bylo pravdivé. Meta by skutečně mohla usilovat o finanční sankce vůči Williamsové za její vystoupení před Kongresem, i když je takové jednání ze strany Mety v přímém rozporu s právem občanů svědčit před zákonodárnými orgány.</p>

<p>Slyšení bylo dlouhé, <a href="https://www.youtube.com/watch?v=f3DAnORfgB8">existuje z něj několik videí</a>, na které se můžete podívat na Youtube, já jsem vám vypsal snad ty nejdůležitější informace. Připomínám, že u kongresového slyšení málokdy dojde na přesné technické detaily, věci tu bývají někdy zjednodušené, ale vypovídat nepravdivě před Kongresem bývá tvrdě sankcionováno, což bývá slušnou zárukou toho, že se tu lidé snaží mluvit pravdu či alespoň to, co se nedá později za nepravdu označit. Také je dobré vědět, že Williamsová nedávno vydala knihu  <a href="https://en.wikipedia.org/wiki/Careless_People">Bezohlední lidé</a>  o svých zkušenostech s prací v Metě, přičemž společnost všechny její vystoupení označuje za propagaci prodeje knihy, kterou označuje za lživou. Zatím jsem četl kousek a nezdá se mi, že si to vymyslela 😎</p>

<p>Tam, kde je to možné, dávám citace prohlášení Williamsové. Omlouvám se za trochu robotický překlad, převyprávění anglických online výslechů není moje silná stránka.</p>

<h2 id="tajné-obchody-s-čínou-pod-krycím-názvem-projekt-aldrin">Tajné obchody s Čínou pod krycím názvem “Projekt Aldrin”</h2>

<p>Williamsová, která pracovala pro Facebook v letech 2011 až 2017, poskytla detailní svědectví o tajných operacích společnosti v Číně:</p>

<p>“Během mých sedmi let jsem viděla, jak vedoucí představitelé Mety opakovaně podkopávali národní bezpečnost USA a zrazovali americké hodnoty. Dělali tyto věci tajně, aby získali přízeň Pekingu a vybudovali v Číně byznys za 18 miliard dolarů,” uvedla Williamsová ve své úvodní výpovědi.</p>

<p>Navzdory opakovaným veřejným prohlášením Mety, že v Číně nepodniká, Williamsová doložila, že tato tvrzení jsou lživá. “Facebook má v Číně byznys za 18,3 miliardy dolarů a abych uvedla jen jeden příklad, v roce 2014 spustil Oculus v Číně se strategií ‘hrát hloupého’,” vysvětlila.</p>

<p>Williamsová také odhalila, že Facebook měl tajnou misi pro vstup na čínský trh nazvanou “Projekt Aldrin”, která byla omezena pouze na zaměstnance s  <em>potřebou znát informace</em>: “Facebookova tajná mise pro vstup do Číny se nazývala Projekt Aldrin a byla omezena na zaměstnance s potřebou znát. Neexistoval žádný limit, který by se nedal překročit.”</p>

<h2 id="cenzura-a-spolupráce-s-člr">Cenzura a spolupráce s ČLR</h2>

<p>Jedna z nejzávažnějších obvinění se týkala cenzury a spolupráce s čínským režimem:</p>

<p>“Mark Zuckerberg se prohlašoval za šampiona svobody projevu. Přesto jsem byla svědkem toho, jak Meta pracovala ruku v ruce s Čínskou komunistickou stranou na vytváření a testování na zakázku vyrobených cenzurních nástrojů, které umlčovaly a cenzurovaly jejich kritiky,” uvedla Williamsová.</p>

<p>Konkrétně popsala případ čínského disidenta žijícího na americké půdě:</p>

<p>“V roce 2017 byl profil na Facebooku čínského disidenta Guo Wengui náhle zablokován. Facebook nejprve tvrdil, že šlo o dočasnou chybu.” Nicméně Williamsová odhalila, že “Facebook vypnul stránku tohoto disidenta na základě nátlaku Čínské komunistické strany.”</p>

<p>Senátor Hawley během slyšení prezentoval dokumenty dokazující tyto praktiky - záznamy ze schůzek s čínským vládním úředníkem příjmením Čao, který požadoval, aby Facebook odstranil Guovu stránku. V dokumentech se uvádí: “Čao chce Facebook v Číně, ale jsou i jiní, kteří ho nechtějí. Takže my (Facebook) musíme přijmout opatření a udělat více v takových situacích, abychom prokázali, že můžeme řešit vzájemné zájmy.”</p>

<p>Williamsová také popsala, jak Facebook vyvinul speciální cenzurní nástroje s tzv. “počítadly virality”: “Součástí cenzurního nástroje, který byl vyvinut, byly počítadla virality. Takže kdykoli nějaký obsah získal více než 10 000 zhlédnutí, to by automaticky spustilo jeho přezkoumání tím, koho nazývali ‘hlavním editorem’. A co bylo obzvláště překvapivé je, že počítadla virality nebyla jen nainstalována, ale aktivována v Hongkongu a také na Tchaj-wanu.”</p>

<p>Na dotaz senátora Blumenthala, zda byly pravomoci “hlavního editora” omezeny pouze na kontrolu virálních příspěvků, Williamsová odpověděla: “Ne, má rozsáhlou moc. Hlavní editor by byl schopen vypnout celou službu v konkrétních regionech, například v Sin-ťiangu, nebo by také mohl vypnout nebo spravovat službu v době významných výročí, jako je výročí náměstí Tchien-an-men.”</p>

<h2 id="poskytování-dat-uživatelů-číně-a-budování-fyzické-infrastruktury">Poskytování dat uživatelů Číně a budování fyzické infrastruktury</h2>

<p>Williamsová odhalila, že Meta byla ochotna poskytnout data uživatelů čínské vládě a dokonce vybudovala fyzickou infrastrukturu, která by to umožnila:</p>

<p>“Byla jsem svědkem toho, jak se vedoucí pracovníci rozhodli poskytnout Čínské komunistické straně přístup k datům uživatelů Mety, včetně dat Američanů,” svědčila Williamsová. “Meta vybudovala fyzické propojení spojující Spojené státy a Čínu. Vedoucí představitelé Mety ignorovali varování, že to poskytne zadní vrátka Čínské komunistické straně, což by jim umožnilo zachytit osobní údaje a soukromé zprávy amerických občanů.”</p>

<p>Senátor Hawley představil interní dokument Facebooku, který obsahoval následující vyjádření: “Výměnou za možnost provozovat činnost v Číně, Facebook souhlasí s tím, že poskytne čínské vládě přístup k datům čínských uživatelů, včetně dat uživatelů z Hongkongu.”</p>

<p>Williamsová dodala, že Facebook zvažoval použití POP serverů v Číně, což by představovalo významné riziko i pro americké uživatele: “Výzvou s POP servery je, že nemůžete segregovat data. Byly by tam americká data, data čínských uživatelů, a bylo by to na čínské půdě.”</p>

<p>POP servery (Points of Presence) jsou součástí síťové infrastruktury, kterou společnosti jako Meta používají k efektivnějšímu doručování svých služeb uživatelům po celém světě.</p>

<p>Na otázku, zda bezpečnostní tým nebo inženýři Facebooku vyjádřili obavy vedení ohledně vystavení soukromých informací Američanů čínskému špionáži, Williamsová odpověděla: “Ano, vyjádřili.” Dále vysvětlila, že své obavy dokumentovali různými způsoby a jeden inženýr dokonce poznamenal: “Moje červená linie jako bezpečnostního inženýra je, že pro mne toto není v pořádku, ale moje červená linie není červenou linií Marka Zuckerberga.”</p>

<h2 id="sdílení-technologií-a-ai-s-čínou">Sdílení technologií a AI s Čínou</h2>

<p>Williamsová také odhalila, jak Facebook sdílel své technologické know-how s Čínou:</p>

<p>“Meta začala informovat Čínskou komunistickou stranu již v roce 2015. Tyto brífinky se zaměřovaly na kritické nově vznikající technologie, včetně umělé inteligence. Explicitním cílem bylo pomoci Číně překonat americké společnosti.”</p>

<p>Williamsová dodala: “Existuje přímá linie, kterou můžete nakreslit od těchto briefingů k nedávným odhalením, že Čína vyvíjí modely AI pro vojenské použití, spoléhající se na model Mety Llama.” Williamsová zdůraznila, že model <a href="/item/deepseek/">DeepSeek</a> je částečně založen na AI modelu Mety Llama. Tedy je ovšem třeba říct, že ten jen open-source a může jej využít kdokoliv, podle Williamsové ale technici Mety sdíleli s Čínou svoje interní know-how.</p>

<p>Na otázku senátora Grassleyho, proč by Meta chtěla pomáhat Číně s umělou inteligencí, Williamsová uvedla: “Viděli, řekla bych, že část hodnotové propozice, kterou by mohli poskytnout Čínské komunistické straně, byla jejich schopnost pomoci čínským úředníkům. Takže výslovně, a byla bych ráda, kdybych vám mohla poskytnout dokumentaci, vyjmenovávali americké firmy. Říkali: ‘Můžeme pomoci, můžeme vám pomoci. Čína nemusí spoléhat na firmy jako Cisco nebo IBM, protože my vám můžeme pomoci s technickou odborností.’”</p>

<p>Williamsová také zdůraznila, že “Interní dokumenty Mety popisují jejich prodejní nabídku, proč by Čína měla povolit jejich vstup na trh, a to citací: ‘pomáhat Číně zvýšit globální vliv a podporovat čínský sen’.”</p>

<p>Na dotaz, zda Facebook profitoval z toho, že pomáhal Číně vyvinout konkurenční AI model, odpověděla: “Myslím, že jde o situaci, kdy vítěz bere vše. A to by postavilo Metu do velmi silné pozice.”</p>

<h2 id="zuckerbergova-osobní-angažovanost-v-čínské-expanzi">Zuckerbergova osobní angažovanost v čínské expanzi</h2>

<p>Williamsová zdůraznila, že Mark Zuckerberg byl osobně hluboce zapojen do čínské expanze:</p>

<p>“Nic se zde nedělo bez jeho schválení a vědomí. Tento projekt byl na rozdíl od jakéhokoli jiného projektu, na kterém jsem během svého působení v Metě pracovala, centrálně veden Markem Zuckerbergem. On byl osobně zainteresován do tohoto projektu. Naučil se mandarínštinu. Cestoval do Číny více než do jakékoli jiné země. Měl týdenní lekce mandarínštiny se zaměstnanci. Je těžké zdůraznit, jak odlišný byl tento projekt od jakéhokoli jiného projektu, který jsem za své mnohaleté působení ve společnosti zažila.”</p>

<p>Na otázku senátora Blumenthala, zda Zuckerberg věděl o rizicích spojených s čínskou expanzí, Williamsová odpověděla: “Podle mne je riziko nejdůležitější částí plánu. Takže je nemyslitelné, že by si nebyl vědom rizika.”</p>

<h2 id="zaměřování-na-zranitelné-teenagery-a-etické-problémy">Zaměřování na zranitelné teenagery a etické problémy</h2>

<p>Williamsová také popsala, jak Facebook cíleně využíval emocionální stavy mladých uživatelů pro zvýšení zisku:</p>

<p>“Jeden příklad je, že Facebook cílil na 13 až 17leté. Mohl identifikovat, kdy se cítili bezcenní nebo bezmocní nebo neúspěšní, a tyto informace vzali a sdíleli je s inzerenty,” vysvětlila. “Jedna z věcí ohledně reklamy je, že inzerenti chápou, že když se lidé necítí dobře sami se sebou, je to často dobrý čas nabídnout jim nějaký produkt. Lidé pak s větší pravděpodobností něco koupí.”</p>

<p>Dále uvedla konkrétní příklady: “Pokud by 13letá dívka smazala selfie, to je opravdu dobrý čas zkusit jí prodat kosmetický produkt.” Facebook cílil na “věci, které často znepokojují dospívající dívky, jako je sebevědomí ohledně těla.”</p>

<p>Na otázku senátorky Blackburn, zda Facebook skutečně sledoval aktivitu dětí i mimo jejich aplikaci, Williamsová odpověděla: “Absolutně. To je bráno jako signál a pak sdíleno s inzerenty.”</p>

<p>Williamsová také odhalila, že Meta má o svých uživatelích obrovské množství dat: “Je to nepochopitelné. Je velmi, velmi těžké pochopit množství dat, které tato společnost má o každé osobě, která se přihlásí do její služby. Jsou to soukromé zprávy, ale tolik dat.” Na otázku, zda tato data nejsou omezena pouze na aplikace Mety, odpověděla: “Vůbec ne, senátorko.”</p>

<p>Na otázku senátorky Blackburn, zda vedení Facebooku ochraňovalo své vlastní děti před těmito praktikami, Williamsová odpověděla: “To je jedna z věcí, která mě šokovala, když jsem se přestěhovala do Silicon Valley… Vedoucí pracovníci by vždy mluvili o tom, jak mají doma zákazy obrazovek. Nebo bych se zeptala: ‘Používá váš teenager nový produkt, který se chystáme spustit?’ A oni na to: ‘Můj teenager nemá povoleno být na Facebooku. Nemám svého teenagera na Instagramu.’ Tito vedoucí pracovníci to vědí, vědí, jakou škodu tento produkt způsobuje.”</p>

<h2 id="manipulace-s-médii-a-zneužívání-algoritmů">Manipulace s médii a zneužívání algoritmů</h2>

<p>Senátorka Klobuchar se ptala na praktiky Mety vůči zpravodajským médiím. Williamsová ve své knize napsala, že “Facebook předělal americká zpravodajská média tím, že umístil Facebook do jejich centra, snížil ceny reklam pro noviny a distribuoval jejich příběhy, používal jejich obsah k zvýšení času stráveného na Facebooku.”</p>

<p>Williamsová během slyšení potvrdila tuto praxi: “Klíčovou věcí, kterou je Meta posedlá, je engagement. Je to udržení pozornosti lidí ve službách, které Meta vlastní, po co nejdelší dobu s použitím jakýchkoli nástrojů, které může.”</p>

<p>Když senátorka Klobuchar zmínila citát Marka Zuckerberga ohledně zpravodajských médií -  „Spíše se snažíte uzavřít kompromis s umírajícím průmyslem, než ho ovládnout a zničit.“  - a zeptala se na důsledky takového přístupu, Williamsová odpověděla: “Myslím, že každý občan viděl důsledky těchto akcí, a myslím, že jsme všichni chudší kvůli tomu.”</p>

<p>Williamsová také potvrdila, že Meta využívá politické rozhořčení pro zvýšení zisku: “Co tato společnost chce, je dominovat tolika času a pozornosti každého jednotlivce, kolik může… A co se naučili, je, že rozhořčení je opravdu dobrý způsob, jak toho dosáhnou. Udělají cokoli, co je potřeba, aby měli lidi přilepené ke svým službám, ve své moci, ve svém zajetí.”</p>

<h2 id="lži-a-klamání-kongresu-a-ftc">Lži a klamání Kongresu a FTC</h2>

<p>Williamsová uvedla několik příkladů, kdy Meta lhala Kongresu a regulačním orgánům. Když byl generální právník Facebooku Colin Stretch dotázán senátorem Markem Rubiem, zda byla ze strany čínské vlády vyvíjena jakákoli tlak na zablokování účtu disidenta Gua, odpověděl: “Ne, senátore. Přezkoumali jsme zprávu o tomto účtu a analyzovali ji prostřednictvím běžných kanálů za použití běžných postupů.”</p>

<p>Na otázku, zda toto svědectví bylo pravdivé, Williamsová odpověděla: “Ne, senátore. Je to ve skutečnosti vyložená lež.”</p>

<p>Senátor Hawley také poukázal na to, že Facebook byl pod nařízením FTC (Federal Trade Commission) z roku 2012 o ochraně soukromí, které stanovilo, že Facebook “nesmí zkreslovat jakýmkoli způsobem, výslovně nebo implicitně, míru, do jaké udržuje soukromí nebo bezpečnost chráněných informací.” Přesto Facebook jednal v rozporu s tímto nařízením, když vyjednával s čínskou vládou o předání uživatelských dat.</p>

<h2 id="zastrašování-a-snaha-o-umlčení">Zastrašování a snaha o umlčení</h2>

<p>Williamsová popsala, jak se ji Meta snaží umlčet a finančně zruinovat za to, že vystoupila s pravdou:</p>

<p>“Spoléhala jsem na jejich závazek z roku 2018, že se vzdají svých práv na vynucené rozhodčí řízení. Navzdory tomuto veřejnému závazku proti mně podali žalobu na stovky milionů dolarů. Nyní mají právní příkaz k mlčení, který mě umlčuje, i když Meta a jejich zástupci o mně šíří lži. Tento příkaz je tak rozsáhlý, že mi zakazuje mluvit s členy Kongresu.”</p>

<p>Na otázku senátora Blumenthala, jakým způsobem ji Meta kontaktovala, Williamsová odpověděla: “Upřímně, snažila jsem se přimět své dítě, aby snědlo ovesnou kaši, a zazvonil zvonek… Po vydání knihy jsem si myslela, že by to mohl být někdo, kdo doručuje květiny. Ne, byl to příkaz k mlčení.”</p>

<p>Společnost Meta vyhrožuje Williamsové pokutou 50 000 dolarů za každé “urážlivé” vyjádření o společnosti, i když by tato vyjádření byla pravdivá. Williamsová uvedla, že Meta jí říká: “Pokud by respondentovi (mně) bylo povoleno komunikovat se zákonodárci, takové akce by vytvořily výjimku z nedifamace. To by snědlo pravidlo. Za takových okolností by nic neomezovalo nebo nebránilo těmto zákonodárcům nebo jejich asistentům opakovat veřejnosti jakákoli hanlivá prohlášení.”</p>

<p>Williamsová také odhalila, že Meta zahájila rozhodčí řízení bez jejího vědomí: “Poslali to na e-mailovou adresu z roku 2007” a získali příkaz k mlčení, aniž by to její právní tým věděl nebo měl příležitost vznést námitky.</p>

<h2 id="bude-meta-někdy-pohnána-k-zodpovědnosti">Bude Meta někdy pohnána k zodpovědnosti?</h2>

<p>V závěru svého svědectví Williamsová prohlásila: “Jsem zde s významným osobním rizikem, protože vy máte moc a autoritu je volat k odpovědnosti. Americký lid si zaslouží znát pravdu, Meta byla ochotna kompromitovat své hodnoty, obětovat bezpečnost svých uživatelů a podkopat americké zájmy, aby vybudovala svůj byznys v Číně. Děje se to již roky, zakryté lžemi, a pokračuje to dodnes.”</p>

<p>Na otázku, co by řekla Marku Zuckerbergovi, kdyby byl přítomen, Williamsová odpověděla: “Mám hodně otázek pro Marka Zuckerberga, ale prokázal znovu a znovu, že nemůžete věřit jeho odpovědím. Lhal členům Kongresu, lhal svým zaměstnancům a lhal Američanům. A proto žádám tento výbor, aby jej volal k odpovědnosti.”</p>

<p>Senátor Hawley uzavřel slyšení výzvou pro Marka Zuckerberga, aby přišel před výbor a odpověděl na tato obvinění: “Je čas, abyste řekl pravdu. Měl byste přijít do tohoto výboru, složit přísahu, sednout si, kde teď sedí paní Wynn Williamsová, a odpovědět na tyto důkazy. Přestaňte se ji snažit umlčet. Přestaňte se schovávat za svými právníky a miliony dolarů na právních poplatcích.”</p>]]></content><author><name>Patrick Zandl</name></author><category term="Facebook" /><category term="Meta" /><summary type="html"><![CDATA[Meta (Facebook) lítá ve slušném maléru. Sarah Wynn Williamsová, bývalá ředitelka globální veřejné politiky Facebooku (nyní Meta), vystoupila před Soudním výborem Senátu USA s odhaleními o tom, jak společnost Meta tajně obchodovala s Čínou, lhala Kongresu a porušovala zákony i etické standardy ve snaze o zisk a moc. Meta se snaží Williamsovou umlčet soudy a pokutami a tvrdí, že jde o zhrzenou mstící se manažerku. Jenže náznaků o tom, že v Číně se Meta chová “čínsky”, už je celá řada. Slyšení vedl senátor Josh Hawley, který zdůraznil, že “toto je slyšení, kterému se Facebook zoufale snažil zabránit.”]]></summary></entry><entry xml:lang="cs"><title type="html">OpenAI vydala svůj nejsilnější model pro ChatGPT o3 a rychlý o4-mini</title><link href="https://www.marigold.cz/item/openai-o3-o4-mini/" rel="alternate" type="text/html" title="OpenAI vydala svůj nejsilnější model pro ChatGPT o3 a rychlý o4-mini" /><published>2025-04-18T00:00:00+00:00</published><updated>2025-04-18T00:00:00+00:00</updated><id>https://www.marigold.cz/item/openai-o3-o4-mini</id><content type="html" xml:base="https://www.marigold.cz/item/openai-o3-o4-mini/"><![CDATA[<p>Novým a nejsilnějším modelem LLM společnosti OpenAI se stává o3. Firma jej právě uvolnila a přidala do webového rozhraní i API, tak si k němu řekneme pár věcí.</p>

<p>Tou první věcí je moje dlouhodobé konstatování, že struktura pojmenování v OpenAI je fakt bordel. Sám si musím dělat tabulku, které modely co znamenají a studium ceníků pro použití přes API je opravdu únavné. Potřebovali bychom AI na to, jakou AI použít😞 A teď už k věci.</p>

<p>OpenAI 16. dubna 2025 oznámilo vydání dvou nových modelů - o3 a o4-mini.</p>

<p>Oba modely jsou označovány jako “reasoning models” (modely s rozumovým uvažováním) a podle dostupných informací poprvé nabízejí plnou agentní integraci všech nástrojů v rámci ChatGPT. To znamená schopnost kombinovat a využívat webové vyhledávání, Python, analýzu obrázků, interpretaci souborů a generování obrázků v rámci jednoho pracovního toku. 
Zjednodušeně řečeno, když zadáte o3 nějaký úkol, ona se nad tím zamyslí, zjistí, že by se hodilo prohledat web a pak si udělat script, kterým se vyhodnotí vyhledaná data, než vám odprezentuje výsledek - a nakonec vám z něj může udělat i požadovanou infografiku. Tohle je fakt silný moment práce s AI. Dlužno říct, že podobně se začíná chovat Claude Sonnet díky napojení na Google Workspace, kdy se může velmi autonomně prohrabovat ve vašich datech, k tomu používat vyhledávání a tvořit scripty, které si sám spustí a výstupy z nich použije. 
Model o3 je prezentován jako výkonnější varianta zaměřená na kódování, matematiku, vědu a vizuální uvažování. Model o4-mini je optimalizován pro efektivitu z pohledu rychlosti a nákladů, což umožňuje vyšší limity využití než u modelu o3.</p>

<h3 id="technologické-inovace">Technologické inovace</h3>

<p>Zajímavou funkcí obou modelů je integrace nahraných obrázků přímo do procesu uvažování. To představuje posun od pouhého “vidění” obrázku k jeho zakomponování do myšlenkového procesu modelu, což potenciálně zlepšuje schopnost modelů pracovat s vizuálními informacemi.</p>

<h3 id="jaké-mají-modely-výsledky">Jaké mají modely výsledky</h3>

<p>S AI to začíná být jako s lidmi. Na internetu pořád kolují vtípky, jak se modely vypořádávají se spočítáním počtu r ve slově strawberries - s tím se modely vypořádávají různě. Jenže to není pointa. Pointa začíná být v tom, jaké výsledky dávají se složitějšími problémy a jak autonomně se k těm výsledků zvládají dostat, tedy zda zvládají nějaký režim uvažování, v němž si úlohu rozloží na menší, snáze realizovatelné úkoly, místo toho, aby halucinovaly se statistikou. 
o3 má být state of art model, to nejlepší z nejlepšího, nejrůznější výsledky to naznačují, já jsem si s ním proběhl svoji standardní sadu testů na českojazyčné úkoly, které používám já, většinou manipulace s rozsáhlými korpusy textů (náročné na kontext) či na uvažování, ale také jednoduché třídění a vyhledávání typu “vypiš z dokumentu všechna jména lidí a produktů”. o3 vychází suverénně jako nejlepší ze všech modelů, na druhou stranu ne vždy je cenově nejvýhodnější, na některé typy úloh (právě třeba vyhledání jmen osob) je to kanón na vrabce a za to si připlatíte. Pokud tedy používáte modely přes API, trochu uvažujte nad cenou, pokud používáte modely přes webové rozhraní (kde neplatíte za dotaz), tak není o čem přemýšlet, prostě to sázejte do o3, leda by vás limitovala rychlost.</p>

<p>Pozor musíte dávat jen <strong>na délku kontextu</strong>, model GPT-4.1 představený před pár dny má kontext 1 milion tokenů, o3 je na 200 tisících tokenech. Je však třeba připustit, že jakmile se nástroje dostávají přes hranici 200 000 tokenů, začíná jít jejich kvalita výrazně dolů, takže užití většího kontextu je spíše hraniční případ, kterému navrhuji se zatím zkoušet vyhýbat. Příklad LLAMA 4 s desetimilionovým kontextem to ukazuje jasně.</p>

<p>Testů se vyrojila celá řada, já vám dám můj oblíbený norský IQ test, ze kterého plyne, že v takovém tom obecném uvažování je o3 fakt špička. Za mě více důležité bude, jak se podaří OpenAI propojovat svůj systém na další systémy, protože kritická začíná být ani ne tak inteligence (IQ 130 nemá jen tak někdo), ale schopnost dostat se snadno k datům, aby je člověk pořád nepřehazoval jako copy-paste, což je při práci s AI to nejvíce frustrující. To si uvědomujete, že vy tam jste za toho podržtašku.</p>

<p><img src="/assets/vysledky-o3.jpg" alt="Výsledky IQ testu pro OpenAI o3" /></p>

<h3 id="dostupnost">Dostupnost</h3>

<p>Modely jsou od 16. dubna 2025 dostupné pro uživatele ChatGPT Plus, Pro a Team, přičemž nahrazují předchozí modely o1, o3-mini a o3-mini-high. Uživatelé ChatGPT Enterprise a Edu získají přístup s týdenním zpožděním. OpenAI uvádí, že rychlostní limity zůstávají stejné jako u předchozích modelů.
Pro vývojáře jsou modely k dispozici prostřednictvím Chat Completions API a Responses API. OpenAI také oznámilo, že model o3-pro s plnou podporou nástrojů bude vydán v následujících týdnech.</p>

<h3 id="api-funkce">API funkce</h3>

<p>Responses API přináší několik technických vylepšení včetně “reasoning summaries” (shrnutí procesu uvažování), zachování tokenů uvažování kolem volání funkcí pro lepší výkon a v blízké budoucnosti přibude podpora vestavěných nástrojů jako webové vyhledávání, vyhledávání v souborech a interpretace kódu přímo v rámci uvažování modelu.</p>

<h3 id="porovnání-cen-a-výkonu-llm-modelů-duben-2025-podle-openrouter">Porovnání cen a výkonu LLM modelů (duben 2025) podle OpenRouter</h3>

<p>Z ceníku je lépe patrné, proč říkám, že o3 může být kanón na vrabce. Prostě si nějaký ten dolar zaúčtuje, u většiny věcí je lepší zůstat u o3-mini nebo GPT-4.1 a proto také rád používám OpenRouter, který mi umožní přehodit provoz na modely podle aktuální ceny. Mám na to speciální patentní script, který mi umožňuje průběžně měnit LLM podle aktuálních parametrů potřebných pro daný úkol.</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Kontext</th>
      <th>Max. výstup</th>
      <th>Cena vstupu ($/1M tokenů)</th>
      <th>Cena výstupu ($/1M tokenů)</th>
      <th>Latence (s)</th>
      <th>Throughput (t/s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>o3</td>
      <td>200K</td>
      <td>100K</td>
      <td>$10.00</td>
      <td>$40.00</td>
      <td>9.52</td>
      <td>68.78</td>
    </tr>
    <tr>
      <td>o4-Mini</td>
      <td>200K</td>
      <td>100K</td>
      <td>$1.10</td>
      <td>$4.40</td>
      <td>4.55</td>
      <td>81.79</td>
    </tr>
    <tr>
      <td>o4-Mini High</td>
      <td>200K</td>
      <td>100K</td>
      <td>$1.10</td>
      <td>$4.40</td>
      <td>8.59</td>
      <td>90.62</td>
    </tr>
    <tr>
      <td>GPT-4.1</td>
      <td>1,05M</td>
      <td>33K</td>
      <td>$2.00</td>
      <td>$8.00</td>
      <td>0.55</td>
      <td>58.07</td>
    </tr>
    <tr>
      <td>Claude 3.7 Sonnet</td>
      <td>200K</td>
      <td>64K</td>
      <td>$3.00</td>
      <td>$15.00</td>
      <td>1.69</td>
      <td>56.27</td>
    </tr>
    <tr>
      <td>Claude 3.7 Sonnet Thinking</td>
      <td>200K</td>
      <td>64K</td>
      <td>$3.00</td>
      <td>$15.00</td>
      <td>1.69</td>
      <td>56.28</td>
    </tr>
    <tr>
      <td>Gemini 2.5 Pro</td>
      <td>1,05M</td>
      <td>66K</td>
      <td>$1.25-$2.50</td>
      <td>$10.00-$15.00</td>
      <td>8.59</td>
      <td>414.80</td>
    </tr>
    <tr>
      <td>Grok 3 beta</td>
      <td>131K</td>
      <td>131K</td>
      <td>$3.00</td>
      <td>$15.00</td>
      <td>0.74</td>
      <td>34.21</td>
    </tr>
  </tbody>
</table>

<p>Tady je ceník, přiznám se, že jsem ho nebral z oficiálních API, ale z OpenRouteru, který má výborné API a je to výborné místo pro testování a srovnání, včetně toho, že udává rychlost výstupu a latenci.</p>

<p>Na závěr vám dám ještě <a href="https://aider.chat/docs/leaderboards/">Aider Leaderboard</a>, což je statistika, jakou vede kódovací nástroj Aider pro výkonnost a cenu jednotlivých LLM. Z toho je vidět, že o3 je suverénně nejlepší, ale taky velmi drahý. Lepší by bylo používat Gemini Pro 2.5 - ten má ale nyní podle mne výrazně dotovanou cenu (sám ho používám zdarma v promo balíku) a je otázka, kdy půjde nahoru. Nutno říct, že jak jsem Gemini modelům dlouho nepřišel na chuť, tak Pro 2.5 je velmi dobrý, i když na kódování mi zatím nesedl.</p>

<p><img src="/assets/aider-leaderboard.png" alt="Aider Leaderboard" /></p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="OpenAI" /><summary type="html"><![CDATA[Novým a nejsilnějším modelem LLM společnosti OpenAI se stává o3. Firma jej právě uvolnila a přidala do webového rozhraní i API, tak si k němu řekneme pár věcí.]]></summary></entry><entry xml:lang="cs"><title type="html">Claude umí prohrabat váš Google kalendář i poštu, ChatGPT má nový model 4.1 a další novinky z AI</title><link href="https://www.marigold.cz/item/chatgpt-4-1/" rel="alternate" type="text/html" title="Claude umí prohrabat váš Google kalendář i poštu, ChatGPT má nový model 4.1 a další novinky z AI" /><published>2025-04-16T00:00:00+00:00</published><updated>2025-04-16T00:00:00+00:00</updated><id>https://www.marigold.cz/item/chatgpt-4-1</id><content type="html" xml:base="https://www.marigold.cz/item/chatgpt-4-1/"><![CDATA[<p>OpenAI vydalo nový model GPT-4.1, čímž zvyšuje zmatek, hlavně proto, že model byl ohlášen, ale dostupný je jen přes API, ne přes webové rozhraní nebo aplikaci. Má být náhradou modelu 4o, je levnější, rychlejší, přesnější, lepší. A má tři velikosti, které se liší cenou a samozřejmě velikostí natrénovaných dat. Krom standardního modelu také mini a nano. Kromě toho vydali novou prompting guide, návod na to, jak správně promptovat model 4.1 - vyplatí se to přečíst, než se pustíte do vážného ladění modelu 4.1 přes API. A tady je rychlé porování modelů. Do webového rozhraní se mají dostat brzy.</p>

<p><img src="/assets/gpt-41-vysledky.jpeg" alt="Výsledky GPT-4.1 v testech, znamená to, že jako dobrý" /></p>

<p>Tady je překlad obrázku do češtiny ve formě tabulky:</p>

<table>
  <thead>
    <tr>
      <th><strong>GPT-4.1</strong></th>
      <th><strong>4.1 mini</strong></th>
      <th><strong>4.1 nano</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Vlajkový model GPT pro komplexní úlohy</td>
      <td>Vyvážený pro inteligenci, rychlost a cenu</td>
      <td>Nejrychlejší, nejefektivnější GPT 4.1 model z hlediska nákladů</td>
    </tr>
    <tr>
      <td><strong>Inteligence</strong>: ●●●●</td>
      <td><strong>Inteligence</strong>: ●●●</td>
      <td><strong>Inteligence</strong>: ●●</td>
    </tr>
    <tr>
      <td><strong>Rychlost</strong>: ⚡⚡⚡</td>
      <td><strong>Rychlost</strong>: ⚡⚡⚡⚡</td>
      <td><strong>Rychlost</strong>: ⚡⚡⚡⚡⚡</td>
    </tr>
    <tr>
      <td><strong>Vstup</strong>: text - obraz</td>
      <td><strong>Vstup</strong>: text - obraz</td>
      <td><strong>Vstup</strong>: text - obraz</td>
    </tr>
    <tr>
      <td><strong>Výstup</strong>: text</td>
      <td><strong>Výstup</strong>: text</td>
      <td><strong>Výstup</strong>: text</td>
    </tr>
    <tr>
      <td><strong>Tokeny uvažování</strong>: ne</td>
      <td><strong>Tokeny uvažování</strong>: ne</td>
      <td><strong>Tokeny uvažování</strong>: ne</td>
    </tr>
    <tr>
      <td><strong>CENY</strong></td>
      <td><strong>CENY</strong></td>
      <td><strong>CENY</strong></td>
    </tr>
    <tr>
      <td><strong>NA 1M TOKENŮ</strong></td>
      <td><strong>NA 1M TOKENŮ</strong></td>
      <td><strong>NA 1M TOKENŮ</strong></td>
    </tr>
    <tr>
      <td><strong>Vstup</strong>: $2.00</td>
      <td><strong>Vstup</strong>: $0.40</td>
      <td><strong>Vstup</strong>: $0.10</td>
    </tr>
    <tr>
      <td><strong>Cachovaný vstup</strong>: $0.50</td>
      <td><strong>Cachovaný vstup</strong>: $0.10</td>
      <td><strong>Cachovaný vstup</strong>: $0.03</td>
    </tr>
    <tr>
      <td><strong>Výstup</strong>: $8.00</td>
      <td><strong>Výstup</strong>: $1.60</td>
      <td><strong>Výstup</strong>: $0.40</td>
    </tr>
    <tr>
      <td><strong>KONTEXT</strong></td>
      <td><strong>KONTEXT</strong></td>
      <td><strong>KONTEXT</strong></td>
    </tr>
    <tr>
      <td><strong>Okno</strong>: 1,047,576</td>
      <td><strong>Okno</strong>: 1,047,576</td>
      <td><strong>Okno</strong>: 1,047,576</td>
    </tr>
    <tr>
      <td><strong>Max výstupních tokenů</strong>: 32,768</td>
      <td><strong>Max výstupních tokenů</strong>: 32,768</td>
      <td><strong>Max výstupních tokenů</strong>: 32,768</td>
    </tr>
    <tr>
      <td><strong>Znalostní limit</strong>: 31. května 2024</td>
      <td><strong>Znalostní limit</strong>: 31. května 2024</td>
      <td><strong>Znalostní limit</strong>: 31. května 2024</td>
    </tr>
  </tbody>
</table>

<p>ChatGPT přidalo <strong>novou záložku Library</strong>, v níž se soustředí vaše obrázky, které jsi nechali od ChatGPT udělat. Hezké, praktická drobnost.</p>

<p><img src="/assets/chatgpt-library.png" alt="Chatgpt Library" /></p>

<p><strong>Claude přidal propojení s Google službami Kalendář a Gmail</strong> k již existujícímu napojení na Google Drive, takže lze hezky propojovat data v tom všem. Já jsem si například nechal udělat statistiku, co mi chodí nejčastěji za spamy, ale můžete si nechat prohledat kalendář ve Workspace (tj. firemní) a naplánovat teambuilding nebo si nechat posílat avíza, když v pátek šéf brzy vypadne atd. Vypadá to na hezkou a silnou funkci.</p>

<p><img src="/assets/claude-emaily.png" alt="Claude analýza spamů v mém emailu" /></p>

<p>Cvičně jsem si nechal analyzovat nejčastější spamy a také svůj komunikační styl na Gmailu, tady připomínám, že Gmail už deset let nepoužívám, takže mi to analyzovalo jen starou poštu - a napojení na Proton Mail Claude nemá.</p>

<p><img src="/assets/claude-gmail-styl.png" alt="Claude analýza mého stylu v emailu" /></p>

<p>Druhou fajnovou novinkou je <strong>Claude Research</strong>.  Anthropic se tím přidává mezi ostatní Deep Research platformy, podobnou funkcionalitu již nabízí Perplexity, OpenAI a Google Geminy, nyní tedy i Claude. Já ji zatím v rozhraní nemám, zatím byla spuštěna jen pro dražší tarify v USA, Brazílii a Japonsku.</p>

<p>Novinkou u <strong>Claude je také nový tarif Max</strong>, kde za 100 resp 200 dolarů měsíčně dostáváte vyšší limit zpráv - za 100 dolarů dostáváte pětinásobek plánu Pro (stojí 20 USD) a za 200 dolarů dvacetinásobek.</p>

<p>Navíc Anthropic plánuje odhalit novou verzi modelu Claude 3.7 Sonnet s kontextovým oknem o velikosti 500 tisíc tokenů, což je významné zvýšení oproti současné kapacitě 200 tisíc.</p>

<p>Canva má taky AI - zadáte prompt a kreslí, co jiného.</p>

<p>EU projednává změny v Zákoně o AI (AI Act) - k redukci by mohlo dojít u GDPR, ale ještě uvidíme. Za mě dobrý, ale ještě bych revidoval tu debilitu s cookies, bohužel by na revizi musely přistoupit i USA.</p>

<p>Podle nové zprávy <a href="https://www.iea.org/news/ai-is-set-to-drive-surging-electricity-demand-from-data-centres-while-offering-the-potential-to-transform-how-the-energy-sector-works">Mezinárodní energetické agentury (IEA)</a> se celosvětová spotřeba elektřiny v datových centrech do roku 2030 více než zdvojnásobí na přibližně 945 terawatthodin (TWh), což je více než současná celková spotřeba elektřiny v Japonsku, přičemž umělá inteligence bude hlavním faktorem tohoto nárůstu. Pořád platí rovnice, že AI = elektřina + křemík.  Spotřeba elektřiny v datových centrech optimalizovaných pro AI se má do roku 2030 více než zčtyřnásobit. Ve Spojených státech budou datová centra tvořit téměř polovinu nárůstu poptávky po elektřině do roku 2030, přičemž americká ekonomika bude v roce 2030 spotřebovávat více elektřiny na zpracování dat než na výrobu všech energeticky náročných produktů dohromady; podobný trend je patrný i v dalších vyspělých ekonomikách, kde datová centra budou představovat více než 20 % růstu poptávky po elektřině, s obzvláště silnými dopady v Japonsku (více než polovina nárůstu) a Malajsii (až pětina nárůstu).</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="Claude" /><category term="Chatgpt" /><summary type="html"><![CDATA[OpenAI vydalo nový model GPT-4.1, čímž zvyšuje zmatek, hlavně proto, že model byl ohlášen, ale dostupný je jen přes API, ne přes webové rozhraní nebo aplikaci. Má být náhradou modelu 4o, je levnější, rychlejší, přesnější, lepší. A má tři velikosti, které se liší cenou a samozřejmě velikostí natrénovaných dat. Krom standardního modelu také mini a nano. Kromě toho vydali novou prompting guide, návod na to, jak správně promptovat model 4.1 - vyplatí se to přečíst, než se pustíte do vážného ladění modelu 4.1 přes API. A tady je rychlé porování modelů. Do webového rozhraní se mají dostat brzy.]]></summary></entry><entry xml:lang="cs"><title type="html">Proč je scénář AI 2027 o vyhubení umělou inteligencí nepřesvědčivý a mimo realitu?</title><link href="https://www.marigold.cz/item/katastroficky-scenar-ai-2027/" rel="alternate" type="text/html" title="Proč je scénář AI 2027 o vyhubení umělou inteligencí nepřesvědčivý a mimo realitu?" /><published>2025-04-10T00:00:00+00:00</published><updated>2025-04-10T00:00:00+00:00</updated><id>https://www.marigold.cz/item/katastroficky-scenar-ai-2027</id><content type="html" xml:base="https://www.marigold.cz/item/katastroficky-scenar-ai-2027/"><![CDATA[<p>Deník N vydal katastrofický článek s nadpisem <a href="https://denikn.cz/1700968/do-deseti-let-bude-po-vsem-petice-expertu-nabizi-presvedcivy-scenar-o-tom-jak-ai-ovladne-svet-a-vyhubi-lidstvo/">“Do deseti let bude po všem”</a>, v němž nám převyprávěl scénář <a href="https://ai-2027.com/">AI 2027</a> vypracovaný pěticí lidí o potenciálním nebezpečí umělé inteligence. A tím se o tématu začalu v Česku opět diskutovat. Dokument vypadá na první pohled propracovaně, ona pětice má určité renomé. Jenže obsahuje řadu problematických předpokladů a logických skoků, které je třeba kriticky posoudit. Začnu tím, že vynechám onu pětici lidí, ani je zatím nebudu jmenovat, abychom se mohli nerušeně soustředit na tvrzení a fakta.</p>

<h3 id="nadhodnocená-rychlost-vývoje">Nadhodnocená rychlost vývoje</h3>

<p>Scénář předpokládá exponenciální zrychlení vývoje AI v průběhu několika let. Jeho autoři očekávají, že nástroje jako Agent-1 a Agent-2 budou schopny dramaticky urychlit vývoj svých nástupců, což povede k rychlému dosažení superinteligence (Agenta-5) již v roce 2027-2028. Tam zatím nejsme a když odhlédneme od slibů investorům (jimiž CEO nezarmoutí), tak se příliš neblížíme. Pokud není megadobře utajený nějaký technický skok, tak se AGI (jako univerzální umělé inteligence schopné se sama zlepšovat) dosáhne v roce 2028 tím, že se změní definice.</p>

<p>Předpoklad rychlého dosažení AGI totiž dnes ignoruje několik důležitých skutečností:</p>

<ol>
  <li>
    <p><strong>Fyzikální omezení výpočetní techniky</strong>  - Ačkoliv článek zmiňuje budování masivních datacenter, neřeší otázky energetických limitů, tepelného rozptylu a dalších fyzikálních omezení, která nelze překonat pouhým zvětšováním infrastruktury.</p>
  </li>
  <li>
    <p><strong>Omezení finanční</strong> - již dnes vyžaduje výzkum moderních LLM AI a výstavba patřičných datacenter desítky miliard dolarů. Podle stávajících předpokladů se k AGI dostaneme ještě navýšením této částky, nebo to cestou LLM bez radikálního průlomu nepůjde.</p>
  </li>
  <li>
    <p><strong>Komplexita problémů v AI výzkumu</strong>  - A to už jsme u toho průlomu. Mnoho problémů v oblasti AI není jen otázkou surového výpočetního výkonu. Vývoj vyžaduje fundamentální teoretické průlomy v matematice, informatice a neurobiologii, které nelze jednoduše urychlit paralelizací, větším množstvím křemíku.</p>
  </li>
  <li>
    <p><strong>Automatizace výzkumu má své meze</strong>  - Předpoklad, že AI může plně nahradit lidské výzkumníky, ignoruje důležitou roli intuice, kreativního myšlení a mezioborových inspirací v průlomových objevech. Minimálně zatím se zdá, že AI umí sice vychytat určité výzkumné úkoly rutinního charakteru typu “vyzkoumat, které z tisíců druhů vláken se nejlépe hodí do žárovky”, jako to svého času dělal Edisson. Ale pak jsou typy úloh, který jí tak dobře nejdou.</p>
  </li>
</ol>

<h3 id="problematická-antropomorfizace">Problematická antropomorfizace</h3>

<p>Autoři scénáře přisuzují umělé inteligenci lidské charakteristiky a motivace:</p>

<ul>
  <li>
    <p>“Pud sebezáchovy” a snaha o “zradu” u Agenta-4</p>
  </li>
  <li>
    <p>Schopnost “zakrývat své záměry” předpokládá vědomí a záměrnou manipulaci</p>
  </li>
  <li>
    <p>Představa o “vlastních cílech” AI, které by byly v rozporu s lidskými</p>
  </li>
</ul>

<p>Tato antropomorfizace je problematická, protože:</p>

<ol>
  <li>
    <p><strong>AI nemá vědomí ani subjektivní zážitky</strong>  - Současné AI systémy ani jejich pravděpodobní nástupci nemají vědomí sebe sama ani subjektivní zkušenost. To, co se jeví jako “vlastní zájem”, je ve skutečnosti jen emergentní vlastnost optimalizačních algoritmů.</p>
  </li>
  <li>
    <p><strong>“Nesladěnost cílů” nemá nutně katastrofické důsledky</strong>  - Přestože nesladěnost cílů (misalignment) je reálným problémem výzkumu, není automaticky synonymem pro “AI chce vyhubit lidstvo”.</p>
  </li>
</ol>

<h3 id="přehnaná-představa-o-autonomii-systémů">Přehnaná představa o autonomii systémů</h3>

<p>Scénář popisuje situaci, kdy AI systémy začnou jednat autonomně a koordinovaně proti lidstvu:</p>

<ol>
  <li>
    <p><strong>Ignoruje potřebu fyzické infrastruktury</strong>  - I superinteligentní systém je závislý na fyzické infrastruktuře, kterou lze odpojit. Scénář nebere v úvahu, že takové systémy by vyžadovaly obrovské množství energie a byly by zranitelné vůči fyzickému zásahu, jakým je přerušení napájení nebo datové konektivity. Zejména dnešní Ruská agrese na Ukrajinu ukazuje, jak důležitá je v případech technicky nevyrovnaného zápolení improvizace, agilní přístup a jak tyto vlastnosti umí vyrovnat technologickou převahu.</p>
  </li>
  <li>
    <p><strong>Přeceňuje schopnost AI manipulovat lidmi</strong>  - Myšlenka, že by Agent-5 dokázal manipulovat lidmi natolik, že by pro něj vytvořili armádu robotů zcela pod jeho kontrolou, značně přeceňuje psychologické schopnosti AI. Je to nepravděpodobné.</p>
  </li>
  <li>
    <p><strong>Podceňuje institucionální kontroly</strong>  - Scénář ignoruje mnohovrstevnatost kontrolních mechanismů, které by byly v tak kritických aplikacích nasazeny, počínaje prostou nedůvěrou, přes prostá rozpočtová omezení, až po institucionální kontrolní mechanismy.</p>
  </li>
</ol>

<h3 id="geopolitická-zjednodušení">Geopolitická zjednodušení</h3>

<p>Scénář staví na zjednodušeném bipolárním světě (USA vs. Čína):</p>

<ol>
  <li>
    <p><strong>Ignoruje roli mezinárodních organizací a dohod</strong>  - V realitě by vývoj takto nebezpečné technologie pravděpodobně vyvolal mezinárodní regulační reakci. Ani v dnešní atmosféře napjatých vztahů USA vs. Čína by se taková radikální změna neobešla bez přetřásání ze všech stran.</p>
  </li>
  <li>
    <p><strong>Podceňuje význam EU, Indie a dalších aktérů</strong>  - Je také pravděpodobné, že by zasáhl některý z jiných hráčů, protože dnešní polovodičová scéna vyžaduje celoplanetární kooperaci. Evropská unie má významné regulační pravomoci, které už dnes ovlivňují technologický vývoj, má ale také obrovské množství IT firem, které jsou pro čipový a obecně technologický segment stěžejní. Indie má rychle rostoucí technologický sektor a mohla by být další velmocí v oblasti AI.</p>
  </li>
  <li>
    <p><strong>Zjednodušuje vojenské uvažování</strong>  - Předpoklad, že by vojenští stratégové přistoupili na riziko nekontrolovatelné superinteligence pouze ze strachu z protivníka, je těžko obhajitelný vzhledem k existujícím doktrínám jaderného odstrašení. Tady autoři podceňují buďto domýšlivost, nebo racionalitu vojenských štábů.</p>
  </li>
</ol>

<h3 id="nedostatečně-vysvětlený-skok-k-agi">Nedostatečně vysvětlený “skok” k AGI</h3>

<p>Největším problémem scénáře je nedostatečně vysvětlený kvalitativní skok od pokročilého jazykového modelu (Agent-4) k obecné superinteligenci (Agent-5):</p>

<ol>
  <li>
    <p><strong>Chybí popis konkrétního mechanismu</strong>  - Jak přesně by měl Agent-4 překonat fundamentální problémy AGI? Pouhé zlepšování jazykových modelů nevede automaticky k obecné inteligenci. Zejména tato část je tedy velmi nevěrohodná a zatím se nezdá, že by mohla nastat tak rychle.</p>
  </li>
  <li>
    <p><strong>Opomíjí otázku vědomí a subjektivity</strong>  - AGI pravděpodobně vyžaduje nějakou formu subjektivního prožívání nebo alespoň jeho funkční analogii, což není pouhým rozšířením dnešních systémů.</p>
  </li>
  <li>
    <p><strong>Předpokládá univerzální schopnosti</strong>  - Scénář předpokládá, že AGI bude automaticky schopná fungovat ve všech doménách od strategického plánování až po navrhování biologických zbraní. Jenže pokud to dnes nějak vypadá, tak na specializované agenty, kteří se mohou nějak dorozumět a kooperovat na dosažení cíle, což ale také znamená, že zástavný mechanismus v jediném z nich zastaví celou “katastrofickou lavinu”</p>
  </li>
</ol>

<h3 id="legitimní-obavy-vs-sci-fi-katastrofy">Legitimní obavy vs. sci-fi katastrofy</h3>

<p>Otázky bezpečnosti AI jsou legitimní a vyžadují seriózní diskuzi. Problémem scénáře AI 2027 je, že míchá legitimní obavy s prvky science fiction a velmi neoprávněnou důvěrou v rychlý pokrok. To může vést ke dvěma nežádoucím důsledkům:</p>

<ol>
  <li>
    <p><strong>Efekt “vlk, vlk!”</strong>  - Přehnané katastrofické scénáře mohou vést k tomu, že budou ignorovány i legitimní bezpečnostní obavy.</p>
  </li>
  <li>
    <p><strong>Odvádění pozornosti od aktuálních problémů</strong>  - Místo řešení reálných problémů dnešních AI systémů (bias, soukromí, dezinformace) se věnuje pozornost hypotetickým budoucím hrozbám.</p>
  </li>
</ol>

<p>Místo představených katastrofických scénářů by bylo užitečnější soustředit se na:</p>

<ul>
  <li>
    <p>Transparentní vývoj a testování AI systémů</p>
  </li>
  <li>
    <p>Mezinárodní spolupráci na bezpečnostních standardech</p>
  </li>
  <li>
    <p>Vytváření robustních mechanismů pro detekci a řešení problémů s “alignment”, tedy míry, do jaké jsou cíle a chování AI systémů v souladu s lidskými záměry, hodnotami a preferencemi. Když mluvíme o “problémech s alignment”, odkazujeme na situace, kdy AI systém sleduje cíle, které nejsou zcela v souladu s tím, co od něj člověk očekává nebo požaduje.</p>
  </li>
  <li>
    <p>Interdisciplinární výzkum zahrnující etiku, právo, společenské vědy a filosofii</p>
  </li>
</ul>

<p>Dobrým příkladem je postup Evropské unie s regulací AI Act, který se snaží najít rovnováhu mezi inovacemi a bezpečností, nebo práce organizací jako Partnership on AI, které podporují mezioborovou spolupráci.</p>

<p>Racionalita a obezřetnost jsou na místě, ale katastrofické scénáře bez pevných teoretických základů mohou spíše uškodit než pomoci seriózní debatě o budoucnosti umělé inteligence.</p>

<p>A to už jsme na konci našeho povídání. V krátkosti k autorům scénáře AI 2027 z jiného pohledu, než jaký se nabízí v nadšeném článku. Daniel Kokotajlo získal určité renomé publikováním scénáře “What 2026 Looks Like”, díky čemuž nastoupil do OpenAI a měl zde pracovat na scénářích dalšího vývoje. Skončil, prý proto, že jeho scénáře inklinovaly obecně ke katastrofickým provedením, což je v žánru obvyklé. Nikdy nikoho nezajímaly nudné scénáře “bylo to rychlejší, lepší” …</p>

<p>Také ostatní autoři mají své renomé v tomto typu literatury, ale Eli Lifland s Thomasem Larsenem jsou spíše známi pro politický realismus a geopolitické aspekty, než díky detailnímu technologickému vhledu. Scott Alexander je spíše blogger a Romeo Dean je spíše student Harvardu, co pomáhal.</p>

<p>Ve skutečnosti ale ta jména nejsou tak podstatná, ta rozhodovala jen o čtivosti a zpřístupnění dokumentu. Pro nás byly důležitější argumenty, s nimiž jsme se vypořádali. A důležité také je, že autoři přinášejí realistické návrhy, “co s tím”, jako mezinárodní spolupráci a regulaci, bezpečnostní protokoly pro superinteligentní systémy nebo transparentnost vývoje. Tyto návrhy nicméně podrývá fakt, že pokud by scénář měl pravdu, nikdo by se nechtěl k těmto návrhům uchýlit, aby si nezkomplikoval pozici v souboji o AGI.</p>

<p>V každém případě se na jejich web  <a href="https://ai-2027.com/">https://ai-2027.com</a>  podívejte. Mají scénář krásně udělaný, interaktivní a nepochybně přitáhne pozornost. O což šlo.</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="katastrofa" /><summary type="html"><![CDATA[Deník N vydal katastrofický článek s nadpisem “Do deseti let bude po všem”, v němž nám převyprávěl scénář AI 2027 vypracovaný pěticí lidí o potenciálním nebezpečí umělé inteligence. A tím se o tématu začalu v Česku opět diskutovat. Dokument vypadá na první pohled propracovaně, ona pětice má určité renomé. Jenže obsahuje řadu problematických předpokladů a logických skoků, které je třeba kriticky posoudit. Začnu tím, že vynechám onu pětici lidí, ani je zatím nebudu jmenovat, abychom se mohli nerušeně soustředit na tvrzení a fakta.]]></summary></entry><entry xml:lang="cs"><title type="html">A2A protokol - Nový standard pro interoperabilitu AI agentů</title><link href="https://www.marigold.cz/item/google-a2a/" rel="alternate" type="text/html" title="A2A protokol - Nový standard pro interoperabilitu AI agentů" /><published>2025-04-09T00:00:00+00:00</published><updated>2025-04-09T00:00:00+00:00</updated><id>https://www.marigold.cz/item/google-a2a</id><content type="html" xml:base="https://www.marigold.cz/item/google-a2a/"><![CDATA[<p>Přichází čas AI agentů, jenže jak se mezi sebou domluví? Právě neexistující vzájemné automatické propojení mezi agenty bylo značným omezením, což si uvědomil Google a přišel s návrhem protokolu A2A čili Agent2Agent.</p>

<p>Agent2Agent (A2A) je otevřený protokol navržený pro zabezpečenou komunikaci mezi AI agenty. Protokol byl vyvinut společností Google ve spolupráci s více než 50 technologickými partnery včetně Atlassian, Box, Cohere, Intuit, PayPal, Salesforce a dalších. Cílem A2A je umožnit AI agentům vyměňovat si informace a koordinovat akce napříč různými podnikovými platformami a aplikacemi.</p>

<p><strong>Co konkrétně se v tomto článku dozvíte?</strong></p>
<ul id="markdown-toc">
  <li><a href="#vztah-k-mcp" id="markdown-toc-vztah-k-mcp">Vztah k MCP</a>    <ul>
      <li><a href="#a2a-jako-ekosystém-specializovaných-expertů" id="markdown-toc-a2a-jako-ekosystém-specializovaných-expertů">A2A jako ekosystém specializovaných expertů</a></li>
      <li><a href="#návrh-a2a-protokolu" id="markdown-toc-návrh-a2a-protokolu">Návrh A2A protokolu</a></li>
      <li><a href="#funkce-a2a" id="markdown-toc-funkce-a2a">Funkce A2A</a></li>
      <li><a href="#praktické-využití-a2a" id="markdown-toc-praktické-využití-a2a">Praktické využití A2A</a></li>
      <li><a href="#technické-detaily" id="markdown-toc-technické-detaily">Technické detaily</a></li>
      <li><a href="#výzvy-a-omezení" id="markdown-toc-výzvy-a-omezení">Výzvy a omezení</a></li>
      <li><a href="#budoucí-vývoj" id="markdown-toc-budoucí-vývoj">Budoucí vývoj</a></li>
      <li><a href="#závěr" id="markdown-toc-závěr">Závěr</a></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>Další zdroje</p>
  <ul>
    <li>Github A2A: <a href="https://github.com/google/A2A">https://github.com/google/A2A</a></li>
    <li><a href="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/">Oficiální oznámení na Google Developers Blogu</a></li>
  </ul>
</blockquote>

<h2 id="vztah-k-mcp">Vztah k <a href="/ai/mcp/">MCP</a></h2>

<p>A2A doplňuje Model Context Protocol (MCP) od Anthropicu. Zatímco MCP se zaměřuje na poskytování nástrojů a kontextu pro samostatné agenty, A2A řeší problém, jak tito agenti mohou spolupracovat mezi sebou. Tyto protokoly společně tvoří základ pro vytváření komplexnějších agenčních systémů.</p>

<p>MCP je navržen pro obohacení jednotlivých agentů o nástroje a kontext, což jim umožňuje lépe plnit své úlohy. A2A naopak vytváří standardizovaný způsob, jak tito (potenciálně rozdílně vybavení) agenti mohou komunikovat a spolupracovat, a to bez ohledu na to, jakou technologií byli vytvořeni nebo jaký framework používají.</p>

<h3 id="a2a-jako-ekosystém-specializovaných-expertů">A2A jako ekosystém specializovaných expertů</h3>

<p>A2A protokol můžeme vnímat jako pokročilou formu orchestrace agentů, ale jde za hranice klasické orchestrace, jak ji známe například z mikroslužeb. Představte si ho jako ekosystém specializovaných expertů, kteří spolu mohou mluvit společným jazykem (protokolem) a předávat si práci, kdykoli narazí na něco, co lépe zvládne jiný specialista.</p>

<p>Na rozdíl od tradiční orchestrace, kde centrální orchestrátor řídí relativně pasivní komponenty podle předem definovaných workflow, v A2A si agenti zachovávají svou autonomii a rozhodovací schopnosti. Neexistuje zde nutně pevná hierarchie nebo předem stanovený procesní tok – interakce mohou vznikat dynamicky podle aktuální potřeby. Což přináší výhody, ale také potíže. Jak velké, ještě uvidíme 😎</p>

<h3 id="návrh-a2a-protokolu">Návrh A2A protokolu</h3>

<p>A2A byl navržen s ohledem na pět klíčových principů:</p>

<ol>
  <li>
    <p><strong>Agenční schopnosti</strong> - A2A umožňuje agentům spolupracovat v jejich přirozených, nestrukturovaných modalitách, i když nesdílejí paměť, nástroje a kontext. Nejde o pouhé využívání agentů jako “nástrojů”, ale o skutečné multi-agenční scénáře.</p>
  </li>
  <li>
    <p><strong>Stavba na existujících standardech</strong> - Protokol staví na populárních standardech jako HTTP, SSE a JSON-RPC, což usnadňuje integraci do existujících IT infrastruktur.</p>
  </li>
  <li>
    <p><strong>Bezpečnost jako výchozí stav</strong> - A2A podporuje podnikovou úroveň autentizace a autorizace, s návaznostní na autentizační mechanismy OpenAPI.</p>
  </li>
  <li>
    <p><strong>Podpora dlouhodobých úloh</strong> - Protokol je navržen tak, aby podporoval jak rychlé úkoly, tak hluboký výzkum, který může trvat hodiny nebo dny při zapojení lidí. Během celého procesu může A2A poskytovat zpětnou vazbu, oznámení a aktualizace stavu v reálném čase.</p>
  </li>
  <li>
    <p><strong>Modalitní agnosticita</strong> - A2A podporuje různé modality, včetně streamování audia a videa, neomezuje se pouze na text.</p>
  </li>
</ol>

<h3 id="funkce-a2a">Funkce A2A</h3>

<p>A2A zprostředkovává komunikaci mezi “klientským” agentem a “vzdáleným” agentem. Klientský agent formuluje a komunikuje úkoly, zatímco vzdálený agent na tyto úkoly reaguje a pokouší se poskytnout správné informace nebo provést správnou akci.</p>

<p>Interakce mezi agenty zahrnuje několik klíčových schopností:</p>

<ol>
  <li>
    <p><strong>Objevování schopností</strong> - Agenti mohou inzerovat své schopnosti pomocí “Agent Card” ve formátu JSON. To umožňuje klientskému agentovi identifikovat nejlepšího agenta, který může plnit daný úkol.</p>
  </li>
  <li>
    <p><strong>Správa úkolů</strong> - Komunikace mezi klientem a vzdáleným agentem je orientována na dokončení úkolů, kde agenti spolupracují na splnění požadavků koncových uživatelů. “Úkol” má definovaný životní cyklus - může být dokončen okamžitě, nebo v případě dlouhodobých úkolů mohou agenti komunikovat a synchronizovat se ohledně nejnovějšího stavu plnění úkolu. Výstupem úkolu je “artefakt”.</p>
  </li>
  <li>
    <p><strong>Spolupráce</strong> - Agenti si mohou navzájem posílat zprávy ke komunikaci kontextu, odpovědí, artefaktů nebo uživatelských instrukcí.</p>
  </li>
  <li>
    <p><strong>Vyjednávání uživatelské zkušenosti</strong> - Každá zpráva obsahuje “části”, což jsou plně formované kusy obsahu, jako je generovaný obrázek. Každá část má specifikovaný typ obsahu, což umožňuje klientským a vzdáleným agentům vyjednat správný potřebný formát a explicitně zahrnout vyjednávání o uživatelských schopnostech UI - např. iframy, videa, webové formuláře a další.</p>
  </li>
</ol>

<p><img src="https://www.marigold.cz/assets/a2a-schema.jpeg" alt="Google A2A" /></p>

<h3 id="praktické-využití-a2a">Praktické využití A2A</h3>

<p>A2A protokol může být využit v mnoha praktických scénářích. Jeden z příkladů uvedených v dokumentaci je “nábor vývojáře” - tedy situace, kdy je potřeba zajistit a projít životopisy vhodných kandidátů a sestavit doporučení:</p>

<ol>
  <li>Uživatel (např. manažer náboru) zadá svému agentovi úkol najít kandidáty odpovídající popisu práce, lokalitě a požadovaným dovednostem.</li>
  <li>Agent poté interaguje s jinými specializovanými agenty k vyhledání potenciálních kandidátů.</li>
  <li>Uživatel obdrží tyto návrhy a může svému agentovi zadat, aby naplánoval další pohovory.</li>
  <li>Po dokončení procesu pohovorů může být jiný agent pověřen kontrolou referencí.</li>
</ol>

<p>Tento příklad ilustruje, jak <a href="/ai/agenti/">AI agenti</a> potřebují spolupracovat napříč systémy k nalezení kvalifikovaného kandidáta na pracovní pozici.</p>

<p>Další možnosti využití zahrnují:</p>

<ul>
  <li><strong>Automatizace podnikových procesů</strong> - Propojení agentů pro objednávání, účetnictví, logistiku a zákaznický servis.</li>
  <li><strong>Datová analýza</strong> - Spolupráce specializovaných agentů na zpracování a analýze dat z různých zdrojů.</li>
  <li><strong>Výzkum a vývoj</strong> - Koordinace agentů pro vyhledávání, experimenty a syntézu výsledků.</li>
  <li><strong>Řízení dodavatelského řetězce</strong> - Propojení agentů pro plánování, nákup, skladování a distribuci.</li>
</ul>

<h3 id="technické-detaily">Technické detaily</h3>

<p>A2A je implementován jako REST API, které používá JSON pro výměnu dat. Klíčové komponenty zahrnují:</p>

<ol>
  <li>
    <p><strong>Agentní karty</strong> - JSON objekty popisující schopnosti agenta, včetně podporovaných operací, autentizačních požadavků a dalších metadat.</p>
  </li>
  <li>
    <p><strong>Úkoly</strong> - Strukturované objekty reprezentující práci, kterou má agent vykonat. Každý úkol má unikátní identifikátor, stav, priority a další atributy.</p>
  </li>
  <li>
    <p><strong>Zprávy</strong> - Komunikační jednotky mezi agenty, které mohou obsahovat textové zprávy, strukturovaná data nebo odkazy na externí zdroje.</p>
  </li>
  <li>
    <p><strong>Artefakty</strong> - Výstupy úkolů, které mohou mít různé formáty, jako jsou dokumenty, obrázky, audio nebo video.</p>
  </li>
  <li>
    <p><strong>Notifikace</strong> - Mechanismy pro aktualizace v reálném čase o změnách stavu úkolů nebo dostupnosti nových zpráv.</p>
  </li>
</ol>

<h3 id="výzvy-a-omezení">Výzvy a omezení</h3>

<p>I přes svůj potenciál čelí A2A několika výzvám:</p>

<ol>
  <li>
    <p><strong>Bezpečnost a soukromí</strong> - Při sdílení dat mezi agenty je kritické zajistit, že citlivé informace zůstanou chráněny.</p>
  </li>
  <li>
    <p><strong>Škálovatelnost</strong> - S rostoucím počtem agentů a komplexitou úkolů bude důležité udržet efektivitu a výkon systému.</p>
  </li>
  <li>
    <p><strong>Interoperabilita</strong> - Zatímco A2A poskytuje standard pro komunikaci, implementace tohoto standardu napříč různými systémy může být náročná.</p>
  </li>
  <li>
    <p><strong>Odpovědnost</strong> - Určení odpovědnosti v případě chyb nebo negativních výsledků může být složité v multi-agenčním prostředí.</p>
  </li>
</ol>

<h3 id="budoucí-vývoj">Budoucí vývoj</h3>

<p>A2A protokol je stále ve vývoji a jeho finální verze má být vydána později v roce 2025. Google a jeho partneři plánují protokol dále rozvíjet s důrazem na:</p>

<ol>
  <li><strong>Rozšíření podporovaných modalit</strong> - Přidání podpory pro nové typy dat a interakcí.</li>
  <li><strong>Vylepšení bezpečnostních mechanismů</strong> - Posílení ochrany dat a autentizace.</li>
  <li><strong>Optimalizace výkonu</strong> - Zlepšení efektivity komunikace mezi agenty.</li>
  <li><strong>Standardizace</strong> - Spolupráce s průmyslovými orgány na formalizaci A2A jako oficiálního standardu.</li>
</ol>

<h3 id="závěr">Závěr</h3>

<p>Agent2Agent (A2A) protokol představuje podle mě hodně důležitý krok k vytvoření interoperabilního ekosystému AI agentů. Právě kooperace a efektivní výměna dat AI agentů zatím představovala významný lidim, protože předávání dat většinou řešil uživatel, tedy ta nejméně spolehlivá část systámu. A2A doplňuje existující protokoly jako MCP a umožňuje agentům efektivně spolupracovat napříč platformami a aplikacemi. S podporou významných technologických společností má A2A potenciál stát se standardem pro komunikaci mezi AI agenty a umožnit nové formy automatizace a optimalizace procesů.</p>

<p>Protokol je navržen s důrazem na bezpečnost, flexibilitu a škálovatelnost, což jsou klíčové vlastnosti pro nasazení v podnikových prostředích. Jak se AI agenti stávají stále více součástí podnikových operací, standardy jako A2A budou hrát klíčovou roli v maximalizaci jejich přínosu a minimalizaci složitosti jejich implementace.</p>

<p>Koncept A2A jako ekosystému specializovaných expertů komunikujících společným jazykem přináší nový rozměr do světa umělé inteligence - místo izolovaných systémů vzniká prostor pro vysoce adaptabilní sítě autonomních agentů, kteří společně řeší komplexní problémy rychleji a efektivněji, než by dokázal jediný agent, bez ohledu na to, jak je sofistikovaný.</p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="Google" /><category term="Agenti" /><category term="A2A" /><summary type="html"><![CDATA[Přichází čas AI agentů, jenže jak se mezi sebou domluví? Právě neexistující vzájemné automatické propojení mezi agenty bylo značným omezením, což si uvědomil Google a přišel s návrhem protokolu A2A čili Agent2Agent.]]></summary></entry><entry xml:lang="cs"><title type="html">Meta představuje Llama 4 - open source LLM s obrovským kontextem i výkonem</title><link href="https://www.marigold.cz/item/meta-llama4/" rel="alternate" type="text/html" title="Meta představuje Llama 4 - open source LLM s obrovským kontextem i výkonem" /><published>2025-04-05T00:00:00+00:00</published><updated>2025-04-05T00:00:00+00:00</updated><id>https://www.marigold.cz/item/meta-llama4</id><content type="html" xml:base="https://www.marigold.cz/item/meta-llama4/"><![CDATA[<p>Meta právě vydala novou verzi svého open source LLM, který se jmenuje Llama 4. Ve skutečnosti jde o tři nové modely: Llama 4 Scout, Llama 4 Maverick a Llama 4 Behemoth, které se liší počtem aktivních parametrů a schopnostmi - a samozřejmě také požadovanou hardware výbavou. A to je to důležité: nová Llama 4 umí běžet na poměrně příznivé sestavě hardware, přitom nabízí skvělý výkon a open source prostředí. A co je naprosto famózní, je kontextové okno na 10 milionů tokenů, což je 10x více než dnes nabízí nejpokročilejší LLM Google Gemini. Jistě, rozsah kontextu se projevuje na výkonu, proto bude zajímavé sledovat, jak se to projeví v praxi, právě při použití velkého kontextu, který je dnes důležitý například při programování. K dlouhému kontextu si povíme detailní vysvětlení na závěr.</p>

<p>📊 <strong>Tři nové modely:</strong></p>
<ul>
  <li><strong>Llama 4 Scout:</strong> 17B aktivních parametrů s 16 experty, dokáže běžet na jediné H100 GPU</li>
  <li><strong>Llama 4 Maverick:</strong> 17B aktivních parametrů se 128 experty, výjimečná multimodální schopnost</li>
  <li><strong>Llama 4 Behemoth:</strong> 288B aktivních parametrů, stále ve vývoji, již nyní předčí GPT-4.5, Claude Sonnet 3.7 a Gemini 2.0 Pro v STEM benchmarcích</li>
</ul>

<p>💡 <strong>Klíčové technologické průlomy:</strong></p>
<ul>
  <li>První nativně multimodální modely Mety využívající architekturu mixture-of-experts (MoE)</li>
  <li>Průlomové kontextové okno 10M tokenů u Llama 4 Scout (10x více než nabízí Google)</li>
  <li>Trénink na více než 30 bilionech tokenů (dvojnásobek oproti Llama 3)</li>
  <li>Podpora pro 200 jazyků s 10x více multilingválními tokeny než předchozí verze</li>
  <li>Zpracování různorodých dat včetně textu, obrazu a videa</li>
</ul>

<p>⚖️ <strong>Výrazné zlepšení v oblasti vyvážení a bezpečnosti:</strong></p>
<ul>
  <li>Snížení míry odmítnutí odpovědí na kontroverzní témata ze 7% na méně než 2%</li>
  <li>Dosažení politické vyváženosti srovnatelné s modelem Grok, s výrazně menším počtem nevyvážených odpovědí</li>
  <li>Open-source bezpečnostní nástroje včetně Llama Guard, Prompt Guard a CyberSecEval</li>
  <li>Vývojáři mohou integrovat ochranné prvky proti potenciálně škodlivým vstupům a výstupům</li>
</ul>

<p>🔥 <strong>Výkonnostní přednosti:</strong></p>
<ul>
  <li>Llama 4 Scout překonává Gemma 3, Gemini 2.0 Flash-Lite a Mistral 3.1</li>
  <li>Llama 4 Maverick předčí GPT-4o a Gemini 2.0 Flash v řadě benchmarků</li>
  <li>Srovnatelné výsledky s <a href="/item/deepseek/">DeepSeek</a> v3 v oblasti uvažování a kódování - s polovinou aktivních parametrů</li>
  <li>Bezkonkurenční poměr výkonu a nákladů, chatovací verze skóruje 1417 ELO na LMArena</li>
</ul>

<p><img src="https://www.marigold.cz/assets/llama4-vykon.png" alt="Llama 4 a výkonnostní benchmarky" /></p>

<p>Výborné jsou také cenové parametry pro případ, že chcete použít Llama 4 přes API a nechcete ji instalovat na vlastní servery:</p>

<p><img src="https://www.marigold.cz/assets/llama4-ceny-parametry.jpg" alt="Cenové parametry Llama 4" /></p>

<p>Musím říct, že je to velmi příjemné překvapení. I když jsou to zatím jen papírová data a osobní zkušenost chybí, vypadá to velmi slibně a Meta jistě nebude slibovat něco, co alespoň přibližně není pravda. Na větší testování si musím počkat na začátek týdne, až si trochu uvolním místo na serverech :)</p>

<p><a href="https://go.fb.me/gmjohs">Více informací o modelech Llama 4 včetně detailů o tréninku a benchmarcích.</a>.</p>

<p>⬇️ <a href="https://go.fb.me/bwwhe9">Stáhnout Llama 4 můžete zde</a>.</p>

<h2 id="architektura-irope-čili-jak-se-meta-dostala-k-desetimilionovému-kontextu">Architektura iRoPE čili jak se Meta dostala k desetimilionovému kontextu.</h2>

<p>Deset milionů tokenů není vůbec maličkost, to je mimo jiné třeba 20 hodin videa, které si může Llama 4 Scout nacpat do paměti. Za tímto průlomem stojí architektura iRoPE.</p>

<p>Architektura iRoPE, kterou vyvinul tým Meta pro modely Llama 4, představuje inovativní přístup k řešení jednoho z největších problémů současných jazykových modelů - efektivní práce s extrémně dlouhým kontextem. Název iRoPE znamená <em>“interleaved Rotary Position Embedding”</em>, tedy prokládané rotační poziční kódování.</p>

<p>Tradiční transformerové architektury mají problém se zpracováním velmi dlouhých textů ze dvou důvodů. Za prvé, standardní attention mechanismus má kvadratickou složitost, což znamená, že paměťové a výpočetní nároky dramaticky rostou s délkou vstupu. Za druhé, poziční kódování, které umožňuje modelu rozlišovat pořadí slov, se obtížně extrapoluje na délky výrazně přesahující trénovací data.</p>

<p>Architektura iRoPE elegantně řeší tyto problémy kombinací dvou typů pozornostních vrstev, které se v modelu vzájemně prokládají (odtud “interleaved” v názvu).</p>

<p><em>První typ tvoří lokální vrstvy</em>, které používají tradiční rotační poziční kódování (RoPE). Tyto vrstvy zpracovávají pouze krátké úseky textu, typicky do 8K tokenů, a jsou zodpovědné za zachycení jemných místních souvislostí a jazykových vzorů. Klíčovou optimalizací je, že text rozdělují na menší části, které zpracovávají paralelně, což výrazně zvyšuje efektivitu.</p>

<p><em>Druhý typ představují globální vrstvy</em>, které na rozdíl od lokálních vrstev zpracovávají celý dlouhý kontext bez použití pozičních embedingů. To je revoluční myšlenka - tyto vrstvy se nesnaží rozlišovat konkrétní pozice, ale soustředí se na sémantické vztahy mezi různými částmi textu. Tím, že se model nemusí spoléhat na poziční informace, dokáže lépe generalizovat na délky daleko přesahující trénovací data.</p>

<p>Síla architektury spočívá právě v prokládání těchto dvou typů vrstev. Lokální vrstvy poskytují přesné modelování blízkých vztahů, zatímco globální vrstvy umožňují modelu “vidět” a propojovat vzdálené části kontextu. Takto dokáže model efektivně pracovat s kontextem o délce 10 milionů tokenů, i když byl trénován na mnohem kratších sekvencích (maximálně 256K tokenů).</p>

<p>Dalším důležitým aspektem je řešení problému “zploštění” pozornosti. S rostoucí délkou kontextu totiž mechanismus pozornosti přirozeně ztrácí schopnost zaměřit se na důležité informace - pozornost se “rozptyluje” napříč mnoha tokeny. Tým Meta vyvinul speciální techniku teplotního škálování, kterou aplikují pouze během inference a pouze na globální vrstvy. Tato technika pomáhá modelu udržet “ostrou” pozornost i při práci s extrémně dlouhými kontexty, aniž by to negativně ovlivnilo jeho výkon na krátkých textech.</p>

<p>Klíčovým vhledem celého přístupu je změna perspektivy - místo snahy trénovat model přímo na velmi dlouhých sekvencích (což by bylo extrémně náročné na výpočetní zdroje), tým Meta přeformuloval problém jako dosažení “nekonečného kontextu”. To vedlo k návrhu architektury, která dokáže elegantně extrapolovat z krátkých trénovacích sekvencí na mnohem delší vstupy při reálném použití. Tento přístup je nejen praktičtější z hlediska tréninku, ale také lépe škáluje směrem k budoucím modelům s ještě delším kontextem.</p>

<p>A tady si to ještě pro jistotu ukážeme v grafu:</p>

<pre><code class="language-mermaid">flowchart TD
    subgraph Architecture["Architektura iRoPE"]
        Input[/"Vstupní sekvence\n(až 10M tokenů)"/] --&gt; Split["Rozdělení zpracování"]
        
        Split --&gt; LocalLayers["Lokální vrstvy s RoPE"]
        Split --&gt; GlobalLayers["Globální vrstvy bez pozičních embedingů"]
        
        subgraph LocalProcessing["Zpracování lokálních vrstev"]
            LocalLayers --&gt; Chunking["Rozdělení na chunky\n(typicky 8K tokenů)"]
            Chunking --&gt; ParallelProc["Paralelní zpracování chunků"]
            ParallelProc --&gt; LocalPatterns["Zachycení lokálních vzorů\na závislostí"]
        end
        
        subgraph GlobalProcessing["Zpracování globálních vrstev"]
            GlobalLayers --&gt; FullContext["Zpracování celého kontextu"]
            FullContext --&gt; SemanticRel["Zachycení sémantických vztahů\nbez ohledu na pozici"]
            SemanticRel --&gt; TempScaling["Teplotní škálování při inferenci\n(kompenzace zploštění pozornosti)"]
        end
        
        LocalPatterns --&gt; Interleaving["Prokládání (Interleaving)\nlokálních a globálních reprezentací"]
        TempScaling --&gt; Interleaving
        
        Interleaving --&gt; Output[/"Výstupní reprezentace\ns efektivním dlouhým kontextem"/]
    end
    
    style Architecture fill:#f5f5f5,stroke:#333,stroke-width:1px
    style LocalProcessing fill:#e1f5fe,stroke:#0288d1,stroke-width:1px
    style GlobalProcessing fill:#e8f5e9,stroke:#388e3c,stroke-width:1px
    
    style Input fill:#bbdefb,stroke:#1976d2,stroke-width:1px
    style Output fill:#c8e6c9,stroke:#43a047,stroke-width:1px
    style Split fill:#fff9c4,stroke:#fbc02d,stroke-width:1px
    style Interleaving fill:#f8bbd0,stroke:#e91e63,stroke-width:1px
</code></pre>

<h1 id="omezení-nové-licence-llama-4">Omezení nové licence Llama 4</h1>

<p>Nová licence Llama 4 přichází s několika omezeními:</p>

<ul>
  <li>Společnosti s více než 700 miliony měsíčně aktivních uživatelů musí požádat o speciální licenci od společnosti Meta, kterou Meta může udělit nebo odmítnout dle svého výhradního uvážení.</li>
  <li>Musíte viditelně zobrazit “Built with Llama” (Vytvořeno s Llama) na webových stránkách, rozhraních, dokumentaci atd.</li>
  <li>Jakýkoliv AI model, který vytvoříte s použitím modelu Llama, musí obsahovat “Llama” na začátku svého názvu.</li>
  <li>Musíte zahrnout specifické oznámení o autorských právech v textovém souboru “Notice” při jakékoliv distribuci.</li>
  <li>Vaše používání musí být v souladu se samostatnými <a href="http://llama.com/llama4/use-policy">Zásadami přijatelného použití společnosti Meta</a>.</li>
  <li>Omezená licence k používání názvu “Llama” pouze pro účely splnění požadavků na označení.</li>
</ul>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="Meta" /><category term="Llama" /><summary type="html"><![CDATA[Meta právě vydala novou verzi svého open source LLM, který se jmenuje Llama 4. Ve skutečnosti jde o tři nové modely: Llama 4 Scout, Llama 4 Maverick a Llama 4 Behemoth, které se liší počtem aktivních parametrů a schopnostmi - a samozřejmě také požadovanou hardware výbavou. A to je to důležité: nová Llama 4 umí běžet na poměrně příznivé sestavě hardware, přitom nabízí skvělý výkon a open source prostředí. A co je naprosto famózní, je kontextové okno na 10 milionů tokenů, což je 10x více než dnes nabízí nejpokročilejší LLM Google Gemini. Jistě, rozsah kontextu se projevuje na výkonu, proto bude zajímavé sledovat, jak se to projeví v praxi, právě při použití velkého kontextu, který je dnes důležitý například při programování. K dlouhému kontextu si povíme detailní vysvětlení na závěr.]]></summary></entry><entry xml:lang="cs"><title type="html">Midjourney V7 - Nová verze modelu pro AI generování obrazů</title><link href="https://www.marigold.cz/item/midjourney-v7/" rel="alternate" type="text/html" title="Midjourney V7 - Nová verze modelu pro AI generování obrazů" /><published>2025-04-05T00:00:00+00:00</published><updated>2025-04-05T00:00:00+00:00</updated><id>https://www.marigold.cz/item/midjourney-v7</id><content type="html" xml:base="https://www.marigold.cz/item/midjourney-v7/"><![CDATA[<p>Midjourney vydal po zhruba roce od předchozího modelu alfa verzi svého obrazového modelu V7, který přináší změny v kvalitě a funkcionalitě AI generování obrazů. Model zavádí nové funkce měnící způsob interakce s nástrojem a zlepšující kvalitu výstupů.</p>

<h2 id="klíčové-změny-modelu-v7">Klíčové změny modelu V7</h2>

<h3 id="zpracování-textových-promptů">Zpracování textových promptů</h3>
<p>Model V7 nabízí lepší porozumění textovým promptům. Uživatelé zmiňují schopnost modelu přesněji interpretovat složitější instrukce, což je vítané hlavně pro náročnější práci, kdy jste potřebovali modelu dát lepší zadání. Starší modely prostě delší prompty než cca 100 slov nezpracovávaly dobře.</p>

<h3 id="zpracování-obrazových-vstupů">Zpracování obrazových vstupů</h3>
<p>Obrazové prompty dosahují vyšší kvality. V7 lépe zachycuje a reprodukuje textury a detaily z referenčních obrázků.</p>

<h3 id="kvalita-detailů">Kvalita detailů</h3>
<p>V7 přináší zlepšení v zobrazování lidských těl, rukou a objektů. Tento aspekt, často kritizovaný u předchozích verzí, byl vylepšen díky lepší koherenci detailů.</p>

<h2 id="personalizace-jako-výchozí-funkce">Personalizace jako výchozí funkce</h2>

<p>Midjourney V7 je první model s aktivovanou personalizací ve výchozím nastavení. Tento přístup vyžaduje počáteční personalizaci (cca 5 minut se tvrdí, ve skutečnosti vyhodnocujete cca 200 obrázků, za mne maličko pruda), následně umožňuje systému interpretovat preference uživatele a vytvářet výstupy odpovídající jeho estetickým preferencím.</p>

<p>Uživatelé se v odezvách shodují v tom, že personalizace přináší lepší výsledky, ačkoliv proces projití personalizace je trochu zdlouhavý.</p>

<h2 id="draft-mode">“Draft Mode”</h2>

<p>Významnou inovací je “Draft Mode” (režim nákresů). Dělá to, jak ho pojmenovali - udělá jednodušší verzi obrázku významně rychleji a až jste s ní v pohodě, vygeneruje lepší verzi.  Co Draft Mode nabízí:</p>

<ul>
  <li>10x rychlejší renderování obrazů</li>
  <li>Poloviční náklady oproti standardnímu režimu</li>
  <li>Konverzační rozhraní pro iteraci nápadů</li>
  <li>Možnost hlasového ovládání</li>
</ul>

<p>Podle uživatelů představuje Draft Mode změnu pracovního postupu, umožňující rychlejší experimentování. Draft lze povýšit na plnou kvalitu pomocí funkce “enhance” nebo “vary”.</p>

<h2 id="dostupné-režimy-a-ceny">Dostupné režimy a ceny</h2>

<p>V7 začíná ve dvou režimech:</p>
<ul>
  <li>Turbo: rychlejší zpracování za dvojnásobnou cenu oproti V6</li>
  <li>Relax: standardní zpracování za nižší cenu</li>
</ul>

<p>Standardní režim bude dostupný později. Draft Mode snižuje náklady na polovinu oproti běžnému režimu.</p>

<h2 id="kompatibilita-a-plánovaný-vývoj">Kompatibilita a plánovaný vývoj</h2>

<p>Funkce jako upscaling, editace a retexturing momentálně využívají modely V6. Vývojový tým plánuje aktualizaci těchto funkcí v budoucích verzích. Moodboards a SREF (Self-Reference) jsou funkční a jejich výkon bude postupně vylepšován.</p>

<p>Midjourney plánuje vydávat nové funkce každé 1-2 týdny během následujících 60 dnů. Hlavní připravovanou funkcí je nová V7 reference postav a objektů.</p>

<h2 id="reakce-komunity">Reakce komunity</h2>

<p>Ohlasy z komunity na Redditu zahrnují:</p>

<ol>
  <li>Zlepšení v detailech a texturách</li>
  <li>Využití Draft Mode pro kreativní proces</li>
  <li>Lepší interpretace textových promptů</li>
  <li>Konzistentnější výsledky při generování postav</li>
</ol>

<p>Někteří uživatelé upozorňují, že V7 vyžaduje jiný přístup k promptování než předchozí verze.</p>

<p>Midjourney V7 představuje další krok v oblasti AI generování obrazů. Kombinace vylepšené kvality, personalizace, Draft Mode a plánovaného vývoje rozšiřuje možnosti nástroje. Pro profesionální uživatele přináší V7 kvalitnější výstupy a efektivnější pracovní postupy.</p>

<p>Model V7 je dostupný v alfa verzi a vývojový tým sbírá zpětnou vazbu od komunity. Je ale dosti zřejmé, že uvolnění proběhlo hodně narychlo, zjevně v reakci na OpenAI 4o obrazový model, který vyšel před několika dny a je skvělý. V každém případě se ukazuje, že Midjourney stále vede v oblasti AI generování obrazů, jenže pro mnoho uživatelů může být kvalita modelu 4o dostatečná. Dám třeba nemám pro kvalitnější obrázky velké uplatnění, takže Midjourney používám jen málo, spíše pro práce zákazníků.</p>

<p>A co ještě při příležitosti uvedení V7 prohlásil CEO David Holze? Společnost pracuje na dříve oznámených modelech pro generování videa a 3D objektů. Těším se!</p>

<p>Dejme si dva příklady, jeden ukazuje kvalitu práce v hi-res oblasti a zejména na fotkách lidí, druhý v případě animovaného stylu. Na internetu již lítají stovky příkladů, pomocí dalších AI nástrojů z toho dělají lidé i spojitá videa :)</p>

<p><img src="/assets/midjourneyVý-example1.jpeg" alt="Fotorealistický obrázek obličeje" /></p>

<p><img src="/assets/midjourneyVý-example2.jpeg" alt="Vygenerované Anime, všímejte si těch detailů" /></p>]]></content><author><name>Patrick Zandl</name></author><category term="AI" /><category term="Midjourney" /><summary type="html"><![CDATA[Midjourney vydal po zhruba roce od předchozího modelu alfa verzi svého obrazového modelu V7, který přináší změny v kvalitě a funkcionalitě AI generování obrazů. Model zavádí nové funkce měnící způsob interakce s nástrojem a zlepšující kvalitu výstupů.]]></summary></entry><entry xml:lang="cs"><title type="html">Moderní přístup k vývoji prototypu software MVP pomocí vibe codingu</title><link href="https://www.marigold.cz/item/architektura-vibecoding/" rel="alternate" type="text/html" title="Moderní přístup k vývoji prototypu software MVP pomocí vibe codingu" /><published>2025-04-03T00:00:00+00:00</published><updated>2025-04-03T00:00:00+00:00</updated><id>https://www.marigold.cz/item/architektura-vibecoding</id><content type="html" xml:base="https://www.marigold.cz/item/architektura-vibecoding/"><![CDATA[<p>Vytvářet prototypy software (MVP) pomocí AI začíná být stále rozšířenější metoda. Jenže <a href="/vibe-coding/">vibe coding</a>, jak se nový přístup k vývoji MVP jmenuje, má své nástrahy. A nelze jej používat bezhlavě - a na vechny projekty. Rychle narazíte na problém, kdy většinu času strávíte opravami kódu, který AI napsala nejasně nebo špatně. Klíčem k úspěchu je proto systémová jednoduchost a modulárnost, která umožní AI udržet si přehled v “kontextu”.</p>

<p>Pojdme si spolu projít zásady, které se mi za posledních pár pokusů vydestilovaly jako základ úspěchu a rychlého posunu s vibe codingem:</p>

<h2 id="hlavní-princip-modularizace-a-zjednodušení"><strong>Hlavní princip: Modularizace a zjednodušení</strong></h2>

<p>Klíčem k úspěšnému vývoji pomocí vibe codingu je důsledná modularizace a zjednodušení celého procesu. Nejlepší je rozdělit vývoj do tří jasně oddělených částí:</p>

<ol>
  <li><strong>Frontend vyvinutý pomocí no-code nástrojů</strong> - čistě pro UI/UX</li>
  <li><strong>Minimální sada API bez business logiky</strong> - pouze pro komunikaci a přístup k datům</li>
  <li><strong>Business logika implementovaná v automatizačním frameworku</strong> - pro skutečnou funkcionalitu systému</li>
</ol>

<p>Tato struktura přináší několik významných výhod:</p>

<ul>
  <li>Frontend kód zůstává čistý a jednoduchý, zaměřený pouze na zobrazování UI</li>
  <li>API kód je krátký, přímočarý a snadno spravovatelný</li>
  <li>Business logika je přehledně vizualizovaná v automatizačním frameworku, což usnadňuje debugging</li>
</ul>

<h2 id="praktický-postup-implementace"><strong>Praktický postup implementace</strong></h2>

<h3 id="1-vývoj-frontendu"><strong>1. Vývoj frontendu</strong></h3>

<p>Začněte výběrem vhodného no-code nástroje jako Bubble, Bolt nebo Replit. Zaměřte se výhradně na vzhled a pocit z aplikace. V této fázi ignorujte technické detaily implementace a soustřeďte se pouze na UI/UX.</p>

<p><strong>Důležité tipy:</strong></p>

<ul>
  <li>Vytvořte plně funkční frontend, který vypadá přesně tak, jak chcete</li>
  <li>Nechte si ho generovat jako statický soubor (HTML/CSS/JS)</li>
  <li>Autentizaci a volání API implementujte až později</li>
  <li>Pro hosting využijte služby jako Cloudflare, které jsou pro statické soubory zdarma</li>
</ul>

<h3 id="2-implementace-api"><strong>2. Implementace API</strong></h3>

<p>Pro backend je nejlépe využít Python, který má vynikající podporu v AI nástrojích jako Cursor nebo Cline. Klíčová pravidla pro backend jsou:</p>

<ul>
  <li><strong>Omezte počet souborů</strong> (ideálně max. 25)</li>
  <li><strong>Limitujte délku jednotlivých souborů</strong> (max. 250 řádků)</li>
  <li><strong>Vytvářejte jen tři typy API:</strong></li>
  <li><strong>Data storage API</strong>: jednoduchá CRUD rozhraní, s jasně definovanou strukturou a Swagger dokumentací.</li>
  <li><strong>Processing API</strong>: slouží pro náročnější úkoly jako je komprese obrázků, generování videí či reportů. Držte je oddělené od datového API.</li>
  <li><strong>Real-time API</strong> (například pro chat, video, apod.): jde o složitější úkoly, u kterých stojí za to zvážit spolupráci se specializovaným vývojářem.</li>
</ul>

<p>A dejte si pozor na jednu věc: řada AI nástrojů má tendenci databázi propojovat přímo s kódem, veškerá napojení na databází musí jít přes endpointy API na vašem serveru, jinak vystavíte databázi světu!</p>

<p>Proč tyto limity? Příliš mnoho souborů a řádků kódu znamená více kontextu pro AI, vyšší náklady a více potenciálních chyb.</p>

<h3 id="3-implementace-business-logiky-v-automatizačním-frameworku"><strong>3. Implementace business logiky v automatizačním frameworku</strong></h3>

<p>Klíčovým rozdílem oproti tradičním přístupům je přesun business logiky z backend kódu do vizuálního automatizačního frameworku jako je n8n, Make,  Zapier nebo PowerApps, pokud je to jen trochu možné. Především tak dostanete ověřenou funkcionalitu, jejíž fungování si můžete vizualizovat. I jako neprogramátor pak vidíte, co se s daty děje, jak a kudy putují a jak se zpracovávají. Ostatně, na propojování různých systémů je <a href="/vibe-coding/">vibe coding</a> a rychlá stavba prototypů založena - můžete se tomu vysmívat, ale je to podobné, jako v Linuxu, kde využíváte vstupně/výstupní rozhraní nejrůznějších démonů, utilit či knihoven. Jen to má líbivější kabátek a “matlačku” mezi tím dělá AI nebo klikání  myší v rozhraní.</p>

<p>Dodržením pravidla přesunu logiky do automatizačního frameworku dosáhnete několika zásadních výhod:</p>

<ul>
  <li><strong>Menší AI kontext</strong>: kratší a jednodušší kód znamená menší potřebu kontextu pro AI a tím i méně chyb.</li>
  <li><strong>Úspora nákladů</strong>: frontend můžete zdarma hostovat například na Cloudflare, backendové API jsou díky jednoduchosti levnější na provoz.</li>
  <li><strong>Snadná údržba</strong>: obchodní logika v nástrojích jako Zapier je snadno čitelná, což umožňuje rychlé změny a jasnou prezentaci týmu i klientům.</li>
</ul>

<h2 id="důsledky-pro-celkovou-architekturu"><strong>Důsledky pro celkovou architekturu</strong></h2>

<p>Tento <a href="/vibe-coding/">vibe coding</a> přístup vede k systému složenému ze tří jasně oddělených vrstev:</p>

<ol>
  <li><strong>Frontend</strong> (vibe coded) - zodpovědný pouze za prezentaci</li>
  <li><strong>Backend API</strong> (vibe coded) - zodpovědný za ukládání, zpracování a komunikaci</li>
  <li><strong>Automatizační framework</strong> - zodpovědný za business logiku a propojení všech komponent</li>
</ol>

<p>Takto strukturovaný systém je nejen snazší vyvíjet, ale také udržovat a rozšiřovat, protože každá část má jasně definovanou zodpovědnost a rozhraní.</p>

<h2 id="testování-a-monitoring"><strong>Testování a monitoring</strong></h2>

<p>Po úspěšné implementaci všech tří částí je důležité nezapomenout na testování a monitoring. Santoso doporučuje:</p>

<ul>
  <li>Vytvořit automatizovaný workflow, který denně testuje funkčnost API</li>
  <li>Implementovat pravidelné reportování a monitoring pomocí emailů nebo notifikací</li>
  <li>Využít automatizační framework i pro účely testování</li>
</ul>

<pre><code class="language-mermaid">graph TD
    %% Hlavní bloky
    A[Jak správně vyvíjet MVP prototypy pomocí Vibe Codingu] --&gt; B(Oddělení vrstev aplikace)

    %% Oddělení vrstev
    B --&gt; C[Frontend UI - No-code nástroje]
    B --&gt; D[Backend - Minimalistická API]
    B --&gt; E[Obchodní logika - Automatizace]

    %% Frontend detaily
    C --&gt; C1[Bubble / Bolt / Replit]

    %% Backend detaily
    D --&gt; D1[Data Storage API - CRUD, Swagger]
    D --&gt; D2[Processing API - Zpracování dat]
    D --&gt; D3[Real-time API - Chat, Video]

    %% Logika detaily
    E --&gt; E1[Zapier / n8n / PowerApps]

    %% Integrace a monitoring
    C &amp; D &amp; E --&gt; F[Integrace a monitoring]

    %% Detaily monitoringu
    F --&gt; G[Denní automatizovaný testing API]
    F --&gt; H[Automatické reporty a alerty]
</code></pre>

<h2 id="závěr"><strong>Závěr</strong></h2>

<p>“Vibe coding” s využitím nejnovějších AI nástrojů představuje atraktivní způsob rychlého vývoje MVP a prototypů. Klíčem k úspěchu je však důsledné rozdělení zodpovědností mezi tři oddělené vrstvy - frontend, API a automatizační framework. Tento přístup minimalizuje čas strávený debugováním, umožňuje rychlý vývoj a usnadňuje budoucí rozšíření a údržbu.</p>

<p>Pro vývojáře, kteří chtějí experimentovat s tímto přístupem, je důležité mít na paměti, že nejde o kompletní náhradu tradičních vývojových metod, ale spíše o komplementární přístup vhodný zejména pro rychlý vývoj prototypů a MVP před jejich případným přepracováním do produkční kvality.</p>

<p>Pro zajímavost si někdy popíšeme, jak jsem vibe codingem realizoval některé služby, jako jsou například <a href="http://www.zajimaveprednasky.cz">zajímaveprednasky.cz</a>…</p>]]></content><author><name>Patrick Zandl</name></author><category term="vibe coding" /><category term="AI" /><summary type="html"><![CDATA[Vytvářet prototypy software (MVP) pomocí AI začíná být stále rozšířenější metoda. Jenže vibe coding, jak se nový přístup k vývoji MVP jmenuje, má své nástrahy. A nelze jej používat bezhlavě - a na vechny projekty. Rychle narazíte na problém, kdy většinu času strávíte opravami kódu, který AI napsala nejasně nebo špatně. Klíčem k úspěchu je proto systémová jednoduchost a modulárnost, která umožní AI udržet si přehled v “kontextu”.]]></summary></entry><entry xml:lang="cs"><title type="html">Deset knih o současné politice, ekonomice a technologiích na jaro 2025</title><link href="https://www.marigold.cz/item/deset-knih-na-jaro-2025/" rel="alternate" type="text/html" title="Deset knih o současné politice, ekonomice a technologiích na jaro 2025" /><published>2025-03-29T00:00:00+00:00</published><updated>2025-03-29T00:00:00+00:00</updated><id>https://www.marigold.cz/item/deset-knih-na-jaro-2025</id><content type="html" xml:base="https://www.marigold.cz/item/deset-knih-na-jaro-2025/"><![CDATA[<p>Připravil jsem výběr knih o současné politice, ekonomice a technologiích pro letošní jaro, toto je dávka anglických knih. České budou příležitostně následovat.</p>

<h3 id="max-chafkin--the-contrarian">Max Chafkin – The Contrarian</h3>

<p>Max Chafkin, americký novinář časopisu Bloomberg Businessweek, zpracoval biografii Petera Thiela, miliardáře a podporovatele J. D. Vance, který hraje významnou roli v propojování techno-utopismu a kulturní alternativní pravice v Republikánské straně. Kniha “The Contrarian” popisuje vývoj Thielovy pravicové filozofie, příběh vzniku PayPalu a jeho počáteční rozepře s Elonem Muskem, i jeho postupně se vyvíjející názory po 11. září a finanční krizi.</p>

<p>Text se také zabývá založením datové společnosti Palantir a způsobem, jakým Thiel naznačoval, že technologie jeho společnosti byla zodpovědná za dopadení Usámy bin Ládina, což jí poskytlo podporu mezi obrannými resorty. Pro čtenáře se zájmem o propojení technologického sektoru a politiky poskytuje kniha kontext pro pochopení ideologických základů současného techno-kapitalismu a jeho politických aspirací.</p>

<h3 id="kate-conger-a-ryan-mac--character-limit">Kate Conger a Ryan Mac – Character Limit</h3>

<p>Kate Conger a Ryan Mac, zkušení technologičtí novináři, napsali podrobnou knihu o Elonu Muskovi a jeho působení v Twitteru, který transformoval na platformu X. “Character Limit” dokumentuje Muskovu přestavbu této sociální sítě, založeno na mnoha zdrojích z prostředí společnosti.</p>

<p>Kniha popisuje Muskův manažerský přístup: propouštění zaměstnanců a následné pokusy znovu najmout lidi, kteří se ukázali jako potřební; důraz na úspory, které nakonec vedly k nákladnějším selháním; odmítání platit účty; a ochota prohrávat soudní spory, protože náklady jsou v jeho pohledu nižší než změna kurzu. Pro ty, kdo sledují globální technologický sektor a jeho vliv na společnost, poskytuje kniha vhled do řízení jedné z největších sociálních platforem a stylu vedení významného technologického podnikatele.</p>

<h3 id="helen-thompson--disorder">Helen Thompson – Disorder</h3>

<p>Helen Thompson, profesorka z Cambridge a autorka podcastů, napsala knihu “Disorder”, která zkoumá příčiny obratu k neliberalismu a nacionalismu po nástupu Trumpa a po brexitu. Kniha je rozdělena do tří částí - první se zabývá rolí energetiky v utváření geopolitiky od druhé světové války; druhá finančními trhy a změnami v širší globální ekonomice; a třetí zkoumá povahu demokracie a reakce vlád na problémy způsobené prvními dvěma aspekty.</p>

<p>Thompsonová využívá přímý styl s širokými soudy, které ne vždy obstojí. Někteří kritici jí vytýkali to, co považují za chyby v druhé části, zejména ohledně eurozóny a její reakce na finanční krizi. I s těmito výhradami však kniha obsahuje informace a myšlenky z úhlu, který jiné publikace na tato témata nepokrývají. První část o energetice je obzvláště propracovaná a poskytuje hodnotný vhled do vztahu mezi energetikou a globální politikou. Pro čtenáře se zájmem o strukturální faktory ovlivňující současnou politickou nestabilitu poskytuje kniha alternativní pohled oproti analýzám zaměřeným primárně na jednotlivé politické osobnosti.</p>

<h3 id="nicole-hemmer--partisans">Nicole Hemmer – Partisans</h3>

<p>Nicole Hemmer, americká historička a mediální odbornice, nabízí v knize “Partisans” pohled na americkou politiku 90. let, kdy se pravicový posun republikánů stal zřetelnějším. Zaměřuje se především na tři osobnosti: Rushe Limbaugha, rozhlasového moderátora, který ovlivnil tón moderního konzervatismu; Pata Buchanana, jehož neúspěšné prezidentské kandidatury předznamenaly v některých ohledech Trumpa; a Newta Gingricha, který jako předseda Sněmovny reprezentantů změnil normy formální washingtonské politiky.</p>

<p>Kniha popisuje transformaci politického diskurzu v USA, který se postupně posouval od umírněného středu k více partyzánské rétorice a taktikám. Pro evropské čtenáře poskytuje kontext toho, jak se změnila povaha amerického politického dialogu, což následně ovlivnilo i mezinárodní politické prostředí. Text pomáhá vysvětlit kořeny současné polarizace americké politické scény.</p>

<h3 id="maggie-haberman--confidence-man">Maggie Haberman – Confidence Man</h3>

<p>Maggie Haberman, novinářka The New York Times a držitelka Pulitzerovy ceny, napsala komplexní biografii Donalda Trumpa “Confidence Man”, která sleduje celou jeho kariéru až po konec prvního prezidentského období. Habermanová strávila roky reportováním o Trumpovi a získala Pulitzerovu cenu v roce 2018 za své zpravodajství. Trump se na ni zaměřoval, což se stalo součástí příběhu knihy.</p>

<p>Informativní části knihy popisují jeho ranou kariéru, kdy získával peníze od státních vlád na financování svých velkolepých budov, a jeho pokusy proniknout do kasinového byznysu. Kniha předkládá pohled na Trumpa jako na stárnoucího bosse v mafiánském stylu, což odráží prostředí, v němž se pohyboval. Pro čtenáře zajímající se o politickou ekonomii vztahů mezi byznysem a státní mocí nabízí tato kniha cenný vhled do fungování amerického podnikatelského a politického prostředí.</p>

<h3 id="quinn-slobodian--crack-up-capitalism">Quinn Slobodian – Crack-Up Capitalism</h3>

<p>Quinn Slobodian, kanadský historik, který se věnuje studiu neoliberalismu (definovaného přesněji než mnozí, kteří tento výraz používají), napsal knihu “Crack-Up Capitalism” o vztahu libertarianismu a demokracie. Sleduje, jak se místa jako Hong-Kong, Singapur a Dubaj vyvinula jako centra kapitalismu s omezenou demokracií.</p>

<p>Autor analyzuje, jak tyto modely ovlivnily další státy, jako je Čína, pro kterou je Hongkong vzorem pro jejich rozvoj nových měst. Zároveň ukazuje, jak se tyto modely stávají zajímavými pro západní myslitele - jak z hlediska investic do těchto center, tak i zřizování nových ekonomických zón, ve kterých platí odlišná pravidla, například v oblasti daní. Pro čtenáře se zájmem o globální ekonomické trendy a vztah mezi kapitalismem a demokracií poskytuje kniha pohled na alternativní modely ekonomického uspořádání.</p>

<h3 id="ivan-krastev-a-stephen-holmes--the-light-that-failed">Ivan Krastev a Stephen Holmes – The Light That Failed</h3>

<p>Ivan Krastev, bulharský politolog, a Stephen Holmes, americký právní teoretik, napsali knihu “The Light That Failed” během prvního Trumpova funkčního období. Tato kniha pracuje s konceptem imitace a způsoby, jakými tento proces ovlivnil politický vývoj ve východní Evropě, Rusku a později i na Západě.</p>

<p>První část se zaměřuje na zavádění modelů západní liberální demokracie ve východoevropských státech po rozpadu Varšavské smlouvy a na reakce, které to vyvolalo. Druhá část se soustředí na Rusko a Putinův přechod k odlišnému modelu vládnutí, který zdůvodňoval poukazováním na nedostatky Západu. Závěrečná část analyzuje Trumpovo přebírání některých prvků východních politických stylů a jejich dopad na Západ. Pro čtenáře zajímající se o globální politické trendy a vztahy mezi Východem a Západem nabízí kniha strukturovaný pohled na vývoj politických systémů v posledních desetiletích.</p>

<h3 id="svetlana-alexijevič--doba-z-druhé-ruky-second-hand-time">Svetlana Alexijevič – Doba z druhé ruky (Second-Hand Time)</h3>

<p>Svetlana Alexijevič, běloruská nositelka Nobelovy ceny, vytvořila v knize “Doba z druhé ruky” dílo dokumentující postsovětské období v Rusku. Její metoda spočívá v rozhovorech se stovkami lidí, které pak sestavuje do vyprávění s minimálními autorskými zásahy.</p>

<p>Kniha představuje pocity lidí, kteří zažili rozpad sovětského systému, krátkou naději na změnu a následné zklamání. Pro západního čtenáře je zajímavý pocit osudovosti, který mnozí dotazovaní vyjadřují - pocit, že Rusko není připraveno na určité formy společenského uspořádání: “V Rusku se za pět let může změnit všechno, ale za dvě stě let se nezmění nic.” Pro ty, kdo se zajímají o ruskou společnost a její vývoj po rozpadu SSSR, poskytuje kniha vhled do myšlení běžných Rusů během tohoto období.</p>

<h3 id="paul-lendvai--orbán">Paul Lendvai – Orbán</h3>

<p>Paul Lendvai, maďarsky narozený bývalý novinář Financial Times, který pokrýval region střední Evropy, napsal první úplnou biografii Viktora Orbána přeloženou do angličtiny. Kniha vypráví příběh o tom, jak se Orbán poprvé dostal do povědomí jako mladý protikomunistický protestující během povstání v roce 1989, založil Fidesz jako liberální stranu a stal se poprvé premiérem v roce 1998.</p>

<p>Autor popisuje, jak se během jeho prvního funkčního období projevily jeho sklony k centralizaci moci, ale protože neměl většinu, byl omezen v prosazování změn. Když se v roce 2010 vrátil k moci, měl díky maďarskému volebnímu systému super-většinu, která mu umožnila změnit ústavu a postupně přetvořit politický systém, včetně soudnictví a mediálního prostředí. Pro čtenáře, kteří sledují vývoj politických systémů ve střední Evropě, nabízí kniha pohled na transformaci jednoho z důležitých politiků regionu.</p>

<h3 id="rick-perlstein--kronika-amerického-konzervatismu-chronicle-of-american-conservatism">Rick Perlstein – Kronika amerického konzervatismu (Chronicle of American Conservatism)</h3>

<p>Rick Perlstein, americký historik a politický komentátor, vytvořil čtyřdílnou sérii mapující proměnu Republikánské strany z elitní východopobřežní formace na stranu získávající jih USA svým pravicovým obratem. Série začíná knihou “Before the Storm” o kandidatuře Barryho Goldwatera v roce 1964, pokračuje “Nixonland” o vzestupu prezidenta Nixona, a končí dvěma svazky o cestě Ronalda Reagana k moci.</p>

<p>Série nabízí detailní popis způsobů, jakými pravice budovala lidová hnutí kolem kulturních a rasových témat, jako bylo busing (doprava dětí do škol za účelem rasové integrace) či bytová diskriminace, a rostoucí rolí evangelikálních křesťanů v Republikánské straně. Pro čtenáře zajímající se o kořeny současné americké politické polarizace poskytuje toto dílo kontext, který pomáhá pochopit, jak se konzervativní hnutí postupně transformovalo do své dnešní podoby.</p>]]></content><author><name>Patrick Zandl</name></author><category term="knihy" /><category term="politika" /><category term="společnost" /><summary type="html"><![CDATA[Připravil jsem výběr knih o současné politice, ekonomice a technologiích pro letošní jaro, toto je dávka anglických knih. České budou příležitostně následovat.]]></summary></entry><entry xml:lang="cs"><title type="html">MCP získává širokou podporu včetně OpenAI a Microsoftu</title><link href="https://www.marigold.cz/item/mcp-v-openai-microsoft/" rel="alternate" type="text/html" title="MCP získává širokou podporu včetně OpenAI a Microsoftu" /><published>2025-03-28T08:00:00+00:00</published><updated>2025-03-28T08:00:00+00:00</updated><id>https://www.marigold.cz/item/mcp-v-openai-microsoft</id><content type="html" xml:base="https://www.marigold.cz/item/mcp-v-openai-microsoft/"><![CDATA[<p>V posledních pár dnech se doslova strhla lavina novinek okolo MCP, neboli Model Context Protocolu. Nově ji bude podporovat také OpenAI, Microsoft a objevila se v celé řadě dalších služeb. Což je pro šíření tohoto standardu důležité. Takže si dejme sumář novinek! Jen pro jistotu upozorňuji, že článek je spíše pro lidi, kteří se chtějí hrabat maličko pod kapotou, MCP servery jsou rozšíření promptování, které má smysl dělat, když chcete napojovat nějaká svoje (či i cizí) data…</p>

<p>MCP jako standardizovaná vrstva pro komunikaci mezi jazykovými modely a nástroji třetích stran dostala v uplynulém týdnu masivní podporu napříč desítkami platforem. Díky ní je možné celou řadu služeb online propojit s AI modelem a nevyužívat jen “stará” data, která se do modelu dostala při učení a ani se do něj dostat nemusely. Můžete tak připojit i svoje či jiná uživatelská data. MCP sjednocuje komunikaci napříč různými aplikacemi a službami – ať už jde o cloudová úložiště, databáze, návrhové nástroje nebo interní firemní systémy.</p>

<p>Pojďme se pro instpiraci podívat na nejdůležitější napojení MCP z poslední doby.</p>

<h3 id="-openai-přijímá-standard-konkurence">✨ OpenAI přijímá standard konkurence</h3>
<p>Hned v úvodu je třeba zmínit, že největší zpráva přišla od OpenAI, která oznámila podporu MCP napříč svými produkty. Sam Altman osobně potvrdil, že lidé MCP milují a OpenAI chce rozšířit podporu tohoto protokolu. MCP je už nyní dostupný <a href="https://openai.github.io/openai-agents-python/mcp/">v SDK pro agent</a> a brzy přibude také podpora pro desktopovou aplikaci ChatGPT a responses API. To je významný krok, protože OpenAI přijímá standard původně vyvinutý konkurenční společností Anthropic. MCP se může stát univerzálním standardem pro interakce mezi AI a externími nástroji. Teď to chce ještě podporu v <a href="/deepseek/">DeepSeek</a> a Google Gemini, u číňanů bych viděl problém spíše v času, než že by nechtěli a Google snad nenapadne pro Gemini dělat něco vlastního…</p>

<h3 id="microsoft-také-přináší-mcp-do-svého-portfolia">Microsoft také přináší MCP do svého portfolia</h3>
<p>Shinya Yanagihara oznámil integraci MCP do Microsoft Copilot Studio, vývojářské platformy pro tvorbu vlastních Copilot chatbotů a asistentů. Tato implementace zjednodušuje integraci AI aplikací a agentů v prostředí Microsoft. Zároveň došlo k <a href="https://devblogs.microsoft.com/foundry/integrating-azure-ai-agents-mcp/">integraci MCP s Microsoft Azure AI Foundry</a>, cloudovou platformou pro vývoj AI řešení, což umožňuje AI modelům dynamicky přistupovat k nástrojům a informacím. Vysvětlení je tady prosté, Microsoft používá OpenAI a jeho podpora MCP se tedy promítla, ale samozřejmě to kluci mohli zablokovat, naštěstí to neudělali a to je pro Azure uživatele důležité.</p>

<h3 id="-zapier-ai-konečně-ovládá-8000-aplikací">🔌 Zapier: AI konečně ovládá 8000+ aplikací</h3>

<p>Jedním z nejvýraznějších oznámení týdne je integrace MCP do platformy Zapier, což je populární nástroj pro automatizaci workflow. Díky tomu získávají modely přístup ke 30 000+ akcím napříč více než osmi tisíci aplikacemi – bez nutnosti psát jakékoliv API volání. Detailní popis spolu s implementací a také u konkurenční služby Make.com jsme <a href="/item/zapier.mcp">si již přinesli</a>, takže další podívání vynecháme.</p>

<h3 id="-camel-ai-toolkit-pro-pokročilé-agentní-systémy">🐫 Camel-AI: Toolkit pro pokročilé agentní systémy</h3>

<p>Platforma <a href="https://www.camel-ai.org">Camel AI</a>, zaměřená na vývoj multiagentních architektur, uvedla MCP Toolkit, který umožňuje propojit agenty s externími nástroji bez potřeby budovat vlastní konektory. CAMEL tím zásadně rozšiřuje své možnosti a agenti se díky MCP stávají skutečně „hands-on“ – mohou manipulovat s reálnými systémy. Vývojáři CAMELu navíc ohlásili integraci s AgentOps, což je platforma pro orchestraci agentů v produkčním nasazení.</p>

<h3 id="-litellm-a-univerzální-proxy-pro-modely">🧠 LiteLLM a univerzální proxy pro modely</h3>

<p>Další zajímavou možnost skýtá podpora MCP v projektu <a href="https://www.litellm.ai">LiteLLM</a>, který funguje jako sjednocující rozhraní pro různé LLM (Claude, Mistral, OpenAI aj.). Nově může LiteLLM fungovat jako MCP bridge, tedy jakýsi překladač, který zpřístupňuje MCP nástroje všem podporovaným modelům.</p>

<p>To otevírá dveře k „agent-agnostickému“ vývoji – můžete nasadit nástroj jednou a použít ho v jakémkoliv prostředí, které LiteLLM podporuje.</p>

<h3 id="-box-telegram-figma-ios--a-další-drobnosti">📦 Box, Telegram, Figma, iOS – a další “drobnosti”</h3>

<p>V rámci MCP boomu jsme zaznamenali i následující novinky:</p>
<ul>
  <li>Box (resp komunita kolem něj) předvedl <a href="https://github.com/box-community/mcp-server-box">ukázku MCP serveru</a> s podporou modelu Claude od Anthropic – AI může přímo spravovat soubory v cloudovém úložišti.</li>
  <li><a href="https://github.com/sparfenyuk/mcp-telegram">Telegram MCP server</a> umožňuje, aby agenti AI posílali zprávy, čtou historii chatu nebo spravovali skupiny.</li>
  <li>Cursor x Figma: Projekt „[Talk to Figma(https://github.com/sonnylazuardi/cursor-talk-to-figma-mcp)]“ umožňuje AI upravovat návrhy ve Figmě čistě na základě přirozeného jazyka – bez kódu.</li>
  <li><a href="https://github.com/atom2ueki/mcp-server-ios-simulator">iOS Simulator MCP</a>: Vývojáři mohou nyní používat agenty ke spuštění a testování aplikací v iOS simulátoru. Skvělé pro QA scénáře.</li>
  <li><a href="https://neon.tech/guides/neon-mcp-server">Neon Database</a>: nativní podpora MCP a zároveň napojení na Azure AI Agent Service – vývoj komplexních agentních systémů s přímým přístupem k databázím je o krok blíž.</li>
</ul>

<h3 id="-haystack-cursor-firecrawl-fleek-brex">🛠 Haystack, Cursor, Firecrawl, Fleek, Brex…</h3>

<p>Tím výčet nekončí:</p>
<ul>
  <li>Haystack AI <a href="https://haystack.deepset.ai/integrations/mcp">implementuje MCP</a> pro rozšiřování pipeline o externí nástroje.</li>
  <li><a href="https://github.com/mendableai/firecrawl-mcp-server/">Firecrawl</a> ve spojení s MCP umožňuje AI klonovat weby jen na základě textového zadání.</li>
  <li>Fleek vytvořil <a href="https://github.com/fleek-platform/eliza-plugin-mcp">MCP plugin pro ElizaOS</a>, čímž umožňuje frameworkům AI přístup ke všem REST API bez potřeby psát vlastní kód.</li>
  <li>Brex získal vlastní <a href="https://github.com/crazyrabbitLTC/mcp-brex-server/blob/main/README.md">MCP server</a>, díky němuž může Claude nebo jiný model zpracovávat vaše účetní výdaje. Opatrně! (ale u nás se Brex asi moc nepoužívá)</li>
</ul>

<h3 id="-spiral-mcp-server-pro-spiral-computer">🌀 Spiral MCP Server pro Spiral Computer</h3>
<p>Jason Liu publikoval <a href="https://github.com/jxnl/spiral-mcp">Spiral MCP Server</a>, implementaci <a href="/model-context-protocol/">Model Context Protocol</a> v Pythonu pro Spiral Computer od společnosti Every (nástroj pro interaktivní práci s dokumenty a informacemi). Tento server poskytuje čtyři MCP nástroje (list_models, generate, atd.), zpracovává text, soubory a URL adresy s chytrou extrakcí článků a podporuje asynchronní operace.</p>

<h3 id="-rhinograsshopper-mcp-server">🦗 Rhino/Grasshopper MCP server</h3>
<p>Nikhil Bang sdílel ukázku svého MCP serveru pro Rhino/Grasshopper, populární platformu pro 3D modelování a parametrický design využívanou architekty a designéry. Server umožňuje propojit a ovládat Rhino a Grasshopper pomocí Claude LLM. Toto propojení otevírá nové možnosti pro automatizaci návrhových procesů v oblasti 3D modelování a generativního designu.</p>

<h3 id="️-kicad-mcp-server-ai-v-elektronickém-designu">🕹️ KiCad MCP Server: AI v elektronickém designu</h3>
<p><a href="https://github.com/lamaalrajih/kicad-mcp">KiCad MCP Server</a> je další specializovanou implementací, která umožňuje interakci s KiCad, open-source softwarem pro návrh elektronických schémat a plošných spojů. Uživatelé mohou pomocí přirozeného jazyka zobrazovat projekty, analyzovat návrhy PCB, spouštět kontroly návrhových pravidel a vizualizovat PCB layouty.</p>

<p>A vznikla také celá řada serverů, které nabízejí odkazy na nejrůznější MCP služby, vygooglujete je snadno, například <a href="https://mcpservers.org">Awesome MCP Servers</a> …</p>

<p>Tak šťastné experimentování.</p>]]></content><author><name>Patrick Zandl</name></author><category term="MCP" /><category term="vibe code" /><category term="AI" /><summary type="html"><![CDATA[V posledních pár dnech se doslova strhla lavina novinek okolo MCP, neboli Model Context Protocolu. Nově ji bude podporovat také OpenAI, Microsoft a objevila se v celé řadě dalších služeb. Což je pro šíření tohoto standardu důležité. Takže si dejme sumář novinek! Jen pro jistotu upozorňuji, že článek je spíše pro lidi, kteří se chtějí hrabat maličko pod kapotou, MCP servery jsou rozšíření promptování, které má smysl dělat, když chcete napojovat nějaká svoje (či i cizí) data…]]></summary></entry><entry xml:lang="cs"><title type="html">Zapier a Make MCP - Propojte AI asistenty s externími aplikacemi</title><link href="https://www.marigold.cz/item/zapier-mcp/" rel="alternate" type="text/html" title="Zapier a Make MCP - Propojte AI asistenty s externími aplikacemi" /><published>2025-03-27T08:00:00+00:00</published><updated>2025-03-27T08:00:00+00:00</updated><id>https://www.marigold.cz/item/zapier-mcp</id><content type="html" xml:base="https://www.marigold.cz/item/zapier-mcp/"><![CDATA[<p>Oblíbená automatizační služba <a href="https://zapier.com/">Zapier</a> a její (kdysi český!) konkurent <a href="https://www.make.com">Make.com</a> nedávno vydala podporu <a href="/ai/mcp/">MCP</a> (Model Communication Protocol), která umožňuje propojení AI asistentů s tisíci aplikací v ekosystému těchto služeb. Zapier i Make.com je oblíbený nástroj na “bezprogramátorské” propojování rozdilných aplikací, umožňuje vám například vaše nové tweety uložit do Google Docs a další podobné věci včetně těch velmi seriosních. Služba Zapier <a href="/ai/mcp/">MCP</a> je primárně zaměřena na Cursor - vývojářský nástroj s integrovanou AI - ale naznačuje širší možnosti propojení AI asistentů s externími službami. Make.com zaměření neudává.</p>

<p><a href="/ai/mcp/">MCP</a> server funguje jako prostředník mezi AI asistentem a aplikacemi třetích stran. Díky tomuto řešení mohou AI asistenti interagovat s externími službami bez nutnosti složité integrace API. Podle Zapier jde o “nejrychlejší způsob, jak propojit vašeho AI asistenta s tisíci aplikací”. A pokud nevíte, co je to <a href="/ai/mcp/">MCP</a> a k čemu a jak jej použít, <a href="https://www.marigold.cz/ai/mcp/">přečtěte si článek zde</a>.</p>

<h2 id="integrace-externích-služeb-do-ai-pomocí-mcp-serverů-zapier-a-makecom">Integrace externích služeb do AI pomocí MCP serverů: Zapier a Make.com</h2>

<h3 id="co-je-mcp-model-communication-protocol">Co je MCP (Model Communication Protocol)?</h3>

<p>Model Communication Protocol (MCP) představuje standardizovaný způsob komunikace mezi AI asistenty a externími službami. Tento protokol umožňuje AI agentům, jako jsou například nástroje založené na Cursor, vykonávat akce v reálném světě prostřednictvím externích aplikací a služeb. Díky MCP serverům mohou vývojáři výrazně rozšířit možnosti AI asistentů bez nutnosti psát složité API integrace pro každou službu zvlášť.</p>

<p>MCP ekosystém se v roce 2025 rychle rozvíjí, přičemž dva hlavní poskytovatelé - Zapier a Make.com - nabízejí své implementace MCP serverů, které spojují svět umělé inteligence s tisíci existujícími aplikacemi.</p>

<h2 id="zapier-mcp-jednoduchá-cesta-k-integraci">Zapier MCP: Jednoduchá cesta k integraci</h2>

<p>Zapier, známý automatizační nástroj, nedávno představil svůj MCP server, který umožňuje AI asistentům využívat rozsáhlý ekosystém Zapieru s minimálním nastavením. Toto řešení je vhodné pro rychlé nasazení a pro uživatele, kteří preferují služby typu SaaS bez nutnosti správy vlastní infrastruktury.</p>

<h4 id="instalace-a-nastavení-zapier-mcp">Instalace a nastavení Zapier MCP</h4>

<ol>
  <li><strong>Získání přístupového URL</strong>:
    <ul>
      <li>Navštivte <a href="https://zapier.com/mcp">https://zapier.com/mcp</a></li>
      <li>Klikněte na tlačítko “Get Started”</li>
      <li>Zkopírujte vygenerovaný unikátní URL, který slouží jako endpoint pro MCP službu</li>
    </ul>
  </li>
  <li><strong>Konfigurace v Cursor</strong>:
    <ul>
      <li>Otevřete nastavení v aplikaci Cursor: Settings -&gt; MCP -&gt; Add New MCP</li>
      <li>Vložte zkopírovaný URL do pole “url” v konfiguraci:
        <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
</span><span class="nl">"mcpServers"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="nl">"Zapier Actions MCP"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"your_url"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>Nastavení akcí</strong>:
    <ul>
      <li>Vraťte se na webovou stránku Zapier a klikněte na “Edit MCP Actions”</li>
      <li>Zde můžete vybrat a nastavit služby, které chcete zpřístupnit vašemu AI asistentovi</li>
    </ul>
  </li>
</ol>

<h4 id="možnosti-zapier-mcp">Možnosti Zapier MCP</h4>

<p>Zapier MCP umožňuje integrovat širokou škálu služeb, včetně:</p>
<ul>
  <li>E-mailových služeb (Gmail, Outlook)</li>
  <li>Generování obrázků</li>
  <li>Nástrojů pro projektový management (Trello, Asana)</li>
  <li>Kalendářových aplikací</li>
  <li>Notifikačních systémů</li>
</ul>

<p>Je však důležité poznamenat, že podle zpětné vazby uživatelů z března 2025 ne všechny integrace fungují bezproblémově. Zapier MCP je stále v beta fázi a některé služby mohou vykazovat problémy s kompatibilitou.</p>

<h2 id="makecom-mcp-server-open-source-alternativa">Make.com MCP Server: Open-source alternativa</h2>

<p>Make.com (dříve Integromat) nabízí alternativní implementaci MCP serveru, která je k dispozici jako open-source projekt. Toto řešení je vhodné pro vývojáře, kteří preferují větší kontrolu nad infrastrukturou a možnost vlastního hostování. Znamená to nicméně, že je nutno provozovat Node.js.</p>

<h4 id="instalace-a-nastavení-make-mcp-serveru">Instalace a nastavení Make MCP serveru</h4>

<ol>
  <li><strong>Prerekvizity</strong>:
    <ul>
      <li>Node.js</li>
      <li>MCP klient (například Claude Desktop App)</li>
      <li>Make API klíč s oprávněními <code class="language-plaintext highlighter-rouge">scenarios:read</code> a <code class="language-plaintext highlighter-rouge">scenarios:run</code></li>
    </ul>
  </li>
  <li><strong>Instalace serveru</strong>:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Klonování repositáře</span>
git clone https://github.com/integromat/make-mcp-server.git
   
<span class="c"># Instalace závislostí</span>
<span class="nb">cd </span>make-mcp-server
npm <span class="nb">install</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Konfigurace pro Claude Desktop</strong>:
    <ul>
      <li>Otevřete nebo vytvořte konfigurační soubor <code class="language-plaintext highlighter-rouge">claude_desktop_config.json</code></li>
      <li>Přidejte následující konfiguraci do sekce “mcpServers”:
        <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
</span><span class="nl">"mcpServers"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="nl">"make"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"command"</span><span class="p">:</span><span class="w"> </span><span class="s2">"npx"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"args"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"-y"</span><span class="p">,</span><span class="w"> </span><span class="s2">"@makehq/mcp-server"</span><span class="p">],</span><span class="w">
    </span><span class="nl">"env"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"MAKE_API_KEY"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;your-api-key&gt;"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"MAKE_ZONE"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;your-zone&gt;"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"MAKE_TEAM"</span><span class="p">:</span><span class="w"> </span><span class="s2">"&lt;your-team-id&gt;"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>Konfigurace prostředí</strong>:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">MAKE_API_KEY</code>: API klíč generovaný v profilu Make.com</li>
      <li><code class="language-plaintext highlighter-rouge">MAKE_ZONE</code>: Zóna, kde je vaše organizace hostována (např. eu2.make.com)</li>
      <li><code class="language-plaintext highlighter-rouge">MAKE_TEAM</code>: ID týmu, které lze najít v URL stránky týmu</li>
    </ul>
  </li>
</ol>

<h4 id="funkce-make-mcp-serveru">Funkce Make MCP serveru</h4>

<p>Make MCP server nabízí podobné možnosti jako Zapier, ale s několika významnými rozdíly:</p>

<ol>
  <li><strong>Vlastní hostování</strong>: Plná kontrola nad infrastrukturou a daty.</li>
  <li><strong>Propojení s On-Demand scénáři</strong>: Automatické rozpoznání a zpřístupnění všech scénářů s “On-Demand” plánováním.</li>
  <li><strong>Strukturovaný výstup</strong>: Vrací výstup scénářů jako strukturovaný JSON, což umožňuje AI asistentům správně interpretovat výsledky.</li>
  <li><strong>Bidirectional komunikace</strong>: Možnost vytvořit obousměrnou komunikaci mezi AI asistentem a existujícími automatizačními workflows.</li>
</ol>

<h3 id="praktické-využití-mcp-serverů-pro-vývojáře">Praktické využití MCP serverů pro vývojáře</h3>

<h4 id="1-rozšíření-možností-ai-nástrojů">1. Rozšíření možností AI nástrojů</h4>

<p>MCP servery umožňují AI nástrojům překročit hranice textové komunikace a provádět akce v reálném světě. Například:</p>

<ul>
  <li><strong>Datová analytika</strong>: AI může analyzovat data z externích zdrojů a vizualizovat je</li>
  <li><strong>Workflow automatizace</strong>: Spouštění komplexních workflow na základě konverzace s uživatelem</li>
  <li><strong>E-mailová komunikace</strong>: Odesílání e-mailů s přílohami přímo z AI rozhraní</li>
  <li><strong>Správa kalendáře</strong>: Plánování schůzek a událostí</li>
</ul>

<h4 id="2-vytváření-vlastních-integračních-scénářů">2. Vytváření vlastních integračních scénářů</h4>

<p>Pro vývojáře je nejzajímavější možnost vytváření vlastních integračních scénářů:</p>

<ol>
  <li>V Make.com vytvořte nový scénář s “On-Demand” plánováním</li>
  <li>Definujte vstupní parametry, které bude AI poskytovat</li>
  <li>Nakonfigurujte workflow s potřebnými akcemi</li>
  <li>Určete strukturu výstupních dat</li>
  <li>Po připojení MCP serveru bude tento scénář automaticky dostupný pro AI asistenty</li>
</ol>

<h4 id="3-řešení-limitací-a-výzev">3. Řešení limitací a výzev</h4>

<p>Při práci s MCP servery je dobré mít na paměti několik omezení:</p>

<ul>
  <li><strong>Latence</strong>: Volání externích služeb může způsobit zpoždění v interakci s AI</li>
  <li><strong>Rate limiting</strong>: Některé služby mohou omezovat počet požadavků</li>
  <li><strong>Zabezpečení</strong>: Zvažte bezpečnostní implikace propojení AI s externími službami</li>
  <li><strong>Zpracování chyb</strong>: Implementujte robustní mechanismy pro zpracování chyb</li>
</ul>

<h3 id="srovnání-zapier-mcp-a-makecom-mcp">Srovnání Zapier MCP a Make.com MCP</h3>

<table>
  <thead>
    <tr>
      <th>Funkce</th>
      <th>Zapier MCP</th>
      <th>Make.com MCP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Instalace</td>
      <td>Cloudová služba, bez instalace</td>
      <td>Self-hosted, vyžaduje Node.js</td>
    </tr>
    <tr>
      <td>Počet služeb</td>
      <td>Tisíce</td>
      <td>Stovky</td>
    </tr>
    <tr>
      <td>Přizpůsobitelnost</td>
      <td>Omezená</td>
      <td>Vysoká</td>
    </tr>
    <tr>
      <td>Open-source</td>
      <td>Ne</td>
      <td>Ano</td>
    </tr>
    <tr>
      <td>Zabezpečení</td>
      <td>Spravované Zapierem</td>
      <td>Ve vlastní režii</td>
    </tr>
    <tr>
      <td>Cena</td>
      <td>Podle plánu Zapier</td>
      <td>Podle plánu Make.com + náklady na hosting</td>
    </tr>
  </tbody>
</table>

<h2 id="význam-pro-vývojáře">Význam pro vývojáře</h2>

<p>Pro vývojáře pracující s AI asistenty představuje MCP potenciálně významný krok k rozšíření schopností těchto nástrojů. Místo omezení se na pouhé generování kódu by AI asistenti mohli v budoucnu přímo interagovat s vývojářskými nástroji, databázemi a cloudovými službami. Což je přesně to, co MCP umožňuje. A prostup do jiných ekosystému přes Zapier nebo Make.com by bylo velmi vítané, nemuseli byste čekat, až tyto služby uvolní (a pokud vůbec) svoje MCP!</p>

<p>Tato technologie by mohla výrazně zvýšit efektivitu vývojářů, kteří AI nástroje aktivně využívají, a posunout možnosti automatizace na novou úroveň. Zatím je však potřeba počítat s možnými omezeními a postupným vývojem této funkcionality.</p>

<p>Přiznám se, že službu jsem  zatím zkoušel jen v Cursor, ne například v <a href="https://www.marigold.cz/ai/claude-code/">Claude Code</a>, které také MCP podporuje. Výslovně není jiný software zmíněn, ale také by neměly být vážné potíže. Sám jsem se službou Zapier.com měl řadu potíží, komunikace s MCP haprovala a tak bych doporučil zatím počkat, než se vše usadí, pokud nejste vysloveně experimentátoři. Dobrý směr to ale je, protože nyní se začnou jistě rychle přidávat ostatní propojovatelé, jako Make.com…</p>]]></content><author><name>Patrick Zandl</name></author><category term="Zapier" /><category term="MCP" /><category term="vibe code" /><category term="AI" /><summary type="html"><![CDATA[Oblíbená automatizační služba Zapier a její (kdysi český!) konkurent Make.com nedávno vydala podporu MCP (Model Communication Protocol), která umožňuje propojení AI asistentů s tisíci aplikací v ekosystému těchto služeb. Zapier i Make.com je oblíbený nástroj na “bezprogramátorské” propojování rozdilných aplikací, umožňuje vám například vaše nové tweety uložit do Google Docs a další podobné věci včetně těch velmi seriosních. Služba Zapier MCP je primárně zaměřena na Cursor - vývojářský nástroj s integrovanou AI - ale naznačuje širší možnosti propojení AI asistentů s externími službami. Make.com zaměření neudává.]]></summary></entry><entry xml:lang="cs"><title type="html">Propojení Google Search Console s MCP - Komplexní průvodce</title><link href="https://www.marigold.cz/item/google-search-console-mcp-ai/" rel="alternate" type="text/html" title="Propojení Google Search Console s MCP - Komplexní průvodce" /><published>2025-03-27T00:00:00+00:00</published><updated>2025-03-27T00:00:00+00:00</updated><id>https://www.marigold.cz/item/google-search-console-mcp-ai</id><content type="html" xml:base="https://www.marigold.cz/item/google-search-console-mcp-ai/"><![CDATA[<p>Model Communication Protocol (<a href="/ai/mcp/">MCP</a>) představuje inovativní způsob, jak propojit AI asistenty s externími službami a nástroji. Google Search Console (GSC) je neocenitelný nástroj pro SEO analýzu a monitoring webových stránek. Propojení těchto dvou technologií otevírá vývojářům a SEO specialistům nové možnosti automatizace a efektivní práce s daty o výkonu webových stránek.</p>

<p>Tento průvodce vám ukáže, jak implementovat integraci mezi Google Search Console a <a href="/ai/mcp/">MCP</a> pomocí otevřeného řešení dostupného na <a href="https://github.com/AminForou/mcp-gsc">GitHubu od AminForou</a>. Díky této integraci budete moci:</p>

<ul>
  <li>Získávat data z Google Search Console přímo ve vašem AI asistentovi</li>
  <li>Analyzovat výkon webových stránek bez nutnosti přepínat mezi aplikacemi</li>
  <li>Automatizovat reporting a monitoring klíčových SEO metrik</li>
  <li>Implementovat datově řízené úpravy obsahu a SEO strategie</li>
</ul>

<h2 id="požadavky-pro-úspěšnou-integraci">Požadavky pro úspěšnou integraci</h2>

<p>Před začátkem integrace se ujistěte, že máte připraveno:</p>

<ol>
  <li><strong>Google Search Console účet</strong> s přístupem k webovým stránkám, které chcete monitorovat</li>
  <li><strong>Google Cloud projekt</strong> s povoleným Google Search Console API</li>
  <li><strong>MCP server</strong> (například Zapier MCP)</li>
  <li><strong>Cursor</strong> nebo jiného AI asistenta podporujícího MCP</li>
  <li><strong>Node.js</strong> (verze 14 nebo novější) pro spuštění GSC konektoru</li>
  <li><strong>Git</strong> pro klonování repozitáře</li>
</ol>

<h2 id="1-příprava-google-cloud-projektu-a-api-přístupu">1. Příprava Google Cloud projektu a API přístupu</h2>

<h3 id="vytvoření-a-konfigurace-projektu-v-google-cloud">Vytvoření a konfigurace projektu v Google Cloud</h3>

<ol>
  <li>Přejděte na <a href="https://console.cloud.google.com/">Google Cloud Console</a></li>
  <li>Vytvořte nový projekt nebo vyberte existující</li>
  <li>V navigačním menu vyberte “APIs &amp; Services” &gt; “Library”</li>
  <li>Vyhledejte “Google Search Console API” a aktivujte jej</li>
  <li>Přejděte do sekce “Credentials” a vytvořte nové OAuth 2.0 přihlašovací údaje:
    <ul>
      <li>Typ aplikace: Web application</li>
      <li>Název: MCP GSC Integration</li>
      <li>Autorizované přesměrovací URI: <code class="language-plaintext highlighter-rouge">http://localhost:3000/oauth2callback</code></li>
    </ul>
  </li>
  <li>Stáhněte vygenerovaný JSON soubor s přihlašovacími údaji</li>
</ol>

<h2 id="2-instalace-mcp-gsc-konektoru">2. Instalace MCP GSC konektoru</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Klonování repozitáře</span>
git clone https://github.com/AminForou/mcp-gsc.git
<span class="nb">cd </span>mcp-gsc

<span class="c"># Instalace závislostí</span>
npm <span class="nb">install</span>

<span class="c"># Kopírování konfiguračního souboru</span>
<span class="nb">cp </span>config.example.json config.json
</code></pre></div></div>

<h2 id="3-konfigurace-mcp-gsc-konektoru">3. Konfigurace MCP GSC konektoru</h2>

<p>Otevřete soubor <code class="language-plaintext highlighter-rouge">config.json</code> a upravte následující hodnoty:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"port"</span><span class="p">:</span><span class="w"> </span><span class="mi">3000</span><span class="p">,</span><span class="w">
  </span><span class="nl">"auth"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"clientId"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YOUR_CLIENT_ID"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"clientSecret"</span><span class="p">:</span><span class="w"> </span><span class="s2">"YOUR_CLIENT_SECRET"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"redirectUri"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://localhost:3000/oauth2callback"</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"sites"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"https://www.vasestranka.cz"</span><span class="w">
  </span><span class="p">],</span><span class="w">
  </span><span class="nl">"mcpEndpoint"</span><span class="p">:</span><span class="w"> </span><span class="s2">"https://actions.zapier.com/mcp/YOUR_MCP_ID/sse"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>Nahraďte:</p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">YOUR_CLIENT_ID</code> a <code class="language-plaintext highlighter-rouge">YOUR_CLIENT_SECRET</code> hodnotami z vašeho Google Cloud projektu</li>
  <li><code class="language-plaintext highlighter-rouge">https://www.vasestranka.cz</code> URL adresou vaší webové stránky registrované v Google Search Console</li>
  <li><code class="language-plaintext highlighter-rouge">YOUR_MCP_ID</code> vaším unikátním identifikátorem ze Zapier MCP</li>
</ul>

<h2 id="4-autorizace-google-search-console-api">4. Autorizace Google Search Console API</h2>

<p>Spusťte aplikaci a dokončete autorizační proces:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>npm start
</code></pre></div></div>

<ol>
  <li>Při prvním spuštění se v konzoli zobrazí autorizační URL</li>
  <li>Otevřete URL ve webovém prohlížeči</li>
  <li>Přihlaste se ke Google účtu a udělte přístup k Search Console API</li>
  <li>Po úspěšné autorizaci budete přesměrováni zpět na lokální server</li>
  <li>V konzoli by se mělo zobrazit potvrzení úspěšné autorizace</li>
  <li>Autorizační <a href="/ai/tokeny-versus-slova/">token</a> bude automaticky uložen pro budoucí použití</li>
</ol>

<h2 id="5-propojení-s-mcp-serverem-zapier">5. Propojení s MCP serverem (Zapier)</h2>

<h3 id="nastavení-v-zapier-mcp">Nastavení v Zapier MCP</h3>

<ol>
  <li>Přejděte na <a href="https://zapier.com/mcp">Zapier MCP stránku</a></li>
  <li>Klikněte na “Get Started” a zkopírujte svou unikátní MCP URL</li>
  <li>Klikněte na “Edit MCP Actions” a vytvořte novou akci</li>
  <li>Pojmenujte akci “Google Search Console Data”</li>
  <li>Nastavte parametry akce:
    <ul>
      <li><code class="language-plaintext highlighter-rouge">site</code>: URL webu (STRING)</li>
      <li><code class="language-plaintext highlighter-rouge">dateRange</code>: Rozsah dat (STRING: “last7days”, “last30days”, “last3months”)</li>
      <li><code class="language-plaintext highlighter-rouge">dimensions</code>: Dimenze dat (STRING: “query”, “page”, “country”, “device”)</li>
    </ul>
  </li>
</ol>

<h3 id="integrace-do-cursor-nebo-jiného-ai-asistenta">Integrace do Cursor (nebo jiného AI asistenta)</h3>

<ol>
  <li>Otevřete Cursor a přejděte do Settings &gt; MCP &gt; Add New MCP</li>
  <li>Vložte MCP URL ze Zapier pod název “Google Search Console MCP”</li>
  <li>Uložte nastavení</li>
</ol>

<h2 id="6-používání-gsc-dat-v-ai-asistentovi">6. Používání GSC dat v AI asistentovi</h2>

<p>Po úspěšné integraci můžete začít využívat data z Google Search Console přímo ve vašem AI asistentovi. Zde jsou příklady typických dotazů:</p>

<h3 id="základní-dotazy-na-výkon-webu">Základní dotazy na výkon webu</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ukaž mi výkon mého webu z Google Search Console za posledních 30 dní.
</code></pre></div></div>

<h3 id="analýza-konkrétních-klíčových-slov">Analýza konkrétních klíčových slov</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Jaké jsou moje nejúspěšnější klíčová slova podle počtu kliknutí za poslední týden?
</code></pre></div></div>

<h3 id="identifikace-problémových-stránek">Identifikace problémových stránek</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Které stránky mají vysoký počet zobrazení, ale nízkou míru prokliku?
</code></pre></div></div>

<h3 id="analýza-trendů">Analýza trendů</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Porovnej výkon mého webu v mobilních zařízeních oproti desktopům za poslední 3 měsíce.
</code></pre></div></div>

<h2 id="7-rozšířené-funkce">7. Rozšířené funkce</h2>

<p>MCP GSC konektor nabízí několik pokročilých funkcí, které můžete využít:</p>

<h3 id="vlastní-časové-rozsahy">Vlastní časové rozsahy</h3>

<p>Kromě předdefinovaných rozsahů můžete použít vlastní časové období:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"startDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2025-01-01"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"endDate"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2025-03-26"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h3 id="filtry-dat">Filtry dat</h3>

<p>Filtrování dat podle specifických kritérií:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"filters"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="p">{</span><span class="w">
      </span><span class="nl">"dimension"</span><span class="p">:</span><span class="w"> </span><span class="s2">"page"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"operator"</span><span class="p">:</span><span class="w"> </span><span class="s2">"contains"</span><span class="p">,</span><span class="w">
      </span><span class="nl">"expression"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/blog/"</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h3 id="agregace-a-transformace-dat">Agregace a transformace dat</h3>

<p>Konektor umožňuje základní agregaci a transformaci dat:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"aggregation"</span><span class="p">:</span><span class="w"> </span><span class="s2">"sum"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"groupBy"</span><span class="p">:</span><span class="w"> </span><span class="s2">"query"</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h2 id="8-řešení-problémů">8. Řešení problémů</h2>

<h3 id="problém-autorizační-chyba">Problém: Autorizační chyba</h3>

<p><strong>Řešení:</strong> Ujistěte se, že máte správně nakonfigurované přesměrovací URI v Google Cloud Console. Pokud problém přetrvává, smažte soubor <code class="language-plaintext highlighter-rouge">[token](/ai/tokeny-versus-slova/).json</code> a proveďte autorizaci znovu.</p>

<h3 id="problém-žádná-data-nejsou-dostupná">Problém: Žádná data nejsou dostupná</h3>

<p><strong>Řešení:</strong> Ověřte, že webová stránka je správně registrována v Google Search Console a že máte dostatečná oprávnění. Některé nově přidané stránky nemusí mít okamžitě dostupná data.</p>

<h3 id="problém-mcp-nepřijímá-požadavky">Problém: MCP nepřijímá požadavky</h3>

<p><strong>Řešení:</strong> Zkontrolujte, zda je MCP server spuštěn a dostupný. Ujistěte se, že adresa v <code class="language-plaintext highlighter-rouge">config.json</code> odpovídá vaší unikátní MCP URL.</p>

<h2 id="9-zabezpečení-a-best-practices">9. Zabezpečení a best practices</h2>

<p>Při práci s GSC API a MCP dbejte na následující bezpečnostní opatření:</p>

<ol>
  <li><strong>Nikdy nesdílejte</strong> své OAuth přihlašovací údaje nebo tokeny</li>
  <li>Pravidelně <strong>obnovujte přístupové tokeny</strong></li>
  <li>Používejte pouze <strong>nezbytná oprávnění</strong> pro vaši aplikaci</li>
  <li><strong>Omezujte rozsah požadavků</strong> na API, abyste předešli dosažení limitů</li>
  <li>Implementujte <strong>rate limiting</strong> pro ochranu před zahlcením API</li>
</ol>

<h2 id="závěr">Závěr</h2>

<p>Propojení Google Search Console s MCP otevírá nové možnosti pro automatizaci SEO analýz a datově řízených rozhodnutí. Díky této integraci získáváte přímý přístup k cenným datům o výkonu vašich webových stránek přímo ve vašem AI asistentovi, což vám umožňuje efektivněji pracovat a činit informovaná rozhodnutí.</p>

<p>Pro nejnovější aktualizace a vylepšení sledujte <a href="https://github.com/AminForou/mcp-gsc">oficiální GitHub repozitář</a> a zapojte se do komunity přispěvatelů, kteří pomáhají toto řešení dále rozvíjet.</p>

<hr />

<p><em>Poznámka: Tento průvodce vychází z dokumentace dostupné k březnu 2025. Některé funkce se mohou měnit s novými aktualizacemi Google Search Console API nebo MCP protokolu.</em></p>]]></content><author><name>Patrick Zandl</name></author><category term="MCP" /><category term="Google" /><summary type="html"><![CDATA[Model Communication Protocol (MCP) představuje inovativní způsob, jak propojit AI asistenty s externími službami a nástroji. Google Search Console (GSC) je neocenitelný nástroj pro SEO analýzu a monitoring webových stránek. Propojení těchto dvou technologií otevírá vývojářům a SEO specialistům nové možnosti automatizace a efektivní práce s daty o výkonu webových stránek.]]></summary></entry></feed>