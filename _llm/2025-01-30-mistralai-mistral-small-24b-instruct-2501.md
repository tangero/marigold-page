---
layout: llm_review
title: "Mistral: Mistral Small 3"
date: "2025-01-30 17:43:29"
model_id: mistralai/mistral-small-24b-instruct-2501
slug: mistralai-mistral-small-24b-instruct-2501
provider: Mistral
pricing:
  prompt_per_m: 0.03
  completion_per_m: 0.11
  blend_per_m: 0.05
context_length: 32,768
max_output: 32,768
input_modalities:
  - text
output_modalities:
  - text
focus:
  - RychlÃ¡ inference
  - ObecnÃ© AI Ãºlohy
strengths:
  - area: Rychlost
    description: VysokÃ¡ rychlost inference s TPS 116.2 a nÃ­zkou latencÃ­ 0.294s umoÅ¾Åˆuje rychlÃ© zpracovÃ¡nÃ­ poÅ¾adavkÅ¯.
  - area: Kontext
    description: Kontext 32,768 tokenÅ¯ je dostateÄnÃ½ pro vÄ›tÅ¡inu RAG Ãºloh a umoÅ¾Åˆuje zpracovÃ¡nÃ­ delÅ¡Ã­ch dokumentÅ¯.
weaknesses:
  - area: VÄ›da a matematika
    description: RelativnÄ› nÃ­zkÃ© skÃ³re v GPQA Diamond (38.1%) a AIME 2025 (6.3%) naznaÄuje slabÅ¡Ã­ schopnosti v nÃ¡roÄnÃ½ch vÄ›deckÃ½ch a matematickÃ½ch ÃºlohÃ¡ch.
  - area: ProgramovÃ¡nÃ­
    description: NÃ­zkÃ© skÃ³re v LiveCodeBench (14.1%) a scicode (15.6%) naznaÄuje omezenÃ© schopnosti v generovÃ¡nÃ­ a porozumÄ›nÃ­ kÃ³du.
competitors:
  - provider: GOOGLE
    model: google/gemini-2.5-flash-image
    model_id: google/gemini-2.5-flash-image
    price_comparison: 6x levnÄ›jÅ¡Ã­ vstup, 44x levnÄ›jÅ¡Ã­ vÃ½stup
    comparison: Gemini 2.5 Flash je vÃ½raznÄ› levnÄ›jÅ¡Ã­, ale mÅ¯Å¾e mÃ­t niÅ¾Å¡Ã­ kvalitu vÃ½stupu pro komplexnÃ­ Ãºlohy.
  - provider: X-AI
    model: x-ai/grok-4.1-fast
    model_id: x-ai/grok-4.1-fast
    price_comparison: 4x levnÄ›jÅ¡Ã­ vstup, 220x levnÄ›jÅ¡Ã­ vÃ½stup
    comparison: Grok-4.1-fast je mnohem levnÄ›jÅ¡Ã­ a mÃ¡ obrovskÃ½ kontext, ale mÅ¯Å¾e mÃ­t niÅ¾Å¡Ã­ kvalitu vÃ½stupu pro komplexnÃ­ Ãºlohy.
  - provider: DEEPSEEK
    model: deepseek/deepseek-v3.2-exp
    model_id: deepseek/deepseek-v3.2-exp
    price_comparison: 1.4x levnÄ›jÅ¡Ã­ vstup, 3.4x levnÄ›jÅ¡Ã­ vÃ½stup
    comparison: Deepseek v3.2-exp nabÃ­zÃ­ podobnÃ½ kontext a mÅ¯Å¾e bÃ½t levnÄ›jÅ¡Ã­, ale je tÅ™eba porovnat kvalitu vÃ½stupu.
  - provider: MISTRALAI
    model: mistralai/ministral-8b-2512
    model_id: mistralai/ministral-8b-2512
    price_comparison: 3x levnÄ›jÅ¡Ã­ vstup, 0.7x levnÄ›jÅ¡Ã­ vÃ½stup
    comparison: Ministral-8b-2512 je levnÄ›jÅ¡Ã­, mÃ¡ vÄ›tÅ¡Ã­ kontext, ale mÅ¯Å¾e mÃ­t niÅ¾Å¡Ã­ vÃ½kon v nÄ›kterÃ½ch ÃºlohÃ¡ch.
recommendation:
  target_users:
    - VÃ½vojÃ¡Å™i aplikacÃ­ s dÅ¯razem na rychlost
    - Firmy hledajÃ­cÃ­ efektivnÃ­ model pro obecnÃ© AI Ãºlohy
  use_cases:
    - Chatboti
    - RychlÃ¡ sumarizace textu
    - GenerovÃ¡nÃ­ obsahu s nÃ­zkou latencÃ­
  avoid_for:
    - NÃ¡roÄnÃ© vÄ›deckÃ© vÃ½poÄty
    - GenerovÃ¡nÃ­ komplexnÃ­ho kÃ³du
    - Ãšlohy vyÅ¾adujÃ­cÃ­ hlubokÃ© logickÃ© uvaÅ¾ovÃ¡nÃ­
verdict: Mistral Small 3 je vhodnÃ½ pro aplikace, kde je prioritou rychlost a efektivita. Je ideÃ¡lnÃ­ pro obecnÃ© AI Ãºlohy, ale mÃ©nÄ› vhodnÃ½ pro specializovanÃ© Ãºkoly vyÅ¾adujÃ­cÃ­ hlubokÃ© znalosti.
benchmark_categories:
  science:
    name: VÄ›da & Matematika
    icon: ğŸ§®
    score: 29.0
    tier: SlabÃ½
  coding:
    name: ProgramovÃ¡nÃ­
    icon: ğŸ’»
    score: 14.1
    tier: SlabÃ½
  intelligence:
    name: ObecnÃ¡ inteligence
    icon: ğŸ§ 
    score: 34.7
    tier: SlabÃ½
  speed:
    name: Rychlost
    icon: âš¡
    score: 64.3
    tier: DobrÃ½
overall_score: 31.4
overall_tier: SlabÃ½
radar:
  logic_code: 21.6
  agentic: 0
  languages: 0
  safety: 0
  speed: DobrÃ½
expert_verdict:
  killer_feature: VynikajÃ­cÃ­ pomÄ›r rychlosti a ceny
  hidden_risk: SlabÅ¡Ã­ vÃ½kon v ÃºlohÃ¡ch vyÅ¾adujÃ­cÃ­ch hlubokÃ© znalosti a logickÃ© uvaÅ¾ovÃ¡nÃ­
  recommended_use_case: RychlÃ© generovÃ¡nÃ­ textu a chatbot aplikace, kde je klÃ­ÄovÃ¡ nÃ­zkÃ¡ latence.
analyzer_model: google/gemini-2.0-flash-001
analyzed_at: "2025-12-09 11:02"
---

Mistral Small 3 je jazykovÃ½ model s 24 miliardami parametrÅ¯ optimalizovanÃ½ pro nÃ­zkou latenci pÅ™i bÄ›Å¾nÃ½ch ÃºlohÃ¡ch umÄ›lÃ© inteligence. Je vydÃ¡n pod licencÃ­ Apache 2.0 a nabÃ­zÃ­ jak pÅ™edtrÃ©novanou, tak i instrukÄnÄ› doladÄ›nou verzi, navrÅ¾enÃ© pro efektivnÃ­ lokÃ¡lnÃ­ nasazenÃ­.

Model dosahuje 81% pÅ™esnosti v benchmarku MMLU a vÃ½konem konkuruje vÄ›tÅ¡Ã­m modelÅ¯m, jako jsou Llama 3.3 70B a Qwen 32B, pÅ™iÄemÅ¾ na ekvivalentnÃ­m hardwaru pracuje tÅ™ikrÃ¡t rychleji. [PÅ™eÄtÄ›te si blogovÃ½ pÅ™Ã­spÄ›vek o modelu zde.](https://mistral.ai/news/mistral-small-3/)

## UnikÃ¡tnÃ­ charakteristiky

Mistral Small 3 je optimalizovÃ¡n pro nÃ­zkou latenci a rychlou inferenci. Dosahuje konkurenceschopnÃ½ch vÃ½sledkÅ¯ v MMLU benchmarku a nabÃ­zÃ­ velkÃ½ kontext 32,768 tokenÅ¯. Jeho rychlost je 3x vyÅ¡Å¡Ã­ neÅ¾ u vÄ›tÅ¡Ã­ch modelÅ¯ na stejnÃ©m hardwaru.

## SilnÃ© strÃ¡nky

### Rychlost
VysokÃ¡ rychlost inference s TPS 116.2 a nÃ­zkou latencÃ­ 0.294s umoÅ¾Åˆuje rychlÃ© zpracovÃ¡nÃ­ poÅ¾adavkÅ¯.

### Kontext
Kontext 32,768 tokenÅ¯ je dostateÄnÃ½ pro vÄ›tÅ¡inu RAG Ãºloh a umoÅ¾Åˆuje zpracovÃ¡nÃ­ delÅ¡Ã­ch dokumentÅ¯.

## SlabÃ© strÃ¡nky

### VÄ›da a matematika
RelativnÄ› nÃ­zkÃ© skÃ³re v GPQA Diamond (38.1%) a AIME 2025 (6.3%) naznaÄuje slabÅ¡Ã­ schopnosti v nÃ¡roÄnÃ½ch vÄ›deckÃ½ch a matematickÃ½ch ÃºlohÃ¡ch.

### ProgramovÃ¡nÃ­
NÃ­zkÃ© skÃ³re v LiveCodeBench (14.1%) a scicode (15.6%) naznaÄuje omezenÃ© schopnosti v generovÃ¡nÃ­ a porozumÄ›nÃ­ kÃ³du.
