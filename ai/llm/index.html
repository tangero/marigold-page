<!DOCTYPE html>
<html>
  <head>
    <title>Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu | Marigold.cz - S√≠tƒõ a Technologie</title>
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu" />
<meta name="author" content="Patrick Zandl" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fungov√°n√≠ velk√Ωch jazykov√Ωch model≈Ø (LLM) po zad√°n√≠ promptu je proces, kter√Ω kombinuje algoritmy, masivn√≠ neuronov√© s√≠tƒõ a komplexn√≠ zpracov√°n√≠ dat. Abyste mƒõli lep≈°√≠ p≈ôedstavu, jak modern√≠ AI na b√°zi LLM funguje, je dobr√© pod√≠vat se krok za krokem, jak tento proces prob√≠h√° od okam≈æiku, kdy u≈æivatel zad√° prompt, a≈æ po generov√°n√≠ fin√°ln√≠ odpovƒõdi." />
<meta property="og:description" content="Fungov√°n√≠ velk√Ωch jazykov√Ωch model≈Ø (LLM) po zad√°n√≠ promptu je proces, kter√Ω kombinuje algoritmy, masivn√≠ neuronov√© s√≠tƒõ a komplexn√≠ zpracov√°n√≠ dat. Abyste mƒõli lep≈°√≠ p≈ôedstavu, jak modern√≠ AI na b√°zi LLM funguje, je dobr√© pod√≠vat se krok za krokem, jak tento proces prob√≠h√° od okam≈æiku, kdy u≈æivatel zad√° prompt, a≈æ po generov√°n√≠ fin√°ln√≠ odpovƒõdi." />
<link rel="canonical" href="https://www.marigold.cz/ai/llm/" />
<meta property="og:url" content="https://www.marigold.cz/ai/llm/" />
<meta property="og:site_name" content="Marigold.cz" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-07-05T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Patrick Zandl"},"dateModified":"2024-07-05T00:00:00+00:00","datePublished":"2024-07-05T00:00:00+00:00","description":"Fungov√°n√≠ velk√Ωch jazykov√Ωch model≈Ø (LLM) po zad√°n√≠ promptu je proces, kter√Ω kombinuje algoritmy, masivn√≠ neuronov√© s√≠tƒõ a komplexn√≠ zpracov√°n√≠ dat. Abyste mƒõli lep≈°√≠ p≈ôedstavu, jak modern√≠ AI na b√°zi LLM funguje, je dobr√© pod√≠vat se krok za krokem, jak tento proces prob√≠h√° od okam≈æiku, kdy u≈æivatel zad√° prompt, a≈æ po generov√°n√≠ fin√°ln√≠ odpovƒõdi.","headline":"Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.marigold.cz/ai/llm/"},"url":"https://www.marigold.cz/ai/llm/"}</script>
<!-- End Jekyll SEO tag -->

        <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>
    <link href="https://fed.brid.gy/" rel="alternate" type="application/activity+json">

    
    <meta property="og:description" content="Fungov√°n√≠ velk√Ωch jazykov√Ωch model≈Ø (LLM) po zad√°n√≠ promptu je proces, kter√Ω kombinuje algoritmy, masivn√≠ neuronov√© s√≠tƒõ a komplexn√≠ zpracov√°n√≠ dat. Abyste mƒõli lep≈°√≠ p≈ôedstavu, jak modern√≠ AI na b√°zi LLM funguje, je dobr√© pod√≠vat se krok za krokem, jak tento proces prob√≠h√° od okam≈æiku, kdy u≈æivatel zad√° prompt, a≈æ po generov√°n√≠ fin√°ln√≠ odpovƒõdi.
" />
    
    <meta name="author" content="Marigold.cz" />

    
    <meta property="og:title" content="Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu" />
    <meta property="twitter:title" content="Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu" />
    

    
    <!-- else -->    
    <meta property="og:image" content="https://www.marigold.cz/images/patrick-avatar.jpg"/>
    <meta property="twitter:image" content="https://www.marigold.cz/images/patrick-avatar.jpg"/>
    

    <meta property="og:site_name" content="Marigold.cz | Technologie a Spoleƒçnost"/>

    


    <link rel="stylesheet" type="text/css" href="/assets/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Marigold.cz - Technologie a Svƒõt" href="/feed.xml" />
    <link rel="canonical" href="https://www.marigold.cz/ai/llm/" />

    <meta name="theme-color" content="#000000">

    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
    <link rel="manifest" href="/images/site.webmanifest">
    <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="/images/favicon.ico">
    <meta name="msapplication-TileColor" content="#2d89ef">
    <meta name="msapplication-config" content="/images/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">
    <script type="text/javascript">
      window.heapReadyCb=window.heapReadyCb||[],window.heap=window.heap||[],heap.load=function(e,t){window.heap.envId=e,window.heap.clientConfig=t=t||{},window.heap.clientConfig.shouldFetchServerConfig=!1;var a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src="https://cdn.us.heap-api.com/config/"+e+"/heap_config.js";var r=document.getElementsByTagName("script")[0];r.parentNode.insertBefore(a,r);var n=["init","startTracking","stopTracking","track","resetIdentity","identify","getSessionId","getUserId","getIdentity","addUserProperties","addEventProperties","removeEventProperty","clearEventProperties","addAccountProperties","addAdapter","addTransformer","addTransformerFn","onReady","addPageviewProperties","removePageviewProperty","clearPageviewProperties","trackPageview"],i=function(e){return function(){var t=Array.prototype.slice.call(arguments,0);window.heapReadyCb.push({name:e,fn:function(){heap[e]&&heap[e].apply(heap,t)}})}};for(var p=0;p<n.length;p++)heap[n[p]]=i(n[p])};
      heap.load("2219710997");
  </script>
  </head>

  <body>
    <div id="bar"></div>
    <div class="wrapper-container">
      <div class="wrapper-masthead">
        <div class="container">
          <header class="masthead clearfix">
            <a href="/" class="site-avatar"><img src="/images/patrick-avatar.jpg" alt="" /></a>

            <div class="site-info">
              <h1 class="site-name"><a href="/">Marigold.cz</a></h1>
              <p class="site-description">Technologie a Svƒõt</p>

            </div>

            <nav>
              <a href="/search">üîç</a> | <a href="https://www.prolnuto.cz/">üßë‚Äçüíª Kurzy AI</a> | <a href="https://www.vibecoding.cz/">üñ•Ô∏è Vibecoding</a> | <a href="/mobilnisite">üóº 4G/5G</a> | <a href="/ai">ü§ñ AI</a> | <a href="/obrazy">üñºÔ∏è Obrazy</a>
            </nav>
          </header>
        </div>
      </div>

      <div class="wrapper-main">
        <div id="main" role="main" class="container">
          <!-- start Mermaid run code --> 
<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.0.2/+esm'
  mermaid.initialize({startOnLoad:true,theme:'neutral'})
  await mermaid.run({querySelector:'code.language-mermaid'})
</script>
<!-- end fMermaid run code --> 

<a href="https://www.arthousemelichar.cz/"><img src="https://www.marigold.cz/assets/arthousemelichar.jpg" alt="Art House Melichar Brand√Ωs nad Labem - popup galerie pro toto l√©to" style="width:100%;display:block;margin:0 auto;" /></a>

<!-- m√≠sto p≈Øvodn√≠ho feedwind code -->


<style>
  code.language-mermaid {
    display: flex;
    justify-content: center;
  }
  pre:has(code.language-mermaid), code.language-mermaid {
    background-color: transparent;
  }
  .edgeLabel {
    font-size: 92%;
    opacity: .95;
    color: #111;
    padding: 0 3px;
  }
  .node rect {
    stroke: #214f78 !important;
  }
  .nodeLabel {
    color: #214f78 !important;
  }

  /* Odstranƒõn√≠ r√°meƒçk≈Ø kolem textu */
  .post.detailed {
    padding: 0;
    margin: 0;
    border: none;
    box-shadow: none;
  }

  .post.detailed .entry {
    padding: 0;
    margin: 0;
    border: none;
    box-shadow: none;
  }

  /* Odstranƒõn√≠ okraj≈Ø kolem sekce ƒål√°nky a novinky */
  .posts {
    margin: 0 !important;
    padding: 0 !important;
    border: none !important;
    box-shadow: none !important;
    background: none !important;
  }

  .posts .post {
    margin: 0 !important;
    padding: 0 !important;
    border: none !important;
    box-shadow: none !important;
    background: none !important;
  }

  .posts .post .entry {
    margin: 0 !important;
    padding: 0 !important;
    border: none !important;
    box-shadow: none !important;
    background: none !important;
  }

  /* CSS pro tlaƒç√≠tko kop√≠rovat */
  .code-block-container {
    position: relative;
    margin: 20px 0;
  }
  .copy-button {
    position: absolute;
    top: 10px;
    right: 10px;
    padding: 8px 15px;
    background-color: #4CAF50;
    color: white;
    border: none;
    border-radius: 5px;
    cursor: pointer;
    font-size: 14px;
    z-index: 1;
  }
  .copy-button:hover {
    background-color: #45a049;
  }
  .copy-button:active {
    background-color: #3e8e41;
  }
  .copy-button.copied {
    background-color: #666;
  }
  .code-block-container pre {
    position: relative;
    padding-top: 40px;
  }
  .toast {
    position: fixed;
    bottom: 20px;
    left: 50%;
    transform: translateX(-50%);
    background-color: #333;
    color: white;
    padding: 12px 24px;
    border-radius: 5px;
    display: none;
    z-index: 1000;
  }
</style>
<!-- end feedwind code -->

<article class="post detailed">
  <h1>Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu</h1>

  

  
  <!-- Zde se zobraz√≠ obsah pro v≈°echny ostatn√≠ kolekce ne≈æ 'obrazy' -->
  <div>
    <p class="author_title">Patrick Zandl  ¬∑

5.
ƒçervenec
  
2024 
    
    </p>

    
    <div class="post-tags">
      
      
    </div>
   
  </div>

  


 



  <div class="entry">
    <p>Fungov√°n√≠ velk√Ωch jazykov√Ωch model≈Ø (LLM) po zad√°n√≠ promptu je proces, kter√Ω kombinuje algoritmy, masivn√≠ <a href="/ai/neuronove-site/">neuronov√© s√≠tƒõ</a> a komplexn√≠ zpracov√°n√≠ dat. Abyste mƒõli lep≈°√≠ p≈ôedstavu, jak modern√≠ AI na b√°zi LLM funguje, je dobr√© pod√≠vat se krok za krokem, jak tento proces prob√≠h√° od okam≈æiku, kdy u≈æivatel zad√° prompt, a≈æ po generov√°n√≠ fin√°ln√≠ odpovƒõdi.</p>

<h3 id="1-zad√°n√≠-promptu">1. Zad√°n√≠ promptu</h3>
<p>V≈°e zaƒç√≠n√°, kdy≈æ u≈æivatel <a href="/ai/prompt/">zad√° textov√Ω prompt</a> do rozhran√≠ LLM. Tento prompt m≈Ø≈æe b√Ωt ot√°zka, instrukce, nebo jak√Ωkoli jin√Ω textov√Ω vstup. Nap≈ô√≠klad: ‚ÄúVysvƒõtli mi, jak funguje fotosynt√©za u rostlin.‚Äù</p>

<h3 id="2-tokenizace">2. Tokenizace</h3>
<p>Jakmile je prompt zad√°n, prvn√≠m krokem je tokenizace. Tokenizace rozdƒõluje text na men≈°√≠ jednotky zvan√© <a href="/ai/tokeny-versus-slova/">tokeny</a>. Tyto <a href="/ai/tokeny-versus-slova/">tokeny</a> mohou b√Ωt slova, ƒç√°sti slov, nebo dokonce jednotliv√© znaky, v z√°vislosti na pou≈æit√©m tokenizaƒçn√≠m algoritmu. Ve <a href="/ai/tokenizace-textu/">zvl√°≈°tn√≠m ƒçl√°nku vysvƒõtluji</a>, jak√Ω je rozd√≠l mezi slovy a <a href="/ai/tokeny-versus-slova/">tokeny</a> a proƒç se mechanismus <a href="/ai/tokeny-versus-slova/">token≈Ø</a> pou≈æ√≠v√°. 
Pro n√°≈° p≈ô√≠klad by tokenizace mohla vypadat takto:
[‚ÄúVysvƒõtli‚Äù, ‚Äúmi‚Äù, ‚Äú,‚Äù, ‚Äújak‚Äù, ‚Äúfunguje‚Äù, ‚Äúfoto‚Äù, ‚Äúsynt√©za‚Äù, ‚Äúu‚Äù, ‚Äúrostlin‚Äù, ‚Äú.‚Äù]</p>

<p>Modern√≠ LLM ƒçasto pou≈æ√≠vaj√≠ metody tokenizace jako <em>Byte-Pair Encoding (BPE)</em> nebo <em>SentencePiece</em>, kter√© umo≈æ≈àuj√≠ efektivnƒõj≈°√≠ zpracov√°n√≠ m√©nƒõ ƒçast√Ωch slov a r≈Øzn√Ωch jazyk≈Ø. V≈°imnƒõte si, ≈æe slovo ‚Äúfotosynt√©za‚Äù bylo rozdƒõleno na dva <a href="/ai/tokeny-versus-slova/">tokeny</a>.</p>

<h3 id="3-numerick√°-reprezentace">3. Numerick√° reprezentace</h3>
<p>Po tokenizaci je ka≈æd√Ω <a href="/ai/tokeny-versus-slova/">token</a> p≈ôeveden na numerickou reprezentaci pomoc√≠ velk√©ho vyhled√°vac√≠ho slovn√≠ku, kde ka≈æd√Ω <a href="/ai/tokeny-versus-slova/">token</a> m√° p≈ôi≈ôazen√© unik√°tn√≠ ƒç√≠slo.</p>

<h3 id="4-kontextov√©-okno">4. Kontextov√© okno</h3>
<p>LLM maj√≠ omezen√Ω poƒçet <a href="/ai/tokeny-versus-slova/">token≈Ø</a>, kter√© mohou zpracovat najednou, tzv. <em>kontextov√© okno</em>. Toto okno m≈Ø≈æe b√Ωt nap≈ô√≠klad 2048 nebo 4096 token≈Ø, u nejmodernƒõj≈°√≠ch LLM i statis√≠ce token≈Ø. V≈°e v tomto oknƒõ slou≈æ√≠ jako kontext pro generov√°n√≠ odpovƒõdi, tedy informace, kter√° m≈Ø≈æe b√Ωt relevantn√≠ a pou≈æita k up≈ôesnƒõn√≠ generovan√© odpovƒõdi.</p>

<h3 id="5-zpracov√°n√≠-neuronovou-s√≠t√≠">5. Zpracov√°n√≠ neuronovou s√≠t√≠</h3>
<p>Nyn√≠ p≈ôich√°z√≠ na ≈ôadu j√°dro LLM - <em>masivn√≠ <a href="/ai/neuronove-site/">neuronov√° s√≠≈•</a></em>, obvykle zalo≈æen√° na architektu≈ôe <em><a href="/ai/transformatory/">Transform√°tor≈Ø</a></em>. Tato s√≠≈• se skl√°d√° z mnoha vrstev a m≈Ø≈æe m√≠t miliardy parametr≈Ø.</p>

<p><strong>a) Token embeddings vrstva</strong>
Prvn√≠ vrstva po samotn√© tokenizaci p≈ôev√°d√≠ numerick√© reprezentace token≈Ø na vektory s plovouc√≠ desetinnou ƒç√°rkou, kter√© zachycuj√≠ s√©mantick√© vlastnosti token≈Ø.</p>

<p>Po tokenizaci je ka≈æd√©mu tokenu p≈ôi≈ôazeno jeho ID ze slovn√≠ku (nap≈ô. token ‚Äúkoƒçka‚Äù m√° ID 587). Tato ID jsou pak p≈ôevedena na vektory s plovouc√≠ desetinnou ƒç√°rkou - tzv. embeddings. Je to v podstatƒõ vyhled√°vac√≠ tabulka (lookup table), kde ka≈æd√©mu ID je p≈ôi≈ôazen vektor ƒç√≠sel (nap≈ô√≠klad vektor o d√©lce 768 nebo 1024 dimenz√≠). Tyto vektory jsou nastaveny bƒõhem tr√©nov√°n√≠ tak, aby tokeny s podobn√Ωm v√Ωznamem mƒõly podobn√© vektorov√© reprezentace - zachycuj√≠ tedy s√©mantick√© vlastnosti token≈Ø.
P≈ô√≠klad:</p>

<ul>
  <li>Slovo ‚Äúkoƒçka‚Äù (ID 587) ‚Üí [0.2, -0.5, 0.1, ‚Ä¶, 0.3]</li>
  <li>Slovo ‚Äúkocour‚Äù (ID 892) ‚Üí [0.19, -0.48, 0.15, ‚Ä¶, 0.28]
(podobn√Ω vektor, proto≈æe v√Ωznamy jsou podobn√©)</li>
  <li>Slovo ‚Äúauto‚Äù (ID 245) ‚Üí [-0.8, 0.2, -0.4, ‚Ä¶, -0.1]
(velmi odli≈°n√Ω vektor, proto≈æe v√Ωznam je odli≈°n√Ω)</li>
</ul>

<p><strong>b) Pozornostn√≠ mechanismus (Self-attention)</strong>
Kl√≠ƒçovou souƒç√°st√≠ <a href="/ai/transformatory">architektury Transform√°tor≈Ø</a> je mechanismus pozornosti (attention mechanism). Mechanismus pozornosti umo≈æ≈àuje rozhodnout se, jak√° ƒç√°st z jinak ‚Äúploch√©ho‚Äù textov√©ho vstupu je v√≠ce ƒçi m√©nƒõ hodn√° pozornosti. Pro ka≈æd√Ω token ve vstupn√≠ sekvenci tento mechanismus vypoƒç√≠t√°v√°:</p>

<ol>
  <li>Query (Q) - dotaz: co token ‚Äúhled√°‚Äù</li>
  <li>Key (K) - kl√≠ƒç: ƒç√≠m token ‚Äúodpov√≠d√°‚Äù na dotazy</li>
  <li>Value (V) - hodnota: jakou informaci token ‚Äúposkytuje‚Äù</li>
</ol>

<p>Funguje to n√°sledovnƒõ:</p>
<ul>
  <li>Pro ka≈æd√Ω token se jeho Query porovn√° s Keys v≈°ech ostatn√≠ch token≈Ø (vƒçetnƒõ sebe sama)</li>
  <li>Toto porovn√°n√≠ vytvo≈ô√≠ ‚Äúattention scores‚Äù - ƒç√≠sla urƒçuj√≠c√≠, jak moc by mƒõl dan√Ω token vƒõnovat pozornost ostatn√≠m token≈Øm</li>
  <li>Tyto sk√≥re se normalizuj√≠ pomoc√≠ softmax funkce na pravdƒõpodobnostn√≠ distribuci</li>
  <li>Nakonec se vypoƒçten√© attention scores pou≈æij√≠ jako v√°hy pro Values p≈ô√≠slu≈°n√Ωch token≈Ø</li>
</ul>

<p>P≈ô√≠klad:
Vƒõta: <em>‚ÄúKoƒçka, kter√° hon√≠ my≈°, je ƒçern√°.‚Äù</em></p>
<ul>
  <li>Kdy≈æ model zpracov√°v√° slovo ‚Äúje‚Äù, mechanismus pozornosti mu umo≈æn√≠ zamƒõ≈ôit se silnƒõ na slovo ‚Äúkoƒçka‚Äù, proto≈æe to je podmƒõt vƒõty</li>
  <li>P≈ôi zpracov√°n√≠ slova ‚Äúƒçern√°‚Äù se model m≈Ø≈æe znovu zamƒõ≈ôit na ‚Äúkoƒçka‚Äù, proto≈æe to je p≈ôedmƒõt, kter√Ω je popisov√°n. 
T√≠m poƒç√≠taƒç z jinak ploch√©ho sdƒõlen√≠ m≈Ø≈æe pochopit, ≈æe to, co hon√≠ my≈°, je koƒçka a tato koƒçka je ƒçern√°.</li>
</ul>

<p>Modern√≠ LLM typicky pou≈æ√≠vaj√≠:</p>
<ul>
  <li>Multi-head attention: nƒõkolik pozornostn√≠ch mechanism≈Ø bƒõ≈æ√≠c√≠ch paralelnƒõ</li>
  <li>Masked attention v p≈ô√≠padƒõ generativn√≠ch model≈Ø: p≈ôi generov√°n√≠ m≈Ø≈æe model vƒõnovat pozornost pouze p≈ôedchoz√≠m token≈Øm, ne budouc√≠m</li>
</ul>

<p>Tento mechanismus je kl√≠ƒçov√Ω pro schopnost LLM porozumƒõt kontextu a dlouhodob√Ωm z√°vislostem v textu.</p>

<p><strong>c) Feed-forward vrstvy (FFN)</strong>
Po tom, co attention mechanismus umo≈ænil obohatil tokeny o pot≈ôebn√Ω kontext, p≈ôich√°z√≠ feed-forward s√≠≈• (FFN). Ta p≈ôedstavuje mo≈ænost, jak pro ka≈æd√Ω token zpracovat a tedy ‚Äúpromyslet‚Äù v≈°echny informace, kter√© nyn√≠ dost√°v√°.</p>

<p>P≈ôedstavte si to jako t≈ô√≠f√°zov√Ω proces:</p>

<ol>
  <li>Roz≈°√≠≈ôen√≠ informac√≠
    <ul>
      <li>Token nejprve ‚Äúrozbal√≠‚Äù v≈°echny svoje informace do vƒõt≈°√≠ho prostoru</li>
      <li>Je to jako kdy≈æ si rozlo≈æ√≠te puzzle na vƒõt≈°√≠ st≈Øl a obr√°t√≠te obr√°zkem nahoru, abyste l√©pe vidƒõli v≈°echny d√≠lky</li>
    </ul>
  </li>
  <li>Zpracov√°n√≠ informac√≠
    <ul>
      <li>Aplikuje se aktivaƒçn√≠ funkce (GELU/ReLU), kter√° nƒõkter√© informace zv√Ωrazn√≠ a jin√© potlaƒç√≠</li>
      <li>Je to jako kdy≈æ z rozlo≈æen√Ωch d√≠lk≈Ø puzzle vyberete ty, kter√© jsou pro v√°s v danou chv√≠li d≈Øle≈æit√© - t≈ôeba ty okrajov√©</li>
    </ul>
  </li>
  <li>Shrnut√≠
    <ul>
      <li>Nakonec se v≈°echny zpracovan√© informace opƒõt ‚Äúsbal√≠‚Äù do p≈Øvodn√≠ velikosti</li>
      <li>Jako kdy≈æ poskl√°d√°te vybran√© d√≠lky puzzle zpƒõt do kompaktn√≠ho celku</li>
    </ul>
  </li>
</ol>

<p>D≈Øle≈æit√© je, ≈æe ka≈æd√Ω token t√≠mto procesem proch√°z√≠ samostatnƒõ - je to jeho ‚Äúosobn√≠ ƒças na p≈ôem√Ω≈°len√≠‚Äù o v≈°em, co se dozvƒõdƒõl z attention mechanismu.</p>

<p>Proto je tento proces velmi n√°roƒçn√Ω na v√Ωpoƒçetn√≠ s√≠lu a ƒças a dƒõl√° to problematick√Ωm zpracov√°n√≠ rozs√°hl√Ωch kontext≈Ø, tedy rozs√°hl√Ωch vstup≈Ø, nap≈ô√≠klad rozs√°hl√Ωch text≈Ø. Ka≈æd√Ω jednotliv√Ω token mus√≠ b√Ωt propoƒç√≠t√°n s ohledem na v≈°echny ostatn√≠ tokeny.</p>

<p>V√Ωsledek se pak p≈ôiƒçte k p≈Øvodn√≠m informac√≠m tokenu (jako kdy≈æ si k p≈Øvodn√≠m pozn√°mk√°m p≈ôid√°te nov√© post≈ôehy) a cel√© se to ‚Äúuƒçe≈°e‚Äù pomoc√≠ normalizace, aby dal≈°√≠ vrstvy mohly efektivnƒõ pracovat s aktualizovan√Ωmi informacemi.</p>

<h3 id="6-generov√°n√≠-v√Ωstupu">6. Generov√°n√≠ v√Ωstupu</h3>
<p>Po zpracov√°n√≠ vstupn√≠ho promptu neuronovou s√≠t√≠ zaƒç√≠n√° proces generov√°n√≠ odpovƒõdi. Tento proces je iterativn√≠ a prob√≠h√° token po tokenu.</p>

<p><strong>a) Predikce dal≈°√≠ho tokenu</strong>
Model pou≈æ√≠v√° sv√© vnit≈ôn√≠ reprezentace a nauƒçen√© vztahy k predikci pravdƒõpodobnostn√≠ho rozdƒõlen√≠ nad v≈°emi mo≈æn√Ωmi n√°sleduj√≠c√≠mi tokeny.  Nap≈ô√≠klad:</p>

<p>‚ÄúPetr ≈°el do obchodu koupit‚Ä¶‚Äù</p>

<p>V tomto momentƒõ model:</p>
<ol>
  <li>Vezme v≈°echna mo≈æn√° slova ze sv√©ho slovn√≠ku (t≈ôeba 50 000 mo≈ænost√≠)</li>
  <li>Ka≈æd√©mu slovu p≈ôi≈ôad√≠ pravdƒõpodobnost, ≈æe by mƒõlo b√Ωt dal≈°√≠ v po≈ôad√≠</li>
  <li>Nap≈ô√≠klad:
    <ul>
      <li>‚Äúchleba‚Äù - 35% pravdƒõpodobnost</li>
      <li>‚Äúml√©ko‚Äù - 25% pravdƒõpodobnost</li>
      <li>‚Äújablka‚Äù - 15% pravdƒõpodobnost</li>
      <li>‚Äúauto‚Äù - 0.001% pravdƒõpodobnost</li>
      <li>(a tak d√°le pro v≈°echna slova)</li>
    </ul>
  </li>
</ol>

<p>Model p≈ôi≈ôazuje vy≈°≈°√≠ pravdƒõpodobnosti slov≈Øm, kter√° d√°vaj√≠ v dan√©m kontextu nejvƒõt≈°√≠ smysl. Slova, kter√° ned√°vaj√≠ smysl (jako ‚Äúauto‚Äù v na≈°em p≈ô√≠kladu n√°kupu), dostanou velmi n√≠zkou pravdƒõpodobnost.</p>

<p>Tento proces se opakuje pro ka≈æd√© dal≈°√≠ slovo, p≈ôiƒçem≈æ ka≈æd√© novƒõ p≈ôidan√© slovo ovliv≈àuje pravdƒõpodobnosti slov n√°sleduj√≠c√≠ch.</p>

<p><strong>b) V√Ωbƒõr tokenu</strong>
Z tohoto pravdƒõpodobnostn√≠ho rozdƒõlen√≠ je vybr√°n dal≈°√≠ token. LLM obvykle pou≈æ√≠vaj√≠ techniku zvanou sampling, kdy vyb√≠raj√≠ z nƒõkolika nejpravdƒõpodobnƒõj≈°√≠ch mo≈ænost√≠. To do jist√© m√≠ry p≈ôid√°v√° elementy kreativity a variability do odpovƒõd√≠, tzn. odpovƒõdi na stejn√© prompty jsou r≈Øzn√©. Je v√Ωznamnou souƒç√°st√≠ ladƒõn√≠ modelu nastaven√≠ samplingu, tedy rozpƒõt√≠ pravdƒõpodobnost√≠, z nich≈æ model vyb√≠r√°. Tedy to, jestli v na≈°em p≈ô√≠padƒõ m≈Ø≈æe vyb√≠rat ze slov chleba, ml√©ko, ale i je≈°tƒõ jablko, nebo u≈æ je jablko p≈ô√≠li≈° m√°lo pravdƒõpodobn√©. Toto nastaven√≠ vytv√°≈ô√≠ rozpƒõt√≠ mezi nudn√Ωmi a spr√°vn√Ωmi odpovƒõƒèmi a inspirativn√≠mi nebo ≈°√≠len√Ωmi na druh√©m p√≥lu‚Ä¶</p>

<p><strong>c) Zpƒõtn√° vazba</strong>
Vybran√Ω token je p≈ôid√°n k dosud vygenerovan√©mu v√Ωstupu a tak√© je pou≈æit jako vstup pro dal≈°√≠ krok generov√°n√≠. Tento proces se opakuje, dokud nen√≠ vygenerov√°n speci√°ln√≠ token oznaƒçuj√≠c√≠ konec sekvence, nebo dokud nen√≠ dosa≈æeno maxim√°ln√≠ d√©lky v√Ωstupu.</p>

<h3 id="7-post-processing">7. Post-processing</h3>
<p>Po vygenerov√°n√≠ surov√©ho v√Ωstupu n√°sleduje detokenizace (p≈ôevod token≈Ø zpƒõt na ƒçiteln√Ω text), p≈ô√≠padn√° filtrace obsahu a form√°tov√°n√≠.</p>

<h3 id="8-zobrazen√≠-odpovƒõdi">8. Zobrazen√≠ odpovƒõdi</h3>
<p>Koneƒçnƒõ, zpracovan√° a form√°tovan√° odpovƒõƒè je zobrazena u≈æivateli.</p>

<h2 id="kl√≠ƒçov√©-koncepty-a-pokroƒçil√©-techniky">Kl√≠ƒçov√© koncepty a pokroƒçil√© techniky</h2>

<p>Nyn√≠, kdy≈æ jsme pro≈°li z√°kladn√≠ proces, pojƒème se pod√≠vat na nƒõkter√© kl√≠ƒçov√© koncepty a pokroƒçil√© techniky, kter√© jsou d≈Øle≈æit√© pro pochopen√≠ fungov√°n√≠ modern√≠ch LLM.</p>

<h3 id="1-princip-predikce-n√°sleduj√≠c√≠ho-slova">1. Princip predikce n√°sleduj√≠c√≠ho slova</h3>

<p>Je d≈Øle≈æit√© pochopit, ≈æe j√°drem fungov√°n√≠ LLM je p≈ôedpov√≠d√°n√≠ n√°sleduj√≠c√≠ho slova (nebo tokenu) na z√°kladƒõ p≈ôedchoz√≠ho kontextu. Tento jednoduch√Ω princip je z√°kladem pro v≈°echny sofistikovan√© schopnosti, kter√© LLM vykazuj√≠.</p>

<h3 id="2-f√°ze-tr√©nov√°n√≠">2. F√°ze tr√©nov√°n√≠</h3>

<p>P≈ôed samotn√Ωm pou≈æit√≠m proch√°z√≠ LLM t≈ôemi hlavn√≠mi f√°zemi tr√©nov√°n√≠:</p>

<p>a) Pre-training: Model se uƒç√≠ p≈ôedpov√≠dat dal≈°√≠ slovo na obrovsk√©m mno≈æstv√≠ textov√Ωch dat, z√≠sk√°vaj√≠c tak ≈°irok√© znalosti o jazyce a svƒõtƒõ.</p>

<p>b) Instruction fine-tuning: Model se uƒç√≠ reagovat na konkr√©tn√≠ instrukce a ot√°zky, co≈æ mu pom√°h√° chovat se v√≠ce jako asistent.</p>

<p>c) Reinforcement Learning from Human Feedback (RLHF): Tato f√°ze d√°le vylep≈°uje model tak, aby jeho odpovƒõdi byly v√≠ce v souladu s lidsk√Ωmi preferencemi a hodnotami.</p>

<h3 id="3-emergentn√≠-schopnosti">3. Emergentn√≠ schopnosti</h3>

<p>S rostouc√≠ velikost√≠ modelu a mno≈æstv√≠m tr√©ninkov√Ωch dat se u LLM objevuj√≠ emergentn√≠ schopnosti - schopnosti, kter√© nebyly explicitnƒõ natr√©nov√°ny. Mezi tyto schopnosti pat≈ô√≠ nap≈ô√≠klad:</p>

<ul>
  <li>≈òe≈°en√≠ v√≠ce√∫rov≈àov√Ωch √∫loh</li>
  <li>Few-shot learning (schopnost uƒçit se z nƒõkolika p≈ô√≠klad≈Ø)</li>
  <li>≈òe≈°en√≠ matematick√Ωch probl√©m≈Ø</li>
  <li>Generov√°n√≠ k√≥du</li>
</ul>

<h3 id="4-techniky-pro-zlep≈°en√≠-v√Ωkonu">4. Techniky pro zlep≈°en√≠ v√Ωkonu</h3>

<p>Existuje nƒõkolik technik, kter√© mohou v√Ωraznƒõ zlep≈°it v√Ωkon LLM:</p>

<p>a) Chain-of-thought prompting: p≈ô√≠stup, kdy model ‚Äúmysl√≠ krok za krokem‚Äù, co≈æ m≈Ø≈æe zlep≈°it jeho schopnost ≈ôe≈°it komplexn√≠ √∫lohy. Tento p≈ô√≠stup vlastnƒõ rozkl√°d√° √∫lohu na jednodu≈°≈°√≠ √∫lohy, p≈ôiƒçem≈æ LLM (stejnƒõ jako ƒçlovƒõk) l√©pe zvl√°d√° v√≠ce z≈ôetƒõzen√Ωch jednodu≈°≈°√≠ch √∫loh, ne≈æ jednu slo≈æitou.  Model tak dost√°v√° ‚Äúpracovn√≠ pamƒõ≈•‚Äù v podobƒõ meziv√Ωsledk≈Ø, kter√© jsou souƒç√°st√≠ kontextu pro dal≈°√≠ generov√°n√≠.</p>

<p>b) Few-shot learning: Pokud je poskytnuto v promptu nƒõkolik p≈ô√≠klad≈Ø, m≈Ø≈æe to pomoci modelu l√©pe pochopit po≈æadovan√Ω form√°t nebo styl odpovƒõdi. Proto tak√© prompty obohacujeme ≈æ√°dostmi, v jak√©m form√°tu ƒçi stylu a odbornost√≠ po≈æadujeme v√Ωstupy, aby to LLM nemusel odhadovat.</p>

<p>c) Retrieval-Augmented Generation (RAG): Kombinace LLM s vyhled√°v√°n√≠m v extern√≠ datab√°zi znalost√≠ m≈Ø≈æe zlep≈°it p≈ôesnost a aktu√°lnost odpovƒõd√≠. Tato technika je zvl√°≈°tƒõ u≈æiteƒçn√° pro p≈ôekon√°n√≠ omezen√≠ spojen√Ωch s cut-off datem tr√©ninkov√Ωch dat.</p>

<h3 id="5-omezen√≠-a-v√Ωzvy">5. Omezen√≠ a v√Ωzvy</h3>

<p>I p≈ôes sv√© schopnosti maj√≠ LLM nƒõkolik v√Ωznamn√Ωch omezen√≠:</p>

<p>a) <a href="/ai/halucinace-ai/">Halucinace</a>: LLM mohou nƒõkdy generovat nepravdiv√© nebo zav√°dƒõj√≠c√≠ informace, zejm√©na kdy≈æ jsou dot√°z√°ny na nƒõco, co je mimo jejich tr√©ninkov√Ω dataset. To je ƒç√°steƒçnƒõ zp≈Øsobeno t√≠m, ≈æe model je tr√©nov√°n pouze na generov√°n√≠ pravdƒõpodobn√©ho textu, ne nutnƒõ fakticky spr√°vn√©ho textu. <a href="/ai/halucinace-ai/">Podrobnƒõji prob√≠r√°me zde</a>.</p>

<p>b) Kontextov√© okno: Omezen√° velikost kontextov√©ho okna limituje schopnost modelu pracovat s velmi dlouh√Ωmi dokumenty nebo udr≈æet kontext v dlouh√Ωch konverzac√≠ch.</p>

<p>c) Aktu√°lnost informac√≠: LLM jsou omezeny na informace, na kter√Ωch byly natr√©nov√°ny, a nemohou p≈ô√≠mo p≈ôistupovat k aktu√°ln√≠m informac√≠m (pokud nejsou kombinov√°ny s RAG).</p>

<p>d) Etick√© ot√°zky: Pou≈æit√≠ LLM vzn√°≈°√≠ ≈ôadu etick√Ωch ot√°zek, vƒçetnƒõ potenci√°ln√≠ch p≈ôedsudk≈Ø, vlivu na soukrom√≠ a autorsk√Ωch pr√°v.</p>

<h2 id="z√°vƒõr">Z√°vƒõr</h2>

<p>Fungov√°n√≠ LLM po zad√°n√≠ promptu je proces, kter√Ω kombinuje hlubok√© strojov√© porozumƒõn√≠ jazyku s pokroƒçil√Ωmi algoritmy <a href="/ai/strojove-uceni-machine-learning/">strojov√©ho uƒçen√≠</a>. Je podle mne velmi zaj√≠mav√©, jak je to na jednu stranu odli≈°n√© od lidsk√©ho postupu uva≈æov√°n√≠ (to je ta ƒç√°st tokenizace, tedy p≈ôevodu jazyka na ƒç√≠sla) a na stranu druhou je dal≈°√≠ postup u≈æ velmi podobn√Ω lidsk√©mu p≈ôem√Ω≈°len√≠ a uƒçen√≠.</p>

<p>Z√°rove≈à je d≈Øle≈æit√© si uvƒõdomit, ≈æe LLM st√°le maj√≠ sv√° omezen√≠, zejm√©na v oblasti <a href="/ai/halucinace-ai/">halucinac√≠</a>. Proto je kritick√© my≈°len√≠ a ovƒõ≈ôov√°n√≠ informac√≠ st√°le nezbytn√©.</p>

<p>S pokraƒçuj√≠c√≠m v√Ωzkumem a v√Ωvojem v oblasti AI m≈Ø≈æeme oƒçek√°vat dal≈°√≠ vylep≈°en√≠ tƒõchto syst√©m≈Ø. Budouc√≠ v√Ωvoj se pravdƒõpodobnƒõ zamƒõ≈ô√≠ na p≈ôekon√°v√°n√≠ souƒçasn√Ωch omezen√≠, jako je velikost kontextov√©ho okna, aktu√°lnost informac√≠ a probl√©m <a href="/ai/halucinace-ai/">halucinac√≠</a>. Z√°rove≈à m≈Ø≈æeme oƒçek√°vat pokrok v oblasti multimod√°ln√≠ch model≈Ø, kter√© budou schopny zpracov√°vat nejen text, ale i obr√°zky, zvuky a videa v jednotn√©m r√°mci.</p>

  </div>

  <div class="ai-rubric-link">
    
    <!-- P≈ôid√°n√≠ tabulky s n√°hodnƒõ vybran√Ωmi obrazy pouze pro ƒçl√°nky z kolekce Obrazy -->
    
  </div>

      <!-- M√≠sto pro widget -->
  <div class="posts">
    <h3>Jak se v√°m l√≠b√≠ tento ƒçl√°nek?</h3>

    <div id="feedback-widget"></div>

    <!-- Widget se vlo≈æ√≠ do #feedback-widget -->
    <script 
        src="https://top.marigold.cz/mg-feedback.js" 
        data-slug="ai-llm" 
        data-title="Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu" 
        data-url="https://www.marigold.cz/ai/llm/"
        data-target="#feedback-widget"
    ></script>
</div>

<!-- M√≠sto pro widget nejƒçtenƒõj≈°√≠ ƒçl√°nky -->
<script src="//widgets.clicky.com/poppy/?site_id=101451859&sitekey=5e093ea9431d06c7b572df6b51eda89f&width=500&height=500&date=last-28-days&type=pages&limit=10&title=Nej%C4%8Dten%C4%9Bj%C5%A1%C3%AD%20%C4%8Dl%C3%A1nky&hide_title=0&hide_branding=1" type="text/javascript"></script>
<!-- Konec widget nejƒçtenƒõj≈°√≠ ƒçl√°nky -->

  
  <div class="commentbox"></div>
  <script src="https://unpkg.com/commentbox.io/dist/commentBox.min.js"></script>
  <script>commentBox('5677112761516032-proj')</script>
  

  <!-- Tady zaƒç√≠n√° odkazov√°n√≠ na featured ƒçl√°nky -->
  
  
    
    <div class="featured-posts">
      <h3>üí° Co je tu dal≈°√≠ho zaj√≠mav√©ho ke ƒçten√≠?</h3>
      <table>
        <tbody>
          
            <tr>
              <td>
                <a href="/item/ma-nova-kniha-o-digitalni-novinarine/">üëâM√° nov√° kniha o digit√°ln√≠ novina≈ôinƒõ</a>
                <p class="excerpt">
                  
                    Vydal jsem novou knihu vƒõnovanou zaj√≠mav√©mu v√Ωseku internetu a to digit√°ln√≠ obƒçansk√© publicistice. Jmenuje se  Zlat√° √©ra weblog≈Ø a m≈Ø≈æete si ji st√°hnout zdar...
                  
                </p>
              </td>
            </tr>
          
            <tr>
              <td>
                <a href="/item/robinhood_wallstreet_pribeh_akcii/">üëâP≈ô√≠bƒõh WallStreetBets jako RobinaHooda, kter√Ω bohat√Ωm akcion√°≈ô≈Øm bral‚Ä¶</a>
                <p class="excerpt">
                  
                    Tenhle p≈ô√≠bƒõh se stane epickou s√°gou o mnoha rozmƒõrech. ≈Ωe nƒõkdo prost≈ôednictv√≠m mobiln√≠ aplikace zbohatne, to se st√°v√°. V√Ωjimeƒçnƒõ i v miliardov√Ωch ƒç√°stk√°ch....
                  
                </p>
              </td>
            </tr>
          
        </tbody>
      </table>
    </div>
    



  <div class="posts">
    <h3>Chcete tyto ƒçl√°nky emailem?</h3>
    <iframe src="https://zandl.substack.com/embed" width="480" height="150" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>
  </div>

  <div>
    <p><span class="share-box">Sd√≠lejte ƒçl√°nek:</span> <a href="http://twitter.com/share?text=Jak funguj√≠ velk√© jazykov√© modely LLM - co se dƒõje po zad√°n√≠ promptu&url=https://www.marigold.cz/ai/llm/" target="_blank">Twitter</a>, <a href="https://www.facebook.com/sharer.php?u=https://www.marigold.cz/ai/llm/" target="_blank">Facebook</a>, 

    
      <a href="https://github.com/tangero/marigold-page/blob/main/_ai/2024-07-04-llm.md" target="_blank">
        Opravit üìÉ
      </a>
    
</p>
    <p>
    <div class="PageNavigation">
      
      
      
        <a class="next" href="/ai/tokenizace-textu/">Tokenizace textu &raquo;</a>
      
    </div>
    </p>
  </div>
</article>

<!-- Toast notifikace -->
<div class="toast" id="toast">Zkop√≠rov√°no do schr√°nky!</div>

<!-- JavaScript pro funkcionalitu kop√≠rov√°n√≠ -->
<script>
document.addEventListener('DOMContentLoaded', function() {
    // Najdi v≈°echny code bloky (kromƒõ Mermaid)
    const codeBlocks = document.querySelectorAll('pre:not(:has(code.language-mermaid))');
    
    codeBlocks.forEach((codeBlock, index) => {
        // Vytvo≈ô kontejner pro code block
        const container = document.createElement('div');
        container.className = 'code-block-container';
        
        // Vytvo≈ô tlaƒç√≠tko kop√≠rovat
        const copyButton = document.createElement('button');
        copyButton.className = 'copy-button';
        copyButton.textContent = 'Kop√≠rovat';
        copyButton.setAttribute('data-index', index);
        
        // Vlo≈æ code block a tlaƒç√≠tko do kontejneru
        codeBlock.parentNode.insertBefore(container, codeBlock);
        container.appendChild(copyButton);
        container.appendChild(codeBlock);
        
        // P≈ôidej event listener na tlaƒç√≠tko
        copyButton.addEventListener('click', async () => {
            try {
                // Z√≠skej text z code bloku
                const code = codeBlock.querySelector('code') || codeBlock;
                const text = code.textContent;
                
                // Kop√≠ruj do schr√°nky
                await navigator.clipboard.writeText(text);
                
                // Zmƒõ≈à stav tlaƒç√≠tka
                copyButton.textContent = 'Zkop√≠rov√°no!';
                copyButton.classList.add('copied');
                
                // Zobraz toast notifikaci
                showToast();
                
                // Po 2 sekund√°ch vra≈• p≈Øvodn√≠ stav
                setTimeout(() => {
                    copyButton.textContent = 'Kop√≠rovat';
                    copyButton.classList.remove('copied');
                }, 2000);
                
            } catch (err) {
                console.error('Chyba p≈ôi kop√≠rov√°n√≠:', err);
                copyButton.textContent = 'Chyba';
                copyButton.classList.add('copied');
                
                setTimeout(() => {
                    copyButton.textContent = 'Kop√≠rovat';
                    copyButton.classList.remove('copied');
                }, 2000);
            }
        });
    });
});

function showToast() {
    const toast = document.getElementById('toast');
    toast.style.display = 'block';
    setTimeout(() => {
        toast.style.display = 'none';
    }, 2000);
}
</script>
        </div>
      </div>

      <div class="wrapper-footer">
        <div class="container">
          <footer class="footer">
            
<a href="mailto:patrick.zandl@marigold.cz"><i class="svg-icon email"></i></a>
<a href="https://www.facebook.com/patrick.zandl"><i class="svg-icon facebook"></i></a>



<a href="https://www.linkedin.com/in/patrickzandl"><i class="svg-icon linkedin"></i></a>

<a href="/feed.xml"><i class="svg-icon rss"></i></a>
<a href="https://www.twitter.com/tangero"><i class="svg-icon twitter"></i></a>





          </footer>
        </div>
      </div>
    </div>

    <a title="GDPR-compliant Web Analytics" href="https://clicky.com/101451859"><img alt="Clicky" src="//static.getclicky.com/media/links/badge.gif" border="0" /></a>
<script async data-id="101451859" src="//static.getclicky.com/js"></script>
<noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/101451859ns.gif" /></p></noscript>
 | <a href="https://github.com/tangero/marigold-page"><img src="https://img.shields.io/github/last-commit/tangero/marigold-page"></a> | <a href="https://www.kronium.eu">flashlights, headlamps Fenix & outdoor</a> | <a href="https://www.vybavenidoprirody.com/">Vybaven√≠ do p≈ô√≠rody</a>
<!-- 100% privacy-first analytics -->
<script async src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<!-- Twitter conversion tracking base code -->
<script>
    !function(e,t,n,s,u,a){e.twq||(s=e.twq=function(){s.exe?s.exe.apply(s,arguments):s.queue.push(arguments);
    },s.version='1.1',s.queue=[],u=t.createElement(n),u.async=!0,u.src='https://static.ads-twitter.com/uwt.js',
    a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(u,a))}(window,document,'script');
    twq('config','pycs2');
</script>
    <!-- End Twitter conversion tracking base code -->


    <script>
    function toggleDetails(button) {
      const content = button.nextElementSibling;
      const isCollapsed = button.classList.contains('collapsed');
      
      if (isCollapsed) {
        button.classList.remove('collapsed');
        content.classList.add('show');
      } else {
        button.classList.add('collapsed');
        content.classList.remove('show');
      }
    }
    </script>
  </body>
</html>
